<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="CS224N-NLP Assignment individual solutionAssignment 1:Q1:Softmax:1.  Prove:$softmax(x)&#x3D;softmax(x+c)$,x is a vector and c is a constantbegin:Let $x&#x3D;(x_1,x_2,…,x_n)$and then we know that $softmax(x)&#x3D;(\f">
<meta property="og:type" content="article">
<meta property="og:title" content="CS224N-NLP Assignment individual solution">
<meta property="og:url" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/index.html">
<meta property="og:site_name" content="SakuyuiのBLOG">
<meta property="og:description" content="CS224N-NLP Assignment individual solutionAssignment 1:Q1:Softmax:1.  Prove:$softmax(x)&#x3D;softmax(x+c)$,x is a vector and c is a constantbegin:Let $x&#x3D;(x_1,x_2,…,x_n)$and then we know that $softmax(x)&#x3D;(\f">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553782661974.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553856612131.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553855679457.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553946699826.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553957081013.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553957203608.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553957378451.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553957404306.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554043286463.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554043272986.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553958439129.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554003540795.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554003569566.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554004432769.png">
<meta property="og:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1554040774886.png">
<meta property="article:published_time" content="2019-12-26T12:52:41.770Z">
<meta property="article:modified_time" content="2019-12-26T12:19:56.000Z">
<meta property="article:author" content="Sakuyui39">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/1553782661974.png">

<link rel="canonical" href="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>CS224N-NLP Assignment individual solution | SakuyuiのBLOG</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SakuyuiのBLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/Sakuyui" class="github-corner" title="My github" aria-label="My github" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/tx.jpg">
      <meta itemprop="name" content="Sakuyui39">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SakuyuiのBLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS224N-NLP Assignment individual solution
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-12-26 20:52:41 / Modified: 20:19:56" itemprop="dateCreated datePublished" datetime="2019-12-26T20:52:41+08:00">2019-12-26</time>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>10k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>9 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="CS224N-NLP-Assignment-individual-solution"><a href="#CS224N-NLP-Assignment-individual-solution" class="headerlink" title="CS224N-NLP Assignment individual solution"></a>CS224N-NLP Assignment individual solution</h1><h2 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1:"></a>Assignment 1:</h2><p><strong>Q1:Softmax:</strong><br>1.<img src="./1553782661974.png" alt="Alt text"></p>
<blockquote>
<p><strong>Prove:$softmax(x)=softmax(x+c)$,x is a vector and c is a constant</strong><br>begin:<br>Let $x=(x_1,x_2,…,x_n)$<br>and then we know that $softmax(x)=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})$<br>and  $softmax(x+c)=(\frac{e^{x_1+c}}{\sum_j e^{x_j+c}},\frac{e^{x_2+c}}{\sum_j e^{x_j}},…,\frac{e^{x_n+c}}{\sum_j e^{x_j+c}})=\\=(\frac{e^{x_1}e^c}{e^c\sum_j e^{x_j}},\frac{e^{x_2}e^c}{e^c\sum_j e^{x_j}},…,\frac{e^{x_n}e^c}{e^c\sum_j e^{x_j}})=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})=softmax(x)$<br>Then this question is solved</p>
</blockquote>
<p>2.softmax</p>
<pre><code class="lang-python">import numpy as np

def softmax_inrow(m):
   # print(m)
    rm=np.max(m,axis=1)
    rm_r=rm.reshape(rm.shape[0],1)
    #print(rm_r)
    m1=m-rm_r
    e1=np.exp(m1)
    sum=np.sum(e1,axis=1)
    sum=sum.reshape(sum.shape[0],1)
    e1=e1/sum
    #print(e1)
    return e1

def softmax_incoloum(m):
    # print(m)
    rm = np.max(m, axis=0)
    #rm_r = rm.reshape(rm.shape[0], 1)
    #print(rm)
    m1 = m - rm
    #print(m1)
    e1 = np.exp(m1)
    sum = np.sum(e1, axis=0)
    #sum = sum.reshape(sum.shape[0], 1)
    e1 = e1 / sum
    # print(e1)
    return e1

N=input()
D=input()
matrix=np.random.rand(int(N),int(D))
print(softmax_incoloum(matrix))
#print(softmax2(matrix))
</code></pre>
<p><strong>Q2:</strong><br><strong>2.1:</strong>对sigma求导，并利用sigma函数来表示其导数</p>
<blockquote>
<p>As $\sigma(x)=\frac{1}{1+e^{-x}}$<br>$\sigma’(x)=\frac{e^{-x}}{(1+e^{-x})^2}\\e^{-x}=\frac{1}{\sigma(x)}-1$<br>So,$\sigma’(x)=\sigma(x)(1-\sigma(x))$</p>
</blockquote>
<p><strong>2.2:求softmax作用于$\theta$下,ont-hot和softmax$\theta$交叉熵的梯度</strong></p>
<blockquote>
<p>solution:<br>We know that $CE(y,\hat y)=-\sum_iy_ilog(\hat y_i)$<br>and let $y=(s_1,s_2,…,s_n)$<br>$\theta=(d_1,d_2,…,d_n)$<br>and then $\frac{\partial CE}{\partial d_i}=\frac{\partial CE}{\partial s_k}\frac{\partial s_k}{\partial d_i}$<br>First we consider $\frac{\partial CE}{\partial s_k}$<br>$\frac{\partial CE}{\partial s_k}=\frac{\partial (-\sum_k y_klog(s_k))}{\partial s_k}=-\sum_k y_k\frac{1}{s_k}$<br>and then we consider $\frac{\partial s_k}{\partial d_i}$<br>there are two situations need to consider:<br>when $k=i$<br>$\frac{\partial s_k}{\partial d_i}=\frac{\partial (  \frac{e^z_j}{\sum_ke^z_k}   )}{\partial s_k}=\frac{\partial s_i}{\partial d_i}=s_i-s_i^2$<br>when $k!=i$<br>$\frac{\partial s_k}{\partial d_i}=\frac{\partial (  \frac{e^z_j}{\sum_ke^z_k}   )}{\partial s_k}=-s_is_j$<br>so $\frac{\partial CE}{\partial d_i}=\frac{\partial CE}{\partial s_k}\frac{\partial s_k}{\partial d_i}=-\frac{y_i}{s_i}s_i(1-s_i)+\sum_{i!=j}y_jy_s=s_i-y_i=s_i-1$<br>i.e. <img src="./1553856612131.png" alt="Alt text"></p>
<p>It’s say that the $softmax(\theta)$ minus 1 in element i(i is the label of right prediction),then we get the gradient</p>
</blockquote>
<p><strong>2.3</strong><br><img src="./1553855679457.png" alt="Alt text"><br>loss function使用上述的交叉熵$CE(y,\hat y)$<br>h-&gt;y^激活函数为softmax<br>x-&gt;h激活函数为sigma<br>求梯度<br>$\hat y=softmax(W_2h+b_2)$<br>$h=\sigma(W_1x+b_1)$</p>
<blockquote>
<p>solution:<br>similar to 2.2<br>i is the position index right prediction<br>$\frac{\partial CE}{\partial x_i}=\frac{\partial CE}{\partial \hat y_k}\frac{\partial \hat y_k}{\partial h_j}\frac{\partial h_j}{\partial x_i}$<br>similar to 2.2, $\frac{\partial CE}{\partial x_i}=W_2(\hat y_i-y_i)\frac{\partial h_j}{\partial x_i}$<br>consider $\frac{\partial h_j}{\partial x_i}$<br>if j=1,then $\frac{\partial h_j}{\partial x_i}=W_1\sigma’(W_1x+b)$,else $\frac{\partial h_j}{\partial x_i}=0$<br>so  $\frac{\partial CE}{\partial x_i}=W_2(\hat y_i-y_i)-\sigma’(W_1x+b_1)_iW_1$</p>
</blockquote>
<p><strong>2.4</strong>(在2.3之前先做这题，把维度搞清楚)<br><strong>assuming the input is D x -dimensional, the output is D y -dimensional, and there are H hidden units</strong></p>
<blockquote>
<p>x’s shape is $(M,D_x)$ and $W_1$’s shape is $(D_x,H)$,and $W_2$’s shape is $(H,D_y)$,$b_1$’s shape ‘(1,H)$b_2$’s shape (1,Dy) ‘<br>so there are $H(D_x+1)+D_y(H+1)$ parameters we need to train’</p>
</blockquote>
<p><strong>2.5</strong></p>
<pre><code class="lang-python">import numpy as np

def sigmoid(m):
    t=1.0/(1+np.exp(-m))
    return t

def sigmoid_gradient(x):
    return sigmoid(x)*(1.0-sigmoid(x))
</code></pre>
<p><strong>2.6</strong></p>
<pre><code class="lang-python">import numpy as np
import random
def gradcheck_naive(f, x):
    &quot;&quot;&quot; Gradient check for a function f.
        Arguments:
        f -- a function that takes a single argument and outputs the
             cost and its gradients
        x -- the point (numpy array) to check the gradient at
    &quot;&quot;&quot;

    rndstate = random.getstate()
    random.setstate(rndstate)
    fx, grad = f(x)  # Evaluate function value at original point,获取函数值和梯度
    h = 1e-4  # Do not change this!

    it = np.nditer(x, flags=[&#39;multi_index&#39;], op_flags=[&#39;readwrite&#39;])  #一个迭代器，flags=[&#39;multi_index&#39;]表示对a进行多重索引，op_flags=[&#39;readwrite&#39;]表示不仅可以对x进行read（读取），还可以write（写入）
    while not it.finished:  #开始迭代
        ix = it.multi_index   #获取迭代到的索引，是(a,b)

        # Try modifying x[ix] with h defined above to compute
        # numerical gradients. Make sure you call random.setstate(rndstate)
        # before calling f(x) each time. This will make it possible
        # to test cost functions with built in randomness later.

        ### YOUR CODE HERE:
        x[ix] += h

        random.setstate(rndstate)
        new_f1 = f(x)[0]

        x[ix] -= 2 * h

        random.setstate(rndstate)
        new_f2 = f(x)[0]

        x[ix] += h

        numgrad = (new_f1 - new_f2) / (2 * h)
        ### END YOUR CODE


#比较梯度
        # Compare gradients
        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))
        if reldiff &gt; 1e-5:
            print
            &quot;Gradient check failed.&quot;
            print
            &quot;First gradient error found at index %s&quot; % str(ix)
            print
            &quot;Your gradient: %f \t Numerical gradient: %f&quot; % (
                grad[ix], numgrad)
            return

        it.iternext()  # Step to next dimension

    print(&quot;Gradient check passed!&quot;)
</code></pre>
<p><strong>反向传播梯度计算</strong><br><img src="./1553946699826.png" alt="Alt text"></p>
<p><strong>反向传播梯度计算</strong></p>
<pre><code class="lang-python">
反向传播:
def forward_back_prop(data, labels, params, dimensions):
    &quot;&quot;&quot;
           2个隐层的神经网络的前向运算和反向传播
    &quot;&quot;&quot;
    if len(data.shape) &gt;= 2:
        (N, _) = data.shape

    ### 展开每一层神经网络的参数
    ofs = 0
    Dx, H, Dy = (dimensions[0], dimensions[1], dimensions[2])  #获取3个超参数

#获取所有参数
    W1 = np.reshape(params[ofs:ofs + Dx * H], (Dx, H)) #取出w1,大小Dx * H
    ofs += Dx * H #偏移增加
    b1 = np.reshape(params[ofs:ofs + H], (1, H))
    ofs += H
    W2 = np.reshape(params[ofs:ofs + H * Dy], (H, Dy))
    ofs += H * Dy
    b2 = np.reshape(params[ofs:ofs + Dy], (1, Dy))



    ### 前向传播
    h = sigmoid(np.dot(data,W1) + b1)
    yhat = softmax_inrow(np.dot(h,W2) + b2)
    ### END

    ### 反向传播
    cost = np.sum(-np.log(yhat[labels == 1])) / data.shape[0]  #-ylog(hat_y) (仅取q的项)，然后求平均

    d3 = (yhat - labels) / data.shape[0]
    gradW2 = np.dot(h.T, d3)   #根据公式来，计算gradW2
    gradb2 = np.sum(d3, 0, keepdims=True)


    dh = np.dot(d3, W2.T)
    grad_h = sigmoid_gradient(h) * dh

    gradW1 = np.dot(data.T, grad_h)
    gradb1 = np.sum(grad_h, 0)
    ### END

    ### Stack gradients (do not modify)
    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(),
                           gradW2.flatten(), gradb2.flatten()))
    return cost,grad
</code></pre>
<h3 id="3-word2vec"><a href="#3-word2vec" class="headerlink" title="3.word2vec"></a>3.word2vec</h3><p><img src="./1553957081013.png" alt="Alt text"><br>因为<img src="./1553957203608.png" alt="Alt text"><br>$dsoftmax/dx_o(softmax关于输入向量的梯度)=\hat y-y$<br>链式法则。图中$\hat y=softmax(U^Tv_c)$<br>所以<img src="./1553957378451.png" alt="Alt text"><br>分类讨论。就得<img src="./1553957404306.png" alt="Alt text"></p>
<p><img src="./1554043286463.png" alt="Alt text"></p>
<p><img src="./1554043272986.png" alt="Alt text"></p>
<p>(b)类似a<br><img src="./1553958439129.png" alt="Alt text"></p>
<p>一样。求导就行<br><img src="./1554003540795.png" alt="Alt text"><br><img src="./1554003569566.png" alt="Alt text"><br><img src="./1554004432769.png" alt="Alt text"></p>
<p><img src="./1554040774886.png" alt="Alt text"></p>
<pre><code class="lang-python">import numpy as np
import random

from q1_softmax import softmax_inrow
from q2_gradcheck import gradcheck_naive
from q2_sigmoid import sigmoid, sigmoid_gradient

#normalize:x每个元素都除以各行平方和的平方根。
def normalizeRows(x):
    &quot;&quot;&quot; Row normalization function
    Implement a function that normalizes each row of a matrix to have
    unit length.
    &quot;&quot;&quot;

    ### YOUR CODE HERE
    temp_x=x
    temp_x=np.square(x)

    norm=np.sum(temp_x,axis=1)

    norm=np.sqrt(norm)
    #print(x)
   #print(norm)
    print((x/norm))
    ### END YOUR CODE
    return (x/norm)

#target是目标的位置
def softmaxCostAndGradient(predicted, target, outputVectors, dataset):
    &quot;&quot;&quot; Softmax cost function for word2vec models
        Implement the cost and gradients for one predicted word vector
        and one target word vector as a building block for word2vec
        models, assuming the softmax prediction function and cross
        entropy loss.
        Arguments:
        predicted -- numpy ndarray, predicted word vector (\hat{v} in
                     the written component)
        target -- integer, the index of the target word
        outputVectors -- &quot;output&quot; vectors (as rows) for all tokens
        dataset -- needed for negative sampling, unused here.
        Return:
        cost -- cross entropy cost for the softmax word prediction
        gradPred -- the gradient with respect to the predicted word
               vector  对已预测词向量的梯度
        grad -- the gradient with respect to all the other word
               vectors  对其他所有词向量的梯度
        We will not provide starter code for this function, but feel
        free to reference the code you previously wrote for this
        assignment!
        &quot;&quot;&quot;
    #target是目标位置
    ### YOUR CODE HERE



    # 计算预测结果
    v_hat = predicted  #已经预测的词向量（中心词向量）
    z = np.dot(outputVectors, v_hat)   #预测得分。也就是输出词向量和中心词向量点乘(可以得到结果得分)
    preds = softmax_inrow(z)     #对预测得分softmax

    cost = -np.log(preds[target])  #计算损失

    # 计算梯度
    z = preds.copy()    #预测得分  (其实就是hat_y)
    z[target] -= 1.0    #梯度为 hat^y-y
    #z相当于^y
    grad = np.outer(z, v_hat) #外积 # dJ/dU  hat_y*u_w  v_hat其实就是v_c 计算输出词向量矩阵的梯度
    # np.outer函数:
    # ①对于多维向量，全部展开变为一维向量
    # ②第一个参数表示倍数，使得第二个向量每次变为几倍
    # ③第一个参数确定结果的行，第二个参数确定结果的列

    gradPred = np.dot(outputVectors.T, z) #dJ/dv_c
    ### END YOUR CODE


    return cost, gradPred, grad

def getNegativeSamples(target, dataset, K):
    &quot;&quot;&quot; Samples K indexes which are not the target &quot;&quot;&quot;

    indices = [None] * K
    for k in range(K):
        newidx = dataset.sampleTokenIdx()
        while newidx == target:
            newidx = dataset.sampleTokenIdx()
        indices[k] = newidx
    return indices
def negSamplingCostAndGradient(predicted, target, outputVectors, dataset,
                               K=10):
    &quot;&quot;&quot; Negative sampling cost function for word2vec models

    Implement the cost and gradients for one predicted word vector
    and one target word vector as a building block for word2vec
    models, using the negative sampling technique. K is the sample
    size.

    Note: See test_word2vec below for dataset&#39;s initialization.

    Arguments/Return Specifications: same as softmaxCostAndGradient
    &quot;&quot;&quot;
    # Sampling of indices is done for you. Do not modify this if you
    # wish to match the autograder and receive points!
    #为每个窗口取k个负样本
    indices = [target]
    indices.extend(getNegativeSamples(target, dataset, K))

#初始化
    grad = np.zeros(outputVectors.shape)
    gradPred = np.zeros(predicted.shape)
    cost = 0

    z = sigmoid(np.dot(outputVectors[target],predicted))

    cost -= np.log(z)
    grad[target] += predicted*(z-1.0)
    gradPred = outputVectors[target] * (z-1.0)

    #最小化这些词随中心词出现在中心词附近的概率
    for k in range(K):
        sample = indices[k+1]
        z = sigmoid(np.dot(outputVectors[sample],predicted))
        cost -= np.log(1.0-z)
        grad[sample] += predicted*z
        gradPred += outputVectors[sample] * z
    return cost, gradPred, grad


def skipgram(currentWord, C, contextWords, tokens, inputVectors, outputVectors,
             dataset, word2vecCostAndGradient=softmaxCostAndGradient):
    &quot;&quot;&quot; Skip-gram model in word2vec

    Implement the skip-gram model in this function.

    Arguments:
    currentWord -- a string of the current center word
    C -- integer, context size
    contextWords -- list of no more than 2*C strings, the context words
    tokens -- a dictionary that maps words to their indices in
              the word vector list
    inputVectors -- &quot;input&quot; word vectors (as rows) for all tokens
    outputVectors -- &quot;output&quot; word vectors (as rows) for all tokens
    word2vecCostAndGradient -- the cost and gradient function for
                               a prediction vector given the target
                               word vectors, could be one of the two
                               cost functions you implemented above.

    Return:
    cost -- the cost function value for the skip-gram model
    grad -- the gradient with respect to the word vectors
    &quot;&quot;&quot;
    cost = 0.0
    gradIn = np.zeros(inputVectors.shape)
    gradOut = np.zeros(outputVectors.shape)

    cword_idx = tokens[currentWord]

    v_hat = inputVectors[cword_idx]
    #skipgram即根据当前词预测一定范围内的上下文词汇，选择让概率分部值最大的向量
    for i in contextWords:#对于窗口中的每个单词
        idx = tokens[i] #target的下标(要预测的单词的下标)
        c_cost,c_grad_in,c_grad_out = word2vecCostAndGradient(v_hat,idx,outputVectors,dataset)
        #更新cost、grad 即使用k个单词来训练这个向量
        cost += c_cost
        gradOut += c_grad_out
        gradIn[cword_idx] += c_grad_in
    return cost, gradIn, gradOut
</code></pre>

    </div>

    
    
    
<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------End of this passage-------------</div>
    
</div>
  
</div>
      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/12/26/CS224n%20Assignment1/" rel="prev" title="CS224n Assignment1">
      <i class="fa fa-chevron-left"></i> CS224n Assignment1
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/12/26/Database/" rel="next" title="Database">
      Database <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CS224N-NLP-Assignment-individual-solution"><span class="nav-number">1.</span> <span class="nav-text">CS224N-NLP Assignment individual solution</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Assignment-1"><span class="nav-number">1.1.</span> <span class="nav-text">Assignment 1:</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-word2vec"><span class="nav-number">1.1.1.</span> <span class="nav-text">3.word2vec</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sakuyui39"
      src="/images/tx.jpg">
  <p class="site-author-name" itemprop="name">Sakuyui39</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Sakuyui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sakuyui" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:microyui39@yahoo.co.jp" title="E-Mail → mailto:microyui39@yahoo.co.jp" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/bkyh/" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;bkyh&#x2F;" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/microice17" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;microice17" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/sakuyui39/" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;sakuyui39&#x2F;" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sakuyui39</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="Symbols count total">281k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">4:16</span>
</div>
  <div class="theme-info">Theme – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.6.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='240' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>

<!-- ҳ����С���� -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>