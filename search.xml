<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【Web】 Java考点对策</title>
    <url>/2019/12/28/j2ee%E8%80%83%E7%82%B9%E5%AF%B9%E7%AD%96/</url>
    <content><![CDATA[<h2 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h2><h3 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h3><p>一个http请求代表客户端浏览器向服务器发送的数据。一个完整的http请求消息，包含一个<strong>请求行</strong>，<strong>若干个消息头（请求头）</strong>，<strong>换行</strong>，<strong>实体内容</strong><br><img src="./1577520192233.png" alt="Alt text"></p>
<p>请求头（消息头）包含（客户机请求的服务器主机名，客户机的环境信息等）：</p>
<ul>
<li><strong>User-Agent：</strong>客户机通过这个头告诉服务器，客户机的软件环境（操作系统，浏览器版本等）</li>
<li><strong>Connection：</strong>告诉服务器，请求完成后，是否保持连接</li>
<li><strong>If-Modified-Since：</strong>客户机通过这个头告诉服务器，资源的缓存时间</li>
<li><strong>Accept</strong>: 告诉服务器可以接收的文件类型</li>
<li><strong>Accept-Charset：</strong>用于告诉服务器，客户机采用的编码格式</li>
<li><strong>Accept-Encoding：</strong>用于告诉服务器，客户机支持的数据压缩格式</li>
<li><strong>Accept-Language：</strong>客户机语言环境</li>
<li><strong>Host:</strong> 客户机通过这个服务器，想访问的主机名</li>
<li><strong>Referer：</strong>客户机通过这个头告诉服务器，它（客户端）是从哪个资源来访问服务器的（防盗链）</li>
</ul>
<p>实体内容：<br>就是指浏览器端通过http协议发送给服务器的实体数据。例如：name=dylan&amp;id=110<br><img src="./1577526986514.png" alt="Alt text"><br>cookies间用:</p>
<h3 id="回应"><a href="#回应" class="headerlink" title="回应"></a>回应</h3><p>一个http响应代表服务器端向客户端回送的数据，它包括：<br>一个<strong>状态行</strong>，<strong>若干个消息头</strong>，以及<strong>实体内容</strong><br><img src="./1577524740633.png" alt="Alt text"></p>
<p>响应头(消息头)包含:<br><strong>Allow:</strong>允许哪些请求方法，post get等    </p>
<ul>
<li><strong>Location：</strong>这个头配合302状态吗，用于告诉客户端找谁</li>
<li><strong>Server：</strong>服务器通过这个头，告诉浏览器服务器的类型</li>
<li><strong>Content-Encoding：</strong>告诉浏览器，服务器的数据压缩格式 <strong>gzip,deflate, sdch….</strong></li>
<li>Content-Length：告诉浏览器，回送数据的长度</li>
<li><strong>Content-Type：</strong>告诉浏览器，回送数据的类型</li>
<li><strong>Last-Modified：</strong>告诉浏览器当前资源缓存时间，只有改动时间迟于该时间的才会返回。否则<strong>304</strong>  一般与与If-Modified-Since一起用</li>
<li><strong>Refresh：</strong>告诉浏览器，隔多长时间刷新</li>
<li>Content-Disposition：告诉浏览器以下载的方式打开数据。例如： context.Response.AddHeader(“Content-+ Disposition”,”attachment:filename=aa.jpg”);                                        context.Response.WriteFile(“aa.jpg”);<br>Transfer-Encoding：告诉浏览器，传送数据的编码格式</li>
<li><strong>ETag：</strong>缓存相关的头,类似一个资源hash函数的存在。可以发现资源是否有变化</li>
<li><strong>Expries：</strong> 过期时间，绝对= <strong>max-age+请求时间</strong> </li>
<li><p><strong>Cache-Control：</strong>控制浏览器缓存 如</p>
<pre><code>      Cache-Control: public, max-age:350000
</code></pre></li>
<li><p><strong>max-age</strong>:是HTTP/1.1中的 过期时间。是个相对的值(<strong>相对于请求时间</strong>)</p>
</li>
<li><strong>Connection：</strong>响应完成后，是否断开连接。  close/Keep-Alive</li>
<li><strong>Content-Disposition</strong><br>Date：告诉浏览器，服务器响应时间</li>
</ul>
<p>》通过AddHeader函数可以为HTTP消息头加入我们自定义的内容。使用这种方法可以强制让浏览器提示下载文件，即使这个文件是我们已知的类型，基于是HTML网页。如果想要让用户下载时提示一个默认的文件名，只需要在前面一句话后加上“filename=文件名”即可。例如：</p>
<pre><code>Response.AddHeader(&quot;Content-Disposition: attachment; filename=mypage.htm&quot;);
</code></pre><h3 id="Http缓存"><a href="#Http缓存" class="headerlink" title="!!Http缓存"></a>!!Http缓存</h3><p>http缓存有<strong>强缓存</strong>,<strong>协商缓存</strong><br>步骤1. 浏览器先根据这个资源的http头信息来判断是否命中强缓存。如果命中则直接加在缓存中的资源，并不会将请求发送到服务器。<strong>(返回200)</strong><br>2.如果未命中强缓存，则浏览器会将资源加载<em>请求发送到服务器<strong>。服务器来</strong>判断浏览器本地缓存是否失效*</em>。若可以使用，则服务器并不会返回资源信息，浏览器继续从缓存加载资源。<br>3.如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存。</p>
<p>在页面设置 如</p>
<pre><code>&lt;meta http-equiv=&quot;Cache-Control&quot; content=&quot;no-cache&quot;/&gt;
</code></pre><h4 id="强缓存"><a href="#强缓存" class="headerlink" title="强缓存"></a>强缓存</h4><p> 利用http的<strong>回应</strong>头中的<strong>Expires</strong>或者<strong>Cache-Control</strong>两个字段来控制的。</p>
<p><strong>Cache-Control</strong>: </p>
<pre><code> Cache-Control: max-age=30  也可以填 no-cache(每次用缓存前都会发请求), no-store 不缓存 public private(不允许任何web代理进行缓存，)
 Expires: Wed, 21 Oct 2015 07:28:00 GMT
</code></pre><p>同时启用的时候Cache-Control优先级高</p>
<h4 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h4><p>服务器根据http头信息中的<strong>Last-Modify/If-Modify-Since</strong>或<strong>Etag/If-None-Match</strong>来判断是否命中协商缓存。如果命中，则http返回码为<strong>304</strong>，浏览器从缓存中加载资源。<br><img src="./1577528193902.png" alt="Alt text"></p>
<h4 id="http状态码："><a href="#http状态码：" class="headerlink" title="http状态码："></a>http状态码：</h4><p>2xx OK<br>—&gt;200 OK<br>—&gt;201 创建<br>—&gt;202 接收<br>—&gt;203 和200一样，不过是说未经认证。。可能是复制得到的</p>
<p>3xx 重定向<br>—&gt;301 代表永久性转移(Permanently Moved) 302是暂时<br>—&gt;302 Object Moved <img src="./1577526473068.png" alt="Alt text"> 要根据Location重新发请求<br>—&gt; 303 当请求者应对不同的位置进行单独的 GET 请求以检索响应时，服务器会返回此代码`<br>—&gt;304 未修改</p>
<p>4xx 客户端错误<br>—&gt;400 请求语法错误<br>—&gt;401 (访问拒绝)客户端证书无效,账号密码错误<br>—&gt;403 Access Forbidden 请求结构正确。但是服务器不想处理.403暗示了所请求的资源确实存在。跟401一样，若服务器不想透露此信息，它可以谎报一个404<br>—&gt;404 资源不存在<br>—&gt;405 请求方法错误。比如用了不支持的协议，或者不支持get,结果用了get<br>—&gt;410 资源曾经存在</p>
<p>5xx:服务器端错误<br>502 代理错误<br>500 异常<br>501 服务器不能识别一个方法。类似405,但是405是能够被服务器识别，但是资源不支持该方法.<br>503 目前服务器处理不了，一段时间后可能正常<br><strong>101表示服务器已经理解了客户端的请求，并将通过Upgrade消息头通知客户端采用不同的协议来完成这个请求。</strong></p>
<h4 id="COOKIES"><a href="#COOKIES" class="headerlink" title="COOKIES"></a>COOKIES</h4><pre><code>Set-Cookie: key=haha; expires=Sun, 31-Dec-2006 16:00:00 GMT; path=/
Set-Cookie: ASPSESSIONIDCSQCRTBS=KOIPGIMBCOCBFMOBENDCAKDP; path=/ (会话)
</code></pre><h4 id="媒体类型"><a href="#媒体类型" class="headerlink" title="媒体类型"></a>媒体类型</h4><p><img src="./1577528293581.png" alt="Alt text"><br><strong>text/xml忽略xml头所指定编码格式而默认采用us-ascii编码，而application/xml会根据xml头指定的编码格式来编码：</strong></p>
<h4 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h4><p>三部分: schema协议 主机地址 资源路径</p>
<h3 id="post和get的区别："><a href="#post和get的区别：" class="headerlink" title="post和get的区别："></a>post和get的区别：</h3><p>都包含请求头请求行，post多了请求body。<br>get多用来查询，请求参数放在url中，不会对服务器上的内容产生作用。post用来提交，如把账号密码放入body中。<br>GET是直接添加到URL后面的，直接就可以在URL中看到内容，而POST是放在报文内部的，用户无法直接看到。<br>GET提交的数据长度是有限制的，因为URL长度有限制，具体的长度限制视浏览器而定。而POST没有。<br><strong>超限返回414</strong><br><strong>GET能被缓存，POST不能</strong><br>GET只允许ASCII字符，POST没有限制</p>
<h4 id="Head"><a href="#Head" class="headerlink" title="Head"></a>Head</h4><p>当客户端仅希望看到响应的头部时，例如Content-Type或Content-Length，它发送一个<strong>HEAD请求</strong>。HTTP HEAD方法对响应中的输出字节进行计数，以便准确地设置Content-Length报头。</p>
<h4 id="Put"><a href="#Put" class="headerlink" title="Put"></a>Put</h4><p> 把消息本体中的消息发送到一个URL,跟POST类似，但不常用。<br>向指定资源位置上传其最新内容。一般是用来数据更新</p>
<h4 id="TRACE"><a href="#TRACE" class="headerlink" title="TRACE"></a>TRACE</h4><p>回显请求。一般用来测试</p>
<h3 id="HTTP特点"><a href="#HTTP特点" class="headerlink" title="HTTP特点"></a>HTTP特点</h3><ul>
<li><strong>无连接</strong><br>每次连接只处理一个请求,处理完请求并受到客户端应答后即断开连接<br>1.1版本后可以用<strong>Connnection: KeepAlive</strong> 长连接，一段时间后才会断开 （1.0默认关闭，1.1默认打开）<br>如何判断请求已完成:<br>  <strong>Content-Length</strong>,<strong>Transfer-Encoding:chunked 或者gzip,chunked</strong>,当收到大小为0的chunked时代表接收完成</li>
</ul>
<ul>
<li><strong>无状态</strong><br><strong>对事物处理没有记忆能力</strong>，因此出现了一些方式进行会话追踪<br><strong>4种会话追踪技术：</strong></li>
<li><ul>
<li><strong>cookies</strong></li>
</ul>
</li>
<li><ul>
<li><p><strong>隐藏域</strong>。把数据存储在一个隐藏域里</p>
<pre><code>       &lt;input type=&#39;hidden&#39; value=&#39;xxx&#39;/&gt;
</code></pre></li>
</ul>
</li>
<li><ul>
<li><strong>session</strong>(本质也是用cookies实现的)</li>
</ul>
</li>
<li><ul>
<li><strong>url重写</strong>: 在url尾部添加额外一些数据，标识当前会话</li>
</ul>
</li>
<li><p><strong>支持C/S模式</strong></p>
</li>
</ul>
<h4 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h4><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><h4 id="SimpleTag接口"><a href="#SimpleTag接口" class="headerlink" title="SimpleTag接口"></a>SimpleTag接口</h4><p>继承了JspTag</p>
<ul>
<li><strong>setJspContext方法</strong><br>　　用于把JSP页面的pageContext对象传递给标签处理器对象<br>setParent方法<br>　　用于把父标签处理器对象传递给当前标签处理器对象<br>getParent方法<br>　　用于获得当前标签的父标签处理器对象<br>doTag方法<br>　　用于完成所有的标签逻辑</li>
</ul>
<h4 id="Tag接口"><a href="#Tag接口" class="headerlink" title="Tag接口"></a>Tag接口</h4><ul>
<li><strong>doEndTag()</strong></li>
<li><strong>doStartTag()</strong></li>
<li>setPageContext(PageContext pc)</li>
<li>setParent(Tag t)</li>
</ul>
<h4 id="TagSupport"><a href="#TagSupport" class="headerlink" title="TagSupport"></a>TagSupport</h4><pre><code>public class TimeTag extends TagSupport{
public int doStartTag() throws JspException{ //现在可以就用doTag()  simpleTagSupport  //不能抛IOException
        JspWriter out=pageContext.getOut();
        //try{
            out.println(xxxx);
        //}catch(...){}
    }
}

//TagHandler
public class ResetTag extends TagSupport{
    public void getColor(){
    }
    public void setColor(){
    }

    public int doEndTag() throws JspException{
        NumberGuessBean numberguessbean=(..)pageContext.get
    }
}
</code></pre><p>配置文件tld</p>
<pre><code>&lt;tag-lib&gt;
    &lt;uri&gt;.............&lt;/uri&gt;  //考试会考    打包后再Jar包里找不到的。。copy一遍扔到jsp
    &lt;tag&gt;
        &lt;short-name&gt;t&lt;/short-name&gt;
        &lt;name&gt;time&lt;/name&gt;   &lt;!--重要，标签名--&gt;
        &lt;tag-class&gt;a.TimeTag&lt;/tag-calss&gt;  &lt;!--重要，标签类--&gt;
        &lt;body-content&gt;&lt;/body-content&gt;
        &lt;!--重要，定义参数--&gt;
        &lt;attribute&gt;
            &lt;name&gt;color&lt;name&gt;
            &lt;Type&gt;java.lang.String&lt;/&gt;
            &lt;required&gt;false&lt;/required&gt;
        &lt;/attribute&gt;
    &lt;/tag&gt;
&lt;/tag-lib&gt;
</code></pre><p>引入且使用</p>
<pre><code>&lt;%@ taglib uri=&quot;...&quot; prefix=&quot;t&quot;%&gt;
&lt;t:time /&gt;
</code></pre><p>执行顺序:</p>
<ul>
<li>WEB容器调用标签处理器对象的setJspContext方法，将代表JSP页面的pageContext对象传递给标签处理器对象。</li>
<li>WEB容器调用标签处理器对象的setParent方法，将父标签处理器对象传递给这个标签处理器对象。注意，只有在标签存在父标签的情况下，WEB容器才会调用这个方法。</li>
<li>如果调用标签时设置了属性，容器将调用每个属性对应的setter方法把属性值传递给标签处理器对象。如果标签的属性值是EL表达式或脚本表达式，则WEB容器首先计算表达式的值，然后把值传递给标签处理器对象。</li>
<li>如果简单标签有标签体，容器将调用setJspBody方法把代表标签体的JspFragment对象传递进来。</li>
</ul>
<blockquote>
<p><strong>doStartTag()</strong>方法是遇到标签开始时执行，其合法的返回值是<strong>EVAL_BODY_INCLUDE</strong>与<strong>SKIP_BODY,</strong>前者表示将显示标签间的内容，后者表示不显示标签间的内容；<strong>doEndTag()</strong>方法是在遇到标签结束时执行，其合法的返回值是<strong>EVAL_PAGE</strong>与<strong>SKIP_PAGE</strong>，前者表示处理完标签后继续执行以下的JSP网页，后者是表示不处理接下来的JSP网页<br><strong>预定的处理顺序是：doStartTag()返回SKIP_BODY,doAfterBodyTag()返回SKIP_BODY,doEndTag()返回EVAL_PAGE.</strong></p>
</blockquote>
<pre><code>doAfterBody()

这个方法是在显示完标签间文字之后呼叫的，其返回值有EVAL_BODY_AGAIN与SKIP_BODY，前者会再显示一次标签间的文字，后者则继续执行标签处理的下一步。
</code></pre><p>如果继承了TagSupport之后，如果没有改写任何的方法，标签处理的执行顺序是：<br>doStartTag() -&gt;不显示文字-&gt;doEndTag()-&gt;执行接下来的网页</p>
<h3 id="HttpSession"><a href="#HttpSession" class="headerlink" title="HttpSession"></a>HttpSession</h3><p>HttpSession生命周期：<br>1.什么时候创建HttpSession<br>1）.对于JSP：<br>是否浏览器访问服务端的任何一个JSP或Servlet，服务器都会立即创建一个HttpSession对象呢？<br>不一定。<br>①. 若当前的JSP或（Servlet）是客户端访问的当前WEB应用的第一个资源，且JSP的page指定的<br>session属性为false，则服务器就不会为JSP创建一个HttpSession对象；<br>②.若当前JSP不是客户端访问的当前WEB应用的第一个资源，且其他页面已经创建一个HttpSession对象，<br>则服务器也不会为当前JSP创建一个新的HttpSession对象，而会把和当前会话关联的那个HttpSession对象返回给当前的JSP页面。<br>2）.page指令的session=”false” 到底表示什么意思：<br>当前JSP页面禁用session<strong>隐含变量</strong>！但可以使用其他的显式的对象</p>
<p>3）.对于Servlet而言：<br>若Servlet是客户端访问的第一个WEB应用的资源，则只有调用了request.getSession()或request.getSession(true)  才会创建HttpSession对象</p>
<p>4）. 在Servlet中如何获取HttpSession对象？<br>request.getSession(boolean create):create为false,若没有和当前JSP页面关联的HttpSession对象<br>则返回null；<br>若有返回true  create为true一定返回一个HTTPSession对象。若没有和昂前JSP页面关联的HttpSession对象，<br>则服务器创建一个新的HttpSession对象返回，若有，则直接返回关联。</p>
<p>request.getSession()等同于request.getSession(true) </p>
<p>2.什么时候销毁HttpSession对象：<br> 1）.直接调用HttpSession的invalidate（）方法：使Httpsession失效<br> 2）.服务器卸载了当前WEB应用。<br> 3）.超出HttpSession的过期时间。<br> 设置HttpSession的过期时间：单位为S</p>
<blockquote>
<p>当程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否已包含了一个session标识 - 称为session id，如果已包含一个session id则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（如果检索不到，可能会新建一个）</p>
</blockquote>
<pre><code>request.getSession(true); //如果没有session会创建一个新session
request.getSession(); //如果没有session会创建一个新session
</code></pre><p><strong>JSP文件在编译成Servlet时将会自动加上这样一条语句 HttpSession session = HttpServletRequest.getSession(true);这也是JSP中隐含的session对象的来历，但如果页面的设置Session=false;是当前页面禁用session隐含的变量，但可以显示的定义其他session变量</strong></p>
<h2 id="关于Servlet和Filter"><a href="#关于Servlet和Filter" class="headerlink" title="关于Servlet和Filter"></a>关于Servlet和Filter</h2><pre><code>对于使用传统的部署描述文件 (web.xml) 配置 Servlet 和过滤器的情况，Servlet 3.0 为 &lt;servlet&gt; 和 &lt;filter&gt; 标签增加了 &lt;async-supported&gt; 子标签，该标签的默认取值为 false，要启用异步处理支持，则将其设为 true 即可。以 Servlet 为例，其配置方式如下所示：
&lt;servlet&gt; 
    &lt;servlet-name&gt;DemoServlet&lt;/servlet-name&gt; 
    &lt;servlet-class&gt;footmark.servlet.Demo Servlet&lt;/servlet-class&gt; 
    &lt;async-supported&gt;true&lt;/async-supported&gt; 
&lt;/servlet&gt;
</code></pre><p><img src="./1577609117012.png" alt="Alt text"><br>如果从errorpage过来的会走ERROR<br>异步请求会async</p>
<h2 id="JSP"><a href="#JSP" class="headerlink" title="JSP"></a>JSP</h2><h3 id="九个内置对象"><a href="#九个内置对象" class="headerlink" title="九个内置对象"></a>九个内置对象</h3><p>reuqest,response,session,application,pageContext,out,exception,page,config</p>
<h3 id="3个指令"><a href="#3个指令" class="headerlink" title="3个指令"></a>3个指令</h3><p>都是<a href="&#109;&#97;&#105;&#x6c;&#116;&#x6f;&#x3a;&#x25;&#64;&#37;">&#x25;&#64;&#37;</a>形式</p>
<h4 id="1-Page指令"><a href="#1-Page指令" class="headerlink" title="1.Page指令"></a>1.Page指令</h4><p><strong>import</strong>=”..”  //引入包<br><strong>session</strong>=”false” 等价于 request.getSession(false); 如果一个seesion不存在，不会创建它。这个指令会禁用jsp的隐藏session对象。但可以显式定义其他session.<br><strong>contentType</strong>=”text/html;charset=utf-8”  等价于response.setContentType(“”)<br><strong>pageEncoding</strong>=”utf-8”</p>
<blockquote>
<p>pageEncoding是jsp<strong>文件本身</strong>的编码<br>contentType的charset是指服务器发送给客户端时的内容编码(也就是显示出来的内容的编码)</p>
</blockquote>
<p>isELIgnored: 是否支持EL表达式。 默认是false<br>isErrorPage: 是否创建throwable对象。默认是false;<br>errorPage: 如果页面中有错误，则跳转到指定的资源。<br><strong>isThreadSafe 默认true,线程安全下servlet可以并行访问</strong></p>
<h4 id="2-Include指令"><a href="#2-Include指令" class="headerlink" title="2. Include指令"></a>2. Include指令</h4><pre><code>&lt;!--动态包含,会编译生成两个servlet，把另一个servlet的结果拿过来用--&gt;
&lt;jsp:include page=&quot;/include/header.jsp&quot;&gt;&lt;/jsp:include&gt;
&lt;!--静态包含,只编译生成1个servlet，拿另一个的jsp代码过来用--&gt;
&lt;%@include file=&quot;/include/header.jsp&quot;%&gt;
</code></pre><h4 id="3-taglib指令"><a href="#3-taglib指令" class="headerlink" title="3.taglib指令"></a>3.taglib指令</h4><pre><code>&lt;%@taglib uri=&quot;xxx&quot; prefix=&quot;xx&quot;%&gt; 引入一个标签库
</code></pre><h3 id="6个动作"><a href="#6个动作" class="headerlink" title="6个动作"></a>6个动作</h3><h4 id="param"><a href="#param" class="headerlink" title="param"></a>param</h4><p>传递参数</p>
<blockquote>
<p>一般配合include forward之类的使用。servlet可以用request.getParameter获取到</p>
</blockquote>
<pre><code>&lt;jsp:param name=&quot;xx&quot; value=&quot;yy&quot;/&gt;  
</code></pre><h4 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h4><blockquote>
<p>jsp本质也是servlet,和reuqest.getRequestDispatcher(“,,”).forward(reuqest,response);一样</p>
</blockquote>
<pre><code>&lt;jsp:forward page=&quot;...&quot;&gt;
    &lt;jsp:param name=&quot;p1&quot; value=&quot;12&quot;/&gt;
&lt;/jsp:forward&gt;
</code></pre><h4 id="include"><a href="#include" class="headerlink" title="include"></a>include</h4><blockquote>
<p>jsp本质也是servlet,和reuqest.getRequestDispatcher(“,,”).include(reuqest,response);一样</p>
</blockquote>
<pre><code>&lt;jsp:include&gt;
    &lt;jsp:param name=&quot;p1&quot; value=&quot;12&quot;/&gt;
&lt;/jsp:include&gt;
</code></pre><h4 id="useBean-setProperty-getProperty"><a href="#useBean-setProperty-getProperty" class="headerlink" title="useBean,setProperty,getProperty"></a>useBean,setProperty,getProperty</h4><blockquote>
<p>这三个指令都是与 JavaBean 相关的指令，其中 useBean 指令用于在 JSP 页面中初始化一个 Java 实例；setProperty 指令用于为 JavaBean 实例的属性设置值；getProperty 指令用于输出 JavaBean 实例的属性。</p>
</blockquote>
<pre><code>&lt;jsp:useBean id=&quot;beanA&quot; class=&quot;com.a.BeanA&quot; scope=&quot;session&quot;/&gt; &lt;!--scope可以是 reuqest,session,application,page--&gt;
&lt;jsp:setProperty property=&quot;name&quot; name=&quot;beanA&quot; value=&quot;12&quot;/&gt;
也可url参数传参
&lt;jsp:setProperty property=&quot;name&quot; name=&quot;beanA&quot; param=&quot;age&quot;/&gt;
&lt;%=beanA.getName()%&gt;
&lt;jsp:getProperty property=&quot;name&quot; name=&quot;beanA&quot;/&gt;
</code></pre><h2 id="EL表达式"><a href="#EL表达式" class="headerlink" title="EL表达式"></a>EL表达式</h2><h3 id="11个内置对象"><a href="#11个内置对象" class="headerlink" title="11个内置对象"></a>11个内置对象</h3><p>pageScope, sessionScope, applicationScope, requestScope, pageContext  四大域+一个context<br>param,paramValues,cookie,header,headerValues, init-param</p>
<p>结构上都是</p>
<pre><code>${....}



${sessionScope.user.sex} //相当于 &lt;%=session.getAttribute(&quot;user&quot;).getSex()%&gt;
直接使用,符号可以调用get函数 也可以用定位符号[]
${sessionScope.userB[&quot;sex&quot;]}
有特殊符号是只能用[]
${sessionScope.userB[data]}  //data是一个变量

EL变量
${username} 这是让他找出某一范围内的名为username的变量
其会按域的从小到大找 page-&gt;request-&gt;session-&gt;applicaiton   也可以直接用xxxScope取出
相当于 &lt;%=xxxScope.getAttribute(&quot;username&quot;)%&gt;
[]可以从数组中取值(填下标)，也可以从map中取值(填key)
</code></pre><p><strong>EL能够自动类型转换</strong><br>EL还能算术运算,逻辑运算（字符间也能比较</p>
<pre><code>${ param.password1 = =param.password2 }
Empty 运算符:
&lt;c:if test=&quot;${! empty key}&quot;&gt;${key}&lt;/c:if&gt;
</code></pre><p><strong>empty运算符规则:</strong><br>1若key为null时，返回true<br>2若key为空String时，返回true<br>3若key为空Array时，返回true<br>4若key为空Map时，返回true<br>5若key为空Collection时，返回true<br>6否则，返回false</p>
<p><strong>EL表达式是在服务端执行的，服务端执行完成后再传给客户端的，js是在客户端执行的，el在js前就被执行了</strong></p>
<h4 id="连接池配置"><a href="#连接池配置" class="headerlink" title="连接池配置"></a>连接池配置</h4><h5 id="Tomcat连接池"><a href="#Tomcat连接池" class="headerlink" title="Tomcat连接池"></a>Tomcat连接池</h5><blockquote>
<p>可以在应用的web.xml也可以在Tomcat的conf/context.xml,也可以在Tomcat的conf/server.xml(GlobalNamingResources标签)中配置,也可以在应用的context.xml中配置。</p>
</blockquote>
<pre><code>&lt;Context&gt;
&lt;Resource name=&quot;jdbc/mysqlds&quot; 
    auth=&quot;Container&quot; //验证方式为容器
    type=&quot;javax.sql.DataSource&quot;     //数据源类
    username=&quot;root&quot; 
    password=&quot;root&quot; 
    maxIdle=&quot;30&quot;   //最多维持几个空闲连接 minIdel:最少维持几个空闲连接(即使没有需求)
    maxWait=&quot;10000&quot;  //最大等待时间（毫秒) 借出连接的最长期限
    initialSize=&quot;20&quot; //初始化时创建多少个连接
    maxActive=&quot;100&quot; //最大连接数

    driverClassName=&quot;com.mysql.jdbc.Driver&quot; //数据库驱动
    url=&quot;jdbc:mysql://127.0.0.1:3306/db_blog&quot; //数据库url地址
    logAbandoned=&quot;true&quot; /&gt;
&lt;/Context&gt;
</code></pre><blockquote>
<p>url 后面还可以?加一些参数 比如serverTimezone=UTC&amp;useSSL=false&amp;useSSL=false</p>
</blockquote>
<h2 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h2><h3 id="Aware"><a href="#Aware" class="headerlink" title="Aware"></a>Aware</h3><p>aware接口就一个函数 名字叫  XXAware那就一个 setXX(XX obj)</p>
<h3 id="Bean"><a href="#Bean" class="headerlink" title="Bean"></a>Bean</h3><pre><code>/*@PostConstruct:在Bean中的某个方法上加上@PostConstruct注解，则该方法将会在Bean初始化之后被Spring容器调用 等同于bean标签init-method属性
@PreDestroy  destroy-method
*/
</code></pre><p>获取BeanFactory,ApplicationContext的方法</p>
<pre><code>1.Aware  (BeanFactoryAware,ApplicationContextAware接口)都有getBean
</code></pre><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletReuqest request,HttpServletResponse)</span> <span class="keyword">throws</span> IOException,ServletException</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.doPost(request,response);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest request, HttpServletResponse)</span> <span class="keyword">throws</span> IOException,ServletException</span>&#123;</span><br><span class="line">		PrintWriter writer = response.getWriter();</span><br><span class="line">		response.setContentType(<span class="string">"text/html;charset=utf-8"</span>);</span><br><span class="line">		response.setCharacterEncoding(<span class="string">"utf-8"</span>);</span><br><span class="line">		request.getRequestDispatcher(<span class="string">"/bs"</span>).forward(request,response); <span class="comment">//***记得url是在getdispatcher时填的，forward要带两个参</span></span><br><span class="line">		request.getRequestDispatcher(<span class="string">"/bs"</span>).include(request,response);</span><br><span class="line">		response.sendRedirect(<span class="string">"/a.jsp"</span>);</span><br><span class="line">		<span class="keyword">this</span>.getServletContext();</span><br><span class="line">		request.getServletContext();</span><br><span class="line">		request.getSession().getServletContext();</span><br><span class="line">		<span class="keyword">this</span>.config.getServletContext();</span><br><span class="line">		ServletContext sc=getServletConfig.getServletContext();</span><br><span class="line">		config.getInitParameter(<span class="string">"p1"</span>);</span><br><span class="line">		sc.getInitParam(<span class="string">"p2"</span>); <span class="comment">//注意</span></span><br><span class="line">		</span><br><span class="line">		request.getParameter(<span class="string">"aaa"</span>);</span><br><span class="line">		request.getParameterValues(<span class="string">"aaa"</span>);  <span class="comment">//string[]</span></span><br><span class="line">		request.getRealPath(<span class="string">"/"</span>);  <span class="comment">//不推荐 use ServletContext.getRealPath(java.lang.String) instead.</span></span><br><span class="line">		request.getProtocol(<span class="string">"/"</span>);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@WebServlet</span>(name=<span class="string">"BServlet"</span>,urlPatterns=&#123;<span class="string">"/bse"</span>&#125;,init-params=&#123;<span class="meta">@WebInitParam</span>(name=<span class="string">"p1"</span>,value=<span class="string">"123"</span>)&#125; )</span><br><span class="line"><span class="meta">@MultipartConfig</span>(localtion=<span class="string">"c:\aaa"</span>,fileSizeThreshold=<span class="number">0</span>,maxFileSize=<span class="number">102400</span>, 	maxRequestSize=<span class="number">102400</span>)</span><br><span class="line"><span class="comment">/*fileSizeThreshold默认0，多少字节后存到文件系统上，mfs:最大文件大小 mrs:最大请求的multipart form大小*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletReuqest request,HttpServletResponse)</span> <span class="keyword">throws</span> IOException,ServletException</span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.doPost(request,response);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doPost</span><span class="params">(HttpServletRequest request, HttpServletResponse)</span> <span class="keyword">throws</span> IOException,ServletException</span>&#123;</span><br><span class="line">		PrintWriter writer = response.getWriter();</span><br><span class="line">		response.setContentType(<span class="string">"text/html;charset=utf-8"</span>);</span><br><span class="line">		response.setCharacterEncoding(<span class="string">"utf-8"</span>);</span><br><span class="line">		response.addCookie(<span class="keyword">new</span> Cookie(<span class="string">"akb"</span>,<span class="string">"111"</span>));  <span class="comment">//不是set是add</span></span><br><span class="line">		Cookie c1=<span class="keyword">new</span> Cookie(<span class="string">"a"</span>,<span class="string">"1"</span>);</span><br><span class="line">		c1.setMaxAge(<span class="number">2000</span>); <span class="comment">//秒</span></span><br><span class="line">		response.addCookie(c1);</span><br><span class="line">		response.sendError(<span class="number">500</span>);</span><br><span class="line">		writer.print(request.getProtocol());</span><br><span class="line">		<span class="comment">//4个路径</span></span><br><span class="line">		request.getRequestURI();</span><br><span class="line">		reuqest.getRequestURL();</span><br><span class="line">		request.getContextPath();</span><br><span class="line">		request.getServletPath();</span><br><span class="line">		</span><br><span class="line">		request.getDispatcherType();  <span class="comment">//FORWARD,    INCLUDE,   REQUEST,   ASYNC,   ERROR</span></span><br><span class="line">		</span><br><span class="line">		<span class="keyword">long</span> l=<span class="keyword">this</span>.getLastModified(request);</span><br><span class="line">		HttpSession hs= request.getSession();</span><br><span class="line">		hs.getID();</span><br><span class="line">		hs.setMaxInactiveInterval(<span class="number">1000</span>); <span class="comment">//s</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">//上传</span></span><br><span class="line">		Part part=request.getPart(<span class="string">"file"</span>); <span class="comment">//寻找指定名称的part</span></span><br><span class="line">		part.write(<span class="string">"c:\aa"</span>);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  <span class="comment">//也可以extends HttpServlet</span></span><br><span class="line">	FilterConfig config;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig c)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.config=c;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request,ServletResponse response,FilterChain chain)</span></span>&#123; <span class="comment">//注意第三个参数</span></span><br><span class="line">		c.getInitParameter(<span class="string">"p1"</span>); <span class="comment">//完整的param</span></span><br><span class="line">		c.getServletContext();</span><br><span class="line">		</span><br><span class="line">		chain.doFilter(request,response); <span class="comment">//往下传</span></span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@WebFilter</span>(name=<span class="string">"BFilter"</span>, initParams=&#123;<span class="meta">@WebInitParam</span>(name=<span class="string">"p1"</span>,balue=<span class="string">"1"</span>) &#125;, urlPatterns=&#123;<span class="string">"/a/*.css"</span>&#125;, servletName=&#123;<span class="string">"AServlet"</span>&#125;)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FIlterConfig c)</span></span>&#123;&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(HttpServletRequest request, HttpServletResponse response, FilterChain chain )</span></span>&#123;</span><br><span class="line">		request.getRequestDispatch(<span class="string">"/login"</span>).forward(request,response);</span><br><span class="line">		Cookie c=<span class="keyword">new</span> Cookie(<span class="string">"c1"</span>,<span class="string">"1"</span>);</span><br><span class="line">		c.setDomain(<span class="string">".kk.com"</span>); <span class="comment">//必须.开头</span></span><br><span class="line">		c.setPath(<span class="string">"/"</span>);</span><br><span class="line">		chain.doFilter(request,response);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  &lt;form action="/HelloWorld/UpLoad" method="post" enctype="multipart/form-data"&gt;//注意</span></span><br><span class="line"><span class="comment">            &lt;input type="file" name="file"&gt;</span></span><br><span class="line"><span class="comment">            &lt;input type="submit" name="upload" value="上传"&gt;</span></span><br><span class="line"><span class="comment">        &lt;/form&gt;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*Listener*/</span>  <span class="comment">/*Event都是EventObject子类  Listener都是 EventListener 子接口*/</span></span><br><span class="line"><span class="comment">//监听三大域的初始化和销毁</span></span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span> <span class="keyword">implements</span> <span class="title">ServletContextListener</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextInitializated</span><span class="params">(ServletConetxtEvent s)</span></span>&#123;  <span class="comment">//注意名字</span></span><br><span class="line">		s.getServletContext();</span><br><span class="line">	&#125; </span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextDestroyed</span><span class="params">(ServletContextEvent s)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function">@WebListener</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class B implements HttpSessionListener</span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sessionCreated</span><span class="params">(HttpSessionEvent session)</span></span>&#123;</span><br><span class="line">		session.getSession();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sessionDestroyed</span><span class="params">(HttpSessionEvent session)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">C</span> <span class="keyword">implements</span> <span class="title">ServletRequestListener</span></span>&#123;  <span class="comment">//名字不是http</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requestInitializated</span><span class="params">(ServletRequestEvent s)</span></span>&#123;</span><br><span class="line">		s.getServletContext();</span><br><span class="line">		s.getServletRequest();  <span class="comment">//httprequest是其子接口</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sessionDestroyed</span><span class="params">(ServletRequestEvent s)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//监听三大域的属性变更</span></span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">D</span> <span class="keyword">implements</span> <span class="title">SerlvetContextAttributeListener</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeAdded</span><span class="params">(ServletAttributeEvent e)</span></span>&#123;</span><br><span class="line">		e.getName();</span><br><span class="line">		e.getValue();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeRemoved</span><span class="params">(ServletAttributeEvent e)</span></span>&#123;&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeReplaced</span><span class="params">(ServletAttributeEvent e)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="keyword">implements</span> <span class="title">HttpSessionAttributeListener</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeAdded</span><span class="params">(HttpSeesionBindingEvent e)</span></span>&#123;  <span class="comment">//注意事件名</span></span><br><span class="line">		e.getSession(); <span class="comment">//HttpSession</span></span><br><span class="line">		e.getName();</span><br><span class="line">		e.getValue();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeRemoved</span><span class="params">(HttpSeesionBindingEvent e)</span></span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeReplaced</span><span class="params">(HttpSeesionBindingEvent e)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="keyword">implements</span> <span class="title">ServletRequestAttriuteListener</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeAdded</span><span class="params">(ServletRequestAttributeEvent e)</span></span>&#123;  <span class="comment">//注意事件名</span></span><br><span class="line">		e.getName();</span><br><span class="line">		e.getValue();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeRemoved</span><span class="params">(ServletRequestAttributeEvent  e)</span></span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attributeReplaced</span><span class="params">(ServletRequestAttributeEvent  e)</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//session的属性绑定与</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="keyword">implements</span> <span class="title">HttpSessionBindingListener</span></span>&#123;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">valueBound</span><span class="params">(HttpSessionBindingEvent event)</span></span>&#123;&#125;  <span class="comment">//属性绑定</span></span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">valueUnbound</span><span class="params">(HttpSessionBindingEvent event)</span>  <span class="comment">//属性解绑</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class implements HttpSessionActivativationListener</span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> 	<span class="title">sessionDidActivate</span><span class="params">(HttpSessionEvent se)</span></span>;  <span class="comment">//会话激活后</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> 	<span class="title">sessionWillPassivate</span><span class="params">(HttpSessionEvent se)</span> <span class="comment">//会话将失效</span></span></span><br><span class="line"><span class="function">&#125; <span class="comment">//**</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">/*执行顺序:</span></span></span><br><span class="line"><span class="function"><span class="comment">+ WEB容器调用标签处理器对象的setJspContext方法，将代表JSP页面的pageContext对象传递给标签处理器对象。</span></span></span><br><span class="line"><span class="function"><span class="comment">+ WEB容器调用标签处理器对象的setParent方法，将父标签处理器对象传递给这个标签处理器对象。注意，只有在标签存在父标签的情况下，WEB容器才会调用这个方法。</span></span></span><br><span class="line"><span class="function"><span class="comment">+ 如果调用标签时设置了属性，容器将调用每个属性对应的setter方法把属性值传递给标签处理器对象。如果标签的属性值是EL表达式或脚本表达式，则WEB容器首先计算表达式的值，然后把值传递给标签处理器对象。</span></span></span><br><span class="line"><span class="function"><span class="comment">+ 如果简单标签有标签体，容器将调用setJspBody方法把代表标签体的JspFragment对象传递进来。*/</span></span></span><br><span class="line"><span class="function"><span class="comment">/*doStartTag()方法是遇到标签开始时执行，其合法的返回值是EVAL_BODY_INCLUDE与SKIP_BODY,前者表示将显示标签间的内容，后者表示不显示标签间的内容；</span></span></span><br><span class="line"><span class="function"><span class="comment">	doEndTag()方法是在遇到标签结束时执行，其合法的返回值是EVAL_PAGE与SKIP_PAGE，前者表示处理完标签后继续执行以下的JSP网页，后者是表示不处理接下来的JSP网页*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class TagA extends TagSupport</span>&#123;</span><br><span class="line">	String n=<span class="string">""</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">getN</span><span class="params">()</span></span>&#123;<span class="keyword">return</span> n;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setN</span><span class="params">(String n)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.n=n;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">doStartTag</span><span class="params">()</span> <span class="keyword">throws</span> JspException</span>&#123;  <span class="comment">//注意抛的异常</span></span><br><span class="line">		<span class="keyword">this</span>.pageContext.getServletContext(); <span class="comment">//pageContext是TagSupport的属性，可以直接用</span></span><br><span class="line">		<span class="keyword">return</span> Tag.EVAL_BODY_INCLUDE;  <span class="comment">//不跳过body</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">doAfterBody</span><span class="params">()</span> throw JspException</span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> Tag.SKIP_BODY;  </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">doEndTag</span><span class="params">()</span> <span class="keyword">throws</span> JspException</span>&#123;</span><br><span class="line">		<span class="keyword">return</span> Tag.EVAL_PAGE;  <span class="comment">//不跳过剩下的页面</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TagB</span> <span class="keyword">extends</span> <span class="title">SimpleTagSupport</span></span>&#123;</span><br><span class="line">	String account=<span class="string">""</span>;</span><br><span class="line">	String passwd=<span class="string">""</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAccount</span><span class="params">(String a)</span></span>&#123;<span class="keyword">this</span>.account=a;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPasswd</span><span class="params">(String p)</span></span>&#123;<span class="keyword">this</span>.passwd=p;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">setAccount</span><span class="params">(String a)</span></span>&#123;<span class="keyword">return</span> account;&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">setPasswd</span><span class="params">(String p)</span></span>&#123;<span class="keyword">return</span> passwd;&#125;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doTag</span><span class="params">()</span> <span class="keyword">throws</span> JspException</span>&#123;</span><br><span class="line">		PageContext pc=(PageContext)<span class="keyword">this</span>.getJspContext;  <span class="comment">//重要，获取pageContext的方式</span></span><br><span class="line">		JspWriter out=pc.getOut();</span><br><span class="line">		pc.getRequest();</span><br><span class="line">		pc.getResponse();</span><br><span class="line">		pc.getSession();</span><br><span class="line">		pc.getServletContext();</span><br><span class="line">		pc.getServletConfig();</span><br><span class="line">		pc.forward(<span class="string">"url"</span>);</span><br><span class="line">		pc.include(<span class="string">"/aaa"</span>,<span class="keyword">true</span>); <span class="comment">//第二个参数flush</span></span><br><span class="line">		pc.setAttribute(<span class="string">"a"</span>,pc,PageContext.SESSION_SCOPE); <span class="comment">//第三个参数可选。在哪个域中写入属性。session,application,request,不写的话是在pagecontext</span></span><br><span class="line">		pc.release();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*struts 1*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Action1</span> <span class="keyword">extends</span> <span class="title">Action</span></span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">execute</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		form.getServlet() <span class="comment">//ActionServlet</span></span><br><span class="line">		<span class="keyword">return</span> mapping.findForward(<span class="string">"success"</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Action2</span> <span class="keyword">extends</span> <span class="title">DispatchAction</span></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">add</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">delete</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">find</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Action3</span> <span class="keyword">extends</span> <span class="title">MappingDispatchAction</span></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">add</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">delete</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ActionForward <span class="title">find</span><span class="params">(ActionMapping mapping,ActionForm form, HttpServletRequest request, HttpServletResponse response)</span></span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyController</span></span>&#123;</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/calc/add"</span>)</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">add</span><span class="params">(@RequestParam(value=<span class="string">"v1"</span>)</span>String v1, @<span class="title">RequestParam</span><span class="params">(value=<span class="string">"v2"</span>)</span> String v2)</span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/calc/substract"</span>)</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">substract</span><span class="params">(@RequestParam(value=<span class="string">"v1"</span>)</span> String v1,@<span class="title">RequestParam</span><span class="params">(value=<span class="string">"v2"</span>)</span> String v2)</span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/calc"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyController2</span></span>&#123;</span><br><span class="line">	<span class="meta">@Value</span>(<span class="string">"$&#123;account&#125;"</span>)</span><br><span class="line">	<span class="keyword">int</span> account;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/add"</span>,method=RequestMethod.GET)</span><br><span class="line">	<span class="function"><span class="keyword">public</span> ModelAndView <span class="title">add</span><span class="params">(@RequestParam(value=<span class="string">"v1"</span>)</span>String v1, @<span class="title">RequestParam</span><span class="params">(value=<span class="string">"v2"</span>)</span> String v2)</span>&#123;</span><br><span class="line">		ModelAndView modelAndView =<span class="keyword">new</span> ModelAndView();</span><br><span class="line">		modelAndView.setViewName(<span class="string">"视图名"</span>);</span><br><span class="line">		modelAndView.addObject(<span class="string">"属性名"</span>,<span class="keyword">new</span> Object());</span><br><span class="line">		<span class="keyword">return</span> modelAndView;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="meta">@PostMapping</span>(<span class="string">"/substract"</span>) <span class="comment">//相当于 @RequestMapping("/subtract",RequestMethod.POST)</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">substract</span><span class="params">(@RequestParam(value=<span class="string">"v1"</span>)</span> String v1,@<span class="title">RequestParam</span><span class="params">(value=<span class="string">"v2"</span>)</span> String v2)</span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="meta">@Scope</span>(value=<span class="string">"singleton"</span>) <span class="comment">//prototype application request session page</span></span><br><span class="line"><span class="keyword">public</span> CacheManager&#123;</span><br><span class="line">	<span class="meta">@Autowired</span>(required=<span class="keyword">false</span>)<span class="meta">@Qualifier</span>(<span class="string">"bb"</span>)</span><br><span class="line">	BeanA ba;</span><br><span class="line">	<span class="meta">@Resource</span>(<span class="string">"bb"</span>)</span><br><span class="line">	BeanB bb;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">studentManagement</span></span>&#123;</span><br><span class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/&#123;stuid&#125;/modify"</span>)</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">modify</span><span class="params">(@PathVariable(<span class="string">"stuid"</span>)</span>String stuid)</span>&#123;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@ComponentScan</span>(value=<span class="string">"com.xx.aa"</span>, useDefaultFilter= <span class="keyword">true</span>, basePackageClass=HelloController<span class="class">.<span class="keyword">class</span>) /*扫描指定包+某个类所在的包*/</span></span><br><span class="line"><span class="class">@<span class="title">ComponentScan</span>(<span class="title">basePackages</span></span>=&#123;<span class="string">"com.sad.xx"</span>,<span class="string">"com.aa.fc"</span>&#125;) <span class="comment">/*扫描多个包*/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ComponentScan</span>(value = <span class="string">"com.xhx.spring"</span>,</span><br><span class="line">        useDefaultFilters = <span class="keyword">false</span>,</span><br><span class="line">        includeFilters = &#123;</span><br><span class="line">            <span class="meta">@ComponentScan</span>.Filter(type = FilterType.ASSIGNABLE_TYPE,classes = &#123;HelloController<span class="class">.<span class="keyword">class</span>&#125;)  /*按类型扫描*/</span></span><br><span class="line"><span class="class">        &#125;</span></span><br><span class="line"><span class="class">)</span></span><br><span class="line"><span class="class">@<span class="title">ComponentScan</span>(<span class="title">value</span> </span>= <span class="string">"com.xhx.spring"</span>,</span><br><span class="line">        useDefaultFilters = <span class="keyword">false</span>,</span><br><span class="line">        includeFilters = &#123;</span><br><span class="line">            <span class="meta">@ComponentScan</span>.Filter(type = FilterType.ANNOTATION,classes = &#123;Controller<span class="class">.<span class="keyword">class</span>&#125;)  /*扫描带注解的*/</span></span><br><span class="line"><span class="class">        &#125;</span></span><br><span class="line"><span class="class">)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">MyConfig</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	HttpSession</span></span><br><span class="line"><span class="comment">		getCreateTime() 返回距离1970,1 的时间 毫秒</span></span><br><span class="line"><span class="comment">		getLastAccessedTime() 返回上一次客户端的请求与这session有关的时间</span></span><br><span class="line"><span class="comment">		getMaxInactivative() 保留会话的最大非活动时间</span></span><br><span class="line"><span class="comment">		isNew()</span></span><br><span class="line"><span class="comment">	</span></span><br><span class="line"><span class="comment">	ServletRequest</span></span><br><span class="line"><span class="comment">		doDelete() doPut() doGet() doTrace() doOptions()</span></span><br><span class="line"><span class="comment">		getLastModified()   距离1970,1的毫秒级时间 HttpServletRequest 对象变动的时间</span></span><br><span class="line"><span class="comment">		</span></span><br><span class="line"><span class="comment">	HttpServletRequest</span></span><br><span class="line"><span class="comment">		changeSessionId() 改变成一个新ID</span></span><br><span class="line"><span class="comment">		getContextPath() 请求的URI部分</span></span><br><span class="line"><span class="comment">		getCookies() cookies[]</span></span><br><span class="line"><span class="comment">		getDateHeader(String name) //long </span></span><br><span class="line"><span class="comment">		getHeader(String name)</span></span><br><span class="line"><span class="comment">		getHeaders(String name) 迭代器</span></span><br><span class="line"><span class="comment">			getMethod()</span></span><br><span class="line"><span class="comment">		isUserInRole(String role)</span></span><br><span class="line"><span class="comment">		isRequestedSessionIdFromURL()</span></span><br><span class="line"><span class="comment">		isRequestedSessionIdFromCookie()</span></span><br><span class="line"><span class="comment">		getSession(false);</span></span><br><span class="line"><span class="comment">	</span></span><br><span class="line"><span class="comment">	HttpServletResponse</span></span><br><span class="line"><span class="comment">		setStatus(int sc); //返回代码</span></span><br><span class="line"><span class="comment">		set/getHeader()</span></span><br><span class="line"><span class="comment">		sendRedirect();</span></span><br><span class="line"><span class="comment">		addCookie();</span></span><br><span class="line"><span class="comment">		</span></span><br><span class="line"><span class="comment">	Cookie</span></span><br><span class="line"><span class="comment">		</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*javaBean 的属性 ：simple,indexed, bound, constrained*/</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"><span class="comment">/*Action接口常量  : success error login input none*/</span></span><br></pre></td></tr></table></figure>
<h3 id="Xml"><a href="#Xml" class="headerlink" title="Xml"></a>Xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">/*部署app在tomcat*/</span><br><span class="line"><span class="tag">&lt;<span class="name">Host</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Host</span>&gt;</span>	</span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--部署--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Host</span> <span class="attr">name</span>=<span class="string">"localhost"</span> <span class="attr">appBase</span>=<span class="string">"webapps"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Context</span> <span class="attr">path</span>=<span class="string">"/a"</span> <span class="attr">docBase</span>=<span class="string">"/s/f"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Context</span> <span class="attr">path</span>=<span class="string">"/b"</span> <span class="attr">docBase</span>=<span class="string">"/s/b"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Context</span> <span class="attr">path</span>=<span class="string">""</span> <span class="attr">docBase</span>=<span class="string">"/u/a"</span>/&gt;</span></span><br><span class="line">	...	</span><br><span class="line"><span class="tag">&lt;/<span class="name">Host</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--web.xml--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">context-param</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>p2<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">param-value</span>&gt;</span>123<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">context-param</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>AServlet<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.a.AServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">init-param</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>p1<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-value</span>&gt;</span>123<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">serlvet-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>AServlet<span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/hello<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">fliter</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">fliter-name</span>&gt;</span>AFilter<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">fliter-class</span>&gt;</span>com.a.AFilter<span class="tag">&lt;/<span class="name">fliter-class</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">init-param</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>f1<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-value</span>&gt;</span>v1<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">fliter-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">filter-nmae</span>&gt;</span>f1<span class="tag">&lt;/<span class="name">filter-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/a/*<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">filter-mapping</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ta.tld</span><br><span class="line"><span class="tag">&lt;<span class="name">taglib...</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">description</span>&gt;</span>d<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">short-name</span>&gt;</span>aaa<span class="tag">&lt;/<span class="name">short-name</span>&gt;</span> <span class="comment">&lt;!--前缀--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">uri</span>&gt;</span>http://java.xx.aaa/aa/core<span class="tag">&lt;/<span class="name">uri</span>&gt;</span>  <span class="comment">&lt;!--等下引入会用到--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--下面是各种标签的定义--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">tag</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hello<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">tag-class</span>&gt;</span>com.akb.TagB<span class="tag">&lt;/<span class="name">tag-calss</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">body-content</span>&gt;</span><span class="tag">&lt;<span class="name">body-content</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">&lt;!--属性定义--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">attribute</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>account<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">required</span>&gt;</span>true<span class="tag">&lt;/<span class="name">required</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">rtexprvalue</span>&gt;</span>false<span class="tag">&lt;/<span class="name">rtexprvalue</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">attribute</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>passwd<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">required</span>&gt;</span>true<span class="tag">&lt;/<span class="name">required</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">rtexprvalue</span>&gt;</span>false<span class="tag">&lt;/<span class="name">rtexprvalue</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">tag</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>tagb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">tag-calss</span>&gt;</span>com.a.TagA<span class="tag">&lt;/<span class="name">tag-calss</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">body-content</span>&gt;</span><span class="tag">&lt;/<span class="name">body-content</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">attribute</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>n<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">required</span>&gt;</span>false<span class="tag">&lt;/<span class="name">required</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">taglib</span>&gt;</span>		</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">引入</span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">taglib</span> <span class="attr">uri</span>=<span class="string">"http://java.xx.aaa/aa/core"</span> <span class="attr">prefix</span>=<span class="string">"aaa"</span>&gt;</span></span><br><span class="line">使用</span><br><span class="line"><span class="tag">&lt;<span class="name">aaa:hello</span> <span class="attr">account</span>=<span class="string">"4442ss"</span> <span class="attr">passwd</span>=<span class="string">"123"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">aaa:tagb</span> <span class="attr">n</span>=<span class="string">"111"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">JSP2.0更简便的办法</span><br><span class="line">创建tag文件 在/WEB-INF/tags下</span><br><span class="line">time.tag</span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">tag</span> <span class="attr">import</span>=<span class="string">"java.util.*"</span> <span class="attr">import</span>=<span class="string">"java.text.*"</span> %&gt;</span>  <span class="comment">&lt;!--在这里引入需要的包--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%</span></span></span><br><span class="line"><span class="tag">  <span class="attr">DateFormat</span> <span class="attr">df</span> = <span class="string">DateFormat.getDateInstance(DateFormat.LONG);</span></span></span><br><span class="line"><span class="tag">  <span class="attr">Date</span> <span class="attr">d</span> = <span class="string">new</span> <span class="attr">Date</span>(<span class="attr">System.currentTimeMillis</span>());</span></span><br><span class="line"><span class="tag">  <span class="attr">out.println</span>(<span class="attr">df.format</span>(<span class="attr">d</span>));</span></span><br><span class="line"><span class="tag">%&gt;</span></span><br><span class="line"></span><br><span class="line">repeater.tag</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">attribute</span> <span class="attr">name</span>=<span class="string">"count"</span> <span class="attr">type</span>=<span class="string">"java.lang.Integer"</span> <span class="attr">required</span>=<span class="string">"true"</span> %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">attribute</span> <span class="attr">name</span>=<span class="string">"value"</span> <span class="attr">type</span>=<span class="string">"java.lang.String"</span> <span class="attr">required</span>=<span class="string">"true"</span> %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">%!</span></span></span><br><span class="line"><span class="tag">  <span class="attr">private</span> <span class="attr">String</span> <span class="attr">repeater</span>(<span class="attr">Integer</span> <span class="attr">count</span>, <span class="attr">String</span> <span class="attr">s</span>) &#123;</span></span><br><span class="line"><span class="tag"> </span></span><br><span class="line"><span class="tag">   <span class="attr">int</span> <span class="attr">n</span> = <span class="string">count.intValue();</span></span></span><br><span class="line"><span class="tag">    <span class="attr">StringBuffer</span> <span class="attr">sb</span> = <span class="string">new</span> <span class="attr">StringBuffer</span>();</span></span><br><span class="line"><span class="tag"> </span></span><br><span class="line">   for (int i = 0; i &lt; n; i++) &#123;</span><br><span class="line">      sb.append(s);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  return sb.toString();</span><br><span class="line">  &#125;</span><br><span class="line">%&gt;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">%</span></span></span><br><span class="line"><span class="tag">  <span class="attr">out.println</span>(<span class="attr">repeater</span>(<span class="attr">count</span>, <span class="attr">value</span>));</span></span><br><span class="line"><span class="tag"></span></span><br><span class="line"><span class="tag"></span></span><br><span class="line"><span class="tag">使用</span></span><br><span class="line">&lt;%@ taglib prefix="util" tagdir="/WEB-INF/tags" %&gt; &lt;!--直接用tagdir指定文件夹--&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">util:repeater</span> <span class="attr">count</span>=<span class="string">'$&#123;3 * 10&#125;'</span> <span class="attr">value</span>=<span class="string">'zzz'</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/*Struts1 配置*/</span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>struts1<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">serlvet-class</span>&gt;</span>org.apache.struts.action.ActionServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">init-param</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>config<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-value</span>&gt;</span>/WEB-INF/struts-config.xml<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>struts1<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>*.do<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--struts-config.xml--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">global-forwards</span>&gt;</span> <span class="tag">&lt;/<span class="name">global-forwards</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">action-mappings</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span></span></span><br><span class="line"><span class="tag">		<span class="attr">path</span>=<span class="string">"/login.do"</span></span></span><br><span class="line"><span class="tag">		<span class="attr">name</span>=<span class="string">"LoginForm"</span>,</span></span><br><span class="line"><span class="tag">		<span class="attr">type</span>=<span class="string">"com.a.Action1"</span> //注意是<span class="attr">type</span></span></span><br><span class="line"><span class="tag">	&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">forward</span> <span class="attr">name</span>=<span class="string">"sucess"</span> <span class="attr">path</span>=<span class="string">"/success.jsp"</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span> <span class="attr">path</span>=<span class="string">"/data"</span> <span class="attr">type</span>=<span class="string">"com.a.Action2"</span> <span class="attr">parameter</span>=<span class="string">"method"</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--省略forward--&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span> <span class="attr">path</span>=<span class="string">"/adddata"</span> <span class="attr">type</span>=<span class="string">"com.a.Action3"</span> <span class="attr">parameter</span>=<span class="string">"add"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span> <span class="attr">path</span>=<span class="string">"/deletedata"</span> <span class="attr">type</span>=<span class="string">"com.a.Action3"</span> <span class="attr">parameter</span>=<span class="string">"delete"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span> <span class="attr">path</span>=<span class="string">"/finddata"</span> <span class="attr">type</span>=<span class="string">"com.a.Action3"</span> <span class="attr">parameter</span>=<span class="string">"find"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">action-mappings</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--JSP 9大对象 request response session application pageContext config page exception  out --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--EL 11个内置对象  pageScope requestScope sessionScope applicationScope pageContext  4大域+一个context</span></span><br><span class="line"><span class="comment">param paramValues cookie header headerValues init-param--&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--a.jsp--&gt;</span></span><br><span class="line">       <span class="comment">&lt;!--非jsp的知识点。不过在html中可以这么写来设置请求头--&gt;</span></span><br><span class="line"> 	 <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"pragma"</span> <span class="attr">content</span>=<span class="string">"no-cache"</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"cache-control"</span> <span class="attr">content</span>=<span class="string">"no-cache"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"expires"</span> <span class="attr">content</span>=<span class="string">"0"</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"keywords"</span> <span class="attr">content</span>=<span class="string">"keyword1,keyword2,keyword3"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"description"</span> <span class="attr">content</span>=<span class="string">"This is my page"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--3大指令--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">import</span>=<span class="string">"java.io.*"</span>,"<span class="attr">java.util.</span>*","<span class="attr">java.awt.</span>*" %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">isELIngnore</span>=<span class="string">"false"</span> %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">session</span>=<span class="string">"true"</span> %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">error</span>=<span class="string">"error.jsp"</span> %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">isErrorPage</span>=<span class="string">"false"</span> %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">page</span> <span class="attr">contentType</span>=<span class="string">"text/html;charset=utf-8"</span> <span class="attr">pageEncoding</span>=<span class="string">"utf-8"</span> %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">include</span> <span class="attr">page</span>=<span class="string">"/sss.jsp"</span> %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%@</span> <span class="attr">taglib</span> <span class="attr">uri</span>=<span class="string">"xcasdfdasf"</span> <span class="attr">prefix</span>=<span class="string">"xxx"</span> %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--6大动作--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:include</span> <span class="attr">file</span>=<span class="string">"/include/h.jsp"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">jsp:param</span> <span class="attr">name</span>=<span class="string">"p1"</span> <span class="attr">value</span>=<span class="string">"123"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">jsp:include</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:param</span> <span class="attr">name</span>=<span class="string">"pname"</span> <span class="attr">value</span>=<span class="string">"pvalue"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:forward</span> <span class="attr">file</span>=<span class="string">"/include/h2.jsp"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">jsp:param</span> <span class="attr">name</span>=<span class="string">"p2"</span> <span class="attr">value</span>=<span class="string">"234"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">jsp:forward</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:useBean</span> <span class="attr">id</span>=<span class="string">"b1"</span> <span class="attr">class</span>=<span class="string">"com.a.BeanA"</span> <span class="attr">scope</span>=<span class="string">"session"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:setProperty</span> <span class="attr">name</span>=<span class="string">"b1"</span> <span class="attr">property</span>=<span class="string">"age"</span> <span class="attr">value</span>=<span class="string">"123"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:setProperty</span> <span class="attr">name</span>=<span class="string">"b1"</span> <span class="attr">property</span>=<span class="string">"age"</span> <span class="attr">param</span>=<span class="string">"age"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">jsp:getProperty</span> <span class="attr">name</span>=<span class="string">"b1"</span> <span class="attr">property</span>=<span class="string">"age"</span>/&gt;</span>  <span class="comment">&lt;!--会输出--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%=</span> <span class="attr">b1.getAge</span>()%&gt;</span></span><br><span class="line"></span><br><span class="line">$&#123;param.username&#125; <span class="comment">&lt;!--获取参数--&gt;</span></span><br><span class="line">$&#123;sessionScope.p1&#125;  <span class="comment">&lt;!--获取session的属性--&gt;</span></span><br><span class="line">$&#123;header.Cache-Control&#125;  <span class="comment">&lt;!--获取请求头属性--&gt;</span></span><br><span class="line">$&#123;b1.username&#125;  <span class="comment">&lt;!--获取javaBean属性--&gt;</span></span><br><span class="line">....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">--Tomcat连接池--</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Context</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Resource</span> <span class="attr">name</span>=<span class="string">"jdbc/mysqlds"</span> </span></span><br><span class="line"><span class="tag">	    <span class="attr">auth</span>=<span class="string">"Container"</span> //验证方式为容器</span></span><br><span class="line"><span class="tag">	    <span class="attr">type</span>=<span class="string">"javax.sql.DataSource"</span>     //数据源类</span></span><br><span class="line"><span class="tag">	    <span class="attr">username</span>=<span class="string">"root"</span> </span></span><br><span class="line"><span class="tag">	    <span class="attr">password</span>=<span class="string">"root"</span> </span></span><br><span class="line"><span class="tag">	    <span class="attr">maxIdle</span>=<span class="string">"30"</span>   //最多维持几个空闲连接 <span class="attr">minIdel:</span>最少维持几个空闲连接(即使没有需求)</span></span><br><span class="line"><span class="tag">	    <span class="attr">maxWait</span>=<span class="string">"10000"</span>  //最大等待时间（毫秒) 借出连接的最长期限</span></span><br><span class="line"><span class="tag">	    <span class="attr">initialSize</span>=<span class="string">"20"</span> //初始化时创建多少个连接</span></span><br><span class="line"><span class="tag">	    <span class="attr">maxActive</span>=<span class="string">"100"</span> //最大连接数</span></span><br><span class="line"><span class="tag">	    </span></span><br><span class="line"><span class="tag">	    <span class="attr">driverClassName</span>=<span class="string">"com.mysql.jdbc.Driver"</span> //数据库驱动</span></span><br><span class="line"><span class="tag">	    <span class="attr">url</span>=<span class="string">"jdbc:mysql://127.0.0.1:3306/db_blog"</span> //数据库<span class="attr">url</span>地址</span></span><br><span class="line"><span class="tag">	    <span class="attr">logAbandoned</span>=<span class="string">"true"</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Context</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"><span class="comment">&lt;!--spring连接池--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"locations"</span> <span class="attr">value</span>=<span class="string">"classpath:com/something/jdbc.properties"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!----使用配置文件注入的方式---&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"dataSource"</span> <span class="attr">destroy-method</span>=<span class="string">"close"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">"org.apache.commons.dbcp.BasicDataSource"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClassName"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.driverClassName&#125;"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"url"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.url&#125;"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.username&#125;"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.password&#125;"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--spring mvc配置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!--导入spring框架--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">listener</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">listener-class</span>&gt;</span>org.springframework.web.context.ContentLoaderListener<span class="tag">&lt;/<span class="name">listener-class</span>&gt;</span>  <span class="comment">&lt;!--会创建 applicationcontext 是parent--&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Listener</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">content-param</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>contextConfigLocation<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">param-value</span>&gt;</span>/WEB-INF/app-context.xml<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">content-param</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">absolute-ordering</span> /&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">&lt;!--配置DispatcherServlet--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>app<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>org.springframwork.web.servlet.DispatcherServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span>   <span class="comment">&lt;!--会创建 applicationcontext--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">init-param</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-name</span>&gt;</span>contextConfigLocation<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">param-value</span>&gt;</span><span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">load-on-startup</span>&gt;</span>1<span class="tag">&lt;/<span class="name">load-on-start-up</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>app<span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--spring配置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mvc:annotation-driven</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"com.abc.project.controller"</span> /&gt;</span> <span class="comment">&lt;!--扫描包--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">context:property-placeholder</span> <span class="attr">location</span>=<span class="string">"classpath:test.property"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">mvc:resource</span> <span class="attr">mapping</span>=<span class="string">"/js/**"</span> <span class="attr">location</span>=<span class="string">"/WEB-INF/js/"</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">mvc:resource</span> <span class="attr">mapping</span>=<span class="string">"/css/**"</span> <span class="attr">location</span>=<span class="string">"WEB-INF/css/"</span> /&gt;</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"t1"</span> <span class="attr">class</span>=<span class="string">"com.aaa.xx.BeanA"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">type</span>=<span class="string">"int"</span> <span class="attr">value</span>=<span class="string">"111333"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"b2"</span> <span class="attr">class</span>=<span class="string">"com.aaa.xx.BeanB"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"p1"</span>&gt;</span></span><br><span class="line">    			<span class="tag">&lt;<span class="name">ref</span> <span class="attr">bean</span>=<span class="string">"anotherExampleBean"</span>/&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"integerProperty"</span> <span class="attr">value</span>=<span class="string">"1"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">	</span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--java.lang.* javax.servlet.* javax.severlet.jsp.*  三个是jsp已加载的基本类--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--JSP的翻译过程</span></span><br><span class="line"><span class="comment">&lt;%! %&gt;声明语句，可以声明成员变量，语句块，自定义方法，  翻译方法：转换成servlet的成员属性或者成员方法的声明</span></span><br><span class="line"><span class="comment">&lt;% %&gt;脚本段，不能声明，定义静态语句块，方法 原封不动地成为servlet的一部分</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">&lt;package name="demo1" extends="struts-default" namespace="/"&gt;</span></span><br><span class="line"><span class="comment">&lt;action name="*_*" class="com.xxx.&#123;1&#125;" method="&#123;2&#125;" &gt;</span></span><br><span class="line"><span class="comment">	&lt;result name="hello"&gt;/jsps/aaa/jsp&lt;/result&gt;</span></span><br><span class="line"><span class="comment">&lt;/action&gt;</span></span><br><span class="line"><span class="comment">&lt;/package&gt;</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>JavaEE复习笔记</title>
    <url>/2019/12/27/JavaEE%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="JavaEE复习笔记"><a href="#JavaEE复习笔记" class="headerlink" title="JavaEE复习笔记"></a>JavaEE复习笔记</h2><blockquote>
<p>根据上课的笔记整理与补充。<br>contact: 405544641@qq.com</p>
</blockquote>
<p>Spring的思想 <strong>控制翻转</strong>:让容器管理对象的创建与销毁，<strong>依赖注入</strong>:利用<strong>反射</strong>实现，动态地向一个对象提供其所需的其他对象</p>
<p>JavaEE三大组件: Servlet, Filter, Listener<br>组件必须有 <strong>init(conf)</strong>  <strong>destroy()</strong></p>
<h5 id="web容器-servlet容器"><a href="#web容器-servlet容器" class="headerlink" title="web容器(servlet容器)"></a>web容器(servlet容器)</h5><p>请求怎么来到servlet呢？答案是servlet容器，比如我们最常用的tomcat，同样，你可以随便谷歌一个servlet的hello world教程，里面肯定会让你把servlet部署到一个容器中，不然你的servlet压根不会起作用。<br>tomcat才是与客户端直接打交道的家伙，他监听了端口，请求过来后，根据url等信息，确定要将请求交给哪个servlet去处理，然后调用那个servlet的service方法，service方法返回一个response对象，tomcat再把这个response返回给客户端。</p>
<p>import javax.servlet servlet是个接口<br>HttpServlert实现Servlet<br>使用Servlet ServletRequest ServletRespond<br>1.首先要在web.xml中进行配置</p>
<pre><code>&lt;servlet&gt;
    &lt;servlet-name&gt;A&lt;/servlet-name&gt;   //servlet名
    &lt;servlet-class&gt;com.xxx.xx.xx.servlet类名&lt;/servlet-class&gt;  //对应的类
    &lt;init-param&gt;   //初始化参数
        &lt;param-name&gt;p1&lt;/param-name&gt;&lt;param-value&gt;123&lt;/param-value&gt;
    &lt;/init-param&gt;
&lt;/servlet&gt;
//! 到这为止已经定义好servlet,不会有任何错误。 当服务器启动后，也会创建好servlet. 但是无法访问因为没mapping
&lt;servlet-mapping&gt;
    &lt;servlet-name&gt;A&lt;/servlet-name&gt; //要和上面对应
    &lt;url-pattern&gt;/login&lt;/url-pattern&gt;     //注意 /代表的是web Content的位置
&lt;/servlet-mapping&gt;


**url-pattern:  /是缺省匹配，若当前访问资源地址的所有 Servlet 都不匹配时，就由缺省的 Servlet 进行处理
               优先级:全路径匹配&gt;部分路径匹配&gt;拓展名匹配
               如果我们web应该中同时配置&quot;/&quot;和&quot;/*&quot;，那么默认的Servelt永远都不会被匹配到，所有的路径最终都会匹配到&quot;/*&quot;上
               /不能匹配jsp,原因是jsp容器已经默认映射了一个*.jsp,优先级要高于/  /*可以
               精确路径匹配&gt;最长路径匹配&gt;扩展匹配     /a/*.xxx 这样方式会报错。不能混搭。
注：Filter不会像servlet只匹配一个。 顺序与定义顺序相同
/*和/** 后者会匹配更多的目录 (Ant path匹配。spring支持。还支持正则表达式,进行更复杂的匹配)
</code></pre><p>关于url-pattern的/, 同样在struts中，默认映射了<em>.action </em>.do ,  /无法覆盖他们<br>strut2的配置文件加载顺序为： </p>
<pre><code>   Struts-default.xml---&gt; struts-plugin.xml--&gt; struts.xml--&gt;   struts.properties--&gt; web.xml
</code></pre><p><strong>使用servlet</strong></p>
<pre><code>//AServlet.java
package a; //倒序 com.xxx,部门,项目:模块

////先引入这3个包
import javax.servlet.*;
import javax.servlet.http.*;
import java.io.*;
public class AServlet extends HttpServlet{


   /*  默认已经实现
   private ServletConfig config;
   @Ovrride
   public void init(ServletConfig config) throws ServletException{
      super(config);
      init();
    }*/

    @Override
    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws    IOException,ServletException{
    response.setContentType(&quot;text/html;charset=UTF-8&quot;);  //默认ISO8859-1
    response.setCharacterEncoding(&quot;UTF-8&quot;)//设置编码
    PrintWriter out=response.getWriter();
    out.println(&quot;&lt;h1&gt;this is servlet&lt;/h1&gt;&quot;);
    //不要close()   谁创建的流谁负责关闭
        }

    @Ovrride
    protected void doPost(HttpServletRequest request,HttpServletResponse){
    }

/*
    @Override
    public void destroy(){
        super.destroy();
    }

    @Override
    public void service(SevletRequest req,ServletResponse res) throws ServletException,IOException{



       res.setContextType(&quot;text/html&quot;)；
       PrintWriter out=response.getWriter();
       out.println(&quot;this is servlet&quot;);

       //获取config
       //getServletConfig();
        //!!!!考ServletConfig   的函数

       HttpServletRquest hsr=(HttpServeltRequest) req;
       HttpServletResponse hsres=(HttpServletResponse) res;
       //GET / HTTP/1.1\r\n            
       //GET /HTTP/a HTTP/1.1\r\n
       String method=res.getMethod();
       if(method.compareTo(&quot;POST&quot;)==0){
           doPost(req,res);
       }else if(&quot;GET&quot;.equals(method)){
            doGet(req,res);
       }

}      
*/
   }
</code></pre><p>注意事项</p>
<ul>
<li>doPost doGet serice 一般抛2个异常  ServletException 和IOException</li>
<li>serve的两个参数是ServletRequest和ServletResponse</li>
<li>Context-Type: </li>
<li><ul>
<li>text/html ： HTML格式<br>text/plain ：纯文本格式<br>text/xml ：  XML格式<br>image/gif ：gif图片格式<br>image/jpeg ：jpg图片格式<br>image/png：png图片格式<br>application/xhtml+xml ：XHTML格式<br>application/xml     ： XML数据格式<br>application/atom+xml  ：Atom XML聚合格式<br>application/json    ： JSON数据格式<br>application/pdf       ：pdf格式<br>application/msword  ： Word文档格式<br>application/octet-stream ： 二进制流数据（如常见的文件下载）</li>
</ul>
</li>
</ul>
<ul>
<li>用<strong>this.getServletConfig().getInitParameter(String);</strong> 获取servlet的初始化参数<br><img src="./1576752145733.png" alt="Alt text"><br>每个servlet有一个servletconfig,但是全局只有一个servletcontext (每个web应用仅有一个，servletcontext也可以叫applicationContext,是最大的web域对象)</li>
</ul>
<p>使用<strong>response.setContentType(String);</strong>设置 如text/html;charset=UTF-8</p>
<ul>
<li>输出办法: 首先从response.getWriter();获取PrintWriter对象，之后利用其进行流操作输出  (<strong>println();</strong>)</li>
<li>HttpServlet 中已存在 service()方法.缺省的服务功能是调用与 HTTP 请求的方法相应的 do 功能。<br>例如,如果 HTTP 请求方法为 GET,则缺省情况下就调用 doGet()。   super(req,res)</li>
</ul>
<p>setContentType(String) 和 setCharacterEncoding()的区别:前者设置的是页面的静态文字编码（浏览器显示的编码），后者关系到动态参数的编码</p>
<p>HTTP缓存<strong>(课上说的必考，但是考纲好像又没有)</strong></p>
<ul>
<li><p>http缓存有<strong>强缓存</strong>,<strong>协商缓存</strong><br>步骤1. 浏览器先根据这个资源的http头信息来判断是否命中强缓存。如果命中则直接加在缓存中的资源，并不会将请求发送到服务器。 (返回<strong>200</strong>)<br>2.如果未命中强缓存，则浏览器会将资源加载请求发送到服务器。服务器来判断浏览器本地缓存是否失效。若可以使用，则服务器并不会返回资源信息，浏览器继续从缓存加载资源。<br>3.如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存。</p>
</li>
<li><p><strong>强缓存</strong>: 利用http的返回头中的<strong>Expires</strong>或者<strong>Cache-Control</strong>两个字段来控制的。前者表示缓存过期时间(具体时间)，后者表示相对时间。如Cache-Control:3600，代表着资源的有效期是3600秒。所以服务器与客户端时间偏差也不会导致问题。<br><strong>同时启用的时候Cache-Control优先级高</strong></p>
</li>
<li><ul>
<li>Cache-Control可包含的字段:<br>1.max-age 单位s<br>2.s-maxage 同1,只适用于共享缓存，私有缓存中被省略<br>3.public 响应可以被任何对象缓存<br>4.private 响应只能被单个用户，非共享。不能被代理服务器缓存<br>5.<strong>no-cache:</strong>强制缓存了响应的用户，在使用数据前都要先发请求到服务器<br>6.<strong>no-store</strong>:禁止缓存</li>
</ul>
</li>
<li><p><strong>协商缓存:</strong><br>服务器根据http头信息中的Last-Modify/If-Modify-Since或Etag/If-None-Match来判断是否命中协商缓存。如果命中，则http返回码为<strong>304</strong>，浏览器从缓存中加载资源。</p>
</li>
</ul>
<p>Last-Modify/If-Modify-Since<br>ETag/If-None-Match<br>与Last-Modify/If-Modify-Since不同的是，Etag/If-None-Match返回的是一个校验码（ETag: entity tag）。ETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化*。ETag值的变更则说明资源状态已经被修改。服务器根据浏览器上发送的If-None-Match值来判断是否命中缓存。</p>
<p><img src="./1576666287803.png" alt="Alt text"></p>
<p><strong>ServletRequest</strong><br><strong>&gt;&gt;getAttribute(String)</strong> //获取存在request的属性  是Object<br><strong>&gt;&gt;getAttributeNames()</strong>  //Enumeration  用hasMoreElements() nextElement()进行遍历<br><strong>&gt;&gt;getParameter(String)</strong>//获取存在request的参数  只能是String  (可以获得通过get post传进来的数据)<br><strong>&gt;&gt;getParameterNames()</strong> //返回迭代器<br><strong>&gt;&gt;getParameterValues()</strong>  //返回String[]<br><img src="./1576668415360.png" alt="Alt text"></p>
<p><strong>&gt;&gt;getProtocol()</strong><br><strong>&gt;&gt;getRealPath(String path)</strong> //寻找某个资源在服务器文件系统上的实际地址<br><strong>&gt;&gt;getServletContext()</strong></p>
<p><strong>HttpServletResponse</strong><br><strong>&gt;&gt;addCookie(Cookie cookie)</strong>      //添加一个cookies</p>
<blockquote>
<p>new Cookie(String name, String value)  之后可以用setMaxAge设置有效时间(秒)</p>
</blockquote>
<p><strong>&gt;&gt;getHeader(String name)</strong><br><strong>&gt;&gt;addHeader(String name, String value)</strong><br>//继承来的<br><strong>&gt;&gt;    getWriter()</strong><br><strong>&gt;&gt;setContentType(String type)</strong></p>
<ul>
<li><strong>ServletConfig getServletConfig(); //必考</strong></li>
</ul>
<p><strong>ServletConfig</strong></p>
<ul>
<li><strong>getInitParameter(String name)</strong></li>
<li><strong>getServletName()</strong></li>
<li><strong>getServletContext()</strong></li>
</ul>
<p>!!!! 必考<strong>ServletContext</strong><br>context可以直接在servlet里get,也可以从request.getSession().getServletContext() 也可以 request.getServletContext();<br>常见的有6种方式可以Get到serveletContext:</p>
<ul>
<li>在servlet类里get</li>
<li>reques.get   //从request get   (域对象 )</li>
<li>request.getSession().get  //从http session get   (域对象)</li>
<li>servletConfig.get  //从servletconfig里get</li>
<li>ServletContextEvent对象里get</li>
<li>PageContext里get   (域对象)</li>
</ul>
<p>也就是从另外三大web域对象都可以get到,再加上从context事件还有servlet配置，还有servlet本身get</p>
<p>servletcontent.getRealPath(“/“)和servletcontent.getContextPath()的区别<br>前面是获取ServletContext 所在的文件系统上的实际位置。  后者是获取配置的servletContext路径</p>
<blockquote>
<p>ServletContext官方叫servlet上下文。服务器会为每一个<strong>应用创建一个对象</strong>，这个对象就是ServletContext对象。这个对象全局唯一，而且工程内部的所有servlet都共享这个对象。所以叫全局应用程序共享对象。<br>凡是域对象都有如下3个方法：</p>
</blockquote>
<p><strong>setAttribute(name,value);</strong>name是String类型，value是Object类型；</p>
<p>往域对象里面添加数据，添加时以key-value形式添加</p>
<p><strong>getAttribute(name);</strong></p>
<p>根据指定的key读取域对象里面的数据</p>
<p><strong>removeAttribute(name);</strong></p>
<p>根据指定的key从域对象里面删除数据</p>
<p>同时因为都是web域对象。所以除servletcontext外，<strong>其他三个域都能通过getServletContext()</strong>获取到servletContext</p>
<p>可以获取web.xml中的全局参数</p>
<pre><code>  &lt;context-param&gt;
         &lt;param-name&gt;param1&lt;/param-name&gt;
         &lt;param-value&gt;value1&lt;/param-value&gt;
  &lt;/context-param&gt;
 用servletContext.getInitParameter(parameName);获取
</code></pre><p><strong>&gt;&gt;getContextPath()；</strong><br>设置contextpath的方式<br>/META-INF/context.xml</p>
<p>!!<strong>可以获取servletContext()的方式</strong></p>
<ul>
<li>ServletConfig的getServletContext()</li>
<li>request.getSession().getServletContext()</li>
<li>直接 getServletContext();</li>
</ul>
<p><strong>WEB应用结构</strong></p>
<blockquote>
<p>xxxxxxxxxxxx\first<br>   -&gt;               WEB-INF<br>    ——&gt;                   classes<br>     ——&gt;                lib<br>             ——&gt;            web.xml<br>             -&gt;     META-INF<br>               ——&gt;          context.xml    </p>
</blockquote>
<p>!!!<strong>URL 三部分</strong><br>1.schema 2.服务器位置 3.资源路径</p>
<pre><code>&lt;schema&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;:&lt;params&gt;?&lt;query&gt;#&lt;frag&gt;
</code></pre><h4 id="header"><a href="#header" class="headerlink" title="header"></a>header</h4><p>http的两部分内容:header body <strong>,header项用\r\n区分</strong>,区分 两次回车换行<br><img src="./1576751175527.png" alt="Alt text"></p>
<blockquote>
<p><strong>编码</strong> base64:3个字节为一组  ucs:任何一个字符都是4字节</p>
</blockquote>
<p><strong>http状态码：</strong></p>
<p>2xx OK<br>3xx 重定向<br>—&gt;302 Object Moved <img src="./1577526473068.png" alt="Alt text"> 要根据Location重新发请求</p>
<p>4xx 客户端错误<br>—&gt;401 (访问拒绝)客户端证书无效,账号密码错误<br>—&gt;403 Access Forbidden 请求结构正确。但是服务器不想处理.403暗示了所请求的资源确实存在。跟401一样，若服务器不想透露此信息，它可以谎报一个404<br>—&gt;404 资源不存在<br>—&gt;405 请求方法错误。比如用了不支持的协议，或者不支持get,结果用了get</p>
<p>5xx:服务器端错误<br>502 代理错误<br>500 异常<br>501 服务器不能识别一个方法。类似405,但是405是能够被服务器识别，但是资源不支持该方法.<br><strong>101表示服务器已经理解了客户端的请求，并将通过Upgrade消息头通知客户端采用不同的协议来完成这个请求。</strong></p>
<p><strong>web.xml</strong></p>
<pre><code>&lt;welcome-file-list&gt;  //可以设置多个,可以访问到web-inf内的文件,会返回第一个找到的文件，找不到就404,首页的路径只能是一个实际存在的物理文件地址，不能将首页设置成Servlet或Controller的地址，再通过来Servlet或Controller返回一个页面
     &lt;welcome-file&gt;a.jsp&lt;/welcome-file&gt;
     &lt;welcome-file&gt;b.html&lt;/welcome-file&gt;
     &lt;welcome-file&gt;c.html&lt;/welcome-file&gt;
&lt;/welcome-file-list&gt;
</code></pre><p>xml区分大小写</p>
<h3 id="部署web-application在Tomcat"><a href="#部署web-application在Tomcat" class="headerlink" title="部署web application在Tomcat"></a>部署web application在Tomcat</h3><pre><code>&lt;Host name=&quot;localhost&quot;  appBase=&quot;webapps&quot;
        unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;


    &lt;!-- 部署 &quot;三个&quot; web application  --&gt;
    &lt;Context path=&quot;/a&quot; docBase=&quot;/somefoler/first&quot;/&gt;  //虚拟路径1 context path=/a
    &lt;Context path=&quot;/s&quot; docBase=&quot;/otherfolder/second&quot;/&gt; //虚拟路径2 context path=/s
    &lt;Context path=&quot;&quot; docBase=&quot;/otherfolder/second&quot;/&gt;   //虚拟路径3

    &lt;!-- SingleSignOn valve, share authentication between web applications
         Documentation at: /docs/config/valve.html --&gt;
    &lt;!--
    &lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt;
    --&gt;

    &lt;!-- Access log processes all example.
         Documentation at: /docs/config/valve.html
         Note: The pattern used is equivalent to using pattern=&quot;common&quot; --&gt;
    &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;
           prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;
           pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;

  &lt;/Host&gt;
</code></pre><p><strong>!!如何自己设计ServletContext().getRealPath(); </strong><br>A: ServletContext().getContextPath();可以用，然后去tomact的 server.xml中寻找对应docBase..然后就可以get到了,如果docBase是相对路径的话，也可以根据tomcat所在路径加上这个相对位置确定</p>
<pre><code>//使用真实路径读取文件
String filename = getServletContext().getRealPath(&quot;/WEB-INF/aFolder/a.txt&quot;);
FileInputStream fis = new FileInputStream(filename);
</code></pre><h3 id="web-socket"><a href="#web-socket" class="headerlink" title="web socket"></a>web socket</h3><blockquote>
<p>现在前后端通讯的常用的方式有ajax，websocket，还有fetch</p>
</blockquote>
<pre><code>  //创建套接字
  Socket s = new Socket(&quot;www.baidu.com&quot;, 80);  //这是Java的Socket建立过程。直接访问底层的TCP协议。
  var socket = new WebSocket(&quot;ws://localhost:8080/websocket1/b&quot;);  //JavaScript代码。
</code></pre><p>websocket可以跨域访问。非常灵活。</p>
<pre><code>Connection: Upgrade
Cookie: JSESSIONID=6FFBEA8EB6951EAD7D123A2D7ED70861
Host: localhost:8080
Origin: http://localhost:8080
Sec-WebSocket-Key: 6ZxylD/4f4qccKeapm3LEQ==
Sec-WebSocket-Version: 13
Upgrade: websocket
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko
</code></pre><p>响应代码：101，不是200， 101表示服务器已经理解了客户端的请求，并将通过Upgrade消息头通知客户端采用不同的协议来完成这个请求。<br>    在发送完这个响应最后的空行后，服务器将会切换到 在Upgrade消息头中定义的那些协议。: 只有在切换新的协议更有好处的时候才应该采取类似措施。<br>    例如，切换到新的HTTP版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。</p>
<pre><code>    Connection: upgrade
    Date: Thu, 12 Sep 2019 00:54:07 GMT
    Sec-WebSocket-Accept: 5uiTO0X9qutU+74Ugp/7eMHoXQk=
    Upgrade: websocket
</code></pre><p>和以往的http请求不同，增加了Connection: Upgrade， Upgrade： websocket等请求头，大家理解，客户端请求建立websocket.<br>    服务器可以不支持。当然，客户端程序来自同一个服务器，在某个使用websocket的应用中，显然支持。我们的JavaEE版本8支持websocket.<br>    至于请求中的Sec-WebSocket-Key, 是base64编码，源数据是16个字节的随机数。服务器收到这个数据， 并不做Base64解码，而是直接拼上一个magic字符串，<br>    “258EAFA5-E914-47DA-95CA-C5AB0DC85B11”, 然后转换为utf-8编码的字节数组，最后做SHA1，（见MD5,CRC,SHA-1,SHA-256）。<br>    对SHA1产生的20个字节（160个比特位）做BASE64，然后就是Sec-WebSocket-Accept: 5uiTO0X9qutU+74Ugp/7eMHoXQk=, 返回给客户端。<br>    客户端当然做同样的算法，然后做比对，实际上就是完成websocket的握手过程。</p>
<pre><code>握手完毕，http协议“转换”到websocket协议。
</code></pre><ul>
<li>1、客户端：申请协议升级</li>
<li>2.服务端：响应协议升级 :状态代码101表示协议切换。到此完成协议升级，后续的数据交互都按照新的协议来。</li>
<li>3、Sec-WebSocket-Accept的计算 :Sec-WebSocket-Accept根据<strong>客户端请求首部</strong>的Sec-WebSocket-Key计算出来。</li>
</ul>
<p><img src="./1576755405347.png" alt="Alt text"></p>
<pre><code>实例:
// Create WebSocket connection.
const socket = new WebSocket(&#39;ws://localhost:8080&#39;);

// Connection opened
socket.addEventListener(&#39;open&#39;, function (event) {
    socket.send(&#39;Hello Server!&#39;);
});

// Listen for messages
socket.addEventListener(&#39;message&#39;, function (event) {
    console.log(&#39;Message from server &#39;, event.data);
});

//javaee
@ServerEndpoint(&quot;/chatroom/{roomId}/{nickName}&quot;)    //挂一个服务器资源
public class ChatRoomServer{
        @OnOpen//连接打开时
        public void onOpen(Session session,@PathParam(&quot;roomId&quot;) long roomId,
        @PathParam(&quot;nickName&quot;) String unDecName){
        }  //可以注入参数
        @OnMessage  //消息抵达

        public void onMessage(Session session, String message, @PathParam(&quot;roomId&quot;) long roomId, 
        @PathParam(&quot;nickName&quot;) String unDecName)
        {

        }

        @OnClose
        public void onClose(Session session, @PathParam(&quot;roomId&quot;) long roomId, 
            @PathParam(&quot;nickName&quot;) String unDecName)
        {}


}
</code></pre><p><img src="./1576755801639.png" alt="Alt text"></p>
<pre><code>package a;

//Socket客户端
import java.io.*;
import java.net.*;

import javax.websocket.*;

@ClientEndpoint
public class WebSocketClienet {

//就是例子代码，只有一个session
public static Session session = null;

@OnOpen
public void onOpen(Session session) {
    try {
        this.session = session;
        System.out.println(&quot;create a session.&quot;);
        session.getBasicRemote().sendText(&quot;hello&quot;);
        System.out.println(&quot;send hello to server.&quot;);

    } catch (IOException ex) {

    }
}

@OnMessage
public void processMessage(Session session, String message, boolean last) {
    System.out.println(message);
}

@OnClose
public void end() {
    System.out.println(&quot;bye server.&quot;);
}

@OnError
public void onError(Throwable t) throws Throwable {
    System.out.println(&quot;meet some exception in client.&quot;);
    t.printStackTrace();
}



public static void main(String[] args) throws Exception {
    WebSocketContainer container = ContainerProvider.getWebSocketContainer();  //获取web容器
    container.connectToServer(WebSocketClienet.class, URI.create(&quot;ws://localhost:8080/websocket1/b&quot;));   //连接到服务器

    for(int i = 0; i &lt; 10; i++) {
        Thread.sleep(1000);
        session.getBasicRemote().sendText(&quot;&quot; + new java.util.Date());
    }
    session.close();
}

}
</code></pre><h4 id="Server-Sent-Event-SSE-服务器向客户端发送消息-应该是只做了解"><a href="#Server-Sent-Event-SSE-服务器向客户端发送消息-应该是只做了解" class="headerlink" title="Server Sent Event(SSE):服务器向客户端发送消息 (应该是只做了解)"></a>Server Sent Event(SSE):服务器向客户端发送消息 (应该是只做了解)</h4><blockquote>
<p>一般服务器向客户端发送消息常用的方式就是用setInterval去做轮询或者是websocket。只是前者setInterval<strong>（//每60秒执行myFunction()一次 setInterval(“myFunction()”,60000); ）</strong>轮询这个中间的时间间隔需要考虑好，如果事件间隔较短，这对服务器的压力比较大，如果事件较长，则有些需要立即立即做出响应的方式是做不到的。后者的websocket相对来说技技术要求有点高，实现起来比较复杂。所以就有现在的这种方式就是Server-sent Events我们只需要需要在服务器端将事件流发送给前端，然后前端接收到后端所传给的事件流，然后触发事件，这是事件的捕获和监听其实和前端的事件捕获和触发是一样的</p>
</blockquote>
<p>用法:</p>
<pre><code>var evtSource = new EventSource(&#39;/sse&#39;); //创建es对象，/sse是服务器端给的向前端发送事件的接口地址。通过get方式进行发送事件。
//var evtSource = new EventSource(&#39;http://www.baidu.com&#39;, { withCredentials: true }); (如果跨域)
//至此接收器创建好了
evtSource.onmessage = function (e) {
      console.log(e.data)
}
//也就是当后端发送的内容之后就会进行触发，并且将data给打印出来，首先要提出的的是，Server-sent Events 所发送的内容都是字符串的流而且是通过utf-8的编码格式的，如果后端希望给前端发送一串json，也需要将json转化成相对应的字符串，然后在发送给前端，前端接收之后，再讲所发送的字符串转换成json，然后进行处理。

//然后就是监听后端发送给前端的事件内容，不如说，我们后端给前端sent一个testEvent事件，前端通过事件接收者，去触犯相对应的事件监听，因此就有了下面的工作流程
evtSource.addEventListener(&#39;testEvent&#39;, function (e) {
      console.log(e)
})
...
后端应该如何才能给我们发送事件呢，
首先我们发送内容是需要给前端设置一个mime为text/event-stream,然后在进行发送事件的内容
&#39;Content-Type&#39;: &#39;text/event-stream&#39;
</code></pre><ul>
<li><strong>注解@Endpoint(“/b”)</strong> // @ServerEndpoint(“/b”)指定服务器资源</li>
<li>sse使用 javax.socket.endpoint</li>
</ul>
<h4 id="javax-websocket-Endpoint类"><a href="#javax-websocket-Endpoint类" class="headerlink" title="javax.websocket.Endpoint类"></a>javax.websocket.Endpoint类</h4><p>使用方法。一个类继承Endpoint,之后重写onOpen,onClose,onError<br>对于Socket来说，每一端都是一个EndPoint<br>还可以具体一点，用ServerEndpoint或者ClientEndpoint</p>
<h4 id="Session-接口-websocket的"><a href="#Session-接口-websocket的" class="headerlink" title="Session 接口  (websocket的)"></a>Session 接口  (websocket的)</h4><p><strong>&gt;&gt;  getBasicRemote()</strong> :返回RemoteEndpoint object，getAsyncRemote是非阻塞式的，getBasicRemote是阻塞式的</p>
<blockquote>
<p>大部分情况下，推荐使用getAsyncRemote()。由于getBasicRemote()的同步特性，并且它支持部分消息的发送即sendText(xxx,boolean isLast). isLast的值表示是否一次发送消息中的部分消息，对于如下情况:<br>           session.getBasicRemote().sendText(message, false);<br>           session.getBasicRemote().sendBinary(data);<br>           session.getBasicRemote().sendText(message, true);<br>                   由于同步特性，第二行的消息必须等待第一行的发送完成才能进行，而第一行的剩余部分消息要等第二行发送完才能继续发送，所以在第二行会抛出IllegalStateException异常。如果要使用getBasicRemote()同步发送消息，则避免尽量一次发送全部消息，使用部分消息来发送。</p>
</blockquote>
<p><strong>&gt;&gt;WebSocketContainer    getContainer()</strong></p>
<h4 id="WebSocketContainer"><a href="#WebSocketContainer" class="headerlink" title="WebSocketContainer"></a>WebSocketContainer</h4><p><strong>connectToServer(class,URI)</strong> ，返回Session</p>
<p>所以…. session &lt;-&gt; WebSocketContainer 可以相互获取。  session是从container连接服务器后来的.</p>
<p>至于<strong>Endpoint</strong>,客户端和服务器都是一个Endpoint</p>
<h3 id="HttpSession"><a href="#HttpSession" class="headerlink" title="HttpSession"></a>HttpSession</h3><pre><code>import javax.servlet.http.*;
</code></pre><p>其是一个域对象。因此也具有<br><strong>getAttribute(String)</strong>,<strong>setAttribute(String,Object)</strong>等函数<br>同时有<strong>getID()</strong>,<strong>getServletContext()</strong>等函数<br><strong>创建时间 getCreationTime()</strong><br><strong>set/getMaxInactiveInterval()</strong> //超时时间</p>
<p>设置超时时间<br>也可以在web.xml中</p>
<pre><code>&lt;session-config&gt;
    &lt;session-timeout&gt;2&lt;/session-timeout&gt;  //2分钟,默认为30
&lt;/session-config&gt;
#也可以session.setMaxInactiveInterval（30*60）;
</code></pre><ul>
<li><strong>扔到Attribute中的对象要序列化</strong></li>
</ul>
<blockquote>
<p><strong>Q:如何识别一个request是某个会话的</strong><br>tomcat有个全局的map,产生的session对象的id一定放在<strong>response中，返回给浏览器.</strong>下次请求会带上它</p>
</blockquote>
<p>一般来说Session是基于Cookie实现的,<br><strong>!!!会话追踪手段</strong></p>
<ul>
<li>手段1：cookies.</li>
<li>手段2: URL重写 如果浏览器不支持Cookie或用户阻止了所有Cookie，可以把会话ID附加在HTML页面中所有的URL上，这些页面作为响应发送给客户。这样，当用户单击URL时，<strong>会话ID被自动作为请求行的一部分</strong>而不是作为头行发送回服务器。这种方法称为URL重写(URL rewriting)。</li>
<li><p>手段3:隐藏域     </p>
<pre><code>  使用隐藏域：&lt;input type=&quot;hidden&quot; name=&quot;…&quot; value=&quot;…&quot;&gt;
</code></pre><p>jsessionID ssessionID …</p>
</li>
</ul>
<p>刷新是个问题<br>有时不用httpsession, 把会话信息放在分布式存储系统。只要ID在就行</p>
<h4 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h4><pre><code>response.addCookies(Cookies);
//Cookie(String name, String value)
还可以setMaxAge()设置生存时间
还有serDomain设置有效域 （于是可以跨域共享cookie）
setPath(String uri) 也和上面差不多，可以指定cookie有效的地址（支持通配符）
setHttpOnly(boolean isHttpOnly)
</code></pre><h4 id="压缩-要考"><a href="#压缩-要考" class="headerlink" title="压缩(要考)"></a>压缩(要考)</h4><p><strong>gzip</strong>是一种数据格式，默认且目前仅使用deflate算法压缩data部分；<br><img src="./1576837387364.png" alt="Alt text"><br><img src="./1576837550820.png" alt="Alt text"></p>
<h4 id="RequestDispatcher"><a href="#RequestDispatcher" class="headerlink" title="RequestDispatcher"></a>RequestDispatcher</h4><p>可以用requestDispatcher来分发请求到多个组件去处理。</p>
<blockquote>
<p>从ServletRequest.getRequestDispatcher(java.lang.String)获取</p>
<p>rd.forward() //转发，让其他组件去处理，自己不管了<br>rd.include(request,response) 包含.是让其他组件去处理，但是还会返回来，自己继续处理</p>
</blockquote>
<p>!!<strong>Interface SingleThreadMode()   //保证不会有多个线程执行service函数</strong></p>
<p>解决并发访问的两种方法：</p>
<ul>
<li>1.加锁</li>
<li>2.数据复制</li>
</ul>
<p><strong>事务的ACID</strong></p>
<ul>
<li>A:原子性</li>
<li>C:一致性</li>
<li>I:隔离性</li>
<li>D:持久性</li>
</ul>
<p><strong>request.getContextPath(): </strong> 可以获取所配置的ServletContext路径</p>
<blockquote>
<p><strong>例:</strong><a href="http://localhost:8080/dmsd-itoo-exam-log-web/course/index.jsp，在tomcat中配置了application" target="_blank" rel="noopener">http://localhost:8080/dmsd-itoo-exam-log-web/course/index.jsp，在tomcat中配置了application</a> context为 /dmsd-itoo-exam-log-web<br>   request.getContextPath()，得到context路径：/dmsd-itoo-exam-log-web (取决于contextpath的配置)；<br>        request.getServletPath()，返回当前请求的资源相对于context的路径：/course/index.jsp；<br>request.getRequestURL()，返回请求资源的完整地址：<a href="http://localhost:8080/dmsd-itoo-exam-log-web/course/index.jsp；" target="_blank" rel="noopener">http://localhost:8080/dmsd-itoo-exam-log-web/course/index.jsp；</a><br> request.getRequestURI() ，返回包含Context路径的资源路径：/dmsd-itoo-exam-log-web/course/index.jsp。</p>
</blockquote>
<h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><pre><code>doFilter(ServletRequest request, ServletResponse response, FilterChain chain)


  import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
public mFliter implements Fliter{
   private FliterConfig config;
   public void destroy(){
   }
   public void doFliter(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException,IoException{
       chain.doFilter(req,res);  //当前过滤器处理结束，往下一个过滤器
       //多个过滤器会形成一个过滤器链，如果不想拦截下该请求的话，应该让Filter往下传，后面没有filter后就到达资源
    //想拦截的话可以什么都不干，也可以直接跳到另一个地方（用redirect,forwer之类的
   }
}
//Filter通常要做的事情：
//Filter最最最早执行。
//在资源到达后端之前就执行了。  也就是拦截器
//数据写在session里
//常见作用:1.认证 不拦截/login.html 2.日志 3.数据转换 4.数据压缩 5.加密 6
</code></pre><p>访问计时： 应该加在filter<br>getServletContext().log(“xxxxxxxxxxxx”);</p>
<p><strong>乱码解决</strong> (Filter不仅可以用来拦截不合法的请求，还可以用来编码转换)</p>
<pre><code>request.setCharcterEncoding(&quot;UTF-8&quot;); //可以用filter实现
String wd=new String(wd.getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;);



public class EncodingFilter(){
     public void doFilter(...){
         request.setCharacterEncoding(&quot;UTF-8&quot;);
         chain.doiFliter(req,res);
         //是ServletRquest，可以处理各种协议.
         HttpServletRequest request=()req;
         HttpServletRespond request=()res;
         HttpSession session=request.getSession();
         String name=()session.getAtrtribute(&quot;Username&quot;);
         if(username==null || username.length()==0){
             request.getRepondDispatcher(&quot;/login.html&quot;).forward(req,res);

         }
     }
 }
 //之后还要部署



    &lt;init-param&gt;&lt;param-name&gt;&lt;/&gt; &lt;param-value&gt;&lt;/&gt;&lt;/&gt;
    [servletConfigure.getConfig().]getInitParameter();



        &lt;/Filter&gt;
&lt;Filter-mapping&gt;
    &lt;url-pattern&gt; /aa/*&lt;/url-pattern&gt;  //可以过滤任何匹配的资源
    &lt;servlet-name&gt;&lt;/&gt;   //指定就过滤某个servlet
    &lt;dispatcher&gt;REQUEST&lt;/&gt; //默认，容器内所产生的请求不拦截  想拦截可以 FORWARD INCLUDE [ERROR]() 都拦截写多个dispatcher
&lt;/Filter-mapping&gt;


//登入服务里，登入完后，把值Set在session的attribute里
request.getSession().inavaild()//把session里面的东西都释放掉

在请求到达资源之前，先到过滤器
filter后面一般处理response.        
用forward过滤器一般不起作用

//Error 触发错误状态时会走过滤器
//include 通过&lt;jsp:include page=&quot;xxx.jsp&quot; /&gt;，嵌入进来的页面，每嵌入的一个页面，都会走一次指定的过滤器。    (servlet通过include指令过来的请求)
//Forward 当前页面是通过请求转发转发过来的场景，会走指定的过滤器

@WebFilter(dispatcherType={...,...})
</code></pre><h3 id="JSP"><a href="#JSP" class="headerlink" title="JSP"></a>JSP</h3><p>由于JSP需要编译，第一次会比较慢<br>其本质是一个servlet,jsp会被编译成servlet,通过调用service()函数，得到结果。浏览器是无法直接识别jsp的。<br>jsp不需要部署</p>
<pre><code>&lt;%= new java.util.Date() &amp;&gt;
    &lt;%@include file=&quot;footer.jsp&quot; %&gt;  //指令include 指令include会把代码直接插入进来用，最终只编译生成一个servlet
    &lt;jsp:include page=&quot;footer2.jsp&quot; %&gt; //动作include,会编译生成2个servlet,把另一个servlet生成的结果拿过来用
    //还可以传参
    //因为指令&lt;%@include 会导致两个jsp合并成为同一个java文件，所以就不存在传参的问题，在发出hello.jsp 里定义的变量，直接可以在footer.jsp中访问。
    //而动作其实是对footer.jsp进行了一次独立的访问，那么就有传参的需要。
    &lt;jsp:include page=&quot;footer2.jsp&quot;&gt;
        &lt;jsp:param  name=&quot;year&quot; value=&quot;2017&quot; /&gt;  //参数是扔到request的parameters里的
    &lt;/jsp:include&gt;
    在footer.jsp中
    &lt;%=request.getParameter(&quot;year&quot;)%&gt; //获取参数
</code></pre><p>&lt;%— 隐式注释：定义类、方法、全局变量、常量 —%&gt;</p>
<p>&lt;%java代码%&gt; <strong>脚本片段:其中可包含局部变量、java语句</strong></p>
<blockquote>
<p>我们可以在&lt;%%&gt;中定义局部变量或者调用方法，但不能定义方法。在jsp页面可以有多个脚本片段，但是多个脚本片段之间要保证结构完整。</p>
</blockquote>
<p>&lt;%@ 指令 </p>
<blockquote>
<p>详见下面的内容</p>
</blockquote>
<p>&lt;%! 声明</p>
<blockquote>
<p>其中写的内容将来会直接翻译在Servlet类中，因为我们可以在类中定义方法和属性以及全局变量，所以我们可以在&lt;%!%&gt;中声明方法、属性、全局变量。</p>
</blockquote>
<p>&lt;%= %&gt;表达式 <strong>用于将已经声明的变量或者表达式输出到网页上面。</strong> </p>
<p><strong>JSP要掌握包括三个指令，六个动作，九个内置对象还有四大域对象等</strong><br>jsp会自动引入</p>
<pre><code>    import java.lang.*;
    import javax.servlet.*;
    import javax.servlet.http.*;
    import javax.servlet.jsp.*;  
</code></pre><h4 id="Page指令"><a href="#Page指令" class="headerlink" title="Page指令"></a>Page指令</h4><blockquote>
<p>作用 : 用于定义JSP页面的各种属性，告诉tomcat服务器如何翻译JSP文件。</p>
<ul>
<li><strong>import</strong>:引入包<br>&lt;%@ page import=”java.util.List”%&gt;</li>
<li><strong>session</strong>:是否自动创建session<br>&lt;%@ page session=”true” %&gt; &lt;%—Default—%&gt; </li>
<li><strong>contentType</strong>:等同于response.setContentType(“text/html;charset=utf-8”);<br>&lt;%@ page contentType=”text/html;charset=utf-8”%&gt;</li>
<li><strong>pageEncoding</strong>:告诉JSP引擎要翻译的文件使用的编码。</li>
<li><strong>isELIgnored</strong>: 是否支持EL表达式。 默认是false</li>
<li><strong>isErrorPage: </strong>是否创建throwable对象。默认是false;</li>
<li><strong>errorPage: </strong>如果页面中有错误，则跳转到指定的资源。</li>
<li><strong>isThreadSafe 默认true</strong>,线程安全下servlet可以并行访问</li>
</ul>
</blockquote>
<h4 id="Include指令"><a href="#Include指令" class="headerlink" title="Include指令"></a>Include指令</h4><p>静态包含：把其它资源包含到当前页面中，代码格式：</p>
<figure class="highlight plain"><figcaption><span>include file</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">动态包含：</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;&lt;jsp:include page&#x3D;&quot;&#x2F;include&#x2F;header.jsp&quot;&gt;&lt;&#x2F;jsp:include&gt;</span><br></pre></td></tr></table></figure>
<h4 id="taglib指令"><a href="#taglib指令" class="headerlink" title="taglib指令"></a>taglib指令</h4><blockquote>
<p>在JSP页面中导入JSTL标签库。替换jsp中的java代码片段。</p>
</blockquote>
<figure class="highlight plain"><figcaption><span>taglib uri</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Q:如何自定义标签?</span><br><span class="line"></span><br><span class="line">**SimpleTag &amp; SimpleTagSupport**</span><br><span class="line">SimpleTag是一个接口，SimpleTagSupport实现了它</span><br><span class="line">&gt;SimpleTag里的函数</span><br><span class="line">&gt;+ **doTag()** &#x2F;&#x2F;是实现这个标签	void</span><br><span class="line">&gt;+ **getParent()** &#x2F;&#x2F;return JspTag ,返回父标签</span><br><span class="line">&gt;**setParent()**</span><br><span class="line"></span><br><span class="line">**SimpleTagSupport**</span><br><span class="line">&gt;+ **doTag()**</span><br><span class="line">&gt;+ **getJspBody()**  &#x2F;&#x2F;JspFragment</span><br><span class="line">&gt;....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">创建自定义标签:</span><br><span class="line">+ **step1:**</span><br><span class="line">创建一个类实现SimpleTag接口,也可以直接继承SimpleTagSupport</span><br><span class="line"></span><br><span class="line">+ **step2:** 重写doTag()</span><br><span class="line"></span><br><span class="line">		package com.akb.tag;</span><br><span class="line">		import java.io.*;</span><br><span class="line">		import javax.servlet.jsp.JspException; &#x2F;&#x2F;要记</span><br><span class="line">		import javax.servlet.jsp.tagext.SimpleTagSupport;</span><br><span class="line">		public class HelloTag extends SimpleTagSupport &#123;</span><br><span class="line">		@Override</span><br><span class="line">		public void doTag() throws JspException, IOException &#123;</span><br><span class="line">		System.out.println(&quot;hello&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+ **step 3:**</span><br><span class="line">创建tld文件</span><br><span class="line">![Alt text](.&#x2F;1576922331031.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		</span><br><span class="line">		&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;</span><br><span class="line"></span><br><span class="line">		&lt;taglib xmlns&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&quot;</span><br><span class="line">	    xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">		    xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee http:&#x2F;&#x2F;java.sun.com&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-jsptaglibrary_2_1.xsd&quot;</span><br><span class="line">	    version&#x3D;&quot;2.1&quot;&gt;</span><br><span class="line">		  &lt;!-- 描述 --&gt;</span><br><span class="line">		  &lt;description&gt;QJL 1.2 core library&lt;&#x2F;description&gt;</span><br><span class="line">		  &lt;!-- 显示名称 --&gt;</span><br><span class="line">		  &lt;display-name&gt;QJL core&lt;&#x2F;display-name&gt;</span><br><span class="line">		  &lt;!-- 版本信息 --&gt;</span><br><span class="line">		  &lt;tlib-version&gt;1.2&lt;&#x2F;tlib-version&gt;</span><br><span class="line">		  &lt;!-- 建议使用的标签的前缀 --&gt;</span><br><span class="line">		  &lt;short-name&gt;akb&lt;&#x2F;short-name&gt;   &#x2F;&#x2F;重要,是标签的前缀</span><br><span class="line">		  &lt;!-- 标签的uri --&gt;</span><br><span class="line">		  &lt;uri&gt;http:&#x2F;&#x2F;java.sun.com&#x2F;akb&#x2F;core&lt;&#x2F;uri&gt;</span><br><span class="line">	</span><br><span class="line">		  &lt;tag&gt;</span><br><span class="line">		&lt;!-- 标签名称 --&gt;</span><br><span class="line">	    &lt;name&gt;hello&lt;&#x2F;name&gt;  &#x2F;&#x2F;重要，标签名</span><br><span class="line">	    &lt;!-- 标签处理类的全限定性类名 --&gt;</span><br><span class="line">	    &lt;tag-class&gt;com.akb.tag.HelloTag&lt;&#x2F;tag-class&gt;  &#x2F;&#x2F;重要，要指定实现了SimpleTag的类</span><br><span class="line">	    &lt;!-- 标签的内容：为空就表示是一个单标签，标签里面没有内容 --&gt;</span><br><span class="line">	    &lt;body-content&gt;empty&lt;&#x2F;body-content&gt;</span><br><span class="line">		  &lt;&#x2F;tag&gt;</span><br><span class="line">		&lt;&#x2F;taglib&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**short-name 用来定义当前定义的一系列标签的前缀，在页面上引入的时候可以这样写：**</span><br><span class="line">&#96;&#96;&#96;&lt;%@ taglib uri&#x3D;&quot;http:&#x2F;&#x2F;java.sun.com&#x2F;akb&#x2F;core&quot; prefix&#x3D;&quot;akb&quot; %&gt;</span><br></pre></td></tr></table></figure>
<p><strong>uri 其实是个虚的路径映射，并不是访问互联网上的某个网址（lz 一开始就以为引入 jstl 就要访问网页…），在 tld 文件中的 uri 标签上写什么，在页面上引入的时候就在 uri 属性上写什么，容器就会自动去 tld 文件中找该 uri 对应的标签了。</strong></p>
<p>之后只需要在jsp中</p>
<pre><code>&lt;akb:hello /&gt;
</code></pre><p>就能输出<strong>hello world</strong></p>
<p>编译后的代码</p>
<pre><code>com.lyu.tag.HelloTag _jspx_th_qjl_005fhello_005f0 = new com.lyu.tag.HelloTag();
  _jsp_getInstanceManager().newInstance(_jspx_th_qjl_005fhello_005f0);
  try {
    _jspx_th_qjl_005fhello_005f0.setJspContext(_jspx_page_context);
// 调用 doTag 方法
_jspx_th_qjl_005fhello_005f0.doTag();
  } finally {
    _jsp_getInstanceManager().destroyInstance(_jspx_th_qjl_005fhello_005f0);
  }
</code></pre><p>可以看到是 servlet 容器（tomcat）创建了标签处理类的对象，并且调用了标签处理类的 doTag 方法。</p>
<p>如何自定义一个单标签<code>&lt;akb:path /&gt;</code>，调用该标签的时候把当前web应用的上下文路径在页面输出?<br>思路：我要要获取ServletContext,而<strong>PageContext有getServletContext()</strong><br>我们可以首先用<strong>SimpleTagSupport </strong>提供的<strong>JspContext getJspContext()</strong>方法, 而PageContext是JspContext的直接子类<br><strong>把他强转换为PageContext</strong></p>
<pre><code>@Override
public void doTag() throws IOException {
// 1.获取当前web应用的上下文路径
PageContext ctx = (PageContext) this.getJspContext();
String path = ctx.getServletContext().getContextPath();
// 2.向浏览器输出路径
ctx.getOut().write(path);
}
</code></pre><p><strong>PageContext非常重要</strong> (四大域之一)<br>可以通过其获取ServletContext,还可以<strong>获取Session</strong>,还有forward()和include(),还可以<strong>getServletConfig()</strong>,<strong>getRequest()</strong>,<strong>getResponse()</strong>  (…因为jsp本质就个servlet)<br>其在 javax.servlet.jsp.*;</p>
<p><strong>有没有想过这个 JspContext 是什么时候注入到 SimpleTagSupport 里面的呢？</strong></p>
<pre><code>com.lyu.tag.PathTag _jspx_th_qjl_005fpath_005f0 = new com.lyu.tag.PathTag();
  _jsp_getInstanceManager().newInstance(_jspx_th_qjl_005fpath_005f0);
  try {
// 看这里，是容器调用了 setJspContext 方法来注入的一个 pageContext，注意是 PageContext，所以我们才可以进行强制类型转换
_jspx_th_qjl_005fpath_005f0.setJspContext(_jspx_page_context);
_jspx_th_qjl_005fpath_005f0.doTag();
} finally {
 _jsp_getInstanceManager().destroyInstance(_jspx_th_qjl_005fpath_005f0);
 }
return false;
</code></pre><p>Q：如何实现一个<code>&lt;akb:set var=&quot;&quot; value=&quot;&quot; scope=&quot;&quot; /&gt;</code>标签来向四大域中设置值?</p>
<p><strong>Web的四大域对象:</strong></p>
<ul>
<li><strong>ServletContext</strong>: 代表<strong>整个web应用的ServletContext对象</strong>，当服务器关闭，或web应用被移除时，ServletContext对象跟着被销毁。</li>
<li><strong>ServletRequest</strong>:在service方法调用前由服务器创建，传入service()方法，整个请求结束，ServletRequest生命周期结束。<br>作用于整个请求链。（请求转发也存在，请求转发属于一次请求。）</li>
<li><strong>Session</strong><br>浏览器可以为每一个用户的浏览器创建一个其独享的session对象，由于session为用户浏览器独享，所以用户在访问服务器的web资源时，可以把各自的数据放在各自的session中，当用户再去访问服务器中的其它web资源时，其它web资源再从用户各自的session中取出数据为用户服务。</li>
<li><strong>PageContext</strong><br>当对JSP的请求开始时创建，当响应结束时销毁。作用于整个JSP页面，是四大域中最小的一个。</li>
</ul>
<p><strong>getAttribute()只能获取自己域中保存的属性，而findAttribute()则会按照pageContext-&gt;request-&gt;session-&gt;servletContext的顺序查找有无对应的属性。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">		<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SetTag</span> <span class="keyword">extends</span> <span class="title">SimpleTagSupport</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">private</span> String <span class="keyword">var</span> = <span class="string">""</span>;</span><br><span class="line">	<span class="keyword">private</span> String value = <span class="string">""</span>;</span><br><span class="line">	<span class="comment">// 因为这个属性在 tld 文件中设置为不是必须的所以要设置一个默认值，否则方法中调用的时候会报空指针</span></span><br><span class="line">	<span class="keyword">private</span> String scope = <span class="string">""</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setVar</span><span class="params">(String <span class="keyword">var</span>)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.<span class="keyword">var</span> = <span class="keyword">var</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(String value)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.value = value;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setScope</span><span class="params">(String scope)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.scope = scope;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doTag</span><span class="params">()</span> <span class="keyword">throws</span> JspException, IOException </span>&#123;</span><br><span class="line">		<span class="comment">// 1.拿到PageContext</span></span><br><span class="line">		PageContext pageContext = (PageContext) <span class="keyword">this</span>.getJspContext();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2.获取标签中设置的属性值</span></span><br><span class="line">		<span class="comment">// get方法中已经获得</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3.判断scope是哪个域，把属性值保存到对应的作用域里面</span></span><br><span class="line">		<span class="keyword">switch</span> (scope) &#123;</span><br><span class="line">		<span class="keyword">case</span> <span class="string">"request"</span>:  <span class="comment">//ServletRequest域</span></span><br><span class="line">			pageContext.setAttribute(<span class="keyword">var</span>, value, PageContext.REQUEST_SCOPE);  <span class="comment">//注意第三个参数</span></span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">case</span> <span class="string">"session"</span>:  <span class="comment">//Session域</span></span><br><span class="line">			pageContext.setAttribute(<span class="keyword">var</span>, value, PageContext.SESSION_SCOPE); <span class="comment">//注意第三个参数</span></span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">case</span> <span class="string">"application"</span>:  <span class="comment">//也就是ServletContext域</span></span><br><span class="line">			pageContext.setAttribute(<span class="keyword">var</span>, value, PageContext.APPLICATION_SCOPE); <span class="comment">//注意第三个参数</span></span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			pageContext.setAttribute(<span class="keyword">var</span>, value);</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>tld文件有点变化,要加上属性声明</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">		&lt;tag&gt;</span><br><span class="line">	        &lt;!-- 标签的名称 --&gt;</span><br><span class="line">	        &lt;name&gt;set&lt;&#x2F;name&gt;</span><br><span class="line">	        &lt;!-- 继承了SimpleTagSupport的标签处理类 --&gt;</span><br><span class="line">		   &lt;tag-class&gt;com.lyu.tag.SetTag&lt;&#x2F;tag-class&gt;</span><br><span class="line">        &lt;!-- 标签的内容，empty就表示是一个单标签 --&gt;</span><br><span class="line">        &lt;body-content&gt;empty&lt;&#x2F;body-content&gt;</span><br><span class="line">        &lt;!-- 属性1 --&gt;</span><br><span class="line">        &lt;attribute&gt;</span><br><span class="line">            &lt;!-- 属性名 --&gt;</span><br><span class="line">            &lt;name&gt;var&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;!-- 该属性是否必须 --&gt;</span><br><span class="line">            &lt;required&gt;true&lt;&#x2F;required&gt;</span><br><span class="line">            &lt;!-- 该属性是否可以接受运行时表达式的值(EL表达式) --&gt;</span><br><span class="line">            &lt;rtexprvalue&gt;false&lt;&#x2F;rtexprvalue&gt;</span><br><span class="line">        &lt;&#x2F;attribute&gt;</span><br><span class="line">        &lt;!-- 属性2 --&gt;</span><br><span class="line">        &lt;attribute&gt;</span><br><span class="line">            &lt;!-- 属性名 --&gt;</span><br><span class="line">            &lt;name&gt;value&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;!-- 该属性是否必须 --&gt;</span><br><span class="line">            &lt;required&gt;true&lt;&#x2F;required&gt;</span><br><span class="line">            &lt;!-- 该属性是否可以接受运行时表达式的值(EL表达式) --&gt;</span><br><span class="line">            &lt;rtexprvalue&gt;true&lt;&#x2F;rtexprvalue&gt;</span><br><span class="line">        &lt;&#x2F;attribute&gt;</span><br><span class="line">        &lt;!-- 属性3 --&gt;</span><br><span class="line">        &lt;attribute&gt;</span><br><span class="line">            &lt;!-- 属性名 --&gt;</span><br><span class="line">            &lt;name&gt;scope&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;!-- 该属性是否必须 --&gt;</span><br><span class="line">            &lt;required&gt;false&lt;&#x2F;required&gt;</span><br><span class="line">            &lt;!-- 该属性是否可以接受运行时表达式的值(EL表达式) --&gt;</span><br><span class="line">            &lt;rtexprvalue&gt;false&lt;&#x2F;rtexprvalue&gt;</span><br><span class="line">        &lt;&#x2F;attribute&gt;</span><br><span class="line">    &lt;&#x2F;tag&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果不用SimpleTagSupport类，我们也可以自己写类继承TagSupport<br>然后重写doEngTag()和doStartTag()函数<br>//doTag() throws JspException,IOException<br>//doStartTag() throws Jspxception<br>是适配器模式设计模式</p>
<p>在jsp2.0还可以使用更简单的方式<br>在<strong>WEB-INF/tags</strong>下创建tag文件 (time.tag)</p>
<pre><code>&lt;%@ tag import=&quot;java.util.*&quot; import=&quot;java.text.*&quot; %&gt;
&lt;%
  DateFormat df = DateFormat.getDateInstance(DateFormat.LONG);
  Date d = new Date(System.currentTimeMillis());
  out.println(df.format(d));
%&gt;
</code></pre><p>引用</p>
<pre><code>&lt;%@ taglib prefix=&quot;util&quot; tagdir=&quot;/WEB-INF/tags&quot; %&gt;
&lt;util:time/&gt;
</code></pre><p>有参数的标签</p>
<pre><code>&lt;%@ attribute name=&quot;count&quot; type=&quot;java.lang.Integer&quot; required=&quot;true&quot; %&gt;
&lt;%@ attribute name=&quot;value&quot; type=&quot;java.lang.String&quot; required=&quot;true&quot; %&gt;
&lt;%!....%&gt;
</code></pre><h4 id="补充PageContext相关"><a href="#补充PageContext相关" class="headerlink" title="补充PageContext相关"></a>补充PageContext相关</h4><pre><code>getSession(),    getServletContext() , getServletConfig()
    getRequest(),     getRequest()     forward(String relativeUrlPath)
        include(String relativeUrlPath)     include(String relativeUrlPath,boolean flush)
</code></pre><p>关于flush:</p>
<blockquote>
<p>默认为false，在include另一个jsp文件时，默认情况下，服务器会等待该文件被读到底端，然后才输出到客户端，并且销毁该次访问的request和response。而当把flush属性赋为真值 时，在缓存累积了一定数据时，服务器会先提供一部分数据给浏览器，并等待后续内容 。</p>
</blockquote>
<h3 id="JSP动作指令"><a href="#JSP动作指令" class="headerlink" title="JSP动作指令"></a>JSP动作指令</h3><ul>
<li><strong>jsp:forward</strong><figure class="highlight plain"><figcaption><span>page</span></figcaption><table><tr><td class="code"><pre><span class="line">既可以转发到静态的 HTML 页面，也可以转发到动态的 JSP 页面，或者转发到容器中的 Servlet。</span><br><span class="line">&#96;&#96;&#96;xml</span><br><span class="line">	&lt;jsp:forward page&#x3D;&quot;&#123;relativeURL | &lt;%&#x3D;expression%&gt;&#125;&quot; &gt;</span><br><span class="line">    &#123;&lt;jsp:param ... &#x2F;&gt;&#125;  &#x2F;&#x2F;可以用getParameter获取</span><br><span class="line">	&lt;&#x2F;jsp:forward&gt;</span><br><span class="line">比如</span><br><span class="line">	&lt;jsp:forward page&#x3D;&quot;form.jsp&quot;&gt;</span><br><span class="line">	    &lt;jsp:param name&#x3D;&quot;age&quot; value&#x3D;&quot;29&quot; &#x2F;&gt;</span><br><span class="line">	&lt;&#x2F;jsp:forward&gt;</span><br><span class="line">	&lt;input type&#x3D;&quot;hidden&quot; name&#x3D;&quot;age&quot; value&#x3D;&quot;&lt;%&#x3D;request.getParameter(&quot;age&quot;)%&gt;&quot;&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>使用 forward 指令转发请求时，用户请求的地址不会改变，客户端的请求参数也不会丢失。<br>从表面上看，<jsp:forward ... /> 指令似乎将用户请求转发到了一个新页面，但实际上只是采用了新页面来对用户请求生成响应 — 请求依然是一次请求，所以请求参数、请求属性都不会丢失。</p>
<ul>
<li><strong>jsp:include</strong></li>
</ul>
<pre><code>    &lt;jsp:include page=&quot;{relativeURL | &lt;%=expression%&gt;}&quot; flush=&quot;true&quot;&gt;
    &lt;jsp:param name=&quot;parameterName&quot; value=&quot;parameterValue&quot; /&gt;
    &lt;/jsp:include&gt;
</code></pre><p>flush 属性用于指定输出缓存是否转移到被导入文件中。如果指定为 true，则包含在被导入文件中；如果指定为 false，则包含在原文件中。</p>
<ul>
<li><strong>useBean、setProperty、getProperty 指令</strong><blockquote>
<p>这三个指令都是与 JavaBean 相关的指令，其中 useBean 指令用于在 JSP 页面中初始化一个 Java 实例；setProperty 指令用于为 JavaBean 实例的属性设置值；getProperty 指令用于输出 JavaBean 实例的属性。</p>
</blockquote>
</li>
</ul>
<pre><code>    &lt;jsp:useBean id=&quot;name&quot; class=&quot;classname&quot; scope=&quot;page | request | session | application&quot; /&gt;
    &lt;jsp:setProperty name=&quot;BeanName&quot; property=&quot;propertyName&quot; value=&quot;value&quot; /&gt;    
    &lt;jsp:getProperty id=&quot;BeanName&quot; property=&quot;propertyName&quot; /&gt;    
    &lt;!--userBean也可以指定type而不用class,一般来说没什么区别。但是当bean变null时，用type的情况会抛出异常，因为如果用class如果一个bean不存在会自动new一个--&gt;
</code></pre><blockquote>
<p>其中，id 属性是 JavaBean 的实例名，class 属性确定 JavaBean 的实现类。scope 属性用于指定 JavaBean 实例的作用范围，该范围有以下 4 个值：<br><strong>page：</strong>该 JavaBean 实例仅在该页面有效。<br><strong>request：</strong>该 JavaBean 实例在本次请求有效。<br><strong>session：</strong>该 JavaBean 实例在本次 session 内有效。<br><strong>application：</strong>该 JavaBean 实例在本应用内一直有效。</p>
</blockquote>
<p> <strong>name 属性确定需要设定 JavaBean 的实例名；property 属性确定需要设置的属性名；value 属性则确定需要设置的属性值。</strong></p>
<pre><code>//尽量少写java代码
&lt;jsp:getProperty name=&quot;a&quot; property=&quot;age&quot;/&gt;
&lt;jsp:setProperty name=&quot;a&quot; property=&quot;age&quot; value=&quot;20&quot;/&gt;   //jsp就是java程序
&lt;jsp:setProperty name=&quot;a&quot; property=&quot;age&quot; param=&quot;age&quot;/&gt; // =student.setAge(Ingter.Parser( request.getParameter(&quot;age&quot;))
page:bean只在当前页面存在.有的话a指向这个对象. request的话到request去找。getAttribute,
session:在session对象中getAttribute有的话能返回 application:只有一个，都能用
</code></pre><p><strong>其中的param属性 相当于value=”&lt;%=request.getParameter(“num”)%&gt;”</strong></p>
<ul>
<li><p><strong>jsp:param</strong></p>
<p>  <jsp:param name="paramName" value="paramValue" /><br>param 指令用于设置参数值，这个指令本身不能单独使用，因为单独的 param 指令没有任何实际意义。<br>param 指令可以与以下三个指令结合使用。<br>jsp:include<br>jsp:forward<br>jsp:plugin</p>
</li>
</ul>
<p>当与 include 指令结合使用时，param 指令用于将参数值传入被导入的页面；当与 forward 指令结合使用时，param 指令用于将参数值传入被转向的页面</p>
<h3 id="JSP-9个-内置对象"><a href="#JSP-9个-内置对象" class="headerlink" title="JSP 9个    内置对象"></a>JSP 9个    内置对象</h3><p><strong>request</strong>,<strong>response</strong>,<strong>session</strong>,<strong>application(javax.servlet.ServletContext)</strong>,<strong>pageContext</strong>  //也就是4大域对象+一个response<br><strong>out (javax.servlet.jsp.JspWriter)</strong>,<strong>config (ServletConfig)</strong>,<strong>page (JspPage)</strong>,<strong>exception (JspException)</strong></p>
<pre><code>###Web Listener

优先加载Listenrer
</code></pre><p><Listener-class>ApplicationInitlizer<Listenre-class></p>
<pre><code>public class ApllicationInitlizer implements ServletContextLisenter{
    //最早最早执行的函数. 创建完context马上执行
    public void contextinitialized(ServletContextEvent sce){
        //创建连接池的代码就应该写在这里
        //sce就一个函数  getServletContext()
    }

    public void contextDestroyed(ServletContextEvent sce){
        //最后一个
        一切事件都是来源于Event
    }
}
</code></pre><ul>
<li><strong>HttpSessionBindingListener</strong>   调用setAttribute时触发</li>
</ul>
<p>web.xml中的监听器设置</p>
<pre><code>&lt;listener&gt;
    &lt;listener-class&gt;nc.xyzq.listener.WebServicePublishListener&lt;/listener-class&gt;
&lt;/listener&gt; 
// 该元素用来注册一个监听器类。可以收到事件什么时候发生以及用什么作为响应的通知。事件监听程序在建立、修改和删除会话或servlet环境时得到通知。常与context-param联合使用。
</code></pre><p>也可以用标注@WebListener 就不用上面的xml定义监听器了<br> listen-class 指定了监听类，上例中该类实现<strong>ServletContextListener </strong>(也可以实现其他的监听器) 包含<strong>初始化方法contextInitialized(ServletContextEvent event) </strong>和<strong>销毁方法contextDestoryed(ServletContextEvent event)；</strong></p>
<p><img src="./1576926948994.png" alt="Alt text"></p>
<p><strong>HttpSessionBindingEvent(session,name,value) //session属性变化时</strong><br>HttpSessionEvent(HttpSession source)<br>ServletRequestEvent(ServletContext sc, ServletRequest request)<br>ServletContextEvent(ServletContext source)<br>HttpSessionAttributeListener:      attributeAdded,    attributeRemoved,    attributeRemoved都可以<br>参数为(HttpSessionBindingEvent event)  和binding不同，binding是监听属性绑定，解绑事件</p>
<p>监听三个作用域的创建和销毁的监听器<br>都只有两个函数 一个是   xxxxDestroyed(xxxxEvent ) 另一个是 xxxxInitialized(xxxxEvent )</p>
<p>监听三个作用域属性变更的监听器:<br>有3个函数     attributeAdded(xxxEvent)      attributeAdded(xxxEvent)      attributeAdded(xxx)  就是监听属性的增删改</p>
<h4 id="PageBean"><a href="#PageBean" class="headerlink" title="PageBean"></a>PageBean</h4><blockquote>
<p> 在开发中有时需要将数据库中的数据显示到页面中，数据中的数据又比较多，使用一页是显示不了的。此时需要在数据库中分页查询，然后分页显示在页面中。如果使用一个通用的分页工具类，会比较方便。只需在创建该类时传入每页显示的行数，总行数（数据库中的数据总行数），以及当前页码。就可以求出总页数，并且对传入的页码数进行判断。</p>
</blockquote>
<p>可以自定义一个PageBean</p>
<pre><code>public class PageBean&lt;T&gt; 
</code></pre><p><img src="./1576927652916.png" alt="Alt text"></p>
<h4 id="JDBC连接池的配置"><a href="#JDBC连接池的配置" class="headerlink" title="JDBC连接池的配置"></a>JDBC连接池的配置</h4><blockquote>
<p>可以在应用的web.xml也可以在Tomcat的conf/context.xml,也可以在Tomcat的conf/server.xml(GlobalNamingResources标签)中配置,也可以在应用的context.xml中配置。</p>
</blockquote>
<pre><code>&lt;Context&gt;
&lt;Resource name=&quot;jdbc/mysqlds&quot; 
    auth=&quot;Container&quot; //验证方式为容器
    type=&quot;javax.sql.DataSource&quot;  
    username=&quot;root&quot; 
    password=&quot;root&quot; 
    maxIdle=&quot;30&quot; 
    maxWait=&quot;10000&quot; 
    maxActive=&quot;100&quot;
    driverClassName=&quot;com.mysql.jdbc.Driver&quot; 
    url=&quot;jdbc:mysql://127.0.0.1:3306/db_blog&quot;
    logAbandoned=&quot;true&quot; /&gt;
&lt;/Context&gt;
</code></pre><h4 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h4><p><code>import javax.naming.*;</code><br><strong>Binding类</strong>:<br><img src="./1576928767713.png" alt="Alt text"><br>只有get,set</p>
<h4 id="目录服务"><a href="#目录服务" class="headerlink" title="目录服务"></a>目录服务</h4><p>目录服务的命名服务的扩展，允许命名服务的入口具有特性。现在再回到打印机的例子中，该打印机有可能具有一定的特性，比如颜色/能够打印双面等，所有这些属性保存在目录服务中.</p>
<p><strong>Java 命名与目录接口（Java Naming and Directory Interface），在J2EE规范中是重要的规范之一</strong></p>
<h6>jvax.naming.directory：对命名包的扩充，提供了访问目录服务的类和接口。例如，它为属性增加了新的类，提供了表示目录上下文的DirContext接口，定义了检查和更新目录对象的属性的方法。
Javax.naming.event：提供了对访问命名和目录服务时的事件通知的支持。例如，定义了NamingEvent类，这个类用来表示命名/目录服务产生的事件，定义了侦听NamingEvents的NamingListener接口。
Javax.naming.ldap：这个包提供了对LDAP 版本3扩充的操作和控制的支持，通用包javax.naming.directory没有包含这些操作和控制。
Javax.naming.spi：这个包提供了一个方法，通过javax.naming和有关包动态增加对访问命名和目录服务的支持。这个包是为有兴趣创建服务提供者的开发者提供的。</h6>


<h2 id="MVC与struts"><a href="#MVC与struts" class="headerlink" title="MVC与struts"></a>MVC与struts</h2><p>Controller: 负责将用户的动作映射到模型的执行<br>controller没有移植性<br><strong>降低软件的粒度就能提高复用性</strong></p>
<h3 id="ActionServlet"><a href="#ActionServlet" class="headerlink" title="ActionServlet"></a><strong>ActionServlet</strong></h3><blockquote>
<p>ActionServlet类是Struts框架的内置核心控制器组件，它继承了javax.servlet.http.HttpServlet类。Struts的启动通常从</p>
</blockquote>
<p>加载ActionServlet开始。Web容器会在首次启动或Struts应用的第一个请求到达时加载ActionServlet。一般情况下都<br>配置web容器比如tomcat启动的时候加载ActionServlet类，使用<load-on-startup>1&lt;/load-on-startup&gt;标签配置启动<br>加载。</p>
<p><em>一定要记</em><br>ActionServlet的功能为</p>
<ul>
<li><strong>读取Struts-config.xml</strong></li>
<li><strong>把请求分发到相应的action</strong></li>
<li><strong>从请求中获取数据，填充FromBean(如果需要)</strong></li>
</ul>
<pre><code>    &lt;servlet&gt;
        &lt;servlet-name&gt;actionServlet&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.apache.struts.action.ActionServlet&lt;/servlet-class&gt; &lt;!--一定要记--&gt;
        &lt;load-on-startup&gt;1&lt;load-on-startup&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;config&lt;/param-name&gt;
            &lt;param-value&gt;/WEB-INF/struts-config.xml&lt;/param-value&gt;  &lt;!--指定配置文件--&gt;
        &lt;/init-param&gt;
    &lt;/servlet&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;actionServlet&lt;/servlet-name&gt;
        &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;
</code></pre><p><strong>struts配置文件</strong></p>
<ul>
<li><p><strong>data-source</strong></p>
<pre><code>  &lt;data-source&gt;
                      &lt;!-- 所用的JDBC驱动类，必须--&gt;
                      &lt;set-property property=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;
                      &lt;!-- 所用的JDBC的URL，必须--&gt;
                      &lt;set-property property=&quot;url&quot; value=&quot;jdbc:mysql://localhost/test&quot;/&gt;
                      &lt;!-- 同时打开的最小连结数，缺省值为1，可选--&gt;
                      &lt;set-property property=&quot;minCount&quot; value=&quot;1&quot;/&gt;
                      &lt;!-- 同时打开的最大连结数，缺省值为2，可选--&gt;
                      &lt;set-property property=&quot;maxCount&quot; value=&quot;5&quot;/&gt;
                      &lt;!-- 连结到数据库的用户名，必须--&gt;
                      &lt;set-property property=&quot;user&quot; value=&quot;root&quot;/&gt;
                      &lt;!-- 连结到数据库的密码，必须--&gt;
                      &lt;set-property property=&quot;password&quot; value=&quot;root&quot;/&gt;
   &lt;/data-source&gt;
</code></pre></li>
</ul>
<ul>
<li><strong>form-beans</strong><blockquote>
<p>子元素form-beans用来配置绑定到Action的各个FormBean的实例。每个FormBean实例用form-bans的子元素form-bean来定义。form-bean又分普通的FormBan和动态FormBean。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>　1. classname：一般用得少，指定和form-bean无素对应的配置类，默认为org.apache.struts.config.FormBeanConfig，如果自定义，则必须扩展FormBeanConfig类。可有可无。<br>　　2. name：ActionForm Bean的惟一标识。必须。<br>　　3. type：ActionForm的完整类名。必须。</p>
</blockquote>
<pre><code>    &lt;form-beans&gt;
    　　&lt;form-bean name=&quot;Loign&quot; type=&quot;com.ha.login&quot;&gt;&lt;/form-bean&gt;
    &lt;/form-beans&gt;
</code></pre><p>对应的FormBean类一般是继承ActionForm类，例如下面的例子定义了一个UserForm，它具有userName和password两个属性。该类的代码如下：</p>
<pre><code>package com.amigo.struts.form.user;
import org.apache.struts.action.ActionForm;
public class UserForm extends ActionForm {
    //...
}
</code></pre><p><strong>动态form-bean</strong></p>
<p>动态form-bean不需要定义对应的javabean类，其元素都在struts-config.xml中定义。其type为：org.apache.struts.validator.DynaValidatorForm。下面的动态FormBean定义了userName和password属性，配置如下：</p>
<pre><code>&lt;form-bean name=&quot;UserForm&quot; type=&quot;org.apache.struts.validator.DynaValidatorForm&quot;&gt;
         &lt;form-property name=&quot;userName&quot; type=&quot;java.lang.String&quot;/&gt;
         &lt;form-property name=&quot;password&quot; type=&quot;java.lang.String&quot;/&gt;
&lt;/form-bean&gt;
</code></pre><ul>
<li><p><strong>global-forwards</strong></p>
<blockquote>
<ol>
<li>className：和forward元素对应的配置类，默认为：org.apache.struts.action.ActionForward。可有可无。<br>　　2. contextRelative：此项为true时，表时path属性以＂/＂开头，相对于当前上下文的URL，默认为false．可有可无。　<br>　　3. name：转发路径的逻辑名．必填。<br>　　4. path：转发或重定向的URL，当contextRelative=false时，URL路径相对于当前应用（application），当为ture时，表示URL路径相对于当前上下文（context）。<br>　　5.  redirect：当此项为ture时，表示执行重定向操作。当此项为false时表示转向操作。默认为false。</li>
</ol>
</blockquote>
<pre><code>  &lt;global-forwards&gt;
  　　&lt;forward  name=&quot;forms1&quot;  path=&quot;/a.do&quot;/&gt;
  　　&lt;forward  name=&quot;forms2&quot;  path=&quot;/nb.jsp&quot;/&gt;
  &lt;global-forwards&gt;
</code></pre><p><strong>global-forwards用于配置全局转发，struts首先会在\<action-mappings\>元素中找对应的<forward>，若找不到，则到全局转发配置中找</strong></p>
</li>
<li><p><strong>action-mapping</strong></p>
<blockquote>
<p>  该元素用于将Action元素定义到ActionServlet类中，它含有0到多个\<action\/>元素，其格式如下：</p>
</blockquote>
<pre><code>  &lt;action-mappings&gt;
  &lt;action path=&quot;Action请求的相对路径&quot;
  type=&quot;该Action的对应类的全路径&quot;
  name=&quot;该Action绑定的FormBean&quot;
  &lt;forward name=&quot;指定处理相应请求所对应的地址&quot; path=&quot;相对路径&quot;/&gt;
  &lt;/action&gt;
  &lt;/action-mappings&gt;
</code></pre></li>
</ul>
<p>name:和Action关联的Action FormBean的名字，必须在FromBean定义过<br>其他属性:<br>scope：指定ActionForm Bean的作用域(session和request)，缺省为session。(可选)；<br>input：当Bean发生错误时返回的路径(可选)；<br>classname：指定一个调用这个Action类的ActionMapping类的全名。缺省用org.apache.struts.action.ActionMapping(可选)；include：如果没有forward的时候，它起forward的作用(可选)；validate：若为true，则会调用ActionForm的validate()方法，否则不调用，缺省为true（可选）。</p>
<ul>
<li><p><strong>message-resources</strong></p>
<blockquote>
<p> 该元素用来定义资源文件，格式如下：</p>
</blockquote>
<pre><code>  &lt;message-resources parameter=&quot;给定资源文件的全名&quot;
  classname=&quot;定义处理消息资源的类名的全名&quot;

  factory=&quot;定义MessageResourcesFactory类的全名&quot;

  key=&quot;定义绑定在这个资源包中的ServletContext的属性主键&quot;

  null=&quot; 如果为true，则找不到消息key时，则返回null &quot;/&gt;
</code></pre></li>
</ul>
<p><strong>理解Form-bean与Action</strong></p>
<pre><code>    &lt;form-beans&gt;
       &lt;form-bean name=&quot;loginForm&quot; type=&quot;com.text.LoginForm&quot;/&gt;
    &lt;/form-beans&gt;
</code></pre><blockquote>
<p>用来设置Model的指向，这个例子意思是页面里的loginForm需要调用com.text.LoginForm 这个bean</p>
</blockquote>
<pre><code>    &lt;action   path=&quot;/login&quot;
           type=&quot;com.test.LoginAction&quot;
           name=&quot;loginForm&quot;
          scope=&quot;request&quot;
          input=&quot;/Login.jsp&quot;&gt;
  &lt;forward name=&quot;logsuccess&quot; path=&quot;/LoginSuccess.jsp&quot;/&gt;
 &lt;/action&gt;
</code></pre><blockquote>
<p>用来设置Control的指向</p>
</blockquote>
<p><strong>ActionForward</strong>:</p>
<p>配置中的forward标签可以看成是一个ActionForward对象<br>ActionForward forward1=new ActionForward();<br>forward1.setName(“success”);<br>forward1.setPath(“/success.jsp”);<br>ActionForward forward2=new ActionForward();<br>forward2.setName(“error”);<br>forward2.setPath(“/error.jsp”);</p>
<p>map.put(“success”,forward1);<br>map.put(“error”,forward2);</p>
<p>要找时: ActionForward forward=mapping.findForward(“result”)</p>
<p><strong>ActionMapping对应的是action标签</strong></p>
<pre><code>public class TestAction extends Action{
    @Override
    public ActionForward(ActionMapping mapping,ActionForm form,HttpServletRequest request,
    HttpServletResponse response) throws Exception{
        return mapping.findForward(&quot;success&quot;);
}
} 
</code></pre><p><strong>DispatchAction</strong></p>
<blockquote>
<p>DispatchAction是Action的子类，它重写了Action的execute方法<br>在Struts中允许多个请求对应一个Action，例如对Book对象的增删改查操作，可以交给一个Action处理，Action根据请求地址中附加的参数信息，再派发到相应的方法<br>DispatchAction是struts包含的另一个能大量节省开发时间的Action类。与其他Action类仅提供单个execute()方法实现单个业务不同，DispatchAction允许你在单个Action类中编写多个与业务相关的方法。这样可以减少Action类的数量，并且把相关的业务方法集合在一起使得维护起来更容易。</p>
</blockquote>
<ol>
<li><p>继承DispatchAction</p>
<pre><code> import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;

 import org.apache.struts.action.ActionForm;
 import org.apache.struts.action.ActionForward;
 import org.apache.struts.action.ActionMapping;
 import org.apache.struts.actions.DispatchAction;

 public class BookAction extends DispatchAction {

     public ActionForward add(ActionMapping arg0, ActionForm arg1, HttpServletRequest arg2, HttpServletResponse arg3)
         throws Exception {
     System.out.println(&quot;add&quot;);
         return null;
 }
 public ActionForward update(ActionMapping arg0, ActionForm arg1, HttpServletRequest arg2, HttpServletResponse arg3)
     throws Exception {
     System.out.println(&quot;update&quot;);
     return null;
 }
 public ActionForward find(ActionMapping arg0, ActionForm arg1, HttpServletRequest arg2, HttpServletResponse arg3)
         throws Exception {
     System.out.println(&quot;find&quot;);
     return null;
 }
 public ActionForward delete(ActionMapping arg0, ActionForm arg1, HttpServletRequest arg2, HttpServletResponse arg3)
         throws Exception {
     System.out.println(&quot;delete&quot;);
     return null;
 }

 }
</code></pre></li>
</ol>
<p>2.配置struts-config文件的action并指定parameter</p>
<pre><code>&lt;action path=&quot;/bookAction&quot; type=&quot;com.kexin.web.action.BookAction&quot;
        parameter=&quot;method&quot;&gt;
    &lt;/action&gt;
</code></pre><p>使用:</p>
<pre><code>&lt;html:link action=&quot;/bookAction?method=add&quot;&gt;增加&lt;/html:link&gt;
&lt;html:link action=&quot;/bookAction?method=delete&quot;&gt;删除&lt;/html:link&gt;
&lt;html:link action=&quot;/bookAction?method=update&quot;&gt;更改&lt;/html:link&gt;
&lt;html:link action=&quot;/bookAction?method=find&quot;&gt;查找&lt;/html:link&gt;
</code></pre><p><strong>MappingDispatchAction</strong></p>
<blockquote>
<p>MappingDispatchAction是DispatchAction的子类，它提供的功能和DispatchAction功能类似，它也允许多个请求对应一个Action，但它的实现方式更加灵活。</p>
</blockquote>
<p>与DispatchAction不同，其配置文件是有几个方法，就写几个Action,path不同</p>
<pre><code>&lt;action path=&quot;/addBook&quot; type=&quot;com.kexin.web.action.BookAction2&quot;
        parameter=&quot;add&quot;&gt;&lt;/action&gt;
    &lt;action path=&quot;/deleteBook&quot; type=&quot;com.kexin.web.action.BookAction2&quot;
        parameter=&quot;delete&quot;&gt;&lt;/action&gt;
</code></pre><p><strong>在配置上 DispatchAction路径所能对应的只能达到类级别,还需要通过request对象传入的一个parameter的值来确定方法,          </strong><br><strong>MappingDispatchAction将不同的路径(action 标签中 path属性来指定)对应到不同的方法级别精度已经达到方法级别具体的方法只需要读配置文件里面的parameter值就可以了</strong></p>
<p>前端控制器(ActionServlet)如何控制后端控制器:<br><img src="./1577019206826.png" alt="Alt text"><br><img src="./1577019274572.png" alt="Alt text"><br><img src="./1577019288532.png" alt="Alt text"></p>
<p>strut2使用:</p>
<p>1.编写xml配置Action</p>
<pre><code>&lt;aciton name=&quot;hello&quot; class=&quot;com.akb.action.HelloAction&quot; method=&quot;sayHello&quot;&gt;
    &lt;!--配置结果视图--&gt;
    &lt;result name=&quot;success&quot;&gt;/success.jsp&lt;/result&gt;
&lt;/action&gt;
//action指向控制器。控制器调用模型的执行， Action最后会返回到一个视图
</code></pre><p>//建立Action类</p>
<pre><code>//不需要继承任何东西
    public String HelloAction{
        public String sayHello(){
            System.out.println(&quot;hello&quot;);
            return &quot;success&quot;;
        }
    }

//struts1
//摘自org.apache.struts.action.Action类
 public ActionForward execute(ActionMapping mapping, ActionForm form,ServletRequest request,ServletResponse response) throws Exception 
 {
    try
    {
        return execute(mapping, form,(HttpServletRequest) (Object) request,(HttpServletResponse) (Object) response);
    } catch (ClassCastException e) {
        return null;
    }
}

public ActionForward execute(ActionMapping mapping, ActionForm form, HttpServletRequest request,HttpServletResponse response) throws Exception 
{
    return null;
}


public class LoginHandlerAction extends Action {

public ActionForward execute(ActionMapping mapping, ActionForm form,
        HttpServletRequest request, HttpServletResponse response) {

    LoginHandlerForm loginHandlerForm = (LoginHandlerForm) form;        
    //从Form中取得表单数据
    String userName = loginHandlerForm.getUserName();
    String userPwd = loginHandlerForm.getUserPwd();

    //生成一个Session对象
    HttpSession session = request.getSession(true);
    session.removeAttribute(&quot;userName&quot;);
    session.setAttribute(&quot;userName&quot;, userName);

    //生成一个ArrayList 
    ArrayList arr = new ArrayList();
    arr.add(userName);
    arr.add(userPwd);

    String forward;

    //调用模型组件
    LoginHandler login = new LoginHandler();
    boolean flag = login.checkLogin(arr);
    if(flag)
        forward = &quot;success&quot;;
    else
        forward = &quot;fail&quot;;

    //转向
    return mapping.findForward(forward);

}
}        
</code></pre><blockquote>
<p>struts2中action是多例的，即一个session产生一个action。struts 2的Action是多实例的并发单例，也就是每次请求产生一个Action的对象<br>struts 2的Action中包含数据，例如你在页面填写的数据就会包含在Action的成员变量里面。如果Action是单实例的话，这些数据在多线程的环境下就会相互影响，例如造成别人填写的数据被你看到了。所以Struts2的Action是多例模式的。<br>多例会对每一个请求产生一个session来处理</p>
</blockquote>
<p>html格式</p>
<ul>
<li>物理格式  应该有起始标记，结束标记</li>
<li>逻辑格式 定义了HTML的逻辑结构，受制于具体应用。</li>
</ul>
<p>dtd文件声明了根元素里面可以写哪些子元素<br>加上xsl:xxxx xml就受控了   .xsd文件</p>
<p>国际化的问题</p>
<p>properties文件</p>
<p>s4.properties<br>s4_zh_CN.properties<br>s4_ja_JP.properties<br>….</p>
<p><strong>java.util.ResourceBoundle() </strong>构造函数:资源文件的名字</p>
<blockquote>
<p>说的简单点，这个类的作用就是读取资源属性文件（properties），然后根据.properties文件的名称信息（本地化信息），匹配当前系统的国别语言信息（也可以程序指定），然后获取相应的properties文件的内容。</p>
</blockquote>
<p><img src="./1577108017698.png" alt="Alt text"><br><img src="./1577108031514.png" alt="Alt text"></p>
<p><strong>struts1 和struts2的区别要考</strong></p>
<p>一个表单多种提交方式比较困难。<br>spring的路径支持更好，可以多种匹配方式</p>
<p>s2不灵活，不支持单实例。</p>
<h2 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h2><p>struts 所有后端控制器都要继承Action</p>
<p>spring配置步骤<br>导入前端控制器<br>创建servlet:<br>initparameter<br>contextConfigLocation<br>urlpattern *.do</p>
<pre><code>&lt;listener&gt;
    &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
&lt;/listener&gt;

&lt;servlet&gt;
    &lt;servlet-name&gt;dispatcherSevlet&lt;/servlet-name&gt;
    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-calss&gt;
    &lt;init-param&gt;
        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;  &lt;!--配置文件路径--&gt;
        &lt;param-value&gt;classpath:spring-config.xml&lt;/param-value&gt;
    &lt;/init-param&gt;
    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
&lt;/servlet&gt;

&lt;servlet-mapping&gt;
    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;
    &lt;url-pattern&gt;/&lt;/url-pattern&gt;
&lt;servlet-mapping&gt;

  &lt;!--读取静态文件--&gt;
&lt;servlet-mapping&gt;
    &lt;servlet-name&gt;default&lt;/servlet-name&gt;
    &lt;url-pattern&gt;*.js&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.css&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.woff&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.woff2&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.ttf&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.png&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.ogg&lt;/url-pattern&gt;
    &lt;url-pattern&gt;*.mp4&lt;/url-pattern&gt;
&lt;/servlet-mapping&gt;


&lt;filter&gt;
&lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;
&lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter
&lt;/filter-class&gt;
&lt;init-param&gt;
    &lt;param-name&gt;encoding&lt;/param-name&gt;
    &lt;param-value&gt;UTF-8&lt;/param-value&gt;
&lt;/init-param&gt;
&lt;init-param&gt;
    &lt;param-name&gt;forceEncoding&lt;/param-name&gt;
    &lt;param-value&gt;true&lt;/param-value&gt;
&lt;/init-param&gt;
&lt;/filter&gt;
&lt;filter-mapping&gt;
&lt;filter-name&gt;encodingFilter&lt;/filter-name&gt;
&lt;url-pattern&gt;/*&lt;/url-pattern&gt;
&lt;/filter-mapping&gt;
</code></pre><p>上下文监听器代码:(前端控制器)</p>
<pre><code>public class ContextLoaderListener extends ContextLoader implements ServletContextListener {



 public ContextLoaderListener() {

 }



 public ContextLoaderListener(WebApplicationContext context) {

           super(context);

 }



 @Override
 ///要考
 public void contextInitialized(ServletContextEvent event) {
           initWebApplicationContext(event.getServletContext());
 }



 @Override

 public void contextDestroyed(ServletContextEvent event) {

           closeWebApplicationContext(event.getServletContext());

           ContextCleanupListener.cleanupAttributes(event.getServletContext());

 }

}
</code></pre><p><strong>!! ContextParameter </strong></p>
<p><strong>getinitparameter()获取servlet的参数。在dopost doget都可以. getServletConfig().getinitparameter() 都可以 HttpServlet实现了2个接口：Servlet和ServletConfig</strong></p>
<p>动后加载ApplicationContext</p>
<p>有2个容器（子容器）<br>一个servlet可以有多个mapping</p>
<p>/*不好，会把jsp引擎过滤掉</p>
<p><img src="./1577109028126.png" alt="Alt text"></p>
<p><strong>@RequestBody</strong><br>如public void add(@RequestBody Account account)  会自动将传入的参数转换成对象<br><strong>@ResponseBody</strong><br>public @ResponseBody Account get() 会把结果转换成JSON </p>
<p><strong>@RestController</strong><br><img src="./1577109361275.png" alt="Alt text"></p>
<p><strong>@Controller</strong></p>
<blockquote>
<p>如果需要返回的是index字符串（JSON、XML等数据类型），则需要在每个方法体里面添加@ResponseBody注解（简单理解为@ResponseBody注解就是标记方法体不调用视图解析器）</p>
</blockquote>
<p><strong>!Controller的返回值可以是</strong></p>
<ul>
<li><strong>void</strong></li>
<li><strong>View</strong></li>
<li><strong>String</strong></li>
<li><strong>map</strong></li>
<li><strong>model</strong></li>
<li><strong>ModelAndView</strong></li>
<li><strong>ModelMap</strong></li>
</ul>
<p>controller依赖于view view依赖于model</p>
<p>把<strong>物理和逻辑视图分离</strong>.</p>
<p>retruern “xxx” //返回的是逻辑名称<br>配置文件里要把逻辑名称映射到物理文件.  为了降低controller对视图的依赖</p>
<p><strong>在SpringMVC后台控制层获取参数的方式主要有两种，一种是request.getParameter(“name”)，另外一种是用注解@RequestParam直接获取。</strong></p>
<pre><code>@RequestMapping(&quot;testRequestParam&quot;)    
   public String filesUpload(@RequestParam String inputStr, HttpServletRequest request) {    
    System.out.println(inputStr);  

    int inputInt = Integer.valueOf(request.getParameter(&quot;inputInt&quot;));  
    System.out.println(inputInt);  

    // ......省略  
    return &quot;index&quot;;  
   }    
   //前端 
   &lt;form action=&quot;/gadget/testRequestParam&quot; method=&quot;post&quot;&gt;    
     参数inputStr:&lt;input type=&quot;text&quot; name=&quot;inputStr&quot;&gt;    
     参数intputInt:&lt;input type=&quot;text&quot; name=&quot;inputInt&quot;&gt;    
    &lt;/form&gt;  
</code></pre><h4 id="注解类"><a href="#注解类" class="headerlink" title="注解类"></a>注解类</h4><p><strong>@Component、@Repository、@Service、@Controller实质上属于同一类注解，用法相同，功能相同，区别在于标识组件的类型。@Component可以代替@Repository、@Service</strong></p>
<h4 id="装配bean"><a href="#装配bean" class="headerlink" title="装配bean"></a>装配bean</h4><p><strong>@Autowired</strong><br><strong>@Resource</strong></p>
<blockquote>
<p>a：提供方 @Autowired是Spring的注解，@Resource是javax.annotation注解，而是来自于JSR-250，J2EE提供， 需要JDK1.6及以上。<br>b ：注入方式 @Autowired只按照Type 注入；@Resource默认按Name自动注入，也提供按照Type 注入；<br>c：属性<br>@Autowired注解可用于为类的属性、构造器、方法进行注值。默认情况下，其依赖的对象必须存在（bean可用），如果需要改变这种默认方式，可以设置其required属性为false。<br>d：@Autowired注解默认按照类型装配</p>
</blockquote>
<h4 id="Spring-MVC注解"><a href="#Spring-MVC注解" class="headerlink" title="Spring MVC注解"></a>Spring MVC注解</h4><ul>
<li><strong>@Controller </strong>：表明该类会作为与前端作交互的控制层组件，通过服务接口定义的提供访问应用程序的一种行为，解释用户的输入，将其转换成一个模型然后将试图呈献给用户</li>
<li>!!<strong>@RequestMapping </strong></li>
<li><p>!!<strong>@RequestParam</strong></p>
<blockquote>
<p>将请求的参数绑定到方法中的参数上，有required参数，默认情况下，required=true，也就是改参数必须要传。如果改参数可以传可不传，可以配置required=false。</p>
</blockquote>
<pre><code>   @PostMapping(value = &quot;/updateStudent&quot;)
    public String updateStudentByStudentId(
    @RequestParam(value = &quot;studentId&quot;) Integer studentId,
    @RequestParam(value = &quot;name&quot;) String name) 
</code></pre></li>
<li><p>!!<strong>@PathVariable</strong><br>该注解用于方法修饰方法参数，会将修饰的方法参数变为可供使用的uri变量（可用于动态绑定）。</p>
<pre><code>  @RequestMapping(&quot;/testPathVariable/{id}&quot;)
  public String testPathVariable(@PathVariable(&quot;id&quot;) Integer id)
  {
      System.out.println(&quot;testPathVariable:&quot;+id);
      return SUCCESS;
  }
</code></pre></li>
<li><p><strong>@RequestBody</strong><br>如public void add(@RequestBody Account account)  会自动将传入的参数转换成对象</p>
</li>
<li><strong>@ResponseBody</strong><br>public @ResponseBody Account get() 会把结果转换成JSON </li>
</ul>
<h4 id="BeanFactory"><a href="#BeanFactory" class="headerlink" title="BeanFactory"></a>BeanFactory</h4><p><img src="./1577149900456.png" alt="Alt text"></p>
<h4 id="视图解析"><a href="#视图解析" class="headerlink" title="视图解析"></a>视图解析</h4><pre><code> &lt;bean id=&quot;viewResolver&quot; class=&quot;...视图解析器类&quot;&gt;
 &lt;!--会新建一个 viewClass 属性指定的视图类型予以返回，即返回一个 url 为“ /WEB-INF/test.jsp ”的 InternalResourceView 对象--&gt;
     &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.InternalResourceView&quot;&gt;
     &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;&gt;  &lt;!--在视图逻辑名前面加上prefix,后面加上suffix--&gt;
     &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;&gt;
 &lt;/bean&gt;
</code></pre><p><strong>UrlBasedViewResolver</strong><br><strong>InternalResourceViewResolver</strong><br><strong>XmlViewResolver</strong><br><strong>ResourceBundleViewResolver</strong></p>
<blockquote>
<p> 在 SpringMVC 中可以同时定义多个 ViewResolver 视图解析器，然后它们会组成一个 ViewResolver 链。当 Controller 处理器方法返回一个逻辑视图名称后， ViewResolver 链将根据其中 ViewResolver 的优先级来进行处理。所有的 ViewResolver 都实现了 Ordered 接口，在 Spring 中实现了这个接口的类都是可以排序的。在 ViewResolver 中是通过 order 属性来指定顺序的，默认都是最大值。所以我们可以通过指定 ViewResolver 的 order 属性来实现 ViewResolver 的优先级， order 属性是 Integer 类型， order 越小，对应的 ViewResolver 将有越高的解析视图的权利</p>
</blockquote>
<pre><code>&lt;bean class=&quot;org.springframework.web.servlet.view.XmlViewResolver&quot;&gt;
   &lt;property name=&quot;location&quot; value=&quot;/WEB-INF/views.xml&quot;/&gt;
   &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt;
&lt;/bean&gt;

&lt;bean
   class=&quot;org.springframework.web.servlet.view.UrlBasedViewResolver&quot;&gt;
   &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/&quot; /&gt;
   &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt;
   &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.InternalResourceView&quot;/&gt;
&lt;/bean&gt;
</code></pre><blockquote>
<p>ViewResolver接口是在DispatcherServlet中进行调用的，当DispatcherServlet调用完 Controller后，会得到一个ModelAndView对象，然后DispatcherServlet会调用render方法进行视图渲染。<br><img src="./1577190283404.png" alt="Alt text"><br>第一步：前端控制器dispatcher接受请求</p>
</blockquote>
<pre><code>Client---url---&gt;Dispatcher
</code></pre><p>第二步：前端控制器去发起handler映射查找请求</p>
<pre><code>Dispatcher---HttpServletRequest---&gt; HandlerMapping
</code></pre><p>第三步：处理器映射器查找hanlder并返回HandlerExetuionChain</p>
<pre><code> Dispatcher &lt;---HandlerExeutionChain---HandlerMapping
</code></pre><p>第四步：前端控制器发起请求处理器适配器请求执行</p>
<p>  Dispatcher—-Handler—-&gt; HandlerAdapter</p>
<p>第五步：处理器适配器去调用handler执行</p>
<p>HandlerAdapter—-HttpServletRequest&gt; Handler(Controller)</p>
<p>第六步：处理器处理后返回ModelAndView给HandlerAdapter</p>
<p>HandlerAdapter &lt;—-ModelAndView—-Handler(Controller)</p>
<p>第七步：处理器适配器将ModelAndView返回给前端控制器</p>
<p>Dispatcher &lt;—-ModelAndView—-HandlerAdapter</p>
<p>第八步：前端控制器请求视图解析器解析ModelAndView</p>
<p>Dispatcher—-ModelAndView—-&gt; ViewReslover</p>
<p>第九步：视图解析器解析视图后返回视图View给前端控制器</p>
<p>Dispatcher &lt;—-View—-ViewReslover</p>
<p>第十步：前端控制器请求视图要求渲染视图</p>
<p>Dispatcher—-&gt;View—-&gt;render</p>
<p>第十一步：前端控制器返回响应</p>
<p>Response &lt;—-Dispatcher</p>
<p>ViewResolver接口就一个函数</p>
<pre><code>    @Nullable
    public void
resolverViewName(String name,Local local)
</code></pre><p>View里面定义了两个抽象函数</p>
<ul>
<li>render(@Nullable Map<String,?> model,HttpServletRequest,HttpServletResoponse) //渲染,把模型中的数据渲染到response中 ?可以extend</li>
<li>String getContentType()</li>
</ul>
<blockquote>
<p>render(@Nullable Map<String,?> model,HttpServletRequest,HttpServletResoponse) //渲染,把模型中的数据渲染到response中 ?可以extend</p>
</blockquote>
<pre><code>protected View resolveViewName(String viewName, Map&lt;String, Object&gt; model, Locale locale,  
        HttpServletRequest request) throws Exception {  

    for (ViewResolver viewResolver : this.viewResolvers) {  
        View view = viewResolver.resolveViewName(viewName, locale);  
        if (view != null) {  
            return view;  
        }  
    }  
    return null;  
}  
</code></pre><h4 id="view-controller"><a href="#view-controller" class="headerlink" title="view controller"></a>view controller</h4><pre><code>#重定向
&lt;mvc:view-controller path=&quot;/&quot; view-name=&quot;redirect:/admin/index&quot;/&gt; &lt;!--即如果当前路径是/ 则重定向到/admin/index--&gt;
&lt;mvc:view-controller path=&quot;/&quot; view-name=admin/index&quot;/&gt; &lt;!--如果当前路径是/ 则交给相应的视图解析器直接解析为视图--&gt;
比如视图解析器配置如下
    &lt;bean id=&quot;defaultViewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; p:order=&quot;2&quot;&gt;
&lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt;
&lt;property name=&quot;contentType&quot; value=&quot;text/html&quot;/&gt;
&lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;
&lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;
&lt;/bean&gt;
则得到的视图: /WEB-INF/jsp/admin/index.jsp
</code></pre><h3 id="Aware接口"><a href="#Aware接口" class="headerlink" title="Aware接口"></a>Aware接口</h3><blockquote>
<p>是为了让组件知道容器的存在.知道了applicationContainer的存在可以知道一切组件的存在。但是应该少用。因为会加大与容器的耦合</p>
</blockquote>
<p><img src="./1577190982621.png" alt="Alt text"></p>
<p>Aware函数就一个setXXXX();</p>
<ul>
<li><strong>BeanNameAware</strong>:<br>   void    setBeanName(String name)</li>
<li><strong>BeanFactoryAware</strong><br>  void    setBeanFactory(BeanFactory beanFactory)    BeanFactory有getBean()函数</li>
<li><strong>ApplicationContextAware</strong><br>  void    setApplicationContext(ApplicationContext applicationContext)   //知道了ApplicationContext,简直可以为所欲为</li>
</ul>
<p>使用例子:</p>
<pre><code>public class User implements BeanNameAware{

private String id;

private String name;

private String address;
@Override
public void setBeanName(String beanName) {
    //ID保存BeanName的值
    id=beanName;
}
}


 &lt;bean id=&quot;zhangsan&quot;  class=&quot;com.github.jettyrun.springinterface.demo.aware.beannameaware.User&quot;&gt;
    &lt;property name=&quot;name&quot; value=&quot;zhangsan&quot;&gt;&lt;/property&gt;
    &lt;property name=&quot;address&quot; value=&quot;火星&quot;&gt;&lt;/property&gt;
&lt;/bean&gt;
</code></pre><h3 id="数据访问，存储"><a href="#数据访问，存储" class="headerlink" title="数据访问，存储"></a>数据访问，存储</h3><p>JDO (java data object) 完成数据持久化 ,代码增强. 性能好,麻烦 </p>
<h4 id="Spring-jdbc"><a href="#Spring-jdbc" class="headerlink" title="Spring jdbc"></a>Spring jdbc</h4><p>1.配置数据源datasource<br>2.初始化jdbcTemplate<br>3.使用jdbcTemplate对数据库做增删查改</p>
<ul>
<li><p><strong>配置数据源</strong></p>
<pre><code>  #代码方式(不推荐,既然可以new 出来的实例，我们应该交给spring去管理。)
   DriverManagerDataSource driverManagerDataSource = new DriverManagerDataSource();
  driverManagerDataSource.setDriverClassName(&quot;com.mysql.cj.jdbc.Driver&quot;);
  driverManagerDataSource.setUrl(&quot;jdbc:mysql://localhost:3306/suveng?serverTimezone=Asia/Shanghai&amp;characterEncoding=utf8&quot;);
  driverManagerDataSource.setUsername(&quot;root&quot;);
  driverManagerDataSource.setPassword(&quot;root&quot;);

   JdbcTemplate jdbcTemplate = new JdbcTemplate(driverManagerDataSource);

  #推荐，Bean配置方式
   &lt;!--配置DataSource--&gt;
  &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt;
  &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;
      &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/suveng?serverTimezone=Asia/Shanghai &amp;amp;characterEncoding=utf8&quot;/&gt;
  &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;
  &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;
  &lt;/bean&gt;
  &lt;!--配置jdbcTemplate--&gt;
  &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt;
      &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;
  &lt;/bean&gt;
</code></pre><p>  之后在代码中直接注入</p>
<pre><code>   @Resource (或@Autowired)
   JdbcTemplate jdbcTemplate;
</code></pre></li>
</ul>
<p>使用JdbcTemplate:</p>
<pre><code>jdbcTemplate.update(&quot;update user set name = ? where id = ?&quot;, &quot;春花&quot;, 1);  //改
jdbcTemplate.update(&quot;insert into user(name,age) values( ?, ?)&quot;, &quot;花花&quot;, 1000); //整
jdbcTemplate.update(&quot;delete from user where id = ?&quot;, 1); //删

String sql=&quot;select id,name,deptid from user where id=?&quot;;
RowMapper&lt;User&gt; rowMapper=new BeanPropertyRowMapper&lt;User&gt;(User.class);
User user= jdbcTemplate.queryForObject(sql, rowMapper,52);


String sql=&quot;select id,name,deptid from user&quot;;

RowMapper&lt;User&gt; rowMapper=new BeanPropertyRowMapper&lt;User&gt;(User.class);
List&lt;User&gt; users= jdbcTemplate.query(sql, rowMapper);
</code></pre><h3 id="mybatist"><a href="#mybatist" class="headerlink" title="mybatist"></a>mybatist</h3><p><img src="./1577192449553.png" alt="Alt text"><br><img src="./1577192453472.png" alt="Alt text"></p>
<p><strong>Transational</strong></p>
<pre><code>Spring框架支持编程式事务管理，也支持声明式事务管理。
</code></pre><p>1) Spring框架事务管理的实现</p>
<blockquote>
<p><strong>org.springframework.transaction.PlatformTransactionManager接口</strong><br>commit()<br>rollback()<br><strong>org.springframework.transaction.TransactionDefinition接口</strong><br>String getName()<br>int getIsolationLevel()<br>int getPropagationBehavior()<br>int getTimeout()<br>boolean isReadOnly()<br><strong>org.springframework.transaction.TransactionStatus接口</strong><br>boolean isNewTransaction();<br>boolean hasSavepoint();<br>void setRollbackOnly();<br>boolean isRollbackOnly();<br>void flush();<br>boolean isCompleted();<br><strong>PlatformTransactionManager接口的实现类：</strong><br>org.springframework.jdbc.datasource.DataSourceTransactionManager（JDBC）<br>org.springframework.transaction.jta.JtaTransactionManager（JTA）<br>（过时了）org.springframework.orm.hibernate.HibernateTransactionManager（Hibernate）<br>（Spring 3.0.0）org.springframework.orm.hibernate3.HibernateTransactionManager（Hibernate）<br>（Spring 3.1.0）org.springframework.orm.hibernate4.HibernateTransactionManager（Hibernate）<br>（Spring 4.2.0）org.springframework.orm.hibernate5.HibernateTransactionManager（Hibernate）</p>
</blockquote>
<p>propagation默认 requre （事务的传播属性）<br><img src="./1577192702206.png" alt="Alt text"></p>
<p>JTS (java transation service) 事务服务</p>
<p>不支持分布式事务 (需要第三方类库 automaker)</p>
<h2 id="编写注解"><a href="#编写注解" class="headerlink" title="编写注解"></a>编写注解</h2><pre><code>//MyAnno.java
import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

@Target({ElementType.METHOD,ElementType.TYPE})  // 表示该注解可以用以标注方法和类
@Retention(RetentionPolicy.RUNTIME)   // 表示该注解是运行时级别(运行时可见) (只有运行时级别,才能通过反射获取到)
public @interface MyAnno {  // 用@interface定义注解

//注解的属性 (后面要有小括号)
String name();

int age() default 28;  // 可以为属性指定默认值

//String value();
//String[] value();

}


public static void main(String[] args) throws NoSuchMethodException, SecurityException {

    //获得字节码对象
    Class clazz = MyAnnoTest.class;

    //获得所有的方法
    Method[] methods = clazz.getMethods();
    if(methods!=null){
        //获得使用了@MyAnno注解的方法
        for(Method method:methods){
            //判断该方法是否使用了@MyAnno注解
            boolean annotationPresent = method.isAnnotationPresent(MyAnno.class);
            if(annotationPresent){  //如果该方法使用了MyAnno注解
                method.invoke(clazz.newInstance(), null);
            }
        }
    }

    Method method = clazz.getMethod(&quot;show&quot;, String.class);
    //获得show方法上的@MyAnno注解
    MyAnno annotation = method.getAnnotation(MyAnno.class); // 只有运行时级别的注解,才能通过反射获取到
    //获得@MyAnno上的属性值
    System.out.println(annotation.name()); //zhangsan
    System.out.println(annotation.age());  //28

    // .....

}
</code></pre><p>JMS (java message service) 消息服务</p>
<blockquote>
<p>使用JMS不仅能发送（send）/发布（publish）消息，也能获得（receive）/订阅（subscribe）的消息</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="相关重要的接口"><a href="#相关重要的接口" class="headerlink" title="相关重要的接口"></a>相关重要的接口</h3><h4 id="Servlet接口"><a href="#Servlet接口" class="headerlink" title="Servlet接口"></a><strong>Servlet</strong>接口</h4><p>因为其是组件。所以有<strong>init(ServletConfig)函数</strong>和<strong>destroy()</strong>函数。为了获取servlet的配置还有<strong>getServletConfig()</strong><br>主要就是<strong>service(ServletRequest,ServletResponse)函数</strong></p>
<h4 id="ServletConfig-类"><a href="#ServletConfig-类" class="headerlink" title="ServletConfig 类"></a><strong>ServletConfig</strong> 类</h4><ul>
<li><strong>可以通过其来获取ServletContext</strong><blockquote>
<p>可以获取ServletContext的方式很多。1. 直接在HttpServlet类里<strong>getServletContext()</strong> 2.从 ServletRequest <strong>getServletContext()</strong> 3.request.getSession().getServletContext() 也就是从<strong>Session</strong>获取 4.从ServletConfig获取<br>5.从ServletContextEvent获取  6.从PageContext获取 (PageContext也是很NB的类，其相当于一个Servlet,servletconfig,session,request,response都可以get到)</p>
</blockquote>
</li>
</ul>
<ul>
<li><p><strong>getInitParameter(String name)</strong><br>很重要的函数，用来获取初始化参数的。 初始化参数定义在web.xml里或者注解里<br>xml形式:</p>
<pre><code> &lt;servlet&gt;
     &lt;servlet-name&gt;A&lt;/servlet-name&gt;
     &lt;servlet-class&gt;....&lt;/servlet-class&gt;
     &lt;init-param&gt;
         &lt;param-name&gt;p1&lt;/param-name&gt;
         &lt;param-value&gt;123&lt;/param-value&gt;
     &lt;/init-param&gt;
     &lt;init-param&gt;
         &lt;param-name&gt;p2&lt;/param-name&gt; 
         &lt;param-value&gt;v2&lt;/param-value&gt;
     &lt;/init-param&gt;
 &lt;servlet&gt;
</code></pre></li>
</ul>
<p>注解形式</p>
<p><code>@WebServlet(name=&quot;A&quot;,urlPatterns={&quot;/hello&quot;},initParms={@WebInitParam(name=&quot;p1&quot;,value=&quot;123&quot;),@WebInitParam(name=&quot;p2&quot;,value=&quot;v2&quot;)})</code></p>
<ul>
<li><strong>getServletName()</strong>:就是获取Servlet的名字。。感觉不太用得上</li>
</ul>
<h4 id="HttpServlet类"><a href="#HttpServlet类" class="headerlink" title="HttpServlet类"></a><strong>HttpServlet</strong>类</h4><p>实现了Servlet接口.默认已经实现了<strong>init</strong>,<strong>destroy</strong>,<strong>getServletConfig</strong>,<strong>service</strong>.<br>可以直接<strong>doGet(ServletRequest,ServeletResponse)</strong>,<strong>doPost(ServletRequest,ServletResponse)</strong></p>
<blockquote>
<p>doHead是一个已经实现的方法，它将执行doGet但是仅仅向客户端返回doGet应该向客户端返回的头部的内容； doOptions方法自动的返回servlet所直接支持的HTTP方法信息； doTrace方法返回TRACE请求中的所有头部信息。 对于那些仅仅支持HTTP/1.0的容器而言，只有doGet, doHead 和 doPost方法被使用</p>
</blockquote>
<p>还有<strong>getLastModified</strong><br><img src="./1577279596344.png" alt="Alt text"></p>
<h4 id="ServletRequest-接口"><a href="#ServletRequest-接口" class="headerlink" title="ServletRequest 接口"></a><strong>ServletRequest</strong> 接口</h4><p>Web四大域之一(session,application(或者servletcontext),pagecontext,request),域都有 <strong>removeAttribute setAttribute</strong></p>
<ul>
<li>可以get的:<br>servletName<br>servletport<br>remotehost<br>remoteport<br>protocol<br>scheme 和protocol差不多。不过不带版本号。 比如http/1.1 只返回http<br><strong>RealPath()</strong></li>
</ul>
<p><strong>Parameter</strong><br><strong>ParameterNames</strong><br><strong>ParameterValues</strong><br>!!<strong>getRequestDispatcher(String path)</strong><br>!!<strong>ServletContext</strong><br>getServletPort<br>getLocale  为实现国际化可以使用。可以获取用户的语言\地区</p>
<h4 id="HttpServletRequest类"><a href="#HttpServletRequest类" class="headerlink" title="HttpServletRequest类"></a><strong>HttpServletRequest</strong>类</h4><p>实现了上面的<strong>ServletRequest</strong>接口。所以上面的函数都有<br>为了适应HTTP协议还具有<br><strong>Cookie[] getCookies()</strong><br><strong>getHeader(String)</strong>  //因为是发来的请求，所以只有get，没有set. response里面get/set都有<br>getMethod() 请求类型是GET还是POST或者PUT</p>
<p>getRequestURL()<br>getRequestURI()<br>getServletPath()<br>getContextPath()<br>的区别<br><img src="./1577348271650.png" alt="Alt text"><br><img src="./1577348422425.png" alt="Alt text"><br><img src="./1577348302257.png" alt="Alt text"><br> 可以看到contextpath是设置好的context地址<br> uri是包含context地址的资源定位地址  因为我们contextpath设成/c后，要使用/c/hello才能访问到相应资源<br> serverpath就是servlet mapping到的地址。<br>url是完整的请求地址</p>
<h4 id="HttpSession-接口"><a href="#HttpSession-接口" class="headerlink" title="HttpSession 接口"></a>HttpSession 接口</h4><p>web四大域之一(session,application(或者servletcontext),pagecontext,request),域都有 <strong>removeAttribute setAttribute</strong><br>也可以<strong>getServletContext()</strong></p>
<p>还可以用<strong>getId()</strong>获取sessionId<br>invalidate()  //干掉一个session</p>
<h4 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h4><p>构造函数<br>:<code>public Cookie(String name,String value)</code><br>还可以设置生存时间<br><code>setMaxAge(int expiry)</code> //秒</p>
<p><code>setDomin(String domin)</code></p>
<blockquote>
<p>可以跨域共享cookies 跨域共享cookie的方法:<br>A机所在的域：home.langchao.com,A有应用cas<br>B机所在的域：jszx.com，B有应用webapp_b<br>1）在cas下面设置cookie的时候，增加cookie.setDomain(“.jszx.com”);，这样在webapp_b下面就可以取到cookie。</p>
</blockquote>
<p><code>setPath(String path)</code></p>
<blockquote>
<p>此处的参数，是相对于应用服务器存放应用的文件夹的根目录而言的(比如tomcat下面的webapp),为了让所有web应该都可以共享cookies,可以cookie.setPath(“/“);</p>
</blockquote>
<h4 id="ServletResponse接口-amp-HttpServletResponse类"><a href="#ServletResponse接口-amp-HttpServletResponse类" class="headerlink" title="ServletResponse接口 &amp; HttpServletResponse类"></a>ServletResponse接口 &amp; HttpServletResponse类</h4><p>ServletResponse接口:<br><strong>PrintWrite getWrite()</strong><br><strong>setContentType(String type)</strong><br><strong>setLocale(Locale loc)</strong><br>HttpServletResponse类:</p>
<pre><code>addCookie(Cookie cookie);//添加cookie
//关于回应头的函数
addDateHeader(String name, long date); //添加日期头信息
addHeader(String name, String value) //添加头信息
containsHeader(String name)
getHeader(String name)

sendRedirect(String location) //跳转
</code></pre><h2 id="突然发现重复的东西太多了，所以下面只补充一些笔记里没有的了"><a href="#突然发现重复的东西太多了，所以下面只补充一些笔记里没有的了" class="headerlink" title="突然发现重复的东西太多了，所以下面只补充一些笔记里没有的了"></a>突然发现重复的东西太多了，所以下面只补充一些笔记里没有的了</h2><h3 id="Annotations-注解"><a href="#Annotations-注解" class="headerlink" title="Annotations  注解"></a>Annotations  注解</h3><p>源注解<br><strong>1. @Target(value=TYPE)</strong> //指定注解的作用范围</p>
<pre><code> /** 可用于类，接口，枚举 */
TYPE,

/** Field declaration (includes enum constants) */
FIELD,

/** 用于方法 */
METHOD,

/** 用于参数 */
PARAMETER,

/** 用于构造函数 */
CONSTRUCTOR,

/** 用于局部变量 */
LOCAL_VARIABLE,

/** 用于注解 */
ANNOTATION_TYPE,

/** 用于包的声明*/
PACKAGE
</code></pre><p><strong>2. @Retention(RetentionPolicy.RUNTIME)</strong><br><img src="./1577334477619.png" alt="Alt text"></p>
<p><strong>3. @Documented</strong><br>Documented注解表明这个注释是由 javadoc记录的，在默认情况下也有类似的记录工具。 如果一个类型声明被注释了文档化，它的注释成为公共API的一部分</p>
<h4 id="javax-servlet-annotation"><a href="#javax-servlet-annotation" class="headerlink" title="javax.servlet.annotation"></a>javax.servlet.annotation</h4><h5 id="WebServlet"><a href="#WebServlet" class="headerlink" title="@WebServlet"></a>@WebServlet</h5><p>直接用注解定义servlet<br>先看看该注解的定义</p>
<pre><code>@Target(value=TYPE)  //说明作用于类
 @Retention(value=RUNTIME)
 @Documented
public @interface WebServlet
</code></pre><p>使用方法<br><code>@WebServlet(name=&#39;&#39;,  urlPatterns={&quot;&quot;,&quot;&quot;...}  , loadOnStartup=1 , initParams={@WebInitParam(name=&quot;&quot;, value=&quot;&quot;),...},  asyncSupported=true, description=&quot;&quot;)</code></p>
<p>参数同在xml里声明servlet一样<br>loadOnStartup是启动优先级，数字越小优先级越高</p>
<h5 id="WebListener"><a href="#WebListener" class="headerlink" title="@WebListener"></a>@WebListener</h5><pre><code>@Target(value=TYPE)
 @Retention(value=RUNTIME)
 @Documented
public @interface WebListener
</code></pre><p>很简单的注解。就是标识监听器类。。。不需要提供任何参数（也没参数可提供，除了一个description）<br>实例: 下面就创建了一个ServletContext的监听。（具体监听器类型已在前面的笔记提到）    </p>
<pre><code>@WebListener
public class MyServletContextListener implements ServletContextListener {
     @Override
    public void contextDestroyed(ServletContextEvent sce) {
        System.out.println(&quot;===========================MyServletContextListener销毁&quot;);
    }

    @Override
    public void contextInitialized(ServletContextEvent sce) {
        System.out.println(&quot;===========================MyServletContextListener初始化&quot;);
        System.out.println(sce.getServletContext().getServerInfo());
    }

}
</code></pre><h5 id="WebInitParam"><a href="#WebInitParam" class="headerlink" title="@WebInitParam"></a>@WebInitParam</h5><p>一个Servlet的初始化参数注解。用在@WebServlet里面, 除了description只有 name,value属性</p>
<h5 id="WebFilter"><a href="#WebFilter" class="headerlink" title="@WebFilter"></a>@WebFilter</h5><p>因为filter本质也是servlet..所以和WebServlet用法差不多<br><code>@WebFilter(filterName=&#39;&#39;,  urlPatterns={&quot;&quot;,&quot;&quot;...}   , initParams={@WebInitParam(name=&quot;&quot;, value=&quot;&quot;),...},  asyncSupported=true, description=&quot;&quot;,  servletNames={&quot;&quot;,&quot;&quot;})</code></p>
<p>不同点</p>
<ol>
<li>name变成了filterName</li>
<li>没有了loadOnstartup属性</li>
<li>增加了servletNames属性。因为其不仅可以作用在urls上，还可以作用在指定servlet上</li>
</ol>
<h5 id="ServletSecurity"><a href="#ServletSecurity" class="headerlink" title="@ServletSecurity"></a>@ServletSecurity</h5><p>servlet的安全机制<br>该注解有两个属性<br><strong>HttpMethodConstraint[]     httpMethodConstraints</strong><br>和<br><strong>HttpConstraint     value</strong></p>
<p>相应的，有注解</p>
<ul>
<li><p><strong>@HttpMethodConstraint(value=”http协议方法名”  ,rolesAllowed={“”,””…},      transportGuarantee=)</strong></p>
<pre><code>  //CODE EXAMPLE 4-3 对所有HTTP方法，所有访问都被拒绝
  @ServletSecurity(@HttpConstraint(EmptyRoleSemantic.DENY))
  //CODE EXAMPLE 4-4 对所有HTTP方法，要求角色R1成员的权限约束
  @ServletSecurity(@HttpConstraint(rolesAllowed=&quot;R1&quot;))
      //CODE EXAMPLE 4-5 对所有除了GET和POST的HTTP方法，没有约束；对GET和POST方法，要求Role R1成员的权限约束，加密传输要求。
          @ServletSecurity((httpMethodConstraints = { @HttpMethodConstraint(value=&quot;GET&quot;, rolesAllowed=&quot;R1&quot;), @HttpMethodConstraint(value=&quot;POST&quot;, rolesAllowed=&quot;R1&quot;, transportGuarantee=TransportGuarantee.CONFIDENTIAL)})
  //CODE EXAMPLE 4-7 对于除了TRACE的所有HTTP方法，要求Role R1中成员的权限约束；对于TRACE， 所有访问都拒绝。
      @ServletSecurity(value = @HttpConstraint(rolesAllowed = &quot;R1&quot;), httpMethodConstraints = @HttpMethodConstraint(value=&quot;TRACE&quot;, emptyRoleSemantic = EmptyRoleSemantic.DENY))
</code></pre></li>
</ul>
<h4 id="HandlesTypes-class"><a href="#HandlesTypes-class" class="headerlink" title="@HandlesTypes(class[])"></a>@HandlesTypes(class[])</h4><p>根据API介绍，该注解定义了能够被ServlerContextInitializer处理的类</p>
<pre><code>@HandlesTypes(WebApplicationInitializer.class)
public class SpringServletContainerInitializer implements ServletContainerInitializer {


@Override
public void onStartup(Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext)
        throws ServletException {

    .......篇幅有限,去除无用代码.......

    for (WebApplicationInitializer initializer : initializers) {  // 通知启动WebApplicationInitializer 的实现

        initializer.onStartup(servletContext);
    }
}
}
</code></pre><p>Tomcat的Host容器在添加子容器时，会<strong>通过解析.xml并通过classloader加载 @HandlesTypes注解的类</strong><br>读取@HandlesTypes注解value值。并放入ServletContainerInitializers 对应的Set集合中<br>在ApplicationContext 内部启动时会通知 ServletContainerInitializers 的onStart方法()。这个onStart方法的第一个参数就是@HandlesTypes注解的value 值指定的Class集合<br>在Spring 应用中，对ServletContainerInitializers的实现就是SpringServletContainerInitializer,注解指定的类就是WebApplicationInitializer.</p>
<p><strong>@MultipartConfig</strong>:</p>
<blockquote>
<p>Servlet3.0提供了对文件上传的支持，通过@MultipartConfig标注和HttpServletRequest的两个新方法getPart()和getParts()，开发者能够很容易实现文件的上传操作。</p>
</blockquote>
<p>使用方法。直接@MultiparConfig标注一个Servlet类(说明该Servlet处理的是multipart/form-data类型的请求)<br>表单代码    </p>
<pre><code>        &lt;form action=&quot;/HelloWorld/UpLoad&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;
            &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt;
            &lt;input type=&quot;submit&quot; name=&quot;upload&quot; value=&quot;上传&quot;&gt;
        &lt;/form&gt;
</code></pre><p>在doPost中request.getPart(“file”); //Servlet3.0中新引入的方法，用来处理multipart/form-data类型编码的表单<br>然后part.write(“路径”)即可完成上传</p>
<pre><code>@MultipartConfig(localtion=&quot;c:\aaa&quot;,fileSizeThreshold=0,maxFileSize=102400,     maxRequestSize=102400)
/*fileSizeThreshold默认0，多少字节后存到文件系统上，mfs:最大文件大小 mrs:最大请求的multipart form大小*/
对应xml
&lt;multipart-config&gt;
    &lt;location&gt;c:\aaa&lt;/location&gt;
&lt;/ultipart-config&gt;
</code></pre><h3 id="EL表达式"><a href="#EL表达式" class="headerlink" title="EL表达式"></a>EL表达式</h3><p>所有EL都是以${为起始、以}为结尾的</p>
<p><img src="./1577353107292.png" alt="Alt text"><br><strong>如果你要用EL输出一个常量的话，字符串要加双引号，不然的话EL会默认把你认为的常量当做一个变量来处理，</strong></p>
<h3 id="Spring-Controller"><a href="#Spring-Controller" class="headerlink" title="Spring Controller"></a>Spring Controller</h3><p>再次上这张图<br><img src="./1577357845641.png" alt="Alt text"></p>
<blockquote>
<p>在SpringMVC 中，控制器Controller 负责处理由DispatcherServlet 分发的请求，它把用户请求的数据经过业务处理层处理之后封装成一个Model ，然后再把该Model 返回给对应的View 进行展示。在SpringMVC 中提供了一个非常简便的定义Controller 的方法，你无需继承特定的类或实现特定的接口，只需使用@Controller 标记一个类是Controller<br>然后使用@RequestMapping 和@RequestParam 等一些注解用以定义URL 请求和Controller 方法之间的映射，这样的Controller 就能被外界访问到。此外Controller 不会直接依赖于HttpServletRequest 和HttpServletResponse 等HttpServlet 对象</p>
</blockquote>
<pre><code>@Controller  
public class MyController {  
  @RequestMapping ( &quot;/showView&quot; )  
    public ModelAndView showView() {  
       ModelAndView modelAndView = new ModelAndView();  
       modelAndView.setViewName( &quot;viewName&quot; );  
       modelAndView.addObject( &quot; 需要放到 model 中的属性名称 &quot; , &quot; 对应的属性值，它是一个对象 &quot; );  
       return modelAndView;  
}        
}   
</code></pre><p>@RequestParam<br>@PathVariable 要看，可以看上面spring部分的笔记</p>
<h3 id="Spring-注解补充"><a href="#Spring-注解补充" class="headerlink" title="Spring 注解补充"></a>Spring 注解补充</h3><p><strong>@Configuration注解</strong></p>
<blockquote>
<p>必需使用<context:component-scanbase-package=”XXX”/>扫描.  也可以直接@ComponentScan(value = “包名”)</p>
</blockquote>
<p>类里面用Bean标记的方法，就会作为这个Spring容器中的Bean</p>
<blockquote>
<p>为了简化从properties里取配置，可以使用@Value, 可以properties文件中的配置值。</p>
</blockquote>
<pre><code>引入配置文件
&lt;context:property-placeholder location=&quot;classpath:test.properties&quot; /&gt;

@Value(“${p1}”)
public String p1;
</code></pre><p><strong>@Async</strong></p>
<blockquote>
<p>基于@Async标注的方法，称之为异步方法,这个注解用于标注某个方法或某个类里面的所有方法都是需要异步处理的。被注解的方法被调用的时候，会在新线程中执行，而调用它的方法会在原来的线程中执行。</p>
</blockquote>
<p><strong>@Singleton</strong><br>让一个类是单例类</p>
<p><strong>@Bean</strong></p>
<p><strong>@Scope(“prototype”或”singleton”)</strong><br><strong>.singleton bean</strong>仅有一个实例<br><strong>prototype bean</strong> 每次对该特定的bean请求时创建一个新的bean实例.</p>
<h3 id="spring补充"><a href="#spring补充" class="headerlink" title="spring补充"></a>spring补充</h3><p>bean可以有多个名字，例如：    </p>
<pre><code>&lt;bean name=&quot;a,b,c&quot; class=&quot;a.b.c.Hello&quot;/&gt;
&lt;bean class=&quot;a.b.c.Hello&quot;/&gt;   id, name都没有指定，那么name值默认为和类的全名一致。
尽量用id来标识bean,因为有唯一性要求
</code></pre><h4 id="ApplicationContext"><a href="#ApplicationContext" class="headerlink" title="ApplicationContext"></a>ApplicationContext</h4><blockquote>
<p>使用FileSystemXmlApplicationContext和使用ClassPathXmlApplicationContext的区别在于： FileSystemXmlApplicationContext在指定的文件系统路径下查找xml文件； 而ClassPathXmlApplicationContext是在所有的类路径（包含JAR文件） 下查找xml文件。<br>    <strong>ClassPathXmlApplicationContext 默认会去 classPath 路径下找。classPath 路径指的就是编译后的 classes 目录。</strong></p>
</blockquote>
<pre><code>ApplicationContext context = new FileSystemXmlApplicationContext(“C:/bean.xml”);//因此如果xml文件放在WEB-INF文件夹下，需要用这个，不然会找不到文件
ApplicationContext context = new ClassPathXmlApplicationContext(“bean.xml”);
a.b.c.Hello h3 = (a.b.c.Hello) ctx.getBean(&quot;a.b.c.Hello&quot;);
</code></pre><h4 id="BeanFactory-1"><a href="#BeanFactory-1" class="headerlink" title="BeanFactory"></a>BeanFactory</h4><p>从名字可以看出来是Bean的工厂类<br>有getBean  ContainBean 等方法</p>
<p>关于对象的创建，有一些设计模式，例如，工厂方法，对应的spring配置为</p>
<pre><code>&lt;bean id=&quot;clientService&quot; class=&quot;examples.ClientService&quot;
factory-method=&quot;createInstance&quot;/&gt;
对应的Java代码
public class ClientService {
private static ClientService clientService = new ClientService();
private ClientService() {}

public static ClientService createInstance() {
    return clientService;
}
}
</code></pre><p>这就声明了ClientService为一个工厂bean,利用createInstance()来创建实例</p>
<pre><code>也可以不指定类型，完全有一个工厂bean来负责创建
&lt;!-- the factory bean, which contains a method called createInstance() --&gt;
&lt;bean id=&quot;serviceLocator&quot; class=&quot;examples.DefaultServiceLocator&quot;&gt;
&lt;/bean&gt;
&lt;!-- 如果id, name都没有指定，那么name值默认为和类的全名一致。--&gt;
&lt;bean id=&quot;clientService&quot;
    factory-bean=&quot;serviceLocator&quot;
    factory-method=&quot;createClientServiceInstance&quot;/&gt;


public class DefaultServiceLocator {

    private static ClientService clientService = new ClientServiceImpl();
    private static AccountService accountService = new AccountServiceImpl();

    public ClientService createClientServiceInstance() {
        return clientService;
    }

    public AccountService createAccountServiceInstance() {
        return accountService;
    }
}
</code></pre><p>//创建bean</p>
<pre><code>&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt;
    &lt;constructor-arg type=&quot;int&quot; value=&quot;7500000&quot;/&gt;     //调用构造函数提供的参数  
    &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;42&quot;/&gt;
&lt;/bean&gt;

下面是通过Setter方法注入依赖。
&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt;
&lt;!-- setter injection using the nested ref element --&gt;
&lt;property name=&quot;beanOne&quot;&gt;
    &lt;ref bean=&quot;anotherExampleBean&quot;/&gt;
&lt;/property&gt;

&lt;!-- setter injection using the neater ref attribute --&gt;
&lt;property name=&quot;beanTwo&quot; ref=&quot;yetAnotherBean&quot;/&gt;
&lt;property name=&quot;integerProperty&quot; value=&quot;1&quot;/&gt;
&lt;/bean&gt;

&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;  
   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  
   xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans  
       http://www.springframework.org/schema/beans/spring-beans-2.5.xsd&quot;&gt;  

&lt;bean id=&quot;id&quot; class=&quot;com.loster.li.Id&quot;&gt;  
    &lt;property name=&quot;id&quot; value=&quot;123&quot;&gt;&lt;/property&gt;  
    &lt;property name=&quot;name&quot; value=&quot;xiaoli&quot;&gt;&lt;/property&gt;  
&lt;/bean&gt;  
&lt;/beans&gt;  
</code></pre><p>需要有set函数</p>
<bean id="anotherExampleBean" class="examples.AnotherBean"/>
<bean id="yetAnotherBean" class="examples.YetAnotherBean"/>

也可以不用type,直接写name="变量名",自动匹配类型


![Alt text](./1577359741824.png)




    当然，一个工厂bean可以定义不同的方法来创建不同类型的bean，配置代码和Java代码如下：
    <bean id="serviceLocator" class="examples.DefaultServiceLocator">
        <!-- inject any dependencies required by this locator bean -->
    </bean>

<pre><code>&lt;bean id=&quot;clientService&quot;
    factory-bean=&quot;serviceLocator&quot;
    factory-method=&quot;createClientServiceInstance&quot;/&gt;

&lt;bean id=&quot;accountService&quot;
    factory-bean=&quot;serviceLocator&quot;
    factory-method=&quot;createAccountServiceInstance&quot;/&gt;


public class DefaultServiceLocator {

    private static ClientService clientService = new ClientServiceImpl();
    private static AccountService accountService = new AccountServiceImpl();

    public ClientService createClientServiceInstance() {
        return clientService;
    }

    public AccountService createAccountServiceInstance() {
        return accountService;
    }
}
</code></pre><p>前面笔记也提到，对于连接池，我们也应该用bean来建立，没必要上java代码</p>
<pre><code>下面是通过Spring来给应用程序配置一个连接池的代码
&lt;bean id=&quot;myDataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt;
    &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;
    &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mydb&quot;/&gt;
    &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;
    &lt;property name=&quot;password&quot; value=&quot;asdfasdf&quot;/&gt;
&lt;/bean&gt;
</code></pre><p>得到ApplicationContext我们就可以获取所有的bean<br>获取ApplicationContext的方式有</p>
<ol>
<li>ApplicationContextAware接口 setApplicationContext()</li>
<li><p>WebApplicationContextUtils抽象类</p>
<pre><code>public static WebApplicationContext getWebApplicationContext(ServletContext sc)
&lt;!--其原理十分简单，在spring容器初始化的方法org.springframework.web.context.ContextLoader.initWebApplicationContext(ServletContext)中--&gt;将WebApplicationContext的实例放入ServletContext 中了。
</code></pre></li>
</ol>
<p>很少用</p>
<p>bean的scope</p>
<pre><code>&lt;bean id=&quot;accountService&quot; class=&quot;com.something.DefaultAccountService&quot; scope=&quot;singleton&quot;/&gt;
</code></pre><p><strong>scope的值可以是singleton, prototype, request, session, application, 以及page。</strong></p>
<ul>
<li><strong>singleton</strong> 单例</li>
<li><strong>prototype</strong> 每次get会新建一个</li>
<li><strong>request</strong> 为每个请求新建一个</li>
<li><strong>session</strong> 为每个session新建一个</li>
<li><strong>application</strong> 每个应用一个</li>
<li><strong>websocket</strong> 每个socket一个</li>
</ul>
<pre><code>通过注解创建bean

      在xml beans里面加
      &lt;context:annotation-config/&gt;

    @Configuration
    public class MyConfiguration {

    @Bean
    public StringStore stringStore() {
        return new StringStore();
    }

    @Bean
    public IntegerStore integerStore() {
        return new IntegerStore();
    }
}
</code></pre><p>这些bean都需要在@Configuration注解下进行创建</p>
<blockquote>
<p>Spring的@Bean注解用于告诉方法，产生一个Bean对象，然后这个Bean对象交给Spring管理。产生这个Bean对象的方法Spring只会调用一次，随后这个Spring将会将这个Bean对象放在自己的IOC容器中。</p>
</blockquote>
<p><strong>依赖注入:</strong> @Autowired</p>
<ol>
<li>@Autowired<br> @Autowired是Spring 提供的，需导入<br> Package:org.springframework.beans.factory.annotation.Autowired;<br> 只按照<strong>byType</strong> 注入。</li>
<li>@Resource<br> @Resource默认按 <strong>byName</strong> 自动注入,是J2EE提供的，</li>
</ol>
<pre><code>    @Autowired(required=false)@Qualifier(&quot;loginService&quot;) 
    private LoginService loginService;
</code></pre><p>   (1).@Autowired 与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上;<br>   (2).@Autowired 默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设<br>    置它的required属性为false，如：@Autowired(required=false) .</p>
<p>如果我们想使用名称装配可以结合 @Qualifier注解进行使用;</p>
<p>Autowired用在属性上:</p>
<pre><code> @Autowired
   private SpellChecker spellChecker;
</code></pre><blockquote>
<p>就免去setter了。会自动寻找bean来注入进去</p>
</blockquote>
<p>用在方法上也差不多(也可以注解在Setter方法上,构造函数注入依赖)</p>
<pre><code>之后
@ComponentScan(basePackages = &quot;org.example&quot;)
或者在xml beans里 &lt;context:component-scan base-package=&quot;org.example&quot;/&gt;
</code></pre><p><strong>组件类可以通过这些注解来声明：@Component, @Repository, @Service, @Controller</strong></p>
<pre><code>比较一下Java注解来声明bean，和使用xml来声明bean
</code></pre><p>@Configuration<br>public class AppConfig {</p>
<pre><code>    @Bean(&quot;myService&quot;)
   public MyService myService() {
        return new MyServiceImpl();
    }
    }
&lt;beans&gt;
    &lt;bean id=&quot;myService&quot; class=&quot;com.acme.services.MyServiceImpl&quot;/&gt;
&lt;/beans&gt;
</code></pre><p>其他资源也是可以注入的<br>资源文件的处理:</p>
<blockquote>
<p>一切资源都使用接口Resource来声明，非常抽象的一个接口，如同BeanFactory, ApplicationContext<br>该接口定义在org.springframework.core.io包中，当然也属于spring core(核心包），<br>如同其他注入的属性类型，也可以注入Resource，例如给某个bean对象注入Resource属性</p>
</blockquote>
<pre><code>&lt;property name=&quot;template&quot; value=&quot;classpath:some/resource/path/myTemplate.txt&quot;&gt;
&lt;property name=&quot;template&quot; value=&quot;file:///some/resource/path/myTemplate.txt&quot;/&gt;

Spring对配置文件的加载
&lt;context:property-placeholder location=&quot;classpath:jdbc.properties &quot; /&gt;
</code></pre><p><strong>property-placeholderlocation元素只能出现一次，出现多个的话，只加载一个，其余不加载。</strong><br>可以这样使用：</p>
<pre><code>&lt;context:property-placeholderlocation=&quot;classpath:*.properties&quot; /&gt;
或者
&lt;bean id=&quot;propertyConfigurer&quot;class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt;
   &lt;property name=&quot;locations&quot;&gt;
     &lt;list&gt;
        &lt;value&gt;conf/sqlmap/jdbc.properties&lt;/value&gt;
        &lt;value&gt;conf/config/app.properties&lt;/value&gt;
    &lt;/list&gt;
   &lt;/property&gt;
&lt;/bean&gt;


#app.properties
abc=123
</code></pre><p>@Value(“${abc}”)<br>private String abc;</p>
<p>于是上面的连接池建立可以直接使用配置文件注入方式</p>
<pre><code>&lt;bean class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt;
&lt;property name=&quot;locations&quot; value=&quot;classpath:com/something/jdbc.properties&quot;/&gt;
&lt;/bean&gt;

&lt;bean id=&quot;dataSource&quot; destroy-method=&quot;close&quot;
        class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt;
    &lt;property name=&quot;driverClassName&quot; value=&quot;${jdbc.driverClassName}&quot;/&gt;
    &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;
    &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot;/&gt;
    &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;
&lt;/bean&gt;
</code></pre><h3>上面是spring的基础,下面是spring MVC内容</h3>

<h4 id="Spring-Controller-1"><a href="#Spring-Controller-1" class="headerlink" title="Spring Controller"></a>Spring Controller</h4><blockquote>
<p>Struts 1的后端控制器侵入性太强，要求必须继承Action或者Action类的某个派生类。<br>从请求(HttpServletRequest)中获取参数也使用了类型（ActionForm），所以使用起来<br>需要记住很多类，需要封装。<br>Strtus2 的后端控制器尽管比较灵活，但是也需要些繁琐的配置文件。后端控制器到<br>路径的映射也是很麻烦。<br>无论Struts哪个版本，对视图技术（view）的支持都不够强。</p>
</blockquote>
<pre><code>spring 前端控制器是org.springframework.web.servlet.DispatcherServlet
</code></pre><p>要导入的话</p>
<pre><code>&lt;web-app&gt;
    &lt;listener&gt;
        &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
    &lt;/listener&gt;

    &lt;context-param&gt;
        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
        &lt;param-value&gt;/WEB-INF/app-context.xml&lt;/param-value&gt;
    &lt;/context-param&gt;

    &lt;!-- 这个子元素必须有，Servlet容器新增加的特性，支持多模块开发 --&gt;
    &lt;absolute-ordering /&gt; 
    &lt;servlet&gt;
        &lt;servlet-name&gt;app&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet
        &lt;/servlet-class&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
            &lt;param-value&gt;&lt;/param-value&gt;
        &lt;/init-param&gt;
        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
    &lt;/servlet&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;app&lt;/servlet-name&gt;
        &lt;url-pattern&gt;/&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;
&lt;/web-app&gt;
</code></pre><ul>
<li>1.添加ContextLoaderListener</li>
<li>2.添加context参数  写上配置文件的路径</li>
<li>3.配置DispatcherServlet  <strong>这个前端控制器DispatcherServlet也可以通过init-param加载ApplicationContext的配置文件。</strong></li>
</ul>
<blockquote>
<p>tomcat安装文件夹下的子文件夹conf下有一个全局的配置文件web.xml，<br>它提供了几个Servlet组件，也配置了/和<em>.jsp路径。<br>请记住：<em>*如果应用的web.xml文件的配置路径和tomcat的web.xml中的路径一致，那么应用程序优先，如果没有配置，那么会继承tomcat的web.xml中的配置。</em></em></p>
<p>建议配置成拦截所有资源，但是不包括jsp文件。用户发送过来的任何请求，都视作用户动作，<br>用户动作当然要由控制器来进行处理!!!<br>!!!所以前端控制器的url-pattern应该是/，而不是/*</p>
</blockquote>
<p><strong>ContextLoaderListener和DispatcherServlet都会创建ApplicationContext，前面创建的是后面创建的AppicationContext的parent，这个可以调用ApplicationContext的getParent函数获取。</strong></p>
<blockquote>
<p>DispatcherServlet和MVC有关，所以，MVC的组件可以配置在DispatcherServlet对应的配置文件中。<br>而ContextLoaderListener尽量是业务逻辑对应的组件。</p>
</blockquote>
<p>因此两个applicationcontext会引起一些问题。最好只定义一个<br><img src="./1577441245805.png" alt="Alt text"></p>
<blockquote>
<p>好了，导入了前端控制器，前端控制器收到客户端发送过来的url，它如何处理呢？</p>
</blockquote>
<p><strong>可以把静态资源和后端控制器逻辑分开。例如，在配置文件中声明：</strong></p>
<p>在beans标签里映射静态资源</p>
<pre><code>    &lt;mvc:resources mapping=&quot;/js/**&quot; location=&quot;/WEB-INF/js/&quot; /&gt;
    &lt;mvc:resources mapping=&quot;/css/**&quot; location=&quot;/WEB-INF/css/&quot; /&gt;
</code></pre><p>上面映射中的**表示支持子文件夹</p>
<p><strong>后端控制器的编写：</strong><br>先在配置文件里     开启MVC注解</p>
<pre><code>&lt;mvc:annotation-driven/&gt;
</code></pre><p>在配置文件中启动扫描组件，注意是包的名字，别写其他的，也别写适配符*</p>
<pre><code>&lt;context:component-scan    base-package=&quot;com.abc.project.controller&quot; /&gt;
</code></pre><blockquote>
<p>那么路径到处理函数的映射？</p>
</blockquote>
<pre><code>@Controller
public class MyController {
    @RequestMapping(&quot;/calc/add&quot;)
    public String add(@RequestParam(value=&quot;v1&quot;) String v1, @RequestParam(value=&quot;v2&quot;) String v2) {

    }

    @RequestMapping(&quot;/calc/subtract&quot;)
    public String subtract(@RequestParam(value=&quot;v1&quot;) String v1, @RequestParam(value=&quot;v2&quot;) String v2) {

    }
}
或者
@Controller
@RequestMapping(&quot;/calc&quot;)
public class MyController {
    @RequestMapping(&quot;/add&quot;)
    public String add(String v1, String v2) {

    }

    @RequestMapping(&quot;/subtract&quot;)
    public String subtract(String v1, String v2) {

    }
}
</code></pre><p>可以指定请求方法<br><strong>@RequestMapping(value=”/add”, method = RequestMethod.GET)</strong><br>或者直接使用不同的注解<br><strong>@GetMapping, @PostMapping, @PutMapping, @DeleteMapping, …</strong></p>
<p>后端控制器的函数名称没有任何要求，不过参数当然不能随意的写。<br>后端控制器支持的常见参数类型列表<br>HttpServletRequest, HttpServletResponse,javax.servlet.http.HttpSession<br>java.util.Locale<br>java.util.Map, org.springframework.ui.Model, org.springframework.ui.ModelMap<br><strong>(也就是request,response,session,locale,map,model,modelmap)</strong><br>@PathVariable<br>@RequestParam<br>@RequestHeader<br>@CookieValue<br>@RequestBody<br>@RequestPart<br>@ModelAttribute, @SessionAttributes, @SessionAttribute, @RequestAttribute</p>
<p>@RequestBody可以直接把输入的json干成对象</p>
<pre><code>public String add(@RequestBody Account account)
</code></pre><p>Spring对路径的支持非常灵活，支持带参数的路径，或者说模板路径<br><strong>@RequestMapping(“/student/{studentid}/modify”);</strong></p>
<pre><code>public String modify(@PathVariable String studentid) {

}
//或者下面的声明
@RequestMapping(&quot;/student/modify/{studentid}&quot;) 
public String modify(@PathVariable(&quot;studentid&quot;) String studentid) {

}
</code></pre><p>controller处理函数的返回数据  (前面笔记也提到)</p>
<h4>
1.ModelAndView <br>
2.Model<br>
3.ModelMap<br>
4.Map<br>
5.View  直接返回视图。<br>
6.String  字符串描述的视图的逻辑名字，通过视图解析器解析为物理视图地址。<br>
7.void            <br>
8.@ResponseBody Object
</h4>

<p>4.返回json数据。</p>
<pre><code>  public @ResponseBody Map&lt;String, Object&gt; add(@RequestParam String id) {
     Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;();
     map.put(.........);
     ......;
     return map;
  }
</code></pre><p>//转JSON可以更简单</p>
<pre><code>@RestController
   public class MyController {
      @RequestMapping(value=&quot;/add&quot;, produces = &quot;application/json; charset=utf-8&quot;)
      public Map /* 或者其他格式的数据，只要能转JSON就可以*/ add(@RequestBody Student s) {

      }
      @RequestMapping(&quot;/retrieve&quot;)
      public Student retrieve(String id) {

      }
   }
</code></pre><p>Model, ModelAndView, View 在后面说</p>
<h3>redirect和forward有何区别？!!!</h3>

<p>response.sendRedirect(“”)<br>request.getDispatcher().forward()</p>
<p>forward是服务器内部重定向，使用的是同一个request  客户端浏览器的网址是不会发生变化的。<br>本质上说：forward转发是服务器上的行为，而redirect是客户端行为<br><img src="./1577442308648.png" alt="Alt text"></p>
<h4 id="View"><a href="#View" class="headerlink" title="View"></a>View</h4><p>视图解析，视图类的选择，可以使用配置来完成。<br>应用程序只管定义模型，更新模型的内容。</p>
<p>如果选择jsp视图技术<br>那么配置如下：</p>
<pre><code>&lt;bean id=&quot;viewResolver&quot; 
        class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;
    &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot; /&gt;
    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt;
    &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt;
&lt;/bean&gt;
</code></pre><blockquote>
<p>如果返回字符串“welcome”，那么spring会选择视图<br>    /WEB-INF/jsp/welcome.jsp</p>
</blockquote>
<p><strong>org.springframework.web.servlet.ViewResolver</strong></p>
<pre><code>定义了根据视图名称和区域语言来决定一个视图的抽象函数
@Nullable
public View resolveViewName(String viewName,Locale locale) throws Exception
</code></pre><p><strong>JSP视图对应的视图类为org.springframework.web.servlet.view.JstlView</strong>,BeanNameAware接口，ApplicationContextAware接口, ServletContextAware接口.实现了View接口</p>
<p>在org.springframework.web.servlet.View接口中声明的两个抽象函数：</p>
<pre><code>    @Nullable
public default String getContentType();
public void render(@Nullable Map&lt;String,?&gt; model,
        HttpServletRequest request,
        HttpServletResponse response) throws Exception
</code></pre><p>spring提供根据mime类型来确定输出视图，对应的视图解析器类是<strong>ContentNegotiatingViewResolver</strong></p>
<p><img src="./1577442800697.png" alt="Alt text"><br><img src="./1577442854042.png" alt="Alt text"></p>
<pre><code>或者控制器的处理函数返回ModelAndView。
@RequestMapping(&quot;welcome&quot;);
public ModelAndView welcome() {
    ModelAndView m = new ModelAndView();
    ModelMap map = m.getModelMap();
    map.addAttribute(&quot;username&quot;, &quot;zs&quot;);

    m.setViewName(&quot;index&quot;);
    return m;
}
</code></pre><p><img src="./1577443042248.png" alt="Alt text"></p>
<p>spring提供<br><strong>org.springframework.jdbc.core.JdbcTemplate类</strong><br>另外，它也提供了O/R Mapping功能。<br>对象到关系数据库的映射。完全可以取代Hibernate，MyBatis等技术。</p>
<pre><code>public List&lt;Map&lt;String,Object&gt;&gt; queryForList(String sql,
                                         @Nullable
                                         Object... args)
                                  throws DataAccessException



List&lt;Student&gt; queryForList(&quot;select * from student&quot;, new BeanPropertyRowMappper&lt;Student&gt;(Student.class))
    还有一个映射类也实现了RowMapper接口
</code></pre><p>ColumnMapRowMapper类，<br>public class ColumnMapRowMapper implements RowMapper<Map<String,Object>&gt;<br>映射函数当然是<br>Map<String,Object> mapRow(ResultSet rs, int rowNum);</p>
<p>可以自己定义RowMapper，将特定表中的数据映射为实体对象。</p>
<p><strong>业务逻辑封装在Service层， Service层访问DAO层。</strong></p>
<p>Service组件的声明也是采用注解这种形式</p>
<pre><code>@Service
public class MyService {
    @Autowired
    private SomeDao dao;

    public void setDao(SomeDao dao) { this.dao = dao; }
    public SomeDao getDao() { return dao; }

    public void businessLogic() {
    //dao operation....
    }

}
</code></pre><p>业务逻辑就处理业务数据，service函数内一般不完成数据格式转换。<br><strong>@Service注解通常和@Transactional注解一起使用。</strong></p>
<p><img src="./1577443381575.png" alt="Alt text"></p>
<pre><code>如果想使用spring提供的事务控制，那么需要在配置文件中，声明事务管理器对象
    &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;
 &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;
&lt;/bean&gt;
</code></pre><p>spring并不支持分布式事务</p>
<h3 id="JSP-1"><a href="#JSP-1" class="headerlink" title="JSP"></a>JSP</h3><p><img src="./1577445252136.png" alt="Alt text"><br><img src="./1577445264912.png" alt="Alt text"><br><img src="./1577445271623.png" alt="Alt text"><br>(上面的笔记也讲过)</p>
<p><img src="./1577445317110.png" alt="Alt text"><br>…具体还是看前面的笔记内容吧。。 4个指令，9个动作，还有4个域对象什么的</p>
<h4 id="EL表达式-1"><a href="#EL表达式-1" class="headerlink" title="EL表达式"></a>EL表达式</h4><p><img src="./1577445380410.png" alt="Alt text"><br><img src="./1577445386386.png" alt="Alt text"><br><img src="./1577445397929.png" alt="Alt text"></p>
<p>EL内置的11个对象:</p>
<ul>
<li><strong>pageScope</strong></li>
<li><strong>requestScope</strong></li>
<li><strong>sessionScope</strong></li>
<li><strong>applicationScope</strong></li>
<li><strong>param</strong> 是一个map,key是参数,value是多个参数值</li>
<li><strong>paramValues</strong> 是一个map,key是参数,value是多个参数值,request.getParameterValues(“xxx”)</li>
<li><strong>header</strong>: 相当于请求头，对应request.getHeader(String)</li>
<li><strong>headerValues</strong></li>
<li><strong>init-param</strong> 获取context-param中的参数</li>
<li><strong>cookie</strong> 中key是cookie的name，value是cookie对象 ${cookie.JSESSIONID.value }就是获取sessionId</li>
<li><strong>pageContext</strong><br>相当于使用该对象调用getxxx()方法，例如pageContext.getRequest()可以写为${pageContext.request)</li>
</ul>
<p>表达式中的变量不给定范围时，则默认在page范围查找，然后依次在request、session、application范围查找。也就是从小到大的范围找**</p>
<pre><code>EL 提供“.“和“[ ]“两种运算符来存取数据。
当要存取的属性名称中包含一些特殊字符，如 . 或 - 等并非字母或数字的符号，就一定要使用“[ ]“。例如：
${ user. My-Name}应当改为${user[&quot;My-Name&quot;]}
如果要动态取值时，就可以用“[ ]“来做，而“.“无法做到动态取值。例如：
${sessionScope.user[data]}中data 是一个变量
</code></pre><p><strong>&lt;%@ page isELIgnored=”true” %&gt; 表示是否禁用EL语言</strong></p>
<pre><code>&lt; %=request. getParameter(“username”)% &gt; 等价于 ${ param. username }
&lt;%=request.getAttribute(“userlist”) %&gt; 等价于$ { requestScope.userlist }
&lt;%=user.getAddr( ) %&gt; 等价于 ${user.addr}
</code></pre><h3 id="补充struts2"><a href="#补充struts2" class="headerlink" title="补充struts2"></a>补充struts2</h3><p><img src="./1577511378663.png" alt="Alt text"></p>
<p>struts2的前端控制器改成了filter而不是servlet</p>
<pre><code>&lt;filter&gt;
    &lt;filter-name&gt;struts2&lt;/filter-name&gt;
    &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;
    &lt;init-param&gt;
        &lt;param-name&gt;config&lt;/param-name&gt;
        &lt;param-value&gt;struts-default.xml,struts-plugin.xml,../struts2.xml&lt;/param-value&gt;
    &lt;/init-param&gt;
&lt;/filter&gt;
    &lt;filter-mapping&gt;
        &lt;filter-name&gt;struts2&lt;/filter-name&gt;
        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;
    &lt;/filter-mapping&gt;
</code></pre><p>Action也和strut1不同。strut1只有一个execute函数而且需要4个参数(request,response,form,mapping)<br>strut2可以自定义函数</p>
<pre><code>//编写Action充当控制器
public class LoginAction extends ActionSupport {
    private String username;
    private String password;
    public String getUsername(){
        return this.username;
    }
    public void setUsername(String s){
        this.username = s;
    }
    public String getPassword(){
        return this.password;
    }
    public void setPassword(String s){
        this.password = s;
    }

    public String execute() throws Exception{

        if(getUsername().equals(&quot;walker&quot;)&amp;&amp;getPassword().equals(&quot;yam&quot;)){
            return &quot;sucess&quot;;
        }
        return “error”;  //返回的是逻辑名
    }
}

对应action 配置
 &lt;action name=&quot;login&quot; class=&quot;mypackage.LoginAction&quot;&gt;
        &lt;result name=&quot;error&quot;&gt;/error.jsp&lt;/result&gt;
        &lt;result name=&quot;success&quot;&gt;/index.jsp&lt;/result&gt;
  &lt;/action&gt;
</code></pre><p>高端用法：</p>
<pre><code>&lt;package name=&quot;mooc&quot; extends=&quot;struts-default&quot; namespace=&quot;/&quot;&gt;
     &lt;action name=&quot;product_*&quot; class=&quot;action.ProductAction&quot;  method=&quot;{1}&quot;/&gt;
  &lt;/package&gt;

{1}代表第一个*
</code></pre><p>获取request的方法:</p>
<pre><code>ActionContext.getContext().get(&quot;request&quot;);
ServletActionContext.getRequest();
ServletRequestAware接口
    public void setServletRequest(HttpServletRequest request){
        this.request = request;

    }
</code></pre>]]></content>
  </entry>
  <entry>
    <title>【深層学習】LSTM-Long-Short Term Memory</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91LSTM-Long-Short%20Term%20Memory/</url>
    <content><![CDATA[<h1 id="【深層学習】LSTM-Long-Short-Term-Memory"><a href="#【深層学習】LSTM-Long-Short-Term-Memory" class="headerlink" title="【深層学習】LSTM:Long-Short Term Memory"></a>【深層学習】LSTM:Long-Short Term Memory</h1><h2 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h2><p>其实就是RNN的进化版,从图中可以看出朴素RNN是<strong>当前的输出结果不仅和当前时刻的输入有关，还和上层的隐藏层计算结果有关</strong>，而LSTM中还加入了$c$，因此LSTM有2个传递状态$h\text{(hidden state)}$与$c\text{(cell state)}$<br><img src="./1558189242145.png" alt="Alt text"></p>
<p>LSTM利用某时刻输入$x_t$和上一时刻隐藏状态$h_{t-1}$经过运算得到<strong>4个状态</strong><br> <img src="./1558189578364.png" alt="Alt text"><br><img src="./1558189600298.png" alt="Alt text"><br><img src="./1558189677265.png" alt="Alt text"></p>
<h2 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h2><h3 id="遗忘门-z-f"><a href="#遗忘门-z-f" class="headerlink" title="遗忘门$z_f$"></a>遗忘门$z_f$</h3><blockquote>
<p>遗忘门决定了应丢弃或保留哪些信息。来自先前隐藏状态的信息和来自当前输入的信息通过<strong>sigmoid</strong>函数传递。值介于0和1之间，<strong>越接近0意味着忘记，越接近1意味着要保持。</strong><br><img src="https://pic2.zhimg.com/v2-6c7bd0888f84cfd7d5cf3bc03e9cdbfd_b.gif" alt="avatar"><br><img src="./1558190292899.png" alt="Alt text"><br><strong>由输出和上一层的隐藏状态来决定遗忘哪些</strong></p>
<h3 id="输入门-z-i-与-z"><a href="#输入门-z-i-与-z" class="headerlink" title="输入门$z_i$与$z$"></a>输入门$z_i$与$z$</h3><p>输入门要<strong>更新单元状态</strong>，首先，我们将先前的隐藏状态和当前输入传递给sigmoid函数。这决定了通过将值转换为0到1来更新哪些值：0表示不重要，1表示重要。接着你还要将隐藏状态和当前输入传递给tanh函数，以便在-1和1之间取值以帮助调节网络。然后将tanh输出与sigmoid输出相乘。<strong>sigmoid输出将决定哪些信息对于输出很重要</strong>。<br>输出门决定下一个隐藏状态应该是什么。请记住，隐藏状态包含有关先前输入的信息，隐藏状态也可用于预测。首先，我们将先前的隐藏状态和当前输入传递给sigmoid函数。然后我们将新修改的单元状态传递给tanh函数。我们将tanh输出与sigmoid输出相乘，以确定隐藏状态应携带的信息，输出的是隐藏状态。然后将新的细胞状态和新的隐藏状态转移到下一个时间步。</p>
</blockquote>
<p><img src="./1558190357604.png" alt="Alt text"></p>
<h3 id="cell-state"><a href="#cell-state" class="headerlink" title="cell state"></a>cell state</h3><blockquote>
<p>现在我们应该有足够的信息来计算细胞状态。首先，细胞状态逐点乘以遗忘向量。如果它乘以接近0的值，则有可能在单元状态中丢弃。然后我们从输入门获取输出并进行逐点相加，将神经网络发现的新值更新为细胞状态中，这就给了我们新的细胞状态。<br><img src="https://pic4.zhimg.com/v2-726bf910e01dea258ccd6bc7ad96e5fb_b.gif" alt="avatar"><br><img src="./1558190401755.png" alt="Alt text"></p>
</blockquote>
<h3 id="输出门-z-o"><a href="#输出门-z-o" class="headerlink" title="输出门$z_o$"></a>输出门$z_o$</h3><blockquote>
<p>输出门<strong>决定下一个隐藏状态</strong>应该是什么。请记住，隐藏状态包含有关先前输入的信息，隐藏状态也可用于预测。首先，我们将先前的隐藏状态和当前输入传递给sigmoid函数。然后我们将新修改的单元状态传递给tanh函数。我们将tanh输出与sigmoid输出相乘，以确定隐藏状态应携带的信息，输出的是隐藏状态。然后将新的细胞状态和新的隐藏状态转移到下一个时间步。<br><img src="https://pic4.zhimg.com/v2-9f6e55b47555f741062211693f6857ff_b.gif" alt="avatar"><br><img src="./1558190458927.png" alt="Alt text"><br><img src="./1558190496501.png" alt="Alt text"><br><img src="./1558190506584.png" alt="Alt text"></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】CNN-Convolutional Neural Network(畳み込みニューラルネットワーク)</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91CNN-Convolutional%20Neural%20Network(%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)/</url>
    <content><![CDATA[<h1 id="【深層学習】CNN-Convolutional-Neural-Network-畳み込みニューラルネットワーク"><a href="#【深層学習】CNN-Convolutional-Neural-Network-畳み込みニューラルネットワーク" class="headerlink" title="【深層学習】CNN:Convolutional Neural Network(畳み込みニューラルネットワーク)"></a>【深層学習】CNN:Convolutional Neural Network(畳み込みニューラルネットワーク)</h1><p><img src="./1558157308207.png" alt="Alt text"><br><img src="https://deepage.net/img/convolutional_neural_network/digit.gif" alt="avatar"><br><img src="./1558158122739.png" alt="Alt text"><br><img src="./1569717035010.png" alt="Alt text"></p>
<h2 id="Convolution-卷积"><a href="#Convolution-卷积" class="headerlink" title="Convolution(卷积)"></a>Convolution(卷积)</h2><p><img src="https://deepage.net/img/convolutional_neural_network/animated_convolution.gif" alt="avatar"><br><img src="https://img-blog.csdn.net/20160707204048899" alt="avatar"></p>
<h2 id="Pooling-池化"><a href="#Pooling-池化" class="headerlink" title="Pooling(池化)"></a>Pooling(池化)</h2><p><img src="./1558157803207.png" alt="Alt text"></p>
<h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>卷积可以用$s(t)=(x*w)(t)$,x是输入,w是核函数</p>
<p>卷积神经网络的原理<br><img src="./1569716966741.png" alt="Alt text"><br>一个神经元只负责一部分</p>
<p><strong>一般感知机</strong><br><img src="./1569716982547.png" alt="Alt text"></p>
<p><img src="./1569717019308.png" alt="Alt text"></p>
<p><img src="./1569717125981.png" alt="Alt text"></p>
<p>！！其实这就是卷积神经网络的原理<br><img src="./1569717279138.png" alt="Alt text"><br>每个神经元为自己负责的区域赋值上权重.</p>
<p><strong>不是全连接，权值共享</strong></p>
<p><strong>全连接层</strong><br><img src="./1569717736184.png" alt="Alt text"></p>
<p>关于0填充<br><img src="./1569718942253.png" alt="Alt text"></p>
<h2 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h2><h3 id="全连接层的参数更新"><a href="#全连接层的参数更新" class="headerlink" title="全连接层的参数更新"></a>全连接层的参数更新</h3><p><img src="./1569719303319.png" alt="Alt text"></p>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><h5 id="损失函数对上一层的输出求导"><a href="#损失函数对上一层的输出求导" class="headerlink" title="损失函数对上一层的输出求导"></a>损失函数对上一层的输出求导</h5><p><img src="./1569719385311.png" alt="Alt text"><br>a_i是n个x_k的线性求和</p>
<p><img src="./1569719550478.png" alt="Alt text"><br><img src="./1569720741769.png" alt="Alt text"></p>
<h5 id="损失函数对权重求导"><a href="#损失函数对权重求导" class="headerlink" title="损失函数对权重求导"></a>损失函数对权重求导</h5><p><img src="./1569720534338.png" alt="Alt text"><br><img src="./1569720746260.png" alt="Alt text"></p>
<h5 id="对偏置系数求导"><a href="#对偏置系数求导" class="headerlink" title="对偏置系数求导"></a>对偏置系数求导</h5><p><img src="./1569720715391.png" alt="Alt text"><br><img src="./1569720753883.png" alt="Alt text"></p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>feature map</p>
<p><img src="./1569720005018.png" alt="Alt text"><br>彩色图片的卷积</p>
<p><img src="./1569720105021.png" alt="Alt text"><br>如果用8个filter进行卷积，那filter的深度应该是4,卷积的结果深度是8.</p>
<p><img src="./1569723077443.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【Notification】BLOG内容恢复について (2019-12-26)</title>
    <url>/2019/12/26/%E3%80%90Notification%E3%80%91BLOG%E5%86%85%E5%AE%B9%E6%81%A2%E5%A4%8D%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%20(2019-12-26)/</url>
    <content><![CDATA[<h1 id="【Notification】BLOG内容恢复について-2019-12-26"><a href="#【Notification】BLOG内容恢复について-2019-12-26" class="headerlink" title="【Notification】BLOG内容恢复について (2019-12-26)"></a>【Notification】BLOG内容恢复について (2019-12-26)</h1><blockquote>
<p>由于本地Markdown文件丢失，Blog进行了重新部署，BLOG仍在修复.</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>日系偶像文化与日式应援概述</title>
    <url>/2019/12/26/%E6%97%A5%E7%B3%BB%E5%81%B6%E5%83%8F%E6%96%87%E5%8C%96%E4%B8%8E%E6%97%A5%E5%BC%8F%E5%BA%94%E6%8F%B4%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p><strong>Japanese-style Live Actions</strong>     is a relatively perfect Live Actions system based on the basic structure of J-POP,which can make everyone become a partcipant in Live and  create better visual and auditory effects for Live. This handbook is written with the purpose of “Feeling Live’s Charm and Promoting the Spirit of Assistance”.</p>
<p><strong>日式应援</strong>是以J-POP基本结构为基础的一套较完善的应援体系。能让每一个人参与进Live,为Live创造更好的视觉与听觉效果。本手册以”感受Live魅力，弘扬应援精神”的宗旨编写。</p>
<p><strong>日式応援</strong>とはJ-POPの基本構造に基づいて、比較的完璧な応援システムである。このシステムを通じて一人一人がライブの中で盛り上がられるのはもちろん、ライブにより良い視覚と聴覚の効果を与えることもできます。本 マニュアルは「ライブの魅力を感じて、 応援の精神を発揚する」っていう趣旨で作ります</p>
<p>本手册可以分成3大部分：</p>
<ul>
<li><strong>应援历史、概念等相关概述</strong> </li>
<li><strong>具体应援方式教学</strong> </li>
<li><strong>案例分析</strong></li>
</ul>
<hr>
<h2 id="一-应援-amp-日式应援概述"><a href="#一-应援-amp-日式应援概述" class="headerlink" title="一:应援&amp;日式应援概述"></a>一:应援&amp;日式应援概述</h2><h3 id="1-1-何为应援-応援って何に？"><a href="#1-1-何为应援-応援って何に？" class="headerlink" title="1.1 何为应援 (応援って何に？)"></a>1.1 何为应援 (応援って何に？)</h3><p>  <center> 应援的含义很广泛，不论是体育竞技比赛中的加油呐喊，还是Live的挥动荧光棒等行为均可以算是广义上的应援。本文只探讨Live上的应援。<br>    <strong>Live上的应援</strong><u>是通过一系列行为为台上加油鼓劲，同时为Live创造更好的视觉与听觉效果，也使自身融入Live的一种方式。</u><br>応援の意味はすごい広くて，スポーツ大会中で選手たちへの叫び声も、</p>
<h3 id="1-2-为何应援-応援はなんのため？"><a href="#1-2-为何应援-応援はなんのため？" class="headerlink" title="1.2 为何应援 (応援はなんのため？)"></a>1.2 为何应援 (応援はなんのため？)</h3><p> 应援的原因有很多。最主要的原因有两个<br> （一）<strong>“感受Live魅力，弘扬应援精神”</strong>:这是最本质的原因。通过应援，使自己融入Live,为Live创造更好的视觉与听觉效果。同时也将其他人带入Live的氛围中。一场相对完美的Live既需要台上的努力也需要台下的努力。<br> （二）<strong>表达自己的信仰</strong>:最直接的原因即是表达对idol的信仰。当表达得过于疯狂，而做出不当举动时。则被称为“厄介”。<br> （附：英和词典对厄介的解释）<img src="./1551270169998.png" alt="Alt text"></p>
<h3 id="1-3-日系偶像文化及其历史"><a href="#1-3-日系偶像文化及其历史" class="headerlink" title="1.3 日系偶像文化及其历史"></a>1.3 日系偶像文化及其历史</h3><blockquote>
<p>此部分参考<br><a href="https://en.wikipedia.org/wiki/Japanese_idol（《维基百科-Japanese" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Japanese_idol（《维基百科-Japanese</a> idol》）<br><a href="https://ja.wikipedia.org/wiki/アイドル（《维基百科-アイドル》）" target="_blank" rel="noopener">https://ja.wikipedia.org/wiki/アイドル（《维基百科-アイドル》）</a><br>以及<br><a href="https://www.jianshu.com/p/757be63ba102《偶像的历史意义》）" target="_blank" rel="noopener">https://www.jianshu.com/p/757be63ba102《偶像的历史意义》）</a><br>制作</p>
</blockquote>
<p>要讨论偶像的社会角色和历史意义足以写一篇长篇论文，因此这里仅进行简述。</p>
<h4 id="1-3-1-偶像的角色"><a href="#1-3-1-偶像的角色" class="headerlink" title="1.3.1 偶像的角色"></a>1.3.1 偶像的角色</h4><p>霓虹的”idol”与国人所认知的idol并不是同一个概念。日本idol是个特殊的职业，也是一个极其独立的职业。他们既不是歌手，也不是舞蹈演员。但也可以既是歌手，又是舞蹈演员。虽然idol主要工作是唱歌与跳舞，但也不止唱歌与跳舞……<br>偶像这个职业在日本之所以能发展得如此高度职业化，很大程度上就是因为分离出了区别于一般歌手和演员的独有特质.<br>其通过多样的艺术形式展现着其自身的魅力。无论是通过怎样的艺术形式，偶像必须要有可互动性和反馈性，一定要能对观众产生实质性的共鸣和激励。</p>
<h5 id="1-3-1-1-偶像存在的意义"><a href="#1-3-1-1-偶像存在的意义" class="headerlink" title="1.3.1.1 偶像存在的意义"></a>1.3.1.1 偶像存在的意义</h5><p>在此提出一个问题:<strong>偶像存在的意义究竟是什么?</strong><br>其歌舞水平既比不上专业的歌手，也比不上专业的舞蹈者，演技也比不上专业的演员……<br>为什么偶像能够在日本这个国家里成为一个特殊的，独立的职业呢？而且需求十分之大。<br>有调查表明。平均4000人里就有一个人能找到偶像作为伴侣。可以看出，在霓虹偶像这个职业的人数之多。但大部分为地下偶像（即少有媒体曝光甚至没有媒体曝光的idol）<br><strong>一个独立职业的存在，必然有相应的社会需求作为支撑。</strong><br>那么为什么，这样看起来一无是处的角色，在社会中会有如此大量的需求呢？<br>这里就要讨论偶像存在的意义了</p>
<p>对于偶像存在的意义，每个人的看法或许都各不相同。也没有一个很统一的说法。<br>在我看来偶像是<strong>一个给周围的世界带来温暖和希望的角色</strong>(出自某小偶像的口中，具体是谁忘记了)<br>在某日综中，主持人问过一个小偶像，其认为作为偶像，最重要的是什么。<br>那个偶像的回答是<strong>“笑顔”</strong>。这也说明了，偶像是给予人们希望与积极的想法的角色。<br>因此可以发现，日系偶像曲子，大多数都为积极，欢快的曲子。就算是悲伤的曲子，表达的也是积极的思想。</p>
<p>2011年3月11日。日本东北地区外海三陆冲区域发生了有观测记录以来最大规模的一次地震，高达9级的地震引发了同样创纪录的日本史上最惨烈的海啸灾害。这次噩梦般的巨型灾难共造成的死亡失踪总人数高达2.2万，并且直接导致了更为可怕的福岛核电站泄露事故，其带来的后续灾祸影响至今仍未消散。</p>
<p>下面就以这个案例来分析偶像的社会意义。（或许没有比这个更好的示例了）</p>
<p>[以下内容为转载]</p>
<blockquote>
<p>“在悲剧方面，人总是相信只有自己是观众。某一天，当被通知‘这次的主角是你’时，才会明白自己只是观众这种想法是没有任何依据的。”    ——《象之背》·秋元康</p>
</blockquote>
<p>在地震发生以后，AKB48在第一时间就中止了预定于3月14日举行的“跟随着Takamina（高桥南）”演唱会，并迅速启动了一系列赈灾企划。这个计划叫做“誰かのために”，除去专项的募捐和义演活动，AKB48还会从常规收入中拿出固定比例的资金直接用于援助救灾工作，所有印制有该计划Logo的周边商品，收入的一部分都会被用作善款。(至今开闭的所有有包装的周边上仍有该LOGO)<img src="./1551537523199.png" alt="Alt text"></p>
<p>在最初最混乱的时期，AKB运营方没有贸然选择去灾区添乱，只是通过筹集善款的方式间接为救灾工作出力。一直等到五月份，灾区情况基本稳定以后，此时灾民们最需要的已经不是救援力量，而是精神层面的抚慰，AKB48才开始陆续前往各大灾区进行慰问演出。<strong>抵达灾区的AKB48成员全部身着素色的T恤以示肃穆，但是演出歌曲却并没有刻意追求煽情，她们站在灾民面前，依旧是面带笑容地全力演唱着《Heavy Rotation》这样充满欢快激情的歌曲。</strong>令人意外的是，灾民们的反应也同样非常积极，每一次演出时台下都会出现热情的应援和大声欢呼，握手会和各种交流活动的气氛也非常温馨融洽……这样的情形令许多媒体都惊诧不已——为什么这群唱唱跳跳的偶像，在充满悲伤氛围的灾区却受到了如此热烈的欢迎？在活动过程中，AKB48的每一个成员都表现出了极高的职业素养，一直以来通过握手会与粉丝们面对面交流的经验在这种场合发挥了作用，她们从头到尾没有任何不当的举动，井然有序，肃然专注，却又温柔真诚，治愈人心。其实成员们也都只是一群普通的小女孩，也都被灾区的惨状所震撼，会感到难受和害怕。但是只要面对灾民，她们每个人都能控制住自己的情绪，拿出最真诚的笑容，用最温柔得体的方式去鼓励对方。或许这才是赈灾义演应该有的样子——每一个灾民的心情、心态和个性是不同的，不能指望所有人都会跟着热闹欢乐的演出一下子变得开心起来，肯定还是会有受伤的人沉默着，悲伤着。<strong>但是身为演出者，在这样的时刻，就应该全力以赴地燃烧起自己去呈现最热情的表演，这种坚定绽放的乐观与不合时宜的搞笑是完全不同的概念。台下的观众越是悲伤，台上的人就越应该让受伤的人看到世界上依旧有着充满激情的美好事物，这才是对于灾民最大的尊重和慰藉。</strong></p>
<p><strong>日本一直都是一个非常矛盾的民族，国民在日常人际交往时显得等级森严、强调“不给别人添麻烦”、年功序列制的冰川社会无时无刻不散发出自私冷漠的氛围；但正因如此，日本人有时候又显得非常“中二病”和感性，坚信八百万神明万物有灵，崇尚幻想和热血，很容易被精神层面的事物所感动和激励。</strong>早在三十多年前的经典动画《超时空要塞Macross》里，歌姬们就能靠着歌声左右宇宙战争的走向，甚至感化外星敌人。他们热衷于把甜美温柔的偶像与冷酷硬朗的机器人大战放在一起，也正是出于对这种将“用爱发电”真正具象化表达的青睐。偶像这个职业在日本之所以能发展得如此高度职业化，很大程度上就是因为分离出了区别于一般歌手和演员的独有特质，无论是通过怎样的艺术形式，偶像必须要有可互动性和反馈性，一定要能对观众产生实质性的共鸣和激励。在这样一个“高语境文化”的国家里，非追星族本来是很难理解所谓偶像的魅力的——他们不可能去深入了解每一个偶像本身，以及他们跟粉丝之间互动的故事，从而不会明白单个偶像对于个体粉丝的重要性，不明白粉丝在面对偶像时为什么可以如此直白狂热地表达自己的情绪。<strong>当这种羁绊局限于个体之间时，偶像就注定是一种小众文化，所谓唱唱跳跳的偶像活动确实就只是一种边缘化的文化符号；而只有当偶像作为一个整体概念，真正参与到社会活动中去，人们才会感受到对于整个文明社会而言，有这种艺术符号形式、有这样优质偶像的存在，是一件多么难能可贵的事情。</strong></p>
<p><strong>所有需要与人互动的社会性职业都是如此，偶像自然也不例外。平时他们只属于可有可无的娱乐消遣，但在这种时刻却成为了证明社会还没有崩溃、生活仍然要继续的有力标志。正是因为天灾太过令人绝望而痛苦，在强大的自然面前人类个体太过渺小，所以灾民们才会迫切需要看到象征着希望的、年轻而充满力量的生命，来证明作为人类种群集体的羁绊与团结的力量。</strong>偶像个体在演出时收获着台下粉丝的应援，而当偶像作为社会团体出现在这种场合时，就化身成为了灾民最需要的，能够带去治愈和激励的一方。1995年的阪神大地震后，出演《music station》的SMAP紧急取消了新歌发表，而是换上黑色的西装演唱了那首《がんばりましょう（加油啊！）》，并启动了一系列公益援助活动——这就是真正的国民团体所谓“国民性”的体现，也是职业偶像积极的社会意义所在</p>
<p>偶像守着的人类最为幼稚却骄傲的部分——所谓偶像就是会带着一点中二特质，<strong>充满活力的年轻生命，蓬勃四溢的青春热血，告诉人们任何时候都可以笑着活下去。</strong>不需要被刻意赋予任何多余的煽情主题，就像地震后废墟里出现的一颗小小嫩芽，它的存在本身对于历经苦难的人民而言就胜过了千言万语。<strong>随着文明和社会的发展，当基本的衣食住行被满足之后，人民精神层面的需求势必会凝结出相应的寄托物。因此，广义上偶像概念的历史其实比人们想象的要久远得多——这种形式伴随着百万年前原始图腾偶像崇拜和部落组织的集体共情而诞生，在漫长的人类发展历史中从未消逝，反而一次又一次地以各种形式鼓舞着这个社会性物种迈过了那些可怕的难关和挑战。</strong></p>
<p><strong>偶像的意义绝不是建立在那些虚浮的剧本和小圈子内部的自我感动里，而是要让所有人看到，偶像在接受了大众的应援之后，一定会以这种堂堂正正的方式回馈和反哺社会。</strong></p>
<blockquote>
<p>“如果神明真的存在<br>请为这片土地再开辟出全新的世界<br>即便如此风依然在吹<br>生命的气息在拂过脸颊<br>……<br>即使眼泪无法避免<br>我也愿意为此有所担当<br>我不要做旁观者。”<br>——《風が吹いている》</p>
</blockquote>
<p><strong>这就是发生在那个2011年的故事，日本多年以来冷漠的“无缘社会”第一次因为这样的天灾而产生了松动，AKB48的表现就是那场让普通民众前所未有地团结在一起的大赈灾活动的注脚和缩影，自此官方视角也开始正视起这个以“面对面”为核心主题的偶像团队所传递出来的积极价值观和社会意义。</strong><br>该年在偶像历史上，也称为”日本总AKB化之年“ ，该年刚经历过偶像冰河期不久，该年后偶像市场也逐渐回暖。出现越来越多的偶像团体。</p>
<h4 id="1-3-2-偶像的历史"><a href="#1-3-2-偶像的历史" class="headerlink" title="1.3.2 偶像的历史"></a>1.3.2 偶像的历史</h4><p>【起源】<br>1940年代称为「女学生のアイドル（bobby-soxer’s idol）」出现，开始出现idol概念<br>对于日本来说最初「アイドル(idol)」主要用来称呼国外艺能人</p>
<blockquote>
<p>1970年代に至り、未成熟な可愛らしさ・身近な親しみやすさなどに愛着を示す日本的な美意識を取り入れた独自の「アイドル」像が創造された。</p>
<p>到了1970年代，对 未成熟的可爱·切身且容易亲近等特征的留恋被引入了日式的审美意识，在这样的审美意识下独特的「偶像」形象被创造了。</p>
</blockquote>
<p><img src="./1551612746575.png" alt="Alt text"><br><img src="./1551612780013.png" alt="Alt text"></p>
<p>近年来还出现了各种二次元偶像、声优偶像等。<br>如《Love Live!》《偶像大师》</p>
<h4 id="1-3-3-Call的历史"><a href="#1-3-3-Call的历史" class="headerlink" title="1.3.3 Call的历史"></a>1.3.3 Call的历史</h4><h5 id="1-3-3-1-MIX的历史"><a href="#1-3-3-1-MIX的历史" class="headerlink" title="1.3.3.1 MIX的历史"></a>1.3.3.1 MIX的历史</h5><p>MIX是CALL的一个种类。具体内容和使用方法后面介绍。这里先说说其历史<br>【MIXの歴史】</p>
<blockquote>
<p>MIXを作ったのはEVELという五人の男たち。<br>そのなかの「黒服」「ゼンキョウ」の二人が中心となり生まれた。<br>彼らが日常生活や旅行などで高まったときに思わず発した言葉を混ぜたのでMIXと呼ぶ。<br>MIXを打つ人のことをMIXerという。</p>
<p>1990年代初頭にイングヴェイ・マルムスティーン、アンスラックスなどの<br>ヘビメタ／ハードロック系のライブにおいてEVELたちがMIXを使い始め、<br>やがてアイドルライブにも用いるようになった。<br>当時はまだ現在のように体系化されていなかったので、<br>文字通り気持ちが「タカまった」ときに思わず叫ぶコトバだった。</p>
<p>はじめてアイドルの現場で用いられたのは1993年のアイドルグループ「MELODY」において。<br>その後、東京パフォーマンスドールやZ-1(上戸彩が所属)、また地下アイドルライブなどで広まっていった。</p>
<p>1999年12月にリリースされたZ-1の2ndシングル「You Your You」のテレビ映像に、<br>当時使用されていたMIXを加えた動画がニコニコ動画で視聴できる。<br><a href="http://www.nicovideo.jp/watch/sm1925287" target="_blank" rel="noopener">http://www.nicovideo.jp/watch/sm1925287</a></p>
<p>MIXを受け継いだのは「マスターあめまる」と北海道の二代目「園長」<br>そして「園長」が北海道でZONEヲタと出会い、<br>ZONEライブでMIXをやり始める。<br>そして園長からMIXを伝授された直系である「EDEN」「マサーシー」「パパ」「ピカ(-∀-)」たちが<br>ZONE、Bon-Bon Blanco、SUNFLOWER(広島の地方アイドル)などのライブでMIXを打つようになり、<br>MIXを世に広めていった。<br>みんなの憧れ「MIX号令発動」である「よっしゃいくぞ〜！」はSUNFLOWERヲタの「パパ」が始めた。<br>もともとは「っしゃあ行くぜ〜っ！」だった。<br>その後「ばか師匠」などのMIXerによってAKB劇場に普及していった。</p>
<p>以上、MIXの歴史。</p>
</blockquote>
<p>【翻译】</p>
<blockquote>
<p>制作MIX的是叫EVEL的五位男士，其中以「黒服」「ゼンキョウ」两位为中心制作而成。他们在日常生活或者旅行之类的时候，情绪上来时就会把一些不经意想到的词语混合起来。于是称作MIX。呼喊MIX的人成为MIXer<br>在1990年代初，在イングヴェイ・マルムスティーン、アンスラックス之类的重金属\硬摇滚Live上。EVEL首次使用MIX<br>不久后在IDOL的live上也开始使用了<br>因为那个时候的MIX还不像现在一样体系化，只是在情绪高涨时不经意地喊出来。<br>MIX首次在偶像Live中使用是在1993年的偶像团体「MELODY」的LIVE中<br>在那之后MIX在东京パフォーマンスドールやZ-1(上戸彩が所属)还有地下idol中流传开来<br>在1999年12月にリリースされたZ-1の2ndシングル「You Your You」的TV映像中、可以看到加上了当时使用的MIX的niconico动画<br><a href="http://www.nicovideo.jp/watch/sm1925287" target="_blank" rel="noopener">http://www.nicovideo.jp/watch/sm1925287</a><br>之后对MIX进行发展的是「マスターあめまる」和北海道的二代目「園長」。然后園長在北海道与ZONE的WOTA(日语为御宅之意)相遇,之后ZONE的live上也开始使用mix.<br>然后園長直接传授MIX于「EDEN」「マサーシー」「パパ」「ピカ(-∀-)」等。MIX开始在ZONE、Bon-Bon Blanco、SUNFLOWER(広島の地方偶像)之类的live上使用。MIX在世上流传开来<br>大家喜欢的「MIX引导信号」——「よっしゃいくぞ〜！」是从SUNFLOWER的一个wota，名为「パパ」那开始的。<br>实际上最开始是「っしゃあ行くぜ〜っ！(sshaikuze~)」だった。<br>在那之后「ばか師匠」之类的MIXer将MIX在AKB劇場中普及。<br>以上就是MIX的历史</p>
</blockquote>
<p>【MIX的意义】<br>传闻MIX的内容来源于一首诗</p>
<blockquote>
<p>虎の如く火の如く人の造らざる繊細な心も維新となれば海を飲み女を喰らふ<br>その振動を心の有るがままに化身し本来繊細な心を飛ばし刹那に思ふがまま除き去る<br>これ己に忠実<br>刹那な刻の流れに身を任せるのみ<br>これこそタカまりの心髄なり</p>
</blockquote>
<p>将一些词语抽出后，就成了MIX的主体部分:</p>
<p><strong>虎、火、人造、繊維、海女、振動、化繊飛除去</strong></p>
<blockquote>
<p>[参考资料]<br>「ピカ(-∀-) 」さんの『「當山奈央の歌を聴きたいから生きる」忍足(-∀-)の日記』<br><a href="http://d.hatena.ne.jp/rina_miyawaki/20050330/" target="_blank" rel="noopener">http://d.hatena.ne.jp/rina_miyawaki/20050330/</a><br>「いぬいぬ」さんのブログ『はろぶろ。』<br><a href="http://d.hatena.ne.jp/helloblog/20080203/p1" target="_blank" rel="noopener">http://d.hatena.ne.jp/helloblog/20080203/p1</a><br><a href="http://d.hatena.ne.jp/helloblog/20080324/p3" target="_blank" rel="noopener">http://d.hatena.ne.jp/helloblog/20080324/p3</a><br>「おしゃむ」さんのブログ『北の狼、南の熊』<br><a href="http://d.hatena.ne.jp/osham/20080320/1206036494" target="_blank" rel="noopener">http://d.hatena.ne.jp/osham/20080320/1206036494</a><br>「オーガ」さんのブログ 『僕は矢島舞美が好きなんです。』<br><a href="http://d.hatena.ne.jp/greatmaimi/20080321/1206114280" target="_blank" rel="noopener">http://d.hatena.ne.jp/greatmaimi/20080321/1206114280</a><br>「夜魔皇」さんの『夜魔皇日記』<br><a href="http://d.hatena.ne.jp/yama_kou/20080321/p7" target="_blank" rel="noopener">http://d.hatena.ne.jp/yama_kou/20080321/p7</a><br>mixiのミックス[MIX]コミュ<br><a href="http://mixi.jp/view_community.pl?id=507582" target="_blank" rel="noopener">http://mixi.jp/view_community.pl?id=507582</a></p>
</blockquote>
<h5 id="1-3-3-2-CALL的相关研究与历史"><a href="#1-3-3-2-CALL的相关研究与历史" class="headerlink" title="1.3.3.2 CALL的相关研究与历史"></a>1.3.3.2 CALL的相关研究与历史</h5><p>对call的相关研究文献较少。    </p>
<blockquote>
<p><a href="http://hajime-semi.jugem.jp/?eid=651「コール」への興味――「どのように」から「なぜ」へ" target="_blank" rel="noopener">http://hajime-semi.jugem.jp/?eid=651「コール」への興味――「どのように」から「なぜ」へ</a><br>《明治学院大学 文学部芸術学科 芸術メディア系列のゼミ》<br><a href="http://www1.meijigakuin.ac.jp/~hhsemi15/member/cherry/mokuji_youyaku.html" target="_blank" rel="noopener">http://www1.meijigakuin.ac.jp/~hhsemi15/member/cherry/mokuji_youyaku.html</a>  ——《How Idol Otakus Perform the“Call”? : Types in Berryz Kobo》</p>
</blockquote>
<p><u>以下内容为对《「コール」への興味――「どのように」から「なぜ」へ》这篇文章的部分翻译与简述</u></p>
<p>call是指在LIVE中共同呼喊的口号(大多为御宅族使用).live中的wota们不是互相认识，但是却能统一全体的call声。这种感觉非常舒适。该论文作者从这个现象引出疑问，某些演唱会（如歌剧中）大声呼喊是不被允许的，为什么在御宅类的Live上会被容许？之后论文作者在暑假中对偶像的历史已经call进行了相关资料的收集与调研。但是虽然许多文献中有对偶像的研究，但是以御宅行为为中心进行研究的文献几乎没有。<br>于是作者开始在live等现场进行实地调研。弄清楚了各种call呼叫的时机与动作。之后对wota是如何打call的的实例进行整理。<br>在10月之后作者转换了方式，寻找御宅们是如何接触到call的，同时访问了5个偶像的live,分别为AKB48、仮面女子、早安、私立恵比寿中学、’15。<br>之后作者有了新的发现<br>比如’15的live会喊<strong>「L・O・V・Eラブリー○○（名）！」</strong>这样的成员call。类似的call在AKB48中为<strong>「超絶かわいい○○（名）！」</strong>、私立恵比寿中学中为<strong>「いけいけ○○（名前）！」</strong>、でんぱ組.inc中为<strong>「お！れ！の！○○（名前）！」</strong><br>同时作者发现了新的类型的call——<strong>MIX</strong>与<strong>口上</strong>.  作者对此感到很不可思议。这些call到底是谁想出来的?又是怎样传播给御宅的?</p>
<p>(由于找不到该篇论文的完整版本，且相关文献实在过少，只介绍到这)</p>
<h2 id="二-开始之前"><a href="#二-开始之前" class="headerlink" title="二:开始之前"></a>二:开始之前</h2><h3 id="2-1-了解日式应援体系"><a href="#2-1-了解日式应援体系" class="headerlink" title="2.1 了解日式应援体系:"></a>2.1 了解日式应援体系:</h3><p>日式应援大体分为三种模式：<br><strong>①打Call</strong>:即普通地挥棒与呼喊，这也是最普遍的应援方式。本文将重点介绍这种方式。<br><strong>②Wota艺</strong>(指狭义上的wota艺指光棒艺，广义上的wota艺包括很多,广义上的WOTA(ヲタ为御宅之意)可以指御宅在LIVE中所作的一切应援行为)<br><strong>③手指艺</strong>:一种早期的空手应援方式，多见于三次元idol的应援<br>           值得注意的是，光棒艺与手指艺因幅度过大，会对live产生一定的干扰，因此现已基本退出较正式的Lve场合。多见于应援团私下娱乐，以及特殊场合或企划录制等，地下idol剧场中也较为常见。</p>
<h3 id="2-2-应援棒的选择"><a href="#2-2-应援棒的选择" class="headerlink" title="2.2 应援棒的选择:"></a>2.2 应援棒的选择:</h3><p><img src="./1551271075496.png" alt="Alt text"></p>
<p><strong>(1)电棒</strong>:<br>电棒的特点为:亮度一般适中(也有高亮电棒),持续时间长,结构设计适合长时间挥舞。于是这些特点决定了电棒非常适合用于打Call。当然某些特殊的电棒也适合打艺。下面列出一些电棒的具体信息：</p>
<p>①KBX II\III:KBX是著名的电棒品牌，稳定性强，抗摔，亮度适中。适合打call.若想打艺也可以使用短棒头（棒头是可换的）但不建议用kbx打艺，KBX III比II多了手机调色功能。价格也更贵。一般250R左右。KBXII 170-200即可。<br>②PL\CL：单色高亮电棒。使用8号电池。亮度极高，较轻，适合打艺。不适合打call.价格较便宜。PL为20-30R/根 </p>
<p>③PENLaUO(电UO)：单色高亮电棒，可以瞬间亮棒，使用4节7号电池。亮度极高，满电状态下可对抗化学棒ARC极橙，因结构设计原因，不会感觉到重。适合打艺，若能忍受不能变色，也可用于打尻（手感还是挺不错的）。</p>
<p>④Lumica 与kbx差不多。同样是著名品牌，lumica的变色按钮相对kbx设计得更合理。亮度与kbx相差不大。适合打call.  </p>
<p>⑤光羽星：类似KBX的较便宜的电棒。一般来说100R左右。</p>
<p><strong>(2)化学棒</strong>:<br>亮度一般来说较高。持续时间短，轻。不怕坏，一次性，适合打艺。以秒计费地烧钱。一般用于正式场合打艺使用。(当然，土豪整场live化棒打call也是有的)<br>   ①ARC：最出名的高亮化学棒，也叫大闪光。分为普通系列\极系列\EX极。亮度依次递增，持续时间依次递减(分布为15分钟，3-5分钟,30秒)  价格相同。均为7元/支</p>
<p> ②river roots(RR) ③brightglow  ④犀利光：可以说是最便宜的可以打艺的化棒。一般1-1.5R/根。持续时间从2min-12h不等。持续时间越长的种类亮度越低（其中绿色亮度最高）。</p>
<p>以上仅对各类棒子进行粗略介绍，总而言之就是:<br>①只想打尻=&gt;预算充足的话kbx/lumica随便选，若预算不充足则光羽星<br>②只想打艺：<br>1）若想用电棒：PL\CL\电UO，以及lumica一个百元的新产品都可以.<br>2)若想用化棒:准备2种化棒，一是练习等一般场合用的犀利光，二是ARC等较贵的化棒，用于正式场合。</p>
<p>③既想打尻也想打艺:这种情况比较复杂。<br>有很多解决方案<br>1)若能忍受不能变色可以直接上电UO。（电UO只能通过换棒头变色）<br> 2)不能忍受不能变色：短棒KBX或Lumica<br> 3)准备两种棒子。一对用来打尻，一对用来打艺。具体参照上面介绍。<br> 4)能忍受不能变色且预算不足也可以考虑pl(不过pl\cl的结构设计来说，更适合打艺，打call会有些不舒服) ，不能忍受不能变色也可考虑光羽星</p>
<h3 id="2-3-熟悉日系歌曲结构（J-POP歌曲结构）"><a href="#2-3-熟悉日系歌曲结构（J-POP歌曲结构）" class="headerlink" title="2.3 熟悉日系歌曲结构（J-POP歌曲结构）"></a>2.3 熟悉日系歌曲结构（J-POP歌曲结构）</h3><blockquote>
<p>任何应援方案都是基于下面的歌曲结构进行，请务必理解、熟悉，并在之后的实际应用中熟记并掌握。</p>
</blockquote>
<p> <img src="./1551271120080.png" alt="Alt text"><br> （本表参考<a href="https://ja.wikipedia.org/wiki/A%E3%83%A1%E3%83%AD" target="_blank" rel="noopener">https://ja.wikipedia.org/wiki/A%E3%83%A1%E3%83%AD</a> （维基百科-J-POPの基本構成）制作）</p>
<font color=#FF0000 size=3>(图中对降落副歌的解释有误，并非’去掉‘)</font>

<p>以上即为日系歌曲的基本结构。有的曲子比较特殊，会有些细节不太相同。但大体结构不变。<br> 为了熟悉上面的结构，可以试听几首歌，并分辨出其结构。<br> （本表参考于维基百科制作。可能和其他一些教程中的表有所不同。<br><strong>【备注】</strong><br>1)Amero冲刺（Aダッシュメロ）段本表单独列出，其他教程一般算进Amero。<br>2)降落副歌(落ちサビ)   (本表单独列出，其他教程一般算进3番副歌）<br>各構成要素は省略されたり、順番が異なる場合もある。（也存在组成要素省略、顺序不同的情况）</p>
<p> <strong>【具体解释】</strong><br> <strong>①0番副歌</strong>：部分歌曲一上来就是一段和高潮部分填词相同的部分，然后才进入前奏或Aメロ.这部分即称为0番副歌。<br> <strong>②Aメロ</strong>：前奏或第一间奏后会先进入的部分。节奏为【强弱】循环<br> <strong>③Aメロ冲刺段</strong>：衔接A Bメロ的一个8拍<br> <strong>④Bメロ</strong>：Aメロ后的部分。可以说call起来最带感的一部分。节奏为【强 弱 次强 弱】。<br> <strong>⑤副歌</strong>：也就是高潮部分<br> <strong>⑥Cメロ</strong>：部分歌曲会有的部分。节奏与Bmero差不多。也称&lt;大サビ&gt;<br> <strong>⑦降落副歌</strong>：大部分歌曲会有的部分。相比1、2番副歌，因降缓了ドラム(鼓点)还有ベース(base)其节奏有种缓慢的感觉。因此此处的挥棒方式一般为”上升气流(具体操作之后解释)”</p>
<p><strong>【附加】</strong><br> 一般来说<br> 1番与2番<u>除了填词</u>，<strong>完全相同</strong>.<br> 1番和3番填词相同。但由于Cmero、降落副歌的存在。以及要收尾。因此不同点很多<br> 所以一般演唱会中，为了节省时间，不能唱完整版曲子时。剪辑方案一般为<strong>【减掉2番，留下其他部分】</strong></p>
<h3 id="2-4-常见应援装备介绍"><a href="#2-4-常见应援装备介绍" class="headerlink" title="2.4 常见应援装备介绍"></a>2.4 常见应援装备介绍</h3><p>即使没有装备也可以使用“手指艺”进行应援，最基本的应援装备就是一根应援棒。下面介绍一下常见的应援装备。一般来说只需应援棒即可进行应援。其余装备感兴趣的话可以购入。但不建议使用过多的装备。<br>①    <strong>应援棒：</strong>这里不多做介绍<br>②    <strong>应援毛巾：</strong>有大尺寸的与小尺寸的。小尺寸的可用来挥动应援（如angela的《Shangri-La(毛巾歌)》需用上毛巾应援。需要使用毛巾应援的曲目极其极其极其稀少），或绑在头上，或披在脖子上<br>③    <strong>应援护腕：</strong>顾名思义就是套在手腕处的东西。<br>④<strong>孔雀：</strong>可以让你持握多棒的神器。拿上瞬间有dalao的感觉。但是除了引人注目外实用性不大。更多是找累（打个PPPH都困难）孔雀更多的是自己DIY。可以自己绘制图纸，然后定制亚克力模型。<br>⑤<strong>光剑袋\包：</strong>即容纳应援棒的东西。一般可以系在腰上。<br>⑥<strong>法披：</strong>一种日式披风，披上看起来还是不错的。<br>⑦<strong>应援扇</strong></p>
<h2 id="三-具体应援教学"><a href="#三-具体应援教学" class="headerlink" title="三:具体应援教学"></a>三:具体应援教学</h2><h3 id="3-1-基本挥棒动作"><a href="#3-1-基本挥棒动作" class="headerlink" title="3.1 基本挥棒动作:"></a>3.1 基本挥棒动作:</h3><p><strong>图中红色曲线表示发力划出</strong><br>1）    <strong>平敲：</strong>一般用于副歌，或其他一些鼓点较密集的地方。为8/8(即一个8拍敲8下)。<br><img src="./1551437372011.png" alt="Alt text"><br>如图,一个来回为一组。<br>一个8拍8组<br>【发力描述】红色曲线为发力曲线。即发力向前划出。然后类似图中蓝色曲线那样自然弹回</p>
<p>2）    <strong>前挥：:</strong>轨迹与平敲相同，也可以理解为平敲4/8(每两拍前挥一次)，2/8.即带有一定停顿的平敲。<br>   作用十分巨大，比如用于卡拍，特殊节奏段等。GT警（后面会提到）报的前两下hai也需要用上4/8版的前挥<br><img src="./1551437706205.png" alt="Alt text"></p>
<p>【发力描述】红色曲线为发力曲线。即发力向前划出。之后停止。等待。<br>下面列出一个8拍内的操作：<br>|类型/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 4/8 | 挥出|  停   |挥出|  停   |挥出|  停   |挥出|  停   |<br>| 2/8     |  挥出|  停   |停|  停   |挥出|  停   |停|  停   |</p>
<p>3）    <strong>上击（前击）：</strong>向前上方击出。一般与喊Hai的call配合，或者歌词call\回应性call时配合使用<br><img src="./1551439295941.png" alt="Alt text"></p>
<p>4）    <strong>上升气流：</strong>一般用于节奏缓慢部分、鼓点不明显部分。特点是可以进行比较缓慢的滑动<br>比较常用的为2/8或1/8.即一个8拍2组或1组<br><img src="./1551439099530.png" alt="Alt text"></p>
<p>【描述】<br>发力下划(①)后一直缓慢上升直到肩部(②),然后接下一组<br>下面列出一个8拍内的操作：<br>|类型/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 2/8 | 发力下划|  缓慢上升   |  缓慢上升|    缓慢上升   |  发力下划|    缓慢上升   |  缓慢上升|    缓慢上升   |<br>| 1/8     | 发力下划|  缓慢上升  |缓慢上升|  缓慢上升   |缓慢上升|  缓慢上升   |缓慢上升| 缓慢上升   |</p>
<p>5）    <strong>里打：</strong>一般用于Amero.<br><img src="./1551439431805.png" alt="Alt text"><br>（里打体现了打call的<strong>弱拍补足原理</strong>）<br>于是强拍(奇数拍)下划，弱拍（偶数拍）击出<br>下面列出一个8拍内的操作：<br>|拍子序号     |    1(强) | 2(弱)  |3(强) | 4(弱)  |5(强) | 6(弱) |7(强) | 8(弱)  |<br>| :———— | ————:| :—: |<br>|  | 下划并返回| 前击   | 下划并返回| 前击 |下划并返回| 前击 |下划并返回| 前击 |</p>
<p>6）    <strong>里跳：</strong>带起跳的里打。即向上击出时顺势起跳。<br>7）    <strong>雨刷：</strong>国人比较熟悉的应援方式，即手臂左右摆动。一般见于慢歌。（注：一般台上不领起该动作，不自行发起。台上领起该动作则跟着做。）<br>8）    <strong>旋转信号：</strong>举起手至顶部，利用腕部发力，旋转棒子。一共4次（合计4拍）<br><img src="./1551439907556.png" alt="Alt text"></p>
<p>9）    <strong>振幅：</strong>类似雨刷。不过一般速度较快。一般以肘部为轴心摆动，雨刷是以肩部为轴心。一般来说2拍为一组。即向左、向右划各一拍。<br><img src="./1551440150283.png" alt="Alt text"></p>
<p>10）    <strong>PPPH：</strong>一般用于Bメロ。极少数歌曲副歌也能用上。<br>一共4拍。有很多种打法。原版是第1拍左胸前敲一次，第3拍右胸前快敲2次，第4拍右手上击，起跳(演唱会中一般无法起跳。因此可以省略。或身体做个样子就行)。 也有一个版本是，从左旋转棒子到右再上击。 再有一个版本是。第一拍下击，第3拍中间击2次，第四拍上击。（简化版本）<br>这里仅列出3种版本。<br>11）    <strong>OPP：</strong>和PPPH的用途相同<br>方式为前两排喊o~ 后两拍每拍拍手一次</p>
<p>12）    <strong>大拍手:</strong>完全展开双手，从两侧向头顶拍手。台上不领一般不自行发起。<br>13）    <strong>振り付けコーピー（舞蹈动作copy）</strong>：同字面意思。</p>
<h3 id="3-2-基本Call"><a href="#3-2-基本Call" class="headerlink" title="3.2   基本Call"></a>3.2   基本Call</h3><p>1)<strong>Se no警报：</strong>喊seno。<br>其作用十分广泛，可以用来领起很多东西。最常用的是用来引起GT警报。有时为了加强气势也可以在喊se no前1拍加喊hey。变成Hey!Se no!<br>seno警报算是一个引导信号。因此新手实际打call时，可注意听这个警报，然后进行接下来的call.</p>
<p>2)<strong>GT警报:</strong> 喊Hai-Hai- HaiHaiHaiHai.(8拍)<br> 一般用于即将进入Bmero的部分。即表中的Amero冲刺部分。也见于某些曲子的副歌内。有时也用作副歌警报。<br>3）<strong>PPPH：</strong>o<del>Hai (4拍)。用于Bmero.挥棒方式不再叙述。见3.1.<br>4）<strong>OPP：</strong>o</del> 2拍后，拍打2下</p>
<blockquote>
<p>进入Bmero的正确方式:<br>Amero 最后两拍:seno,Amero冲刺:GT警报,Bmero:PPPH/OPP/Bmero成员名call 等<br>即Seno警报-&gt;GT警报-&gt;PPPH/OPP/Bmero成员名call</p>
</blockquote>
<p>5）<strong>旋转信号:</strong>fuwa~(发音类似hu第二声)<em>4,挥棒方式不再叙述<br>6)<strong>fufu：</strong>第四声，1拍快速喊出。对应挥棒方式为向前上快辉两下。或者快速拍手2次<br>7)<strong>-Hai：</strong>在弱拍喊Hai.一般见于前/间/(尾奏) 还有MIX预警<br>8)<strong>uya-Hai/u-Hai：</strong>一般见于地下idol的应援。在强拍喊uya/u 在弱拍喊hai.<br>9)<strong>Bmero 成员call</strong>:按PPPH/OPP的节奏喊出成员名字<br>10)<em>*超絶可愛い call</em></em>：用于Amero.  即喊出 超絶可愛い（chouzetsu kawaii） 【成员名】</p>
<p><strong>(注，如第一章所说。不同的idol前缀使用的词不同，但是喊法一样。这里仅以”超絶可愛い为例子)</strong></p>
<p>一般用在<strong>Aメロ1段(4个8拍)的末尾</strong><br>如表所示:<br>|8拍序号/拍子序号(里打 里/外)     |    1(里) | 2（外）  |3（里） | 4（外）  |5（里） | 6（外） |7（里） | 8（外）  |<br>| :———— | ————:| :—: |<br>| 1 | -| -   |  -|   -  | -|  -   |  -|  -  |<br>| 2    |-|  -  |-| -  |-| -   |成员| 名~！   |<br>| 3    |-|  -  |-| -  |-| -   |-| -   |<br>| 4    |cho|  ~  |zetsu| kawaii  |-|   - |成员| 名~！   |</p>
<p>11)<strong>副歌内的GT警报</strong>：也是GT警报。具体使用方法见第四章<br>12)<strong>歌词call</strong>：少数曲子的某个部分可能要一起喊出歌词</p>
<p>13)<strong>回应式call</strong></p>
<h3 id="3-3-MIX"><a href="#3-3-MIX" class="headerlink" title="3.3 MIX"></a>3.3 MIX</h3><p><strong>【简介】</strong>:MIX是用于前奏\间奏的应援方式。一般见于对48G等三次元idol的应援。相比前奏、间奏重复弱拍喊Hai的方式。使用MIX将更带感。（对于以下情况尽量不用MIX： 1.二次元系曲子，有统一应援方案，且应援方案中不使用MIX的  2.应援方案高度统一化的曲子，且方案中不使用MIX（如LoveLive的曲子）  以下任意情况中推荐使用MIX：1.应援对象为三次元idol  2.无统一的应援方案的曲子）下面开始正式介绍MIX</p>
<h4 id="3-3-1-MIX结构"><a href="#3-3-1-MIX结构" class="headerlink" title="3.3.1 MIX结构"></a>3.3.1 MIX结构</h4><p>1)    MIX整体由三部分组成 ——<strong>MIX预警</strong>、<strong>MIX引导信号</strong>、<strong>MIX主体</strong></p>
<p>2)    <strong>MIX预警</strong>：1个8拍。喊-Hai-Hai-Hai-Hai (喊于弱拍)<br>3)<strong>MIX引导信号</strong>: 引导信号为一个8拍（A<del>~ + (4拍内容)）<br>①MIX第一引导信号:A</del>~yosshaikuzo!(あ～よっしゃ行くぞ!)<br>②MIX第二引导信号:A<del>~mouicchoikuzo!(あ～もういっちょ行くぞ！)<br>③MIX通用引导信号:A</del>~Jya~Jya~<br>4)    <strong>MIX主体</strong>:每段MIX为2个8拍<br>①    第一段:-TaiGa-FaiYa-SaiBa-FaiBa-DaiBa-BaiBa-Jya~Jya~<br>②    第二段:-Tora-Hi-Jinzou-Seni-Ama-SendouKansentobejyokyo~<br>③    第三段:-ChaPe-Ape-Kara-Kina-Rara-Tosuke-miuhotosuke<br>解释：其实第一段为英文，第二段为日文，第三段为阿依努语。翻译过来是虎、火、人造、纤维、海女、振动、化纤飞除去。据说来源于一首诗.</p>
<h4 id="3-3-2-MIX的使用"><a href="#3-3-2-MIX的使用" class="headerlink" title="3.3.2 MIX的使用"></a>3.3.2 MIX的使用</h4><p> 1]一般情况：当前\间奏正式开始时（注意是正式开始，这个应该还是挺好感悟的），开始喊MIX预警，然后接引导信号、再接MIX主体部分。</p>
<p>下面根据歌曲不同部分具体分析:<br>①<strong>前奏:</strong><br>MIX预警(极少数歌曲可能不用MIX预警)后用第一引导信号，从第一段MIX开始顺序喊。要注意的是，<u><strong>前奏最多能喊到第二段MIX完。(称为2连MIX，只喊完第一段MIX的称为1连MIX)</strong></u>。从这就会出现一个问题：预警+信号+主体 最多有6个8拍（1+1+2<em>2），但是有的曲子前奏很长（8个8拍）。于是就有了<em>*2.5连MIX</em></em>的出现。喊法是：按正常喊到第二段一半（即Seni）后，从新拉一次第一引导信号，再从第一段MIX开始喊。这样恰好8个8拍（1+1+2+2/2+1+2=8）。一般来说前奏都为偶数个8拍，且不会多于8个8拍</p>
<p>②<strong>第一间奏：</strong><br>预警后，使用第二引导信号，从第二段MIX按顺序喊下去。</p>
<p>③<strong>第二间奏：</strong><br>使用第一引导信号，从第一段MIX开始喊。</p>
<p>【特殊情况】<br>①第一间奏过短：只有2个8拍的情况——直接接第二MIX，略去预警和引导信号<br>只有4 个8拍的情况——直接引导信号+第二MIX\第二+第三MIX（视具体曲子而定）<br>②第一间奏过长：一般不会有这种情况，若有这种情况，第二间奏一般会比较特殊。<br>这种情况下第一间奏 也使用第一引导信号，从第一MIX开始喊喊到尾。<br>③    前奏过短：对于前奏过短的情况一般选择不喊MIX。而使用其他应援方案。或者省略MIX预警<br>④    前奏过长：采取一部分先喊-Hai的方式，后面再喊MIX。或者使用其他应援方案</p>
<p>MIX4种版本的使用:<br><strong>1连版本</strong><br>|8拍序号/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 1 | -|  Hai   |  -|   Hai   | -|  Hai   |  -|  Hai   |<br>| 2    | A|  ~  |~| ~   |よっ| しゃ   |行く| ぞー！   |<br>| 3   | -|  TaiGa  |-| FaiYa   |-| SaiBa   |-| FaiBa   |<br>| 4   | -|  DaiBa  |-| BaiBa   |-| Jya   |Jya| ~   |<br><strong>2连版本</strong><br>|8拍序号/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 1 | -|  Hai   |  -|   Hai   | -|  Hai   |  -|  Hai   |<br>| 2    | A|  ~  |~| ~   |よっ| しゃ   |行く| ぞー！   |<br>| 3   | -|  TaiGa  |-| FaiYa   |-| SaiBa   |-| FaiBa   |<br>| 4   | -|  DaiBa  |-| BaiBa   |-| Jya   |Jya| ~   |<br>| 5  | -|  Tora  |-| Hi   |-| Jinzou   |-| Seni   |<br>| 6  | -|  Ama  |-| Sendo   |Kasen|  tobe  |Jyo|kyo ~   |<br><strong>2.5连版本</strong><br>|8拍序号/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 1 | -|  Hai   |  -|   Hai   | -|  Hai   |  -|  Hai   |<br>| 2    | A|  ~  |~| ~   |よっ| しゃ   |行く| ぞー！   |<br>| 3   | -|  TaiGa  |-| FaiYa   |-| SaiBa   |-| FaiBa   |<br>| 4   | -|  DaiBa  |-| BaiBa   |-| Jya   |Jya| ~   |<br>| 5  | -|  Tora  |-| Hi   |-| Jinzou   |-| Seni   |<br>| 6    | A|  ~  |~| ~   |よっ| しゃ   |行く| ぞー！   |<br>| 7   | -|  TaiGa  |-| FaiYa   |-| SaiBa   |-| FaiBa   |<br>| 8   | -|  DaiBa  |-| BaiBa   |-| Jya   |Jya| ~   |</p>
<p><strong>3连版本</strong><br>|8拍序号/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 1 | -|  Hai   |  -|   Hai   | -|  Hai   |  -|  Hai   |<br>| 2    | A|  ~  |~| ~   |よっ| しゃ   |行く| ぞー！   |<br>| 3   | -|  TaiGa  |-| FaiYa   |-| SaiBa   |-| FaiBa   |<br>| 4   | -|  DaiBa  |-| BaiBa   |-| Jya   |Jya| ~   |<br>| 5  | -|  Tora  |-| Hi   |-| Jinzou   |-| Seni   |<br>| 6  | -|  Ama  |-| Sendo   |Kasen|  tobe  |Jyo|kyo ~   |<br>| 7   | -|  ChaPe  |-| Ape   |-| Kara   |-| Kira(na)   |<br>| 8   | -|  Rara  |-| Tosuke   |miu| hou   |tusu| ke~   |</p>
<h4 id="3-3-3-倍速MIX"><a href="#3-3-3-倍速MIX" class="headerlink" title="3.3.3 倍速MIX"></a>3.3.3 倍速MIX</h4><p>即MIX主体部分以2倍速喊出（每拍一词）多见于地下IDOL的应援。一般使用倍数MIX时不需要引导信号与预警信号。<br>一般用以补拍。如在Bメロ的后半部分使用。或者用作副歌警报(也就是进入副歌前的一小段)</p>
<p><strong>注意:</strong>使用第二段的倍数mix时tobejyo-kyo~不念。也就是说只念tora hi jinzou seni ama sendo ka!sen!<br>也就是<br>|   |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| Tora  | Hi|  Jinzou  |Seni| Ama   |Sendo| Ka!   |Sen!|</p>
<h3 id="3-4-特殊call"><a href="#3-4-特殊call" class="headerlink" title="3.4   特殊call"></a>3.4   特殊call</h3><p>这里列出一些特殊Call.可以仅作了解</p>
<h4 id="3-4-1-口上"><a href="#3-4-1-口上" class="headerlink" title="3.4.1 口上"></a>3.4.1 口上</h4><p> “口上”翻译过来即“顺口溜”，多用于尾奏。一般见于地下IDOL的应援。AKB Team8的《47の素敵な街》首次将口上引入了对48G的应援。也是目前唯一一首能用口上应援的48G曲子。<br>口上有很多种。具体可见<a href="http://kuroneko096.web.fc2.com/koujyou.html" target="_blank" rel="noopener">http://kuroneko096.web.fc2.com/koujyou.html</a> (口上集)。<br>这里仅介绍最出名的“ガチ恋口上”(真爱顺口溜)。其一共9句话，9个8拍，每个句子一个8拍</p>
<blockquote>
<p>言いたいことがあるんだよ      （i i ta i ko to ga a ru n da yo）<br>やっぱり○○はかわいいよ        (ya ppa ri xx wa ka wa i i yo)<br>すきすき大好き、やっぱ好き     (su ki su ki daisuki ya ppa su ki)<br>やっと見つけたお姫様               (ya tto mi tsu ke ta o hi me sa ma)<br>俺が生まれてきた理由              (o re ga u ma re te ki ta ri yu)<br>それはお前に出会うため           (so re wa o ma e ni de a u ta me)<br>俺と一緒に人生歩もう               (o re to i ssho ni jin sen a yu mo u)<br>世界で一番愛してる                   (se kai de ichiban a i shi te ru)<br>ア・イ・シ・テ・ル                  (A I SHI TE RU)</p>
<h4 id="3-4-2-Faibo-Waipa"><a href="#3-4-2-Faibo-Waipa" class="headerlink" title="3.4.2  Faibo Waipa"></a>3.4.2  Faibo Waipa</h4><p>一般见于地下idol的应援。有时由前奏/间奏/Bmero进入副歌时。会出现“多余”的4拍。这时可用Faipo Wwaipa补足。若“多余出”1个8拍时选择使用倍速mix.</p>
</blockquote>
<h4 id="3-4-3-前奏混合mix"><a href="#3-4-3-前奏混合mix" class="headerlink" title="3.4.3 前奏混合mix"></a>3.4.3 前奏混合mix</h4><p>这个是新的方式。大概是2018年出现的。<br>某些歌曲的前奏由两部分组成 先是一段鼓点不算明显、比较缓慢的部分之后进入正常的部分(这里成为正式的前奏)。<br>这样的前奏时，可以使用前奏混合MIX<br>使用方式为<br>一般在进入正式前奏前倒数两8拍按如下使用<br>|8拍序号/拍子序号     |    1 | 2  |3 | 4  |5 | 6 |7 | 8  |<br>| :———— | ————:| :—: |<br>| 1 | miu|  hou   | tusu |   ke   | Kasen|  tobe   |  jyo|  kyo   |<br>| 2    | JyaJya|  —  |Faibo| —   |Wai| ~  |Pa| ~   |</p>
<h4 id="3-4-4-Ye-TaiGa"><a href="#3-4-4-Ye-TaiGa" class="headerlink" title="3.4.4 Ye TaiGa"></a>3.4.4 Ye TaiGa</h4><p>使用方式同FaiBo Waipa.</p>
<h4 id="3-4-5-Ore-no-俺～の"><a href="#3-4-5-Ore-no-俺～の" class="headerlink" title="3.4.5 Ore~no(俺～の)"></a>3.4.5 Ore~no(俺～の)</h4><p>同样是用在Amero的call.下面以一段(4拍)的拍数为例<br>|8拍序号/拍子序号(里打 里/外)     |    1(里) | 2（外）  |3（里） | 4（外）  |5（里） | 6（外） |7（里） | 8（外）  |<br>| :———— | ————:| :—: |<br>| 1 | -| -   |  -|   -  | -|  -   |  -|  -  |<br>| 2    |o|  ~  |re| ~  |no| ~   |成员| 名~！   |<br>| 3    |-|  -  |-| -  |-| -   |-| -   |<br>| 4    |cho|  ~  |zetsu| kawaii  |-| -   |成员| 名~！   |</p>
<h4 id="3-4-6-Omaegaichiban-お前が一番"><a href="#3-4-6-Omaegaichiban-お前が一番" class="headerlink" title="3.4.6 Omaegaichiban(お前が一番)"></a>3.4.6 Omaegaichiban(お前が一番)</h4><p>同样是用在Amero的call.下面以一段(4拍)的拍数为例<br>|8拍序号/拍子序号(里打 里/外)     |    1(里) | 2（外）  |3（里） | 4（外）  |5（里） | 6（外） |7（里） | 8（外）  |<br>| :———— | ————:| :—: |<br>| 1 | -| -   |  -|   -  | o| mae  | gai| chiban |<br>| 2    |o|  ~  |re| ~  |no| ~   |成员| 名~！   |<br>| 3    |-|  -  |-| -  | o| mae  | gai| chiban |<br>| 4    |cho|  ~  |zetsu| kawaii  |-| -   |成员| 名~！   |</p>
<h2 id="四-Call-Leader养成计划"><a href="#四-Call-Leader养成计划" class="headerlink" title="四 Call Leader养成计划"></a>四 Call Leader养成计划</h2><h3 id="4-1-定位技巧"><a href="#4-1-定位技巧" class="headerlink" title="4.1.定位技巧:"></a>4.1.定位技巧:</h3><p> 以下的定位技巧可以帮助定位各种警报所在的位置。不过如能凭乐感喊call，不建议使用以下方式。以下方式可以帮助定位一些凭感觉难以确认的call，还有对不熟悉，甚至没听过的乐曲的call.<br><strong>(1)短距离定位工具:</strong><br>①里打：2拍一组，适合定位感受点到喊call点距离较短的情况。比如bmero警报。一般来说很容易识别到Amero最后一个8拍的开头。于是这时只要里打三下，然后击出喊se no即可。<br><strong>(2)中、长距离定位工具：</strong><br>MIX.  MIX是强大的定位工具，可以定位一切整数个8拍倍数的距离，而且具有精确性（因为各个词都不同，在的位置都是确切的）。下面列出MIX各构成的拍子数：<br>                        MIX预警  4下弱拍HAI             - 1个8拍<br>                         Mix引导信号                              -1个8拍<br>                         1-MIX                                      -2个8拍<br>                         2-MIX                                       -2个8拍<br>                         3-MIX                                        -2个8拍<br>                     主体部分每喊出一个词是2个8拍。   对于过长的距离（大于8个8拍），还可以采用x.5连的方式。即喊到某段MIX一半时，重拉一遍警报，再重喊MIX。</p>
<p>(3)关于副歌中的GT警报。某些副歌末尾会喊-Hai-Hai Haihaihaihai.   其实许多歌副歌偶数<strong>段(一般4个8拍)</strong>末尾都可以拉GT警报    。但是一般来说要遵循1.不抢词原则：有唱词时，不抢着拉警报。   一般来说副歌中用上GT警报的情况为：1.最后8拍为尾音拖长 2.最后8拍无词 3.节奏有降落感</p>
<h2 id="五-案例分析"><a href="#五-案例分析" class="headerlink" title="五 案例分析"></a>五 案例分析</h2><h2 id="5-1《47の素敵な街へ》"><a href="#5-1《47の素敵な街へ》" class="headerlink" title="5.1《47の素敵な街へ》"></a>5.1《47の素敵な街へ》</h2><p><img src="./1556876111339.png" alt="Alt text"><br><img src="./1556876127021.png" alt="Alt text"></p>
<h3 id="5-1《青春修炼手册》"><a href="#5-1《青春修炼手册》" class="headerlink" title="5.1《青春修炼手册》"></a>5.1《青春修炼手册》</h3><blockquote>
<p><strong>[0番副歌]</strong><br><strong>&gt;全程上升气流</strong><br>凯：跟着我 左手<br>右手 一个慢动作<br>右手 左手 慢动作重播<br>玺：这首歌 给你快乐<br>你有没有爱上我<br>源： 跟着我 鼻子<br>眼睛 动一动耳朵<br>装乖 耍帅 换不停风格<br>合：青春有太多<br>未知的猜测<br>成长的烦恼算什么</p>
</blockquote>
<p><strong>&gt;One Two Three Go!</strong></p>
<blockquote>
<p><strong>[前奏]</strong><br><strong>&gt;Mix:</strong><br><strong>&gt;-Hai-Hai-Hai-Hai </strong><br><strong>&gt;A~~~Yosshaikuzo~!</strong><br><strong>&gt;-TaiGa-FaiYa-SaiBa-FaiBa-DaiBa-BaiBa-Jya~Jya~</strong></p>
<p><strong>[Aメロ]</strong><br>源：皮鞋擦亮 换上西装 <strong>#里打</strong><br>佩戴上一克拉的梦想    <strong>#里打</strong><br>玺：我的勇敢充满电量  <strong>#里打</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <strong>&gt;Hai! Se no!</strong><br>昂首到达每一个地方  <strong>#前挥</strong><br><strong>&gt;Hai!— Hai!—HaiHaiHaiHai</strong></p>
<p><strong>[Bメロ]</strong><br>凯： 这世界 的太阳 <strong>#PPPH*2</strong><br>因为自信才能把我照亮   <strong>#PPPH*2</strong><br>这舞台 的中央<br><strong>&gt;-Tora-Hi-Jinzo-seni</strong><br>合：有我才闪亮<br><strong>&gt;-Ame-Sendo-</strong><br>有我才能发着光<br><strong>Kasentobejyokyo JyaJya~ Faibo! Waipa~~~</strong></p>
<p><strong>[第一副歌]</strong><br>合： 跟着我 左手 右手<br>一个慢动作<br>&emsp;&emsp;<strong>&gt;o~~~ huhu!</strong><br>右手 左手慢动作重播<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>&gt;hu~hu~</strong><br>这首歌 给你快乐<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>&gt;Se no!</strong><br>你有没有爱上我<br><strong>&gt;Hai!— Hai!—HaiHaiHaiHai</strong><br>跟着我 鼻子眼睛  <strong>#平敲</strong><br>动一动耳朵  <strong>#平敲</strong><br>装乖 耍帅 换不停风格 <strong>#平敲</strong><br>青春有太多 未知的猜测 <strong>#前挥</strong><br>成长的烦恼算什么   <strong>#前挥后部分上升气流</strong></p>
<p><strong>[第一间奏]</strong><br><strong>&gt;Mix:</strong><br><strong>&gt;-Hai-Hai-Hai-Hai </strong><br><strong>&gt;A~~~Mouicchoikuzo!~!</strong><br><strong>&gt;-Tora-Hi-Jinzou-Seni-Ama-Sendo-Kasentobejyokyo!</strong></p>
<p><strong>[Aメロ]</strong><br>源：经常会想 长大多好 <strong>#里打</strong><br>有些事情却只能想象<strong>#里打</strong><br>玺：想说就说 想做就做<strong>#里打</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <strong>&gt;Hai! Se no!</strong><br>为了明天的自己鼓掌<br><strong>&gt;Hai!— Hai!—HaiHaiHaiHai</strong><br>凯：这世界 的太阳  <strong>#PPPH*2</strong><br>因为自信才能把我照亮  <strong>#PPPH*2</strong><br>这舞台 的中央<br><strong>&gt;-Tora-Hi-Jinzo-seni</strong><br>合：有我才闪亮<br><strong>&gt;-Ame-Sendo-</strong><br>有我才能发着光<br><strong>Kasentobejyokyo JyaJya~ Faibo! Waipa~~~</strong></p>
<p><strong>[第二副歌]</strong><br>合： 跟着我左手右手 <strong>#平敲</strong><br>一个慢动作  <strong>#平敲</strong><br>&emsp;&emsp;<strong>&gt;o~~~ huhu!</strong><br>右手 左手 慢动作重播 <strong>#平敲</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>&gt;hu~hu~</strong><br>这首歌 给你快乐 <strong>#平敲</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>&gt;Se no!</strong><br>你有没有爱上我 <strong>#平敲</strong><br><strong>&gt;Hai!— Hai!—HaiHaiHaiHai</strong><br>跟着我 鼻子 眼睛<strong>#平敲</strong><br>动一动耳朵<strong>#平敲</strong><br>装乖 耍帅 换不停风格<strong>#平敲</strong><br>青春有太多 未知的猜测<strong>#前挥</strong><br>成长的烦恼算什么 <strong>#前挥最后上升气流</strong></p>
<p><strong>[Cメロ]</strong><br><strong>#全程前挥</strong><br>凯：<br>向明天 对不起<br>向前冲 不客气<br>一路有你 充满斗志无限动力<br>合：男子汉 没有什么输不起<br>正太修炼成功的秘籍</p>
<p><strong>[降落副歌]</strong><br><strong>#全程前挥</strong><br>源： 跟着我左手右手<br>一个慢动作<br>玺： 右手左手慢动作重播<br>凯： 这首歌 给你快乐<br>你有没有爱上我</p>
<p><strong>[第三副歌]</strong><br>合： 跟着我鼻子眼睛<br>动一动耳朵<br>装乖 耍帅 换不停风格<br>青春有太多 未知的猜测<br>成长的烦恼算什么</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>矩阵求导法则</title>
    <url>/2019/12/26/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E6%B3%95%E5%88%99/</url>
    <content><![CDATA[<h1 id="矩阵求导法则"><a href="#矩阵求导法则" class="headerlink" title="矩阵求导法则"></a>矩阵求导法则</h1><p>[TOC]</p>
<h2 id="一-矩阵求导"><a href="#一-矩阵求导" class="headerlink" title="一.矩阵求导"></a>一.矩阵求导</h2><p><img src="./1554209833185.png" alt="Alt text"></p>
<h3 id="1-求导"><a href="#1-求导" class="headerlink" title="1.求导"></a>1.求导</h3><p><img src="./1554209993479.png" alt="Alt text"></p>
<h3 id="2-几种例子"><a href="#2-几种例子" class="headerlink" title="2 几种例子"></a>2 几种例子</h3><p><img src="./1554210138211.png" alt="Alt text"><br><img src="./1554210165607.png" alt="Alt text"><br><img src="./1554210182350.png" alt="Alt text"></p>
<h3 id="3-常用求导公式"><a href="#3-常用求导公式" class="headerlink" title="3.常用求导公式"></a>3.常用求导公式</h3><p><img src="./1554210105505.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>概率论与数理统计学习笔记</title>
    <url>/2019/12/26/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<hr>
<h2 id="1-概率论的基本概念"><a href="#1-概率论的基本概念" class="headerlink" title="1.概率论的基本概念"></a>1.概率论的基本概念</h2><h3 id="1-1-样本空间与随机事件"><a href="#1-1-样本空间与随机事件" class="headerlink" title="1.1 样本空间与随机事件"></a>1.1 样本空间与随机事件</h3><p><strong>随机试验</strong>：对随机现象的观察、记录、实验<br><strong>样本空间</strong>：随机试验所有可能结果构成的集合  记为&ensp; $S$</p>
<h3 id="1-2-事件的相互关系及运算"><a href="#1-2-事件的相互关系及运算" class="headerlink" title="1.2 事件的相互关系及运算"></a>1.2 事件的相互关系及运算</h3><p>同集合的概念差不多<br><strong>包含关系</strong> &ensp; $A\subset B$ : A事件的发生一定导致B发生<br> <strong>相等关系</strong> &ensp; $A=B$ : 当$A\subset B \bigwedge B\subset A  $<br> <strong>和事件</strong> &ensp; $A\cup B$ : A B至少一个发生<br> <strong>积事件</strong> &ensp; $A\cap B$ 或 $A<em>B$ 或 $AB$ ：AB同时发生<br> <strong>差事件</strong> &ensp; $A-B$ : A发生且B不发生<br> <em>*逆事件</em></em> &ensp; $\bar{A}$</p>
<p> $AB=\Phi$：A B互斥或不相容 </p>
<h3 id="1-3-频率"><a href="#1-3-频率" class="headerlink" title="1.3 频率"></a>1.3 频率</h3><blockquote>
<p>频率是0~1之间的一个实数</p>
</blockquote>
<p><strong>频率定义</strong>:$f_n(A)=n_A/n$    $n_A$:次数  $n$:试验次数</p>
<p>性质<br>1.$0\le f_n(A)\le 1$  (定义)<br>2.$f_n(S)=1$  (样本空间中的事件必然发生)<br>3.$A_1 A_2 …A_n$不相容 有 $f_n(\bigcup_{i=1}^N A_i)=\sum_{i=1}^n f(A_i)$ (不相容事件至少一个发生的频率等于各个事件频率和)</p>
<h3 id="1-4-概率"><a href="#1-4-概率" class="headerlink" title="1.4 概率"></a>1.4 概率</h3><p> 性质</p>
<p>1.非负性<br>2.$f_n(S)=1$  (必然事件概率=1)<br>3.可列可加性 $A_1 A_2 …A_n$不相容 有 $P_n(\bigcup_{i=1}^N A_i)=\sum_{i=1}^n P(A_i)$ (不相容事件至少一个发生的频率等于各个事件概率和)</p>
<p> 公式<br> 1.$P(B-A)=P(B)-P(AB)$<br> 2.$P(A+B)=P(A)+P(B)-P(AB)$<br> 多个事件和时 P=单个事件概率和-任2个事件积概率和+任3个事件积概率和-…+…</p>
<h3 id="1-5-古典概型"><a href="#1-5-古典概型" class="headerlink" title="1.5 古典概型"></a>1.5 古典概型</h3><p>1.不放回抽样<br>step1:计算样本总数<br>step2:计算包含指定事件的样本数<br>step3:相除</p>
<p>顺序无关时，可以用组合数：<br>如 黄球2，白球3个。 取两次都是白球 $P(A)=C_3^2/C_{5}^2$<br><strong>有a个白球取n次恰好取到k个白球一般情况:</strong>  $P=\frac{C_a^kC_b^{n-b}}{C_N^n} $<br>2.放回抽样</p>
<h3 id="1-6-条件概率"><a href="#1-6-条件概率" class="headerlink" title="1.6 条件概率"></a>1.6 条件概率</h3><p>$P(B|A)=\frac{P(AB)}{P(A)}$ 在事件A发生的情况下发生B的概率<br>$P(AB)=P(A)<em>P(B|A)=P(B)</em>P(A|B)$<br>$P(ABC)=P(A)<em>P(B|A)</em>P(C|BA)$<br>….<br>$P(A_1A_2A_3..A_n)=P(A_1)P(A_2|A_1)P(A_3|A_1A_2)…$</p>
<h3 id="1-7-全概率公式与贝叶斯"><a href="#1-7-全概率公式与贝叶斯" class="headerlink" title="1.7 全概率公式与贝叶斯"></a>1.7 全概率公式与贝叶斯</h3><p><strong>全概率公式</strong><br>$P(A)=\sum_{j=1}^nP(B_j)*P(A|B_j)$      &ensp; $B_j$为S一个划分中的一块<br><img src="./1548997593872.png" alt="Alt text"></p>
<p><strong>贝叶斯公式</strong><br><img src="./1548997685347.png" alt="Alt text"><br>即$P(B_i|A)=\frac{P(B_i)P(A|B_i)}{P(A)}=P(AB_i)/P(A)$  知道B_i发生下评估在A发生下的情况<br><strong>先验概率</strong> $P(B_i)$<br><strong>后验概率</strong> $P(B_i|A)$</p>
<p>利用全概率公式与贝叶斯解题<br>可以画划分图<br>如<img src="./1548997985564.png" alt="Alt text"></p>
<h3 id="1-8-事件独立性"><a href="#1-8-事件独立性" class="headerlink" title="1.8 事件独立性"></a>1.8 事件独立性</h3><p>$P(AB)=P(A)P(B)$则说明事件A、B相互独立<br>A、B独立&lt;=&gt;$\bar A$、$B$独立&lt;=&gt;$\bar B$、$A$独立&lt;=&gt;$\bar B$、$\bar A$独立</p>
<p>事件两两独立不一定相互独立</p>
<h2 id="2-随机变量及其分布"><a href="#2-随机变量及其分布" class="headerlink" title="2.随机变量及其分布"></a>2.随机变量及其分布</h2><h3 id="2-1-随机变量"><a href="#2-1-随机变量" class="headerlink" title="2.1 随机变量"></a>2.1 随机变量</h3><p>$X=X(e)  为定义在S上的单值函数，则称X(e)为随机变量,简写X$<br>实质是一个函数，为$S\to R$的映射<br>$随机事件A={\{e:X(e) \in I\}} 可由随机变量表示相应随机事件e$<br>$如\{e:X(e)=1\} 也可记作X=1$</p>
<p>注:e-&gt;X(e)为单值函数</p>
<p><strong>随机变量的类型</strong><br><strong>(1)离散型随机变量</strong>：X的取值为有限个或可数集(与自然数集合等势)<br><img src="./1549000777536.png" alt="Alt text"><br>表示形式$P(X=x_k)=p_k$</p>
<p><strong>几何分布</strong>(在伯努利试验中，成功的概率为p，若ξ表示出现首次成功时的试验次数)<br>$P(X=k)=(1-p)^{k-1}p$<br>X服从几何分布，记为X ～ GE(p) 。<br>$E(X)=\frac{1}{p}$<br>$D(X)=\frac{1-p}{p^2}$</p>
<p><strong>(2)连续型随机变量</strong></p>
<h3 id="2-2-离散型随机变量"><a href="#2-2-离散型随机变量" class="headerlink" title="2.2 离散型随机变量"></a>2.2 离散型随机变量</h3><h4 id="2-2-1-0-1分布（伯努利分布）"><a href="#2-2-1-0-1分布（伯努利分布）" class="headerlink" title="2.2.1 0-1分布（伯努利分布）"></a>2.2.1 0-1分布（伯努利分布）</h4><p>X=0或1,0&lt;p&lt;1<br><img src="./1549001417013.png" alt="Alt text"><br>记为$X\sim 0-1(p) 或 X\sim B(1,p)$<br>$P(X=k)=p^k(1-p)^{1-k}$ k=0,1   p为1时的概率<br>样本空间只有两个元素e1 e2时总能定义服从0-1分布的随机变量</p>
<h4 id="2-2-2-退化分布"><a href="#2-2-2-退化分布" class="headerlink" title="2.2.2 退化分布"></a>2.2.2 退化分布</h4><p>X只能取一个值<br>$P(X=c)=1$</p>
<h4 id="2-2-3-二项分布"><a href="#2-2-3-二项分布" class="headerlink" title="2.2.3 二项分布"></a>2.2.3 二项分布</h4><p>X为n重伯努利试验下结果A发生的次数，$X=0,1,2,…,n$<br>$P\{X=k\}=C_n^kp^k(1-p)^{n-k}$   (特定顺序下发生k次的概率乘个组合数就行)</p>
<p>*二项分布记为$X\sim B(n,p)$   p是A在一次试验中的概率</p>
<h4 id="2-2-4-泊松分布"><a href="#2-2-4-泊松分布" class="headerlink" title="2.2.4 泊松分布"></a>2.2.4 泊松分布</h4><p>$X\sim \pi(\lambda)$ 或 $X\sim P(\lambda)$<br>$P(X=k)={\lambda}^ke^{-k}/k!$</p>
<p>泊松分布的用途:<br>某人一天收到信件的数量<br>显微镜下某区域中的白血球<br>来到某公共车站的乘客</p>
<p><strong>某事件以固定强度lambda随机且独立出现，该事件在单位时间内出现的次数，可看作泊松分布</strong></p>
<p><strong>泊松分布与二项分布的近似</strong><br>n&gt;10 p<0.1时
$C_n^kp^k(1-p)^{n-k}\approx e^{-\lambda}\lambda^k/k!$&ensp;    $\lambda=np$
即当n>10 p&lt;0.1时<br>$B(n,p)$ 可用$\pi(np)$近似</p>
<h4 id="2-2-5-几何分布"><a href="#2-2-5-几何分布" class="headerlink" title="2.2.5 几何分布"></a>2.2.5 几何分布</h4><p>$X\sim Geom(p)$<br>$P(X=k)=p(1-p)^{k-1}$<br>意义:<br>重复多次伯努利试验 进行到出现第一次A结果为止，实验的总次数符合几何分布<br>(二项分布是n次试验发生结果A的次数  几何分布是发生结果A的试验次数)</p>
<h3 id="2-3-分布函数"><a href="#2-3-分布函数" class="headerlink" title="2.3 分布函数"></a>2.3 分布函数</h3><p>$F(x)=P(X\le x)$ 为对X的概率分布函数,简称分布函数<br>意义：<img src="./1549017899667.png" alt="Alt text"><br>X落在(-∞,x]的概率</p>
<p><strong>离散型随机变量分布函数为阶梯函数</strong>  跳跃值$p_k=P\{X=x_k\}$</p>
<h3 id="2-4-连续型随机变量"><a href="#2-4-连续型随机变量" class="headerlink" title="2.4 连续型随机变量"></a>2.4 连续型随机变量</h3><p>定义$F(x)=\int_{-∞}^x f(t) dt$<br>f(x)为<strong>概率密度函数</strong><br>f(x)=F’(x)</p>
<h3 id="2-5-均匀分布与指数分布"><a href="#2-5-均匀分布与指数分布" class="headerlink" title="2.5 均匀分布与指数分布"></a>2.5 均匀分布与指数分布</h3><h4 id="2-5-1-均匀分布"><a href="#2-5-1-均匀分布" class="headerlink" title="2.5.1 均匀分布"></a>2.5.1 均匀分布</h4><p>概率密度函数<br>$f(x)=\begin{cases}1/(b-a),  &amp;x\in(a,b); \cr  0, &amp;otherwise\end{cases}$<br>易得<br>$F(x)=\begin{cases}0,  &amp;x&lt;a; \cr  (x-a)/(b-a), &amp;a\le x&lt;b; \cr 1, &amp;x\ge b\end{cases}$</p>
<p>记为$X\sim U(a,b)$或$X\sim Unif(a,b)$</p>
<h4 id="2-5-2-指数分布"><a href="#2-5-2-指数分布" class="headerlink" title="2.5.2 指数分布"></a>2.5.2 指数分布</h4><p>$f(x)=\begin{cases}\lambda e^{-\lambda x},  &amp;x&gt;0; \cr  0, &amp;x\le 0;\end{cases}$<br>得<br>$F(x)=\begin{cases}1-e^{-\lambda x},  &amp;x&gt;0; \cr  0, &amp;x\le0;\end{cases}$</p>
<p>记为$X\sim E(\lambda)$或$X\sim Exp(\lambda)$</p>
<p><strong>指数分布具有无记忆性</strong>:<br>$P(X&gt;t_0+t|X&gt;t_0)=P(X&gt;t)$</p>
<h3 id="2-6-正态分布-高斯分布"><a href="#2-6-正态分布-高斯分布" class="headerlink" title="2.6 正态分布(高斯分布)"></a>2.6 正态分布(高斯分布)</h3><h4 id="2-6-1-一般正态分布"><a href="#2-6-1-一般正态分布" class="headerlink" title="2.6.1 一般正态分布"></a>2.6.1 一般正态分布</h4><p>$f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$<br>记作$X\sim N(\mu,\sigma^2)$<br><img src="./1549027032660.png" alt="Alt text"></p>
<p>特点：<br>1.关于$x=\mu$对称<br>2.$f_{max}=1/\sqrt{2\pi}\sigma$</p>
<p><strong>$\mu$称为位置参数，改变后图形不变，图形平移</strong></p>
<p><strong>$\sigma$称为尺度参数，改变后分散程度改变,越大越瘦长</strong></p>
<p>**随机变量的和可用正态分布近似（后面中心极限定理）</p>
<p><strong>分布函数计算</strong><br>$P(X\le x)=F(x)=\frac{1}{\sqrt{2\pi}\sigma}\int_{-∞}^xe^{-\frac{(t-u)^2}{2\sigma^2}}dt $<br>//无法手算。结果不是初等函数。。可用相关软件计算</p>
<h4 id="2-6-2-标准正态分布"><a href="#2-6-2-标准正态分布" class="headerlink" title="2.6.2 标准正态分布"></a>2.6.2 标准正态分布</h4><p>$Z\sim N(0,1)$<br>$\varphi(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}} $<br>性质<br>$\Phi(-z_0)=1-\Phi(z_0)$</p>
<p>一般情况下<br>$\frac{X-\mu}{\sigma}\sim N(0,1) $<br><img src="./1549103713107.png" alt="Alt text"><br><strong>$3\sigma$准则:  随机变量大部分落在$3\sigma$范围内</strong></p>
<h3 id="2-7-随机变量函数的分布"><a href="#2-7-随机变量函数的分布" class="headerlink" title="2.7 随机变量函数的分布"></a>2.7 随机变量函数的分布</h3><p>问题:已知X分布，讨论Y=g(X)分布<br>方式1:由X与g(*) 求出Y的取值。利用等价事件思想，求出Y分布  （离散）<br>方式2:连续： 先求出分布函数F，Y用X表示，化简X范围，积分，求导<br>或者<img src="./1549109838996.png" alt="Alt text"><br>h为反函数<br><img src="./1549109685210.png" alt="Alt text"><br><img src="./1549110047922.png" alt="Alt text"></p>
<h2 id="3-多维随机变量及其分布"><a href="#3-多维随机变量及其分布" class="headerlink" title="3.多维随机变量及其分布"></a>3.多维随机变量及其分布</h2><h3 id="3-1-二元离散型随机变量分布律"><a href="#3-1-二元离散型随机变量分布律" class="headerlink" title="3.1 二元离散型随机变量分布律"></a>3.1 二元离散型随机变量分布律</h3><p>$<br>X=X(e)  \quad Y=Y(e) \quad 当(X,Y)只有有限对时，是二元离散型随机变量<br>$<br>落在某区域D的概率<br>$P((X,Y)\in D)=\sum_{(x_i,y_i)\in D}p_{ij}$</p>
<p>列X 行Y<br>X分布律是行相加 Y分布律是列相加</p>
<h3 id="3-2-边缘分布"><a href="#3-2-边缘分布" class="headerlink" title="3.2 边缘分布"></a>3.2 边缘分布</h3><h4 id="3-2-1-离散型"><a href="#3-2-1-离散型" class="headerlink" title="3.2.1 离散型"></a>3.2.1 离散型</h4><p>X的边缘分布$P(X-x_i)=\sum_{j=1}^∞p_{ij}=p_{i\bullet}$  (其实就是表行相加)<br>加上边际分布律后<br><img src="./1549162889144.png" alt="Alt text"></p>
<h4 id="3-2-2-连续型"><a href="#3-2-2-连续型" class="headerlink" title="3.2.2 连续型"></a>3.2.2 连续型</h4><script type="math/tex; mode=display">f_X(x)=\int_{-∞}^{+∞}f(x,y) dy</script><script type="math/tex; mode=display">f_Y(y)=\int_{-∞}^{+∞}f(x,y) dx</script><h3 id="3-3-条件分布"><a href="#3-3-条件分布" class="headerlink" title="3.3 条件分布"></a>3.3 条件分布</h3><h4 id="3-3-1-离散型"><a href="#3-3-1-离散型" class="headerlink" title="3.3.1 离散型"></a>3.3.1 离散型</h4><script type="math/tex; mode=display">P(X=x_i|Y=y_j)=\frac{P(X=x_i,Y=y_j)}{P(Y=y_j)}=\frac{p_{ij}}{p_{\bullet j}} \quad i=1,2,3...</script><p>为在Y=y_j下 随机变量X的条件分布率 (条件定，X变)</p>
<h4 id="3-3-2-连续型"><a href="#3-3-2-连续型" class="headerlink" title="3.3.2 连续型"></a>3.3.2 连续型</h4><p>在X=x条件下 Y的条件概率密度</p>
<script type="math/tex; mode=display">f_{Y|X}(y|x)=\frac{f(x,y)}{f_X(x)}  \quad(联合概率密度/边界概率密度)</script><h3 id="3-4-二元随机变量分布函数"><a href="#3-4-二元随机变量分布函数" class="headerlink" title="3.4 二元随机变量分布函数"></a>3.4 二元随机变量分布函数</h3><h4 id="3-4-1-离散型"><a href="#3-4-1-离散型" class="headerlink" title="3.4.1 离散型"></a>3.4.1 离散型</h4><p>$F(x,y)表示落入X&lt;x且Y&lt;y的概率$<br>$F(x,y)关于x,y右连续  x+\varepsilon \quad y+\varepsilon 分别取极限相同    $<br>边际分布函数</p>
<script type="math/tex; mode=display">F_X(x)=\lim_{y->∞}F(x,y)</script><script type="math/tex; mode=display">F_Y(y)=\lim_{x->∞}F(x,y)</script><p>条件分布函数</p>
<script type="math/tex; mode=display">F_{X|Y}(x|y)=P(X\le x|Y=y)</script><h4 id="3-4-2-连续型"><a href="#3-4-2-连续型" class="headerlink" title="3.4.2 连续型"></a>3.4.2 连续型</h4><p>落在某区域D的概率<br>$P((X,Y)\in D)=\iint_{D}f(x,y)dxdy$<br>于是F对x,y二阶偏导=f(x,y)<br>边缘概率密度</p>
<script type="math/tex; mode=display">f_X(x)=\int_{-∞}^{+∞}f(x,y) dy</script><script type="math/tex; mode=display">F_X(x)=F(x,+∞)=\int_{-\infty}^x{(\int_{-\infty}^{+\infty}f(u,y)dy)}du=\int_{-\infty}^xf_X(u)du</script><p> <img src="./1549182864261.png" alt="Alt text"></p>
<h3 id="3-5-二元均匀分布、高斯分布"><a href="#3-5-二元均匀分布、高斯分布" class="headerlink" title="3.5  二元均匀分布、高斯分布"></a>3.5  二元均匀分布、高斯分布</h3><h4 id="3-5-1-均匀分布"><a href="#3-5-1-均匀分布" class="headerlink" title="3.5.1 均匀分布"></a>3.5.1 均匀分布</h4><p>区域D的面积为A</p>
<script type="math/tex; mode=display">f(x,y)=\begin{cases} 
1/A,&(x,y)\in D \cr
0,&otherwise
\end{cases}</script><p>二元均匀分布的条件分布依然为均匀分布</p>
<h4 id="3-5-2-高斯分布"><a href="#3-5-2-高斯分布" class="headerlink" title="3.5.2 高斯分布"></a>3.5.2 高斯分布</h4><script type="math/tex; mode=display">(X,Y)\sim N(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho)</script><p>两个边际分布都是正态分布。且与$\rho$无关<br>在X=x下，Y的条件分布依然是正态分布</p>
<h3 id="3-6-随机变量的独立性"><a href="#3-6-随机变量的独立性" class="headerlink" title="3.6 随机变量的独立性"></a>3.6 随机变量的独立性</h3><p>定义</p>
<script type="math/tex; mode=display">F(x,y)=F_X(x)F_Y(y)</script><p>则随机变量X Y相互独立<br>$p_{ij}=p_{i\bullet}\times p_{\bullet j}$<br>从概率密度上讨论<br>对于离散型<br>$P(X=x_i,Y=y_j)=P(X=x_i)P(Y=y_j)$<br>连续型<br>$f(x,y)=f_X(x)f_Y(y)$</p>
<p>推论1:对于二维正态分布（X,Y）<br>XY相互独立充分必要条件是 $\rho=0$</p>
<h3 id="3-7-n元推广"><a href="#3-7-n元推广" class="headerlink" title="3.7 n元推广"></a>3.7 n元推广</h3><p>1.$(X_1,X_2,X_3…X_n)$为n元随机变量<br>2.$F(x_1,x_2,…,x_n)$为分布函数<br>3.概率密度$f(x_1,x_2,…,x_n) $ n重积分后得到F<br>4.边际分布:<br>$f_{X_1}(x_1)=F(x_1,∞,∞,∞,…)$ 也就是把f从x2开始积到xn的n-1重积分<br>5.独立性<br>$f(x_1,x_2,…,x_n)=f_{X_1}(x_1)f_{X_2}(x_2)…f_{X_n}(x_n)$<br>两组多元随机变量的独立性<br><img src="./1549513210964.png" alt="Alt text"><br><img src="./1549513247526.png" alt="Alt text"><br>(两组随机变量相互独立则每组各取一个变量也相互独立，通过连续函数的映射后，仍然相互独立)</p>
<h3 id="3-8-二元随机变量函数分布"><a href="#3-8-二元随机变量函数分布" class="headerlink" title="3.8 二元随机变量函数分布"></a>3.8 二元随机变量函数分布</h3><p>U=g(X,Y) 的分布<br>1.对于离散型<br>算出U的取值，找出对应等价事件，计算</p>
<p>2.对于连续型<br>有f(x,y) 若Z=g(X,Y) 求Z的密度函数:<br>方法:先计算分布函数，再求导</p>
<script type="math/tex; mode=display">F_Z(z)=\iint_{g(x,y)\le z}f(x,y) dxdy</script><h3 id="3-9-Z-X-Y的分布"><a href="#3-9-Z-X-Y的分布" class="headerlink" title="3.9 Z=X+Y的分布"></a>3.9 Z=X+Y的分布</h3><p><img src="./1549516729266.png" alt="Alt text"><br><img src="./1549516802170.png" alt="Alt text"><br><img src="./1549516847646.png" alt="Alt text"></p>
<p>推论:<br>1.$X\sim N(\mu_1,\sigma_1^2),Y\sim N(\mu_2,\sigma_2^2)$有$X+Y \sim N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$<br>2.n个独立正态分布的变量的线性组合仍服从正态分布:</p>
<script type="math/tex; mode=display">\mu=c_0+c_1\mu+...+c_n\mu</script><script type="math/tex; mode=display">\sigma^2=c_1^2\sigma_1^2+c_2^2\sigma_2^2+...+c_n\sigma_n^2</script><p>3.指数分布:<br>Z=X+Y后变成Gamma分布</p>
<script type="math/tex; mode=display">X=Y=\beta e^{-\beta x}</script><script type="math/tex; mode=display">f_Z(z)=\beta^2ze^{-\beta z} \quad z>0</script><p>4.<br><img src="./1549517692533.png" alt="Alt text"></p>
<h3 id="3-10-max与min的分布函数"><a href="#3-10-max与min的分布函数" class="headerlink" title="3.10 max与min的分布函数"></a>3.10 max与min的分布函数</h3><p><img src="./1549518105046.png" alt="Alt text"><br>n元时</p>
<script type="math/tex; mode=display">F_{max}(z)=F_{X_1}(z)F_{X_2}(z)F_{X_3}(z)...</script><script type="math/tex; mode=display">F_{min}(z)=1-[1-F_{X_1}(z)][1-F_{X_2}(z)][1-F_{X_3}(z)]...</script><h2 id="4-随机变量的数字特征"><a href="#4-随机变量的数字特征" class="headerlink" title="4.随机变量的数字特征"></a>4.随机变量的数字特征</h2><h3 id="4-1-数学期望"><a href="#4-1-数学期望" class="headerlink" title="4.1 数学期望"></a>4.1 数学期望</h3><h4 id="4-1-1-随机变量的数学期望"><a href="#4-1-1-随机变量的数学期望" class="headerlink" title="4.1.1 随机变量的数学期望"></a>4.1.1 随机变量的数学期望</h4><script type="math/tex; mode=display">E(X)=\int_{-\infty}^{+\infty}xf(x)dx</script><p>1.0-1分布</p>
<script type="math/tex; mode=display">E(X)=0\times (1-p)+1\times p=p</script><p>2.泊松分布 $X\sim \pi(\lambda)$</p>
<script type="math/tex; mode=display">E(X)=\lambda</script><p>3.正态分布 $Z\sim N(\mu,\sigma^2)$</p>
<script type="math/tex; mode=display">E(Z)=\mu</script><p>4.指数分布 $X\sim E(\lambda)$</p>
<script type="math/tex; mode=display">E(X)=\frac{1}{\lambda}</script><p>5.二项分布 $X\sim B(n,p)$</p>
<script type="math/tex; mode=display">E(X)=np</script><p>6.均匀分布 $X\sim U(a,b)$</p>
<script type="math/tex; mode=display">E(X)=\frac{(a+b)}{2}</script><p>7.几何分布</p>
<script type="math/tex; mode=display">E(X)=\frac{1}{p}</script><h4 id="4-1-2-随机变量函数的数学期望"><a href="#4-1-2-随机变量函数的数学期望" class="headerlink" title="4.1.2 随机变量函数的数学期望"></a>4.1.2 随机变量函数的数学期望</h4><p>1.一元</p>
<script type="math/tex; mode=display">E(Y)=E(g(X))=\sum_{k=1}^{\infty}g(x_k)p_k</script><script type="math/tex; mode=display">E(Y)=E(g(X))=\int_{-\infty}^{+\infty}g(x)f(x)\quad dx</script><p>2.二元</p>
<script type="math/tex; mode=display">E(Z)=E[h(X,Y)]=\sum_{i=1}^{+\infty} \sum_{j=1}^{+\infty}h(x_i,y_j)p_{ij}</script><script type="math/tex; mode=display">E(Z)=E[h(X,Y)]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}h(x,y)f(x,y) dxdy</script><script type="math/tex; mode=display">E(X)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}xf(x,y) dxdy</script><script type="math/tex; mode=display">E(Y)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}yf(x,y) dxdy</script><h4 id="4-1-3-E-X-的性质"><a href="#4-1-3-E-X-的性质" class="headerlink" title="4.1.3 E(X)的性质"></a>4.1.3 E(X)的性质</h4><p>1.随机变量的线性组合的数学期望=数学期望的线性组合<br>2.X\Y相互独立 E(XY)=E(X)E(Y)</p>
<h3 id="4-2-方差"><a href="#4-2-方差" class="headerlink" title="4.2 方差"></a>4.2 方差</h3><p>方差</p>
<script type="math/tex; mode=display">D(X)=E\{[X-E(X)]^2\}</script><p>标准差</p>
<script type="math/tex; mode=display">\sigma(X)=\sqrt {D(X)}</script><p>计算方法<br>一般</p>
<script type="math/tex; mode=display">D(X)=E(X^2)-[E(X)]^2</script><p>X\Y相互独立时：</p>
<script type="math/tex; mode=display">D(X+Y)=D(X)+D(Y)</script><p>一般结论<br>1.两点分布</p>
<script type="math/tex; mode=display">D(X)=p(1-p)</script><p>2.泊松分布</p>
<script type="math/tex; mode=display">D(X)=E(X)=\lambda</script><p>3.均匀分布</p>
<script type="math/tex; mode=display">D(X)=\frac{(b-a)^2}{12}</script><p>4.指数分布</p>
<script type="math/tex; mode=display">D(X)=[E(X)]^2=\frac{1}{\lambda^2}</script><p>5.正态分布</p>
<script type="math/tex; mode=display">D(X)=\sigma^2</script><p>线性组合仍服从正态分布<br>标准化变量</p>
<script type="math/tex; mode=display">X^*=\frac{X-\mu}{\sigma}</script><p>性质<br>1.</p>
<script type="math/tex; mode=display">D(cX)=c^2D(X)</script><p>2.</p>
<script type="math/tex; mode=display">D(X+Y)=D(X)+D(Y)+2\times E\{[X-E(X)][Y-E(X)]\}</script><p>3.<script type="math/tex">D(X+c)=D(X)</script></p>
<h3 id="4-3-协方差"><a href="#4-3-协方差" class="headerlink" title="4.3 协方差"></a>4.3 协方差</h3><h4 id="4-3-1-协方差定义与性质"><a href="#4-3-1-协方差定义与性质" class="headerlink" title="4.3.1 协方差定义与性质"></a>4.3.1 协方差定义与性质</h4><p>就是上面的 <script type="math/tex">Cov(X,Y)=E\{[X-E(X)][Y-E(X)]\}=E(XY)-E(X)E(Y)</script></p>
<p><strong>协方差表现X Y直接的线性相关性</strong><br>Cov&gt;0:正相关<br>Cov&lt;0:负相关<br>Cov=0:不相关</p>
<p><strong>性质</strong><br>1.$Cov(X,X)=D(X)$<br>2.$Cov(aX,bY)=ab\bullet Cov(X,Y)$<br>3.$Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$<br><img src="./1549685692456.png" alt="Alt text"></p>
<h4 id="4-3-2-相关系数"><a href="#4-3-2-相关系数" class="headerlink" title="4.3.2     相关系数"></a>4.3.2     相关系数</h4><script type="math/tex; mode=display">\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}}</script><script type="math/tex; mode=display">X^*=\frac{X-E(X)}{\sqrt{D(X)}}</script><script type="math/tex; mode=display">Y^*=\frac{Y-E(Y)}{\sqrt{D(Y)}}</script><script type="math/tex; mode=display">\rho_{XY}=Cov(X^*,Y^*)</script><p>相关系数绝对值<strong>在0~1</strong>之间，越靠近1表明<strong>线性相关性</strong>越大<br>=1时有严格的线性关系<br>X Y相互独立-&gt;不相关，反之不成立<br>二元正态分布的第五个参数就是相关系数,<br>对于二元正态，<strong>相关系数=0</strong> 等价于 <strong>相互独立</strong></p>
<h4 id="4-4-矩"><a href="#4-4-矩" class="headerlink" title="4.4 矩"></a>4.4 矩</h4><script type="math/tex; mode=display">E(X^k)称为X的k阶矩$$(X的k次方的数学期望)
$$E\{(X-E(X))^k\}称为X的k阶中心矩$$ (X方差的k次方)
$$E\{X^kY^l\}为X与Y的k+l阶混合矩</script><script type="math/tex; mode=display">E\{[X-E(X)]^k[Y-E(Y)]^l\}为X与Y的k+l阶混合中心矩</script><p>期望和方差其实就是1阶矩和2阶中心矩</p>
<script type="math/tex; mode=display">\widetilde{X}=(X_1,X_2,...,X_n)^T</script><p><center>n元随机变量的定义为</center></p>
<script type="math/tex; mode=display">E(\widetilde{X})=(E(X_1),E(X_2),...,E(X_n))^T</script><p><center>协方差矩阵定义</center></p>
<script type="math/tex; mode=display">C=Cov(\widetilde{X})=
\begin{equation}
\left(
  \begin{array}{cccc}
        D(X_1) & Cov(X_1,X_2) & ... & Cov(X_1,X_n)\\
        Cov(X_2,X_1) & D(X_2) & ... & Cov(X_2,X_n)\\
        ... &...&...&...\\
        Cov(X_n,X_1)&Cov(X_n,X_2)&...&D(x_n)    
  \end{array}
\right)
\end{equation}</script><p><center>第i,j个元素为Cov(X_i,Y_j)</p>
<hr>
<p><center>*n元正态分布联合概率密度(可无视)</p>
<script type="math/tex; mode=display">f(x_1,x_2,...x_n)=\frac{1}{(2\pi)^{\frac{n}{2}}|C|^{\frac{1}{2}}}\exp\{-\frac{1}{2}(\widetilde{x}-\widetilde{\mu})^TC^{-1}(\widetilde{x}-\widetilde{\mu})\}</script><hr>
<p><center>性质<br>线性变化下仍是正态分布<br>1.<strong>从n元里任取k元都能构成k元正态分布</strong><br>2.<strong>X_i的任意线性组合构成一元正态分布</strong><br>3.<strong>Y_i为X_i的线性函数 则Y也构成n元正态分布</strong><br>4.<strong>若X_i全部相互独立，协方差矩阵为对角矩阵。</strong></p>
<h3 id="4-5-依概率收敛、切比雪夫不等式"><a href="#4-5-依概率收敛、切比雪夫不等式" class="headerlink" title="4.5 依概率收敛、切比雪夫不等式"></a>4.5 依概率收敛、切比雪夫不等式</h3><p> 1.依概率收敛<br>n充分大后，频率与概率的偏差越来越小<br>即<script type="math/tex">\lim_{n->\infty}P\{|\frac{n_A}{n}-p|\ge \epsilon\}=0</script></p>
<script type="math/tex; mode=display">\lim_{n->\infty}P\{|X_i-c|\ge \epsilon\}=0</script><p><center>性质</p>
<script type="math/tex; mode=display">若X_n\xrightarrow{P}{}a \quad Y_n\xrightarrow{P}{}b \quad g(x,y)在（a,b）连续 
则\\g(X_n,Y_n)\xrightarrow{P}g(a,b)</script><p><strong>切比雪夫不等式</strong></p>
<script type="math/tex; mode=display">若E(X)=\mu且D(X)=\sigma^2则对任意\epsilon>0\\有P\{|X-\mu|\ge \epsilon\}\le\frac{\sigma^2}{\mu^2}</script><p>(给出一个随机变量与均值的偏差超过epsilon的上界还有小于epsilon的下界)<br><strong>重要性</strong><br>给出一个随机变量落在期望附近区域内或外 一个界的估计</p>
<h2 id="5-大数定律及中心极限定律"><a href="#5-大数定律及中心极限定律" class="headerlink" title="5 大数定律及中心极限定律"></a>5 大数定律及中心极限定律</h2><h3 id="5-1-大数定律"><a href="#5-1-大数定律" class="headerlink" title="5.1 大数定律"></a>5.1 大数定律</h3><p>1.贝努里大数定律<br>频率在n充分大后趋近于概率p</p>
<p><center><strong>大数定律</strong><br><strong>定理1</strong></p>
<script type="math/tex; mode=display">随机变量X_1 X_2...X_n在一定条件下Y_n=\frac{X_1+...+X_n}{n}\\收敛到\mu,当n->\infty</script><p>含义为:依概率收敛 若X_i期望相同,收敛到E(X)<br><strong>定理2</strong></p>
<script type="math/tex; mode=display">X_1X_2...X_n为相互独立的随机变量,期望方差相同，那么均值依概率收敛到期望</script><p>&lt;/center&gt;<br>方差存在期望一定存在，反之不成立<br>定理3未要求方差存在</p>
<p><center><strong>定理3</strong><br>要求:所有随机变量分布相同，且期望存在。则随机变量的算术平均值扔依概率收敛到mu</p>
<h3 id="5-2-中心极限定理"><a href="#5-2-中心极限定理" class="headerlink" title="5.2 中心极限定理"></a>5.2 中心极限定理</h3><p><center><strong>n个独立同分布随机变量的中心极限定理</strong></p>
<script type="math/tex; mode=display">\sum_{i=1}^{n}X_i\sim N(n\mu,n\sigma^2)</script><h2 id="6-样本及抽样分布"><a href="#6-样本及抽样分布" class="headerlink" title="6 样本及抽样分布"></a>6 样本及抽样分布</h2><p><strong>简单随机样本</strong>:满足代表性(X_i与X同分布)、独立性(各X_i相互独立)<br>样本方差要除n-1</p>
<h3 id="6-1-统计量"><a href="#6-1-统计量" class="headerlink" title="6.1 统计量"></a>6.1 统计量</h3><p>统计量是参数为随机变量的函数值。</p>
<h3 id="6-2-统计量的分布"><a href="#6-2-统计量的分布" class="headerlink" title="6.2 统计量的分布"></a>6.2 统计量的分布</h3><h4 id="6-2-1-卡方分布"><a href="#6-2-1-卡方分布" class="headerlink" title="6.2.1 卡方分布"></a>6.2.1 卡方分布</h4><p><img src="./1549805847793.png" alt="Alt text"><br>n越大，最大值右移<br><img src="./1549805895616.png" alt="Alt text"></p>
<h4 id="6-2-2-t分布"><a href="#6-2-2-t分布" class="headerlink" title="6.2.2 t分布"></a>6.2.2 t分布</h4><p><img src="./1549805948434.png" alt="Alt text"><br><img src="./1549805974216.png" alt="Alt text"></p>
<h4 id="6-2-3-F分布"><a href="#6-2-3-F分布" class="headerlink" title="6.2.3 F分布"></a>6.2.3 F分布</h4><p><img src="./1549805998151.png" alt="Alt text"><br><img src="./1549806020818.png" alt="Alt text"></p>
<h3 id="6-3-单个正态总体的抽样分布"><a href="#6-3-单个正态总体的抽样分布" class="headerlink" title="6.3 单个正态总体的抽样分布"></a>6.3 单个正态总体的抽样分布</h3><p><center><strong>定理一</strong><br>总体$X\sim N(\mu,\sigma^2)$<br>(1)$\overline{x} \sim N(\mu,\frac{\sigma^2}{n})$(样本均值服从正态分布)<br>(2)$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$ 且$\overline{X}$与S^2相互独立<br><strong>定理二</strong></p>
<script type="math/tex; mode=display">\frac{\overline{X}-\mu}{S/\sqrt{n}}\sim t(n-1)</script><p><u><strong>有两个正态总体的情况</strong></u></p>
<script type="math/tex; mode=display">样本来自N(\mu_1,\sigma_1^2)\quad N(\mu_2,\sigma_2^2)</script><p><strong>定理三</strong><br>(1)$F=\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}\sim F(n_1-1,n_2-1)$<br>(2)$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)$<br>(3)$\frac{(\overline{X}-\overline{Y})-(\mu_1-\mu_2)}{S_w\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim t(n_1+n_2-2)$</p>
<script type="math/tex; mode=display">S_w^2=\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}</script><script type="math/tex; mode=display">D(S_w^2)=\frac{\sigma^4}{n_1+n_2-2}其比D(S_1^2)和D(S_2^2)都小</script><p>&lt;/center&gt;<br>作用:(1)对于单个正态整体，知道样本均值和方差后，对\mu和\sigma进行参数估计<br>(2)对于两个独立正态整体，知道样本的均值相减的分布还有方差相除的分布后，对mu相减和方程相除 进行参数推断</p>
<h2 id="7-参数估计"><a href="#7-参数估计" class="headerlink" title="7 参数估计"></a>7 参数估计</h2><p><strong>参数</strong>:反应总体某方面特征的量<br><strong>估计形式</strong>:<strong>点估计</strong>和<strong>区间估计</strong><br><strong>点估计</strong>:构造函数，使$\widehat{\theta}=\widehat{\theta}(X_1,…,X_n)$ 常用<strong>矩估计法</strong>、<strong>最大似然估计</strong></p>
<h3 id="7-1-矩估计"><a href="#7-1-矩估计" class="headerlink" title="7.1 矩估计"></a>7.1 矩估计</h3><p><center></p>
<script type="math/tex; mode=display">\mu为一阶原点矩，用样本矩作为总体矩的估计即为矩估计\\
依据为大数定理。n趋向于无穷大时，\widehat{\mu}收敛到\mu_j</script><p><center><strong>矩估计步骤</strong></p>
<script type="math/tex; mode=display">有n个未知参数(\theta_1,\theta_2,...,\theta_n)</script><p>step1:$建立(\theta_1,\theta_2,…,\theta_n)和(\mu_1,\mu_2,…,\mu_n)的联系,用函数h,\mu_i=E(X^i)=h_i(\theta…)$<br>step2:求各参数关于k阶矩的反函数</p>
<script type="math/tex; mode=display">\theta_i=g_i(\mu...)</script><p>step3:用样本各阶矩，代替整体各阶矩<br>总之就是靠各阶矩与未知参数的联系，然后用样本各阶矩代进去</p>
<h3 id="7-2-极大似然估计"><a href="#7-2-极大似然估计" class="headerlink" title="7.2 极大似然估计"></a>7.2 极大似然估计</h3><p>思想 从样本推出最可能导致该结果的总体分布</p>
<p><center><strong>离散下</strong></p>
<script type="math/tex; mode=display">似然函数:L(\theta)=\Pi_{i=1}^np(x_i;\theta)</script><p>也就是，在某参数下，事件x1,x2,…发生的概率。找出这样的参数，让L最大<br><strong>连续下</strong></p>
<script type="math/tex; mode=display">L(\theta)=\Pi_{i=1}^nf(x_i;\theta)</script><p>极大似然估计就是求Lmax,也可转换为求(ln L)max使计算简化 </p>
<h3 id="7-3-估计量的评价"><a href="#7-3-估计量的评价" class="headerlink" title="7.3 估计量的评价"></a>7.3 估计量的评价</h3><p>4条准则</p>
<h4 id="7-3-1-无偏性"><a href="#7-3-1-无偏性" class="headerlink" title="7.3.1 无偏性"></a>7.3.1 无偏性</h4><p><center>定义<br>若$E(\widehat\theta)=\theta 则为$<strong>无偏估计量</strong><br>$|E(\widehat\theta)-\theta|为偏差$<br>若n-&gt;∞时,两者相等，则为<strong>渐进无偏估计量</strong><br>纠偏方法：定义$E(\widehat\theta)=a\theta+b$</p>
<h4 id="7-3-2-有效性"><a href="#7-3-2-有效性" class="headerlink" title="7.3.2 有效性"></a>7.3.2 有效性</h4><p>某参数方差小于另一个参数方差，则该参数更有效</p>
<h4 id="7-3-3-均方误差"><a href="#7-3-3-均方误差" class="headerlink" title="7.3.3 均方误差"></a>7.3.3 均方误差</h4><script type="math/tex; mode=display">Mse(\widehat{\theta})=E(\widehat\theta-\theta)^2\\无偏状态下Mse=D\\Mse越小越优</script><h4 id="7-3-4-相合性"><a href="#7-3-4-相合性" class="headerlink" title="7.3.4 相合性"></a>7.3.4 相合性</h4><p>样本容量-&gt;无穷时的性质</p>
<script type="math/tex; mode=display">\widehat\theta \rightarrow^{P}\theta则为相合估计量或一致估计量</script><h3 id="7-4-区间估计"><a href="#7-4-区间估计" class="headerlink" title="7.4 区间估计"></a>7.4 区间估计</h3><p><strong>目的:</strong>找到两个统计量$\widehat\theta_1$和$\widehat\theta_2$使构成的随机区间以一定可靠程度，盖住$\theta$</p>
<p><center>给$\alpha$使$P(\theta \in (\widehat\theta_L,\widehat\theta_U))\ge 1-\alpha$<br>$此为置信水平为1-\alpha的双侧置信区间$<br>$\widehat\theta_L:双侧置信区间下限\quad \widehat\theta_U:双侧置信区间上限)$</p>
<script type="math/tex; mode=display">1-\alpha_1:单侧置信下限 \quad 1-\alpha_2:单侧置信上限 \quad 双侧置信区间置信度=1-\alpha_1-\alpha_2</script><p><strong>置信区间的精确度:</strong>区间的平均长度<br><strong>误差限</strong>:精确度的一半,置信度相同时，选精确度高的.<strong>优先考虑置信度</strong><br>$单侧置信上限:P\{\theta\le T_1\}=1-\alpha$<br>$单侧置信下限:P\{\theta\ge T_1\}=1-\alpha$</p>
<h3 id="7-5-枢轴量法"><a href="#7-5-枢轴量法" class="headerlink" title="7.5 枢轴量法"></a>7.5 枢轴量法</h3><script type="math/tex; mode=display">G=G(X_1,...,X_n,\theta)$$<center>G为枢轴量</center>
G与统计量的区别:G分布不依赖于任何未知参数，其是样本和待估参数的函数。而统计量分布常依赖于未知参数，且只是样本的函数
step1:找个已知分布的枢轴量
step2:求P(a<G<b)=0.95 且|b-a|最短的的a,b (a,b对称情况下最短)
![Alt text](./1549883475538.png)
![Alt text](./1549883684753.png)
![Alt text](./1549883720060.png)
![Alt text](./1549937898831.png)
![Alt text](./1549937871901.png)
![Alt text](./1549938219953.png)
![Alt text](./1549938322162.png)


##8.假设检验
**step1:**建立两个对立的假设，**原假设H0**和**备择假设H1** 
选取原则:(1)保护原假设。**若错误拒绝A后果更严重，则A作原假设**
(2)维持现状：如“无改进”“无效果”等
(3)原假设取简单假设。

检验有**3种情形**
对于某参数$\theta$
$$H_0: \theta=\theta_0 \quad H_1:\theta<\theta_0 \quad (左边检验)</script><p><center>或</p>
<script type="math/tex; mode=display">H_0: \theta\ge\theta_0 \quad H_1:\theta<\theta_0 \quad (左边检验)</script><script type="math/tex; mode=display">H_0: \theta=\theta_0 \quad H_1:\theta>\theta_0 \quad (右边检验)</script><p><center>或</p>
<script type="math/tex; mode=display">H_0: \theta\le\theta_0 \quad H_1:\theta>\theta_0 \quad (右边检验)</script><script type="math/tex; mode=display">H_0: \theta=\theta_0 \quad H_1:\theta\ne\theta_0 \quad (双边检验)</script><p><strong>step2:</strong>根据资料，假设。给出检验方法，对假设进行判断</p>
<p><strong>检验统计量：取值大小和原假设是否成立有着密切关系的量</strong><br><strong>第1类错误：错误拒绝原假设</strong><br><strong>第2类错误：错误接受原假设</strong><br><strong>显著水平:</strong><br>$\alpha,控制犯第一类错误的概率不超过\alpha,再寻求检验使犯第二类错误的概率尽可能小。常取\alpha=0.01,0.05,0.1等$</p>
<p><strong>step3:根据显著水平和统计量分布确定临界值C</strong><br>计算$P\{\overline X\ge C|H_0\}\le\alpha$得到C，确定拒绝域</p>
<p><strong>step4:根据样本计算，得到结论</strong></p>
<p>也可以P值法:</p>
<script type="math/tex; mode=display">P\_值:原假设成立时，检验统计量取比观察者更为极端的数值的概率，之后比较P\_值与显著水平得到结论 P\_值是一个最小显著性水平</script><p>(1)$P_\le\alpha$,样本落在拒绝域内 (统计显著的)<br>(2)$P_&gt;\alpha,样本不落在拒绝域内(统计不显著)$</p>
<h3 id="8-1-Z检验-标准差已知"><a href="#8-1-Z检验-标准差已知" class="headerlink" title="8.1 Z检验 (标准差已知)"></a>8.1 Z检验 (标准差已知)</h3><p><strong>检验统计量</strong>取 $Z=\frac{\overline X-\mu_0}{\sigma/\sqrt n}$<br><strong>拒绝域</strong> $W=\{|Z|\ge z_{\alpha/2}\}$</p>
<script type="math/tex; mode=display">z_0=\frac{\overline x-\mu_0}{\sigma/\sqrt n }</script><p><strong>P_=</strong>$P_{H_0}\{|Z|\ge|z_0|\}=2(1-\Phi(|Z_0|))$<br><img src="./1549949836265.png" alt="Alt text"></p>
<h3 id="8-2-t检验-标准差未知"><a href="#8-2-t检验-标准差未知" class="headerlink" title="8.2 t检验(标准差未知)"></a>8.2 t检验(标准差未知)</h3><p><strong>(1)设总体$X\sim N(\mu,\sigma^2)$</strong><br><strong>(2)用样本标准差S代替总体标准差</strong></p>
<script type="math/tex; mode=display">T=\frac{\overline X-\mu_0}{S/\sqrt n}</script><p><strong>(3)拒绝域|T|&gt;=k    </strong></p>
<script type="math/tex; mode=display">T=\frac{\overline X-\mu_0}{S/\sqrt n}\sim t(n-1)</script><p>即</p>
<script type="math/tex; mode=display">|T|\ge t_{\alpha/2}(n-1)</script><p>计算样本$t_0=\frac{\overline x-\mu_0}{s/\sqrt n}$</p>
<script type="math/tex; mode=display">P\_=2P\{t(n-1)\ge|t_0|\}</script><h3 id="8-3-成对数据的检验"><a href="#8-3-成对数据的检验" class="headerlink" title="8.3 成对数据的检验"></a>8.3 成对数据的检验</h3><p><center>t检验</p>
<script type="math/tex; mode=display">(X_1,Y_1)...(X_n,Y_n)</script><p>差值$D_i=X_i-Y_i$<br>确定D的均值和方差<br><strong>检验统计量$T=\frac{\sqrt n\overline D}{S_D}$</strong><br><strong>拒绝域$W=\{|T|\ge t_{\alpha/2}(n-1)\}$</strong></p>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><h3 id="1-推导伯努利类型的均值"><a href="#1-推导伯努利类型的均值" class="headerlink" title="1.推导伯努利类型的均值"></a>1.推导伯努利类型的均值</h3><script type="math/tex; mode=display">X\sim B(n,p)\\E(X)=np</script><p><center>Proof：<br>step1:let <script type="math/tex">X_1,X_2,X_3....,X_n</script> represent the <strong>i th</strong> experiment result,which $X_i=1$ is positive result,0 if negative result.<br>step2:We can easily get $E(X_i)=p$<br>the count of success experiments is $X_1+X_2+…+X_n$<br>So,$E(X)=E(X_1+X_2+…+X_n)=np$</p>
<h3 id="2-Gaussian-Distribution-linear-combination’s-Expectation-and-Variance"><a href="#2-Gaussian-Distribution-linear-combination’s-Expectation-and-Variance" class="headerlink" title="2.Gaussian Distribution linear combination’s Expectation and Variance"></a>2.Gaussian Distribution linear combination’s Expectation and Variance</h3><script type="math/tex; mode=display">X\sim N(\mu_1,\sigma_1^2)\\Y\sim N(\mu_2,\sigma_2^2)\\E(aX+bY)=aE(X)+bE(Y)=a\mu_1+b\mu_2\\For D(aX+bY)$$IF X and Y are independent,$$D(aX+bY)=a^2D(X)+b^2D(Y)\\otherwise$$ use the follow way to calculate $$D(aX+bY)=D(X'+Y')=E(X'^2+Y'^2+2X'Y')-E^2(X'+Y')</script><p><center><br>or use</p>
<script type="math/tex; mode=display">D(X+Y)=D(X)+D(Y)±+2Cov(X,Y)</script><blockquote>
<p><strong>Independent(<script type="math/tex">f(x,y)=f(x)f(y))--->unrelative(COV(X,Y)=0\quad or\quad E(XY)=E(X)E(Y)</script>)</strong></p>
</blockquote>
<h3 id="Law-of-large-numbers-amp-Central-Limit-Theorem-Part"><a href="#Law-of-large-numbers-amp-Central-Limit-Theorem-Part" class="headerlink" title="Law of large numbers&amp;Central Limit Theorem Part"></a>Law of large numbers&amp;Central Limit Theorem Part</h3><p>In this part most questions are based on the follows formulas:</p>
<script type="math/tex; mode=display">P\{X-\mu\ge\epsilon\}\le\frac{\sigma^2}{\epsilon^2}\tag{切比雪夫}</script><script type="math/tex; mode=display">\lim_{n->+\infty}P\{|\frac{1}{n}\sum_{i=1}^nX_i-\mu|>\epsilon\}=0 \tag{辛钦}</script><script type="math/tex; mode=display">\lim_{n->+\infty}P\{|\frac{1}{n}\sum_{i=1}^nX_i-\frac{1}{n}\sum_{i=1}^nE(X_i)|\ge\epsilon\}=0\tag{样本均值等于期望均值}</script><script type="math/tex; mode=display">X_1,X_2,...,X_n$$ are **i.i.d**.   $(X_1+X_2+...+X_n)\sim N(n\mu,n\sigma^2)$


###Rooms assignment Problem
Q:There are N rooms and n persons,everyone need to be assign to room.Let $X_i$ represent the ith room's has how many person.
Now calculate $P(X_i=m)$

A:
step1:First we take m people from n people set,which has $C_n^m$ plan.
step2:We can assume that these m people been allocated to the ith room,so next we consider the rest $n-m$ persons.
they must be allocated to other $N-1$ rooms.So has $(N-1)^(n-m)$ possible situation
step3,simple amount is $N^n$,so $$P(X_i=m)=\frac{C_n^m(N-1)^{n-m}}{N^n}</script><h3 id="Matching-success-count-Problem"><a href="#Matching-success-count-Problem" class="headerlink" title="Matching success count Problem"></a>Matching success count Problem</h3><p>Q:there are n things need to match,and randomly match</p>
<p>for convenience n  take 5.<br>1.calculate the probability that <strong>only 1</strong> matching success.<br>step1:Event $A_i$ represent ith matched success</p>
<script type="math/tex; mode=display">P(A_i)=1/5</script><p>step2:<br>consider the probability of $A_i$ is matched success and other 4 are matched fail</p>
<script type="math/tex; mode=display">P(B_i)=P(A_i)[1-P(A_1\cup ...\cup A_{i-1}\cup A_{i+1}\cup ...\cup A_n]</script><script type="math/tex; mode=display">P(B)=C_n^1P(B_i)</script><blockquote>
<p><img src="./1556198321665.png" alt="Alt text"><br><img src="./1556198569503.png" alt="Alt text"></p>
</blockquote>
<h3 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h3><script type="math/tex; mode=display">\Gamma(\alpha,\frac{1}{2})=X^2(2\alpha)</script><script type="math/tex; mode=display">\Gamma(1,\theta)=e(\theta)</script><h3 id="Groups-Division-Question"><a href="#Groups-Division-Question" class="headerlink" title="Groups Division Question"></a>Groups Division Question</h3><p><strong>To divide n things to k group,there has </strong></p>
<script type="math/tex; mode=display">\frac{n!}{m_{k_1}m_{k_2}...m_{k_n}}</script><p>m_k_i is the size of ith group</p>
<p><strong>Q:Consider that now,we distribute 52 Pokers to 4 persons,What is the possibility of 4 A pokers are fall into the same person</strong><br>1.The are $\frac{52!}{(13!)^4}$ way to  distibute 52 pokers<br>2.We can choose one person has 4 A,and distribute other 48 poker to other 3 persons.So,there are $C_4^1\frac{48!}{(13!)^39!}$ ways.<br>3.1 divide 2</p>
<h3 id="Gamma"><a href="#Gamma" class="headerlink" title="Gamma"></a>Gamma</h3><script type="math/tex; mode=display">\Gamma(\alpha)=\int_0^\infty x^{\alpha-1}e^{-x}dx</script><script type="math/tex; mode=display">\Gamma(n+1)=n!</script><h3 id="Even-and-Odd-Possibility-Problem-in-discrete-situation"><a href="#Even-and-Odd-Possibility-Problem-in-discrete-situation" class="headerlink" title="Even and Odd Possibility Problem in discrete situation"></a>Even and Odd Possibility Problem in discrete situation</h3><p>Calculate P(Odd)+P(Even) and P(Odd)-P(Even)</p>
<h3 id="Possibility-Calculation"><a href="#Possibility-Calculation" class="headerlink" title="Possibility Calculation"></a>Possibility Calculation</h3><script type="math/tex; mode=display">P(A\overline{B})=P(A)-P(AB)</script><p>共分散-&gt;协方差</p>
<h2 id="確率過程"><a href="#確率過程" class="headerlink" title="確率過程"></a>確率過程</h2><p><img src="./1562671773440.png" alt="Alt text"><br>F(X,t)<br>每个时间t上有一个概率分布X<br>因此对于每个时间t可以计算均值方差之类的</p>
]]></content>
  </entry>
  <entry>
    <title>复变函数学习笔记</title>
    <url>/2019/12/26/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="1-复变函数论"><a href="#1-复变函数论" class="headerlink" title="1 复变函数论"></a>1 复变函数论</h2><h3 id="1-1-复数及复数计算"><a href="#1-1-复数及复数计算" class="headerlink" title="1.1 复数及复数计算"></a>1.1 复数及复数计算</h3><script type="math/tex; mode=display">代数式:z=x+iy</script><center>实部:**Re z** 
虚部:**Im z**</center>
$$指数式:z=\rho (cos \alpha+isin \alpha) \\ z=\rho e^{i\alpha}$$
$\alpha$为**辐角**，记作**Arg z**.$\rho$为**模**,$0\le Arg z \le 2\pi$的解为**主值\主辐角**,记为**arg z**
**共轭复数:**$z^*=x-iy$
####1.1.1 复球面
![Alt text](./1551957165927.png)
####1.1.2 复数的运算
1) 加减法略
2)乘法,按四则运算相乘即可
3)除法:
$$\frac{z_1}{z_2}=\frac{x_1x_2+y_1y_2}{x_2^2+y_2^2}+i\frac{x_2y_1-x_1y_2}{x_2^2+y_2^2}$$
>虚实部分母均为z2的模平方，实部为数量积，虚部为向量积的相反数

4)三角式下:
乘:两模相乘,辐角相加
除:两模相除,辐角相减
幂运算:略

###1.2 复变函数
$$\omega=f(z) \quad z\in E$$
$$sin z=\frac{1}{2i}(e^{iz}-e^{-iz})$$
$$cos z=\frac{1}{2}(e^{iz}+e^{-iz})$$
$$sh z=\frac{1}{2}(e^{z}-e^{-z})$$
$$ch z=\frac{1}{2}(e^{z}+e^{-z})$$
**(sh与ch具有纯虚周期2pi*i)**
复数->二元实变函数
$z=x+iy----->z=u(x,y)+iv(x,y)$

###1.3 导数
实变函数只能沿x轴逼近。复变函数可以沿各个方向逼近。
**1.沿实轴逼近时: lim=**$\frac{\partial u}{\partial x}+i\frac{\partial v}{\partial x}$
**1.沿虚轴逼近时: lim=**$\frac{\partial v}{\partial y}-i\frac{\partial u}{\partial y}$
<center>**柯西-黎曼方程\柯西黎曼条件（C-R条件）：**
$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}$
$\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}$
**这是复变函数可导的必要条件（非充分）**
</center>


<center>
**复变函数可导的充要条件为:**
**1)对两个函数的四个偏导全部存在**
**2)4个偏导都连续**
**3)满足C-R条件**
</center>

<center>
**极坐标下的柯西-黎曼方程:**
$\frac{\partial u}{\partial \rho}=\frac{1}{\rho}\frac{\partial v}{\partial \varphi}$
$\frac{1}{\rho}\frac{\partial u}{\partial \varphi}=-\frac{\partial v}{\partial \rho}$
$\rho$变成$\varphi$后乘个1/p就行

</center>

<h3 id="1-4-解析函数"><a href="#1-4-解析函数" class="headerlink" title="1.4 解析函数"></a>1.4 解析函数</h3><p><strong>解析:</strong>f(z)在z_0邻域上处处可导，即f(z)在z_0处<strong>解析</strong><br><strong>解析函数:</strong>f(z)在区域B上处处解析。<br><strong>调和函数:f=u+iv</strong>在区域B上解析。则u和v是B上的调和函数<br>也就是满足<center>**拉普拉斯方程**
$\triangledown^2H=0$在区域B连续且满足拉普拉斯方程的H(x,y)称为调和函数
u、v都满足二维的拉普拉斯方程，所以都是调和函数。因为是同一个负数的实部与虚部，所以为
**共轭调和函数**
</center></p>
<p>由一个调和函数确定解析函数:<br>运用C-R条件确定<br>$dv=-\frac{\partial u}{\partial y}dx+\frac{\partial u}{\partial x}dy$也就是一个全微分<br>之后3种积分法积出v<br><strong>①曲线积分:</strong><br><strong>②凑全微分</strong><br><strong>③不定积分法</strong><br>P.S 见数学分析</p>
<p>解题步骤:<br>1.对给定函数验证是调和函数<br>2.利用C-R条件求出4个偏导，记住C-R得到的那两个偏导<br>3.dv=C-R条件得到的那两个偏导分别乘dx dy<br>4.积分得到v<br>路径无关条件:对于Qdx+Pdy  Q对y求导=P对x求导</p>
<h4 id="1-4-1-解析函数的性质"><a href="#1-4-1-解析函数的性质" class="headerlink" title="1.4.1 解析函数的性质"></a>1.4.1 解析函数的性质</h4><p>1.u(x,y)=C1 v(x,y)=C2 (C1,C2为常数)。两组曲线簇<strong>正交</strong><br>实际上,C-R条件相乘。得到$\triangledown u+\triangledown v=0$<br>说明两梯度正交。而两梯度是曲线簇的法向量。于是两曲线簇正交</p>
<h3 id="1-5-平面标量场"><a href="#1-5-平面标量场" class="headerlink" title="1.5 平面标量场"></a>1.5 平面标量场</h3><p>例:<br>若u(x,y)=C1为电势(这样的解析函数称为<strong>复势</strong>)，等势线簇。则v(x,y)=C2为电场线簇。且对v沿某路径积分能得到通量。因此v也叫<strong>通量函数</strong></p>
<h3 id="1-6-多值函数"><a href="#1-6-多值函数" class="headerlink" title="1.6 多值函数"></a>1.6 多值函数</h3><p>如:$\omega=\sqrt z $可得到<br>$\omega_1=\sqrt{|Z|}e^{i(arg z)/2}\\ \omega_2=\sqrt{|Z|}e^{i(arg z)/2+i\pi}=-\omega_1$<br>称为两个单值分支<br>性质:从某点z_0出发，沿包围z=0的闭合路径一圈能够进入另一个单值分支。（不包围则不变）<br><strong>支点:</strong>绕该点一圈w不复原。且该点单值分支函数值相同<br><strong>n-1阶支点</strong>:绕n圈w函数值复原.如z=0是1阶支点(z=无穷大也是1阶支点)</p>
<h4 id="1-6-1-黎曼面"><a href="#1-6-1-黎曼面" class="headerlink" title="1.6.1 黎曼面:"></a>1.6.1 <strong>黎曼面:</strong></h4><p>(假设绕的第一圈和第二圈在两个复平面上运行)<br><img src="./1552044725599.png" alt="Alt text"></p>
<h2 id="2-复变函数积分"><a href="#2-复变函数积分" class="headerlink" title="2 复变函数积分"></a>2 复变函数积分</h2><h3 id="2-1-复变函数的积分"><a href="#2-1-复变函数的积分" class="headerlink" title="2.1 复变函数的积分"></a>2.1 复变函数的积分</h3><p>$f(z)=u(x,y)+iv(x,y)$<br>1.<strong>路积分</strong> 将一条路径分段后积分</p>
<script type="math/tex; mode=display">\int_lf(z)dz=\int_lu(x,y)dx-v(x,y)dy+i\int_lv(x,y)dx+u(x,y)dy</script><p>复变函数的积分与路径有关</p>
<h3 id="2-2-柯西定理"><a href="#2-2-柯西定理" class="headerlink" title="2.2 柯西定理"></a>2.2 柯西定理</h3><h4 id="2-2-1-单连通区域的柯西定理"><a href="#2-2-1-单连通区域的柯西定理" class="headerlink" title="2.2.1 单连通区域的柯西定理"></a>2.2.1 单连通区域的柯西定理</h4><script type="math/tex; mode=display">\oint_lf(z)dz=0</script><h4 id="2-2-2-复连通区域的柯西定理"><a href="#2-2-2-复连通区域的柯西定理" class="headerlink" title="2.2.2 复连通区域的柯西定理"></a>2.2.2 复连通区域的柯西定理</h4><script type="math/tex; mode=display">\oint_lf(z)dz+\sum_{i=1}^n\oint_{l_i}f(z)dz=0</script><p>l_i为区域内边界线,l为外边界线<br>f(z)若在单连通域B上解析，则沿B上任一路径l的积分值与路径无关</p>
<h3 id="2-3-不定积分"><a href="#2-3-不定积分" class="headerlink" title="2.3 不定积分"></a>2.3 不定积分</h3><p>由<strong>柯西定理</strong>知f(z)若在单连通域B上解析，则沿B上任一路径l的积分值与路径无关.于是起点z_0确定后，到终点z的积分能够形成函数</p>
<script type="math/tex; mode=display">F(z)=\int_{z_0}^zf(\xi)d\xi</script><p>性质:<br>①F(z)在B上解析<br>②F’(z)=f(z)<br>③路积分值=原函数改变量</p>
<script type="math/tex; mode=display">\frac{1}{2\pi i}\oint_l\frac{dz}{z-\alpha}=
f(x)=\begin{cases}
0& \text{l不包围}\alpha\\
1& \text{l包围}\alpha
\end{cases}</script><h3 id="2-4-柯西公式"><a href="#2-4-柯西公式" class="headerlink" title="2.4 柯西公式"></a>2.4 柯西公式</h3><p><strong>若f(z)在连通区域</strong>$\overline{B}$,l为区域$\overline{B}的边界$,$\alpha$为区域内任意一点</p>
<script type="math/tex; mode=display">f(\alpha)=\frac{1}{2\pi i}\oint_i \frac{f(z)}{z-\alpha}dz</script><p>其将任一点的函数值用沿边界线l的积分表示了出来</p>
<p>复连通域上的柯西公式仍然成立。l为所有边界线，且均取正方形</p>
<p>性质、推论:<br>①解析函数可以任意求导多次</p>
<script type="math/tex; mode=display">f^{(n)}(z)=\frac{n!}{2\pi i}\oint_l\frac{f(\xi)}{(\xi-z)^{n+1}}d\xi</script><p>②<strong>模数定理</strong>:f(z)在某个闭区域上解析，|f(z)|只能在边界线上取得极大值<br>③刘维尔定理:f(z)在全平面上解析，f(z)只能为常数</p>
<h2 id="3-幂级数展开"><a href="#3-幂级数展开" class="headerlink" title="3 幂级数展开"></a>3 幂级数展开</h2><h3 id="3-1-复数项级数"><a href="#3-1-复数项级数" class="headerlink" title="3.1 复数项级数"></a>3.1 复数项级数</h3><script type="math/tex; mode=display">\sum_{k=0}^\infty w_k=w_0+w_1+...+w_n\\w_k=u_k+iv_k</script><p><strong>柯西收敛判定：</strong><br>级数各项模的和的级数收敛，则级数<strong>绝对收敛</strong></p>
<p>两个绝对收敛的级数，逐项相乘仍然收敛，且和=AB</p>
<script type="math/tex; mode=display">\sum_{k=0}^\infty p_k \sum_{l=0}^\infty q_l=\sum\sum p_kq_l=\sum c_n=AB\\c_n=p_kq_{n-k}</script><p>一致收敛:<br>N与z无关</p>
<script type="math/tex; mode=display">|\sum_{k=n+1}^{n+p}w_k(z)|<\epsilon</script><p>对给定小正数$\epsilon$必有N(z)存在,n&gt;N(z)时上式成立</p>
<p>性质:<br>1.连续保持:若<strong>每一项都是连续函数</strong>,和也是连续函数<br>2.积分:可以逐项积分<br>3.求导：可以逐项求导。且求导结果在任意子闭区域内一致收敛</p>
<p>如果$|w_k(z)|\le m_k$ $\sum m_k$为正的常数项级数，且收敛。则 wk<strong>绝对且一致收敛</strong></p>
<h3 id="3-2-幂级数"><a href="#3-2-幂级数" class="headerlink" title="3.2 幂级数"></a>3.2 幂级数</h3><script type="math/tex; mode=display">\sum_{k=0}^\infty a_k(z-z_0)^k</script><p>收敛判断:<br>1.求收敛半径$R=\lim_{k-&gt;\infty}|\frac{a_k}{a_{k+1}}|$ 若$|z-z_0|&lt;R$则绝对收敛<br>2.对于正项级数<strong>根植判断</strong>:每项根号k后，k取极限，若&lt;1则绝对收敛<br>3.逐项积分\逐项求导不改变收敛半径</p>
<h3 id="3-3-泰勒级数展开"><a href="#3-3-泰勒级数展开" class="headerlink" title="3.3 泰勒级数展开"></a>3.3 泰勒级数展开</h3><center>**定理**</center>
<center>$f(z)=\sum_{k=0}^\infty a_k(z-z_0)^k$
则f(z)在以z_0为圆心的圆C_R内解析。f(z)可展开为幂级数
$a_k=\frac{f^{(k)}(z_0)}{k!}$
以z_0为中心的泰勒级数
$f(z)=\frac{f^{(k)}(z_0)}{k!}(z-z_0)^k$
<center>

###3.4 解析延拓
就是使用合理的方法，使定义域扩大。具有唯一性
###3.5 洛朗级数
**双边幂级数**
$...+a_{-2}(z-z_0)^{-2}+a_{-1}(z-z_0)^{-1}+a_0+a_{1}(z-z_0)+a_{2}(z-z_0)^{2}+...$
分为两个部分。正的部分收敛半径为R1，代换1/z-z_0,得到负项部分半径1/R_2.  则R2<|z-z_0|<R1为**收敛环**

**洛朗级数展开**
<center>f(z)在环形区域R2<|z-z_0|<R1内解析
则$f(z)=\sum_{-\infty}^\infty a_k(z-z_0)^k$
$a_k=\frac{1}{2\pi i}\oint_C\frac{f(\epsilon)}{(\epsilon-z_0)^{k+1}}d\epsilon$
C为环域内任一逆时针闭合路径
</center>
###3.6 独立奇点的分类
在z0不可导，在Z0任意小邻域能除z0外处处可导。则为**独立奇点**
**可去奇点**:洛朗级数没有负幂项
**极点**:洛朗级数只有有限个负幂项
**本性奇点**:无限个负幂项
##4 留数定理
###4.1 留数定理
(单个奇点下)
**留数**:$(z-z_0)^{-1}$项的系数$a_{-1}$有特别的地位。因此称为f(z)在$z_0$的**留数**.记作**Res f(z_0)**
根据柯西定理在比$l$小的回路$l_0$上积分，除-1项外全部为0

**于是**$\oint_l f(z)dz=2\pi iRes f(z_0)$

---
<center>**留数定理(Residue theorem)**
设函数$f(z)$在回路**l**所围区域**B**上除**有限**个奇点b1,b2,..,bn外**处处解析**。在闭区域$\hat{B}$上除b1,b2,...,bn外**处处连续**.
则$\oint_l f(z)dz=2\pi i\sum_{j=1}^n Res f(b_j)$
</center>

<hr>
<p><strong>留数定理将回路积分归结为被积函数在回路所围区域上奇点留数的和</strong></p>
<p>对于1阶极点z_0<br>$Res f(z_0)=\lim_{z-&gt;z_0}(z-z_0)\frac{P(z)}{Q(z)}=\frac{P(z_0)}{Q’(z_0)}$(计算留数)<br>$\lim_{z-&gt;z_0}(z-z_0)^mf(z)=非0有限值$(判断极点的阶)</p>
<h3 id="4-2-应用留数定理计算实变函数积分"><a href="#4-2-应用留数定理计算实变函数积分" class="headerlink" title="4.2 应用留数定理计算实变函数积分"></a>4.2 应用留数定理计算实变函数积分</h3><h4 id="4-2-1-三角函数有理式型"><a href="#4-2-1-三角函数有理式型" class="headerlink" title="4.2.1 三角函数有理式型"></a>4.2.1 三角函数有理式型</h4><script type="math/tex; mode=display">\int_0^{2\pi}R(cos x,sin x) dx</script><p>step1:作变换$z=e^{ix}$.x从0到2pi变化。则z沿逆时针绕单位圆走一圈<br>step2:利用第一章的变换。把sin\cos换成z表示：<br>$cos x=\frac{1}{2}(z+z^{-1})$<br>$sin x=\frac{1}{2i}(z-z^{-1})$<br>$dx=\frac{1}{iz}dz$<br>step3:求积分<br>$\oint_{|z|=1}R(\frac{z+z^{-1}}{2},\frac{z-z^{-1}}{2i})dz/iz$</p>
<p>利用留数定理积分步骤:<br>1.找出极点<br>2.判断每个极点是否在回路内，不在的不管<br>3.对在回路内的极点利用留数定理积分</p>
<h4 id="4-2-2-正负无穷的积分"><a href="#4-2-2-正负无穷的积分" class="headerlink" title="4.2.2 正负无穷的积分"></a>4.2.2 正负无穷的积分</h4><script type="math/tex; mode=display">f_{-\infty}^\infty f(z)=2\pi i{f(x)在上半平面所有奇点的留数之和}</script><h4 id="4-2-3-0到无穷大与三角函数积分"><a href="#4-2-3-0到无穷大与三角函数积分" class="headerlink" title="4.2.3 0到无穷大与三角函数积分"></a>4.2.3 0到无穷大与三角函数积分</h4><script type="math/tex; mode=display">\int_0^\infty F(x)cos mxdx=\frac{1}{2}\int_{-\infty}^\infty F(x)e^{imx}dx</script><script type="math/tex; mode=display">\int_0^\infty G(x)sin mxdx=\frac{1}{2i}\int_{-\infty}^\infty G(x)e^{imx}dx</script><p><strong>约当定理</strong>:<br>$C_R$为上半圆。z-&gt;无穷大时F(z)一致的-&gt;0<br>则</p>
<script type="math/tex; mode=display">lim_{R->0}\int_{C_R}F(z)e^{imz}dz=0</script><p>于是又可得到</p>
<script type="math/tex; mode=display">\int_0^\infty F(x)cos mxdx=\pi i{\{F(z)e^{imz}}在上平面所有奇点留数之和\}</script><script type="math/tex; mode=display">\int_0^\infty G(x)sin mxdx=\pi {\{G(z)e^{imz}}在上平面所有奇点留数之和\}</script>]]></content>
  </entry>
  <entry>
    <title>創造情報学入学試験について</title>
    <url>/2019/12/26/%E5%89%B5%E9%80%A0%E6%83%85%E5%A0%B1%E5%AD%A6%E5%85%A5%E5%AD%A6%E8%A9%A6%E9%A8%93%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/</url>
    <content><![CDATA[<h1 id="創造情報学入学試験について"><a href="#創造情報学入学試験について" class="headerlink" title="創造情報学入学試験について"></a>創造情報学入学試験について</h1><p>[TOC]</p>
<h2 id="1-試験涉及内容"><a href="#1-試験涉及内容" class="headerlink" title="1.試験涉及内容"></a>1.試験涉及内容</h2><table><tbody>
    <tr>
        <th rowspan="6">基础科目</th>
        <th>科目</th>
        <th>考过的名词</th>
        <th>考过的知识点</th>
        <th>教材</th>
        <th>是否已学</th>
    </tr>
    <tr>
        <td>線形代数(<b>线性代数</b>)</td>
        <td></td>
        <td></td>
        <td>《演習大学院入試問題〈数学〉I》</td>
        <td>Y</td>
    </tr>
    <tr>
        <td><b>复数分析</b> </td>
        <td></td>
        <td></td>
        <td></td>
        <td>Y</td>
    </tr>
     <tr>
        <td><b>矢量分析</b> </td>
        <td></td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>解析（<b>数学分析</b>) </td>
        <td></td>
        <td></td>
        <td>《複素関数問題集》《新版 複素解析 (基礎数学)》《演習と応用 ベクトル解析.》《微分方程式問題集》《演習微分積分..》</td>
        <td>Y</td>
    </tr>
     <tr>
        <td>確率・統計 （<b>概率与统计</b>） [注意名词] </td>
        <td>共分散分析(协方差分析)</td>
        <td></td>
        <td>《演習 大学院入試問題[数学]II》</td>
        <td>I</td>
    </tr>
     <tr>
        <th rowspan="23">专业科目</th>
         <th>科目</th>
        <th>考过的名词</th>
        <th>考过的知识点</th>
        <th>教材</th>
        <th>是否已系统学习</th>
    </tr>
     <tr>
        <td>アルゴリズム（数据结构\算法）</td>
        <td>旅行商问题,分治法</td>
        <td></td>
        <td>《データ構造とアルゴリズム 》</td>
        <td>Y</td>
    </tr>
    <tr>
        <td>深度学习**</td>
        <td>CPU加速、增强学习</td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>自然语言处理**</td>
        <td>TD-IDF</td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
    <tr>
        <td>计算机视觉**</td>
        <td></td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
     <tr>
        <td>机器学习**</td>
        <td></td>
        <td>线性回归</td>
        <td></td>
        <td></td>
    </tr>
     <tr>
        <td>論理回路(数字电路)</td>
        <td>组合数字电路</td>
        <td></td>
        <td>《論理回路入門》 </td>
        <td>Y</td>
    </tr>
     <tr>
        <td>操作系统</td>
        <td></td>
        <td></td>
        <td>《オペレーティングシステムの仕組み》《オペレーティングシステム (情報処理入門コース 2)》</td>
        <td>I</td>
    </tr>
         <tr>
        <td>计算机组成原理</td>
        <td>流水线风险,register renaming<计算机体系结构></td>
        <td></td>
        <td>《コンピュータアーキテクチャ》《コンピュータの構成と設計~ハードウエアとソフトウエアのインタフェース 第3版 》 </td>
        <td>Y</td>
    </tr>
         <tr>
        <td>计算机网络</td>
        <td>TCPウィンドウ制御</td>
        <td></td>
        <td></td>
         <td>I</td>
    </tr>
     </tr>
         <tr>
        <td>计算机图形学**</td>
        <td></td>
        <td></td>
        <td></td>
         <td></td>
    </tr>
     </tr>
         <tr>
        <td>形式语言与自动机</td>
        <td>RE和RG</td>
        <td></td>
        <td></td>
         <td>I</td>
    </tr>
     </tr>
         <tr>
        <td>编译原理**</td>
        <td>register renaming(寄存器重命名)</td>
        <td></td>
        <td></td>
         <td></td>
    </tr>
     </tr>
         <tr>
        <td>软件工程</td>
        <td>持续集成</td>
        <td></td>
        <td>《ソフトウェア工学の基礎知識 》</td>
        <td>Y</td>
    </tr>
     </tr>
         <tr>
        <td>网络安全</td>
        <td>ゼロデイ攻撃</td>
        <td></td>
        <td></td>
        <td>N</td>
    </tr>
     </tr>
         <tr>
        <td>机器人论**</td>
        <td></td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
   </tr>
         <tr>
        <td>密码学**</td>
        <td>公钥和私钥</td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
    </tr>
         <tr>
        <td>离散数学</td>
        <td></td>
        <td></td>
        <td></td>
        <td>Y</td>
    </tr>
       </tr>
         <tr>
        <td>信息论</td>
        <td></td>
        <td></td>
        <td>《情報理論》</td>
        <td></td>
    </tr>
     </tr>
         <tr>
        <td>通信原理</td>
        <td>Vector quantization,Kalman filter</td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
      </tr>
         <tr>
        <td>控制论</td>
        <td></td>
        <td></td>
        <td></td>
        <td></td>
    </tr>
</table>  


<p>夏入试可选数学或者编程。<br>冬入试只能选编程。<br>算法书籍；<br>ACM/ICPCの問題集<br>AIZU ONLINE JUDGE: Programming Challenge<br>プログラミングコンテストチャレンジブック [第2版] ?問題解決のアルゴリズム活用力とコーディングテクニックを鍛える?</p>
<p>数学书籍：<br><img src="./1552307625814.png" alt="Alt text"><br><img src="./1552307633406.png" alt="Alt text"><br><img src="./1552307639312.png" alt="Alt text"><br><img src="./1552307698892.png" alt="Alt text"><br><img src="./1552307705097.png" alt="Alt text"><br><img src="./1552307708824.png" alt="Alt text"></p>
<h2 id="2-真实面试问题"><a href="#2-真实面试问题" class="headerlink" title="2.真实面试问题"></a>2.真实面试问题</h2><p>1.<strong>「当該分野について何か勉強などしていますか？その内容について説明してください」</strong>(在这个领域有学过什么吗?说明一下)</p>
<p>2.<strong>卒論などこれまで行って来た研究についておしえて</strong>(请说一下毕业论文还有来这之后的研究打算)</p>
<h2 id="3-语义说明对策"><a href="#3-语义说明对策" class="headerlink" title="3.语义说明对策"></a>3.语义说明对策</h2><p>アルゴリズム・システムアーキテクチャ＞情報理論・離散数学＞＞プログラミング用語＞暗号理論＞人工知能・ロボット・CG＞＞データベース・ネットワーク</p>
<p>算法数据结构，系统结构&gt;情报理论<em>离散数学&gt;编程语言&gt;密码学&gt;人工智能,机器人论,CG&gt;&gt;数据库</em>计算机网络</p>
<p>方法：利用维基<br>勉強手順<br>wikiを見て軽く理解する→４～８行で説明出来るか確認する→出来たら次の言葉へ、出来なかったらwikiを読み直す<br>この繰り返しで語彙を増やすことができます。また、説明の際に図を書くと高い点数がもらえる傾向にあるそうなので、意識して勉強するといいかもしれません</p>
<blockquote>
<p>对于某个词汇首先在wiki上简单了解。然后用4~8行文字说明出来。如果能说明出来的话，就进入下一个词语。不行的话重新看wiki.直到可以。<br>然后说明时画图有高分倾向，最好养成习惯.</p>
</blockquote>
<h2 id="4-大题结构"><a href="#4-大题结构" class="headerlink" title="4.大题结构"></a>4.大题结构</h2><h3 id="問1"><a href="#問1" class="headerlink" title="問1"></a>問1</h3><p><img src="./1552307282501.png" alt="Alt text"><br>特点:出题范围窄，好好研究算法就行<br>出过的问题:<br>（10）斐波那契数列和高数化<br>（10）背包问题<br>（09）有向最短路径<br>（08）记录和顺序搜索、二分搜索、散列表<br>（07）整数和约数个数、素因数分解<br>（08）ソーティングネットワーク、复杂度分析<br>（05） 文字列置換、削除、追加、編集距離、再帰式 </p>
<h3 id="問2"><a href="#問2" class="headerlink" title="問2"></a>問2</h3><p>特点：涉及硬件、OS、记忆与技巧为主的东西较多,词汇题中也常出现<br>出现过的问题:</p>
<p>2010冬 状態遷移図(ミーリ型・ムーア型)、回路図  （状态转移图、电路图）</p>
<p>2010夏 命令セットアーキテクチャの設計（指令集设计）</p>
<p>2009 加算器と乗算器と遅延時間の減少方法   （减少加法器和乘法器延迟时间的方法）</p>
<p>2008 同期式4bit<em>4桁カウンタの設計、状態遷移、Dフリップフロップ、遅延時間 （同步4</em>4计数器,状态迁移,D触发器,延迟时间）</p>
<p>2007 並列コンピュータの排他制御（プログラムも）、test and set、compare and swap、セマフォ、メッセージ通信、3台以上のコンピュータの制御</p>
<p>2006 センサからのデータ入力、プログラムの時間ダイアグラム、並列処理システム設計の際の注意点</p>
<p>2005 プロセッサのキャッシュメモリ、2-way set associativeのキャッシュメモリのブロック図、ヒット率向上のハードウェア技術とプログラミング技法</p>
<p><img src="./1552307537527.png" alt="Alt text"><img src="./1552307551019.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>Operating System Concepts</title>
    <url>/2019/12/26/Operating%20System%20Concepts/</url>
    <content><![CDATA[<h1 id="Operating-System-Concepts"><a href="#Operating-System-Concepts" class="headerlink" title="Operating System Concepts"></a>Operating System Concepts</h1><p>[TOC]</p>
<h2 id="Chapter-1-Introduction-介绍"><a href="#Chapter-1-Introduction-介绍" class="headerlink" title="Chapter 1 Introduction(介绍)"></a>Chapter 1 Introduction(介绍)</h2><h3 id="1-1-What-OS-Do"><a href="#1-1-What-OS-Do" class="headerlink" title="1.1 What OS Do?"></a>1.1 What OS Do?</h3><p>A computer system can be divided roughly into <strong>four</strong> components: the <strong>hardware</strong>, the <strong>operating system</strong>, the <strong>application programs</strong>,and a <strong>user</strong></p>
<h4 id="1-1-1-User-View"><a href="#1-1-1-User-View" class="headerlink" title="1.1.1 User View"></a>1.1.1 User View</h4><p><img src="./1552728926122.png" alt="Alt text"><br>Some Computer have little or no user view,such as <strong>embedded computers(嵌入式计算机)</strong></p>
<h4 id="1-1-2-System-View"><a href="#1-1-2-System-View" class="headerlink" title="1.1.2 System View"></a>1.1.2 System View</h4><p>we can view OS as a <strong>resource allocator</strong></p>
<h4 id="1-1-3-Defining-OS"><a href="#1-1-3-Defining-OS" class="headerlink" title="1.1.3 Defining OS"></a>1.1.3 Defining OS</h4><p><strong>middleware</strong>:a set of software frameworks that provide additional services to application developers<br>In summary OS include:<br><strong>Kernal(内核):</strong>alway running<br><strong>Middleware(中间件)</strong>:ease application development and provide features<br><strong>system programs(系统程序)</strong>:aid in managing the system while it is running</p>
<h3 id="1-2-Computer-System-Organization"><a href="#1-2-Computer-System-Organization" class="headerlink" title="1.2 Computer-System Organization"></a>1.2 Computer-System Organization</h3><p><img src="./1552730553032.png" alt="Alt text"></p>
<h4 id="1-2-1-Interrupts-中断"><a href="#1-2-1-Interrupts-中断" class="headerlink" title="1.2.1 Interrupts(中断)"></a>1.2.1 Interrupts(中断)</h4><p>Start a <strong>I/O operation</strong>:<br>(1)device driver loads the appropriate registers in the device controller.<br>(2)device controller  examines the contents of these registers to determine what action to take</p>
<h5 id="1-2-1-1-Overview"><a href="#1-2-1-1-Overview" class="headerlink" title="1.2.1.1 Overview"></a>1.2.1.1 Overview</h5><p><img src="./1552731054149.png" alt="Alt text"><br><strong>interrupt vector</strong> is the memory location of an interrupt handler</p>
<h5 id="1-2-1-2-Implementation"><a href="#1-2-1-2-Implementation" class="headerlink" title="1.2.1.2 Implementation"></a>1.2.1.2 Implementation</h5><p>the device controller <strong>raises</strong> an interrupt by asserting a signal on the<br>interrupt request line, the CPU <strong>catches</strong> the interrupt and <strong>dispatches</strong> it to the<br>interrupt handler, and the handler <strong>clears</strong> the interrupt by servicing the device<br><img src="./1552731541789.png" alt="Alt text"><br>Most CPUs have two <strong>interrupt request lines</strong>. One is the <strong>nonmaskable interrupt(不可屏蔽中断)</strong><br>,another is <strong>maskable interrupt(可屏蔽中断)</strong></p>
<h4 id="1-2-2-Storage-Structure"><a href="#1-2-2-Storage-Structure" class="headerlink" title="1.2.2 Storage Structure"></a>1.2.2 Storage Structure</h4><p><strong>bootstrap(引导程序)</strong><br><img src="./1552732221601.png" alt="Alt text"></p>
<h4 id="1-2-3-I-O-Structure"><a href="#1-2-3-I-O-Structure" class="headerlink" title="1.2.3 I/O Structure"></a>1.2.3 I/O Structure</h4><p><img src="./1552732309932.png" alt="Alt text"><br><strong>DMA(Direct Memory Access)</strong>:After setting up buffers, pointers, and counters for the I/O device, the device controller transfers an entire block of data directly to or from the device and main memory, with no intervention by the CPU. Only one interrupt is generated per block, to tell the device driver that the operation has completed, rather than the one interrupt per byte generated for low-speed devices. (为I/O设备设置好<strong>缓冲区</strong>，<strong>指针</strong>，和<strong>计时器</strong>后。设备控制器就传输完整的数据块在主存和设备之间，不需要CPU干预。整个过程只有一次<strong>中断</strong>-通知操作完成)</p>
<h3 id="1-3-Computer-System-Architecture"><a href="#1-3-Computer-System-Architecture" class="headerlink" title="1.3 Computer-System Architecture"></a>1.3 Computer-System Architecture</h3><h4 id="1-3-1-Single-Processor-System-单道程序系统"><a href="#1-3-1-Single-Processor-System-单道程序系统" class="headerlink" title="1.3.1 Single-Processor System(单道程序系统)"></a>1.3.1 Single-Processor System(单道程序系统)</h4><p>All of these special-purpose processors run a limited instruction set and do not run processes.<br>只有一个程序,顺序执行,独占资源,结果可再现性</p>
<h4 id="1-3-2-MultiProcessor-System-多道程序系统"><a href="#1-3-2-MultiProcessor-System-多道程序系统" class="headerlink" title="1.3.2 MultiProcessor System(多道程序系统)"></a>1.3.2 MultiProcessor System(多道程序系统)</h4><p><strong>symmetric multiprocessing(对称多处理):</strong><br><strong>SMP (symmetric multiprocessing) </strong>is the processing of programs by multiple processors that share a common operating system and memory.<br><img src="./1552733022090.png" alt="Alt text"><br><strong>多核处理器的结构和缓存</strong><br><img src="./1552733107211.png" alt="Alt text"><br><strong>non-uniform memory access(NUMA,非均匀存储器存储):</strong> is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to the processor<br><img src="./1552733465957.png" alt="Alt text"></p>
<h4 id="1-3-3-Clustered-Systems-集群系统"><a href="#1-3-3-Clustered-Systems-集群系统" class="headerlink" title="1.3.3 Clustered Systems(集群系统)"></a>1.3.3 Clustered Systems(集群系统)</h4><p>Clustering is usually used to provide <strong>high-availability service</strong><br><img src="./1552733800515.png" alt="Alt text"></p>
<h3 id="1-4-Operating-System-Operations"><a href="#1-4-Operating-System-Operations" class="headerlink" title="1.4 Operating-System Operations"></a>1.4 Operating-System Operations</h3><p>计算器启动:<br><strong>第一阶段</strong><br>1.最先读取BIOS（里面包含自检程序,CMOS设置程序,系统自动装载程序、主要I/O驱动和中断服务）<br>2.自检<br>3.控制权转交到引导设备<br><strong>第二阶段</strong><br>1.读取主引导记录(512B)<br>2.运行启动管理器<br>3,转交启动管理器</p>
<h4 id="1-4-1-Multiprogramming-and-Multitasking"><a href="#1-4-1-Multiprogramming-and-Multitasking" class="headerlink" title="1.4.1 Multiprogramming and Multitasking"></a>1.4.1 Multiprogramming and Multitasking</h4><h4 id="1-4-2-Dual-Mode-and-Multimode-Operation"><a href="#1-4-2-Dual-Mode-and-Multimode-Operation" class="headerlink" title="1.4.2 Dual-Mode and Multimode Operation"></a>1.4.2 Dual-Mode and Multimode Operation</h4><p>存在两种模式<br><strong>user mode</strong> and <strong>kernel mode(also called supervisor mode, system mode, or privileged mode)</strong><br>在hardware里加个模式位<br><img src="./1552734674000.png" alt="Alt text"><br>系统启动时处于<strong>kernel mode</strong><br><strong>转换到user mode 的命令本身就是privileged instruction</strong><br>When a <strong>system call</strong> is executed, it is typically treated by the hardware as a <strong>software interrupt</strong>. Control passes through the <strong>interrupt vector</strong> to a service routine in the operating system, and the mode bit is set to <strong>kernel mode</strong><br>(系统调用被看作软中断，然后会变成kernel mode)</p>
<h4 id="1-4-3-Timer"><a href="#1-4-3-Timer" class="headerlink" title="1.4.3 Timer"></a>1.4.3 Timer</h4><p>防止死循环，维持对系统的控制</p>
<h3 id="1-5-Resource-Management-资源管理"><a href="#1-5-Resource-Management-资源管理" class="headerlink" title="1.5 Resource Management(资源管理)"></a>1.5 Resource Management(资源管理)</h3><h4 id="1-5-1-Process-Management-进程管理"><a href="#1-5-1-Process-Management-进程管理" class="headerlink" title="1.5.1 Process Management(进程管理)"></a>1.5.1 Process Management(进程管理)</h4><h4 id="1-5-2-Process-Management-内存管理"><a href="#1-5-2-Process-Management-内存管理" class="headerlink" title="1.5.2 Process Management(内存管理)"></a>1.5.2 Process Management(内存管理)</h4><h4 id="1-5-3-File-System-Management-文件系统管理"><a href="#1-5-3-File-System-Management-文件系统管理" class="headerlink" title="1.5.3 File-System Management(文件系统管理)"></a>1.5.3 File-System Management(文件系统管理)</h4><h4 id="1-5-4-Mass-Storage-Management-大容量存储器管理"><a href="#1-5-4-Mass-Storage-Management-大容量存储器管理" class="headerlink" title="1.5.4 Mass-Storage Management(大容量存储器管理)"></a>1.5.4 Mass-Storage Management(大容量存储器管理)</h4><h4 id="1-5-5-Cache-Management-缓存管理"><a href="#1-5-5-Cache-Management-缓存管理" class="headerlink" title="1.5.5 Cache Management(缓存管理)"></a>1.5.5 Cache Management(缓存管理)</h4><h4 id="1-5-6-I-O-System-Management-I-O系统管理"><a href="#1-5-6-I-O-System-Management-I-O系统管理" class="headerlink" title="1.5.6 I/O System Management(I/O系统管理)"></a>1.5.6 I/O System Management(I/O系统管理)</h4><h3 id="1-6-Security-and-Protection-安全与保护"><a href="#1-6-Security-and-Protection-安全与保护" class="headerlink" title="1.6 Security and Protection(安全与保护)"></a>1.6 Security and Protection(安全与保护)</h3><h3 id="1-7-Virtualization-虚拟化"><a href="#1-7-Virtualization-虚拟化" class="headerlink" title="1.7 Virtualization(虚拟化)"></a>1.7 Virtualization(虚拟化)</h3><h3 id="1-8-Distributed-Systems-分布式系统"><a href="#1-8-Distributed-Systems-分布式系统" class="headerlink" title="1.8 Distributed Systems(分布式系统)"></a>1.8 Distributed Systems(分布式系统)</h3><h3 id="1-9-Distributed-Systems-核心数据结构"><a href="#1-9-Distributed-Systems-核心数据结构" class="headerlink" title="1.9 Distributed Systems(核心数据结构)"></a>1.9 Distributed Systems(核心数据结构)</h3><p>略<br><strong>Bitmaps：</strong>实际上是一个字符串。不过可以对字符串的位进行操作</p>
<h3 id="1-10-Computing-Environments"><a href="#1-10-Computing-Environments" class="headerlink" title="1.10 Computing Environments"></a>1.10 Computing Environments</h3><p>传统计算、移动计算、C\S计算、<br><img src="./1552735817737.png" alt="Alt text"><br>P2P计算<br>云计算<br><img src="./1552735865692.png" alt="Alt text"><br><img src="./1552735956426.png" alt="Alt text"></p>
<h2 id="Chapter-2-Operating-System-Structures"><a href="#Chapter-2-Operating-System-Structures" class="headerlink" title="Chapter 2:Operating System Structures"></a>Chapter 2:Operating System Structures</h2><h3 id="2-1-Operating-System-Services-OS服务"><a href="#2-1-Operating-System-Services-OS服务" class="headerlink" title="2.1 Operating-System Services(OS服务)"></a>2.1 Operating-System Services(OS服务)</h3><p><img src="./1552736201373.png" alt="Alt text"></p>
<h3 id="2-2-User-and-Operating-System-Interface"><a href="#2-2-User-and-Operating-System-Interface" class="headerlink" title="2.2 User and Operating-System Interface"></a>2.2 User and Operating-System Interface</h3><p>也就<br>命令解释器<br>GUI<br>触屏</p>
<h3 id="2-3-System-Calls-系统调用"><a href="#2-3-System-Calls-系统调用" class="headerlink" title="2.3 System Calls(系统调用)"></a>2.3 System Calls(系统调用)</h3><p><strong>System calls</strong> provide an interface to the services made available by an operating system.</p>
<h4 id="2-3-2-API"><a href="#2-3-2-API" class="headerlink" title="2.3.2 API"></a>2.3.2 API</h4><p>好处:提高可移植性,可以在任何支持同样API的系统上运行</p>
<h4 id="2-3-3-Types-of-System-Calls"><a href="#2-3-3-Types-of-System-Calls" class="headerlink" title="2.3.3 Types of System Calls"></a>2.3.3 Types of System Calls</h4><p><strong>process control</strong>,<strong>file management</strong>, <strong>device management</strong>, <strong>information maintenance</strong>, <strong>communications</strong>,and <strong>protection</strong><br>(进程控制，文件管理，设备管理，信息维护，交流，保护)</p>
<h3 id="2-4-System-Services-系统程序"><a href="#2-4-System-Services-系统程序" class="headerlink" title="2.4 System Services(系统程序)"></a>2.4 System Services(系统程序)</h3><p><strong>System services</strong>, also known as <strong>system utilities</strong>,<br><strong>File management.</strong><br><strong>Status information</strong><br><strong>File modificatio(文件修改)</strong><br><strong>Programming-language support.(编程语言支持)</strong><br><strong>Program loading and execution.</strong><br><strong>Communications.</strong><br><strong>Background services.</strong></p>
<h3 id="2-5-Linker-and-Loader"><a href="#2-5-Linker-and-Loader" class="headerlink" title="2.5 Linker and Loader"></a>2.5 Linker and Loader</h3><p><img src="./1552736911733.png" alt="Alt text"><br>Linker链接文件后，统一了代码逻辑地址</p>
<h3 id="2-8-Operating-System-Structure"><a href="#2-8-Operating-System-Structure" class="headerlink" title="2.8 Operating-System Structure"></a>2.8 Operating-System Structure</h3><p><img src="./1552737044796.png" alt="Alt text"></p>
<h4 id="2-8-1-Monolithic-Structure-整体架构"><a href="#2-8-1-Monolithic-Structure-整体架构" class="headerlink" title="2.8.1 Monolithic Structure(整体架构)"></a>2.8.1 Monolithic Structure(整体架构)</h4><p><img src="./1552737162694.png" alt="Alt text"></p>
<h4 id="2-8-2-Layered-Approach"><a href="#2-8-2-Layered-Approach" class="headerlink" title="2.8.2 Layered Approach"></a>2.8.2 Layered Approach</h4><p><img src="./1552737173089.png" alt="Alt text"></p>
<h4 id="2-8-3-Microkernels-微内核"><a href="#2-8-3-Microkernels-微内核" class="headerlink" title="2.8.3 Microkernels(微内核)"></a>2.8.3 Microkernels(微内核)</h4><p><img src="./1552737210202.png" alt="Alt text"><br>内核只有基本功能。</p>
<h3 id="2-9-Building-and-Booting-an-Operating-System-启动"><a href="#2-9-Building-and-Booting-an-Operating-System-启动" class="headerlink" title="2.9 Building and Booting an Operating System(启动)"></a>2.9 Building and Booting an Operating System(启动)</h3><h4 id="2-9-2-System-Boot"><a href="#2-9-2-System-Boot" class="headerlink" title="2.9.2 System Boot"></a>2.9.2 System Boot</h4><ol>
<li>A small piece of code known as the bootstrap program(In <strong>BIOS</strong>) or boot loader<br>locates the kernel.(This initial boot loader usually does nothing more than load<br>a second boot loader, which is located at a fixed disk location called the <strong>boot block</strong>.)</li>
<li>The kernel is loaded into memory and started.</li>
<li>The kernel initializes hardware.</li>
<li>The root file system is mounted.</li>
</ol>
<p><strong>UEFI</strong></p>
<h2 id="Chapter-3-Process"><a href="#Chapter-3-Process" class="headerlink" title="Chapter 3 Process"></a>Chapter 3 Process</h2><h3 id="3-1-Process-Concept"><a href="#3-1-Process-Concept" class="headerlink" title="3.1 Process Concept"></a>3.1 Process Concept</h3><h4 id="3-1-1-The-Process"><a href="#3-1-1-The-Process" class="headerlink" title="3.1.1 The Process"></a>3.1.1 The Process</h4><p><img src="./1552738190888.png" alt="Alt text"><br><strong>Text section:</strong>the executable  code<br><strong>Data section:</strong>global variables<br><strong>Heap section:</strong>动态分配的内存(memory that is dynamically allocated during program run<br>time)<br><strong>Stack section:</strong>临时数据存储。<br><img src="./1552738507541.png" alt="Alt text"></p>
<h4 id="3-1-2-Process-State"><a href="#3-1-2-Process-State" class="headerlink" title="3.1.2 Process State"></a>3.1.2 Process State</h4><p><img src="./1552738557383.png" alt="Alt text"><br>k核,n进程时<br><strong>等待状态:</strong>最多n个(全部死锁),最少0个<br><strong>运行状态:</strong>最多k个(全核运行),最少0个(死锁)<br><strong>就绪状态:</strong>最多n-k个(全核运行，没有等待的进行),最少0个(一部分运行，一部分等待)</p>
<h4 id="3-1-3-Process-Control-Block（PCB）"><a href="#3-1-3-Process-Control-Block（PCB）" class="headerlink" title="3.1.3 Process Control Block（PCB）"></a>3.1.3 Process Control Block（PCB）</h4><p><img src="./1552738864025.png" alt="Alt text"><br>有进程状态，进程变化(pid),程序计数器，寄存器，内存界限，打开文件列表等</p>
<h3 id="3-2-Process-Scheduling"><a href="#3-2-Process-Scheduling" class="headerlink" title="3.2 Process Scheduling"></a>3.2 Process Scheduling</h3><h4 id="3-2-1-Scheduling-Queues"><a href="#3-2-1-Scheduling-Queues" class="headerlink" title="3.2.1 Scheduling Queues"></a>3.2.1 Scheduling Queues</h4><p><img src="./1552739139108.png" alt="Alt text"><br><img src="./1552739184872.png" alt="Alt text"></p>
<h4 id="3-2-2-CPU-Scheduling"><a href="#3-2-2-CPU-Scheduling" class="headerlink" title="3.2.2 CPU Scheduling"></a>3.2.2 CPU Scheduling</h4><h4 id="3-2-3-Context-Switch"><a href="#3-2-3-Context-Switch" class="headerlink" title="3.2.3 Context Switch"></a>3.2.3 Context Switch</h4><p><img src="./1552739310149.png" alt="Alt text"></p>
<h3 id="3-3-Operations-on-Processes"><a href="#3-3-Operations-on-Processes" class="headerlink" title="3.3 Operations on Processes"></a>3.3 Operations on Processes</h3><h4 id="3-3-1-Process-Creation"><a href="#3-3-1-Process-Creation" class="headerlink" title="3.3.1 Process Creation"></a>3.3.1 Process Creation</h4><p><img src="./1552739460392.png" alt="Alt text"><br><img src="./1552739477121.png" alt="Alt text"></p>
<blockquote>
<p>pid＝fork()<br>执行这一句时，PC在下一句<br>fork()内会用一段嵌入式汇编进行系统调用<br>copy_process将父进程的内容复制给子进程，但是子进程tss中的eax值赋值为0（这也是为什么子进程中返回0的原因）<br>当赋值完成 后，copy_process会返回新进程（该子进程）的pid，这个值会被保存到eax中。这时子进程就产生了，此时子进程与父进程拥有相同的代码空 间，程序指针寄存器eip指向相同的下一条指令地址</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>Note:Automata Theory Languages,and Computation(形式语言与自动机)</title>
    <url>/2019/12/26/Note_Automata%20Theory%20Languages,and%20Computation(%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%9C%BA)/</url>
    <content><![CDATA[<h2 id="Chapter-1-Automata-The-methods-and-the-Madness"><a href="#Chapter-1-Automata-The-methods-and-the-Madness" class="headerlink" title="Chapter 1:Automata:The methods and the Madness"></a>Chapter 1:Automata:The methods and the Madness</h2><h3 id="1-1-Why-study-Automata-Theory"><a href="#1-1-Why-study-Automata-Theory" class="headerlink" title="1.1 Why study Automata Theory"></a>1.1 Why study Automata Theory</h3><p><img src="./1552139318458.png" alt="Alt text"><br>It’s conventional to designate <strong>accepting states</strong> by a double circle(haven’t show in pic above)<br><img src="./1552139472965.png" alt="Alt text"><br><strong>decidable:</strong>problems that can be solved by computer<br><strong>tractable(难解)</strong></p>
<h3 id="1-2-Introduction-to-Formal-Pr"><a href="#1-2-Introduction-to-Formal-Pr" class="headerlink" title="1.2 Introduction to Formal Pr"></a>1.2 Introduction to Formal Pr</h3><p>oof(形式证明)<br><strong>Formal Proof:</strong><br>Statements:<br>①<strong>If-Then</strong>:<br>A-&gt;B<br>②<strong>If-And-Only-If:</strong><br>A&lt;-&gt;B</p>
<h3 id="1-3-Additional-Form-of-Proof-其他形式的证明方法"><a href="#1-3-Additional-Form-of-Proof-其他形式的证明方法" class="headerlink" title="1.3 Additional Form of Proof(其他形式的证明方法)"></a>1.3 Additional Form of Proof(其他形式的证明方法)</h3><p>略</p>
<h3 id="1-4-Inductive-Proofs-归纳证明"><a href="#1-4-Inductive-Proofs-归纳证明" class="headerlink" title="1.4 Inductive Proofs(归纳证明)"></a>1.4 Inductive Proofs(归纳证明)</h3><p>略</p>
<h3 id="1-5-The-Central-Concepts-of-Automata-Theory-自动机的中心概念"><a href="#1-5-The-Central-Concepts-of-Automata-Theory-自动机的中心概念" class="headerlink" title="1.5 The Central Concepts of Automata Theory(自动机的中心概念)"></a>1.5 The Central Concepts of Automata Theory(自动机的中心概念)</h3><p>The most important concepts in automata:<br><strong>Alphabets</strong>、<strong>Strings</strong>、<strong>language</strong></p>
<h4 id="1-5-1-Alphabets"><a href="#1-5-1-Alphabets" class="headerlink" title="1.5.1 Alphabets"></a>1.5.1 Alphabets</h4><p>Which is a <strong>finite</strong> and <strong>not empty</strong> set of symbols<br>Usually  represented by $\sum$</p>
<h4 id="1-5-2-Strings"><a href="#1-5-2-Strings" class="headerlink" title="1.5.2 Strings"></a>1.5.2 Strings</h4><p>A <strong>finite</strong> sequence of symbols chosen from some <strong>alphabets</strong><br>$\sum^k$ is the set of strings of length <strong>k</strong><br>$\sum^*$=$\sum^+ \cup\{\epsilon\} $<br>$\sum^+$=$\sum^1 \cup \sum^2 \cup…$</p>
<h4 id="1-5-3-Langugaes"><a href="#1-5-3-Langugaes" class="headerlink" title="1.5.3 Langugaes"></a>1.5.3 Langugaes</h4><p><strong>Definition:</strong><br>A set of strings all of which are chosen from some $\sum^*$</p>
<center>
If $\sum$ is an alphabet,and **$L \subset\sum^*$**
then L is a langugae over $\sum$
</center>
some example:
**1.**n个0 n个1:
$\epsilon,01,0011,000111,...$
**2.**0,1数量相同的串
$\epsilon,01,10,0011,0101,1001,...$
**3.** $\sum^*$
**4.** 空语言$\emptyset$ ，which is langugae over all alphabets
**5.**$\{\epsilon\}$,which is also a language over all alphabets

####1.5.4 Problems
**Definition:**
A problem is the question of deciding whether a given string is a member of some particular language.
![Alt text](./1552144462663.png)
###1.6 Summary
**Finite Automata:** is a simple idealized machine used to recognize patterns within input taken from some character set,which contains states and transitions.

**Regular Expressions:**A structural notation for describing the same pattern that can be represented by finite automata.

**Context-Free Grammar(上下文无关文法):**is a certain type of formal grammar.a set of **production rules** that describe all possible strings in a given formal language

##Chapter2: Finite Automata(有限自动机)
**DFA**:Deterministic Finite Automata(确定有限自动机)
**NFA**:Nondeterministic Finite Automata(非确定有限自动机)
NFA是对每个状态和输入符号对可以有多个可能的下一个状态的有限状态自动机。
###2.1 An Informal Picture of Finite Automata
略
###2.2 Deterministic Finite Automata(确定有限自动机)
####2.2.1 Definition of a Deterministic Finite Automaton
We often talk about a DFA in **"five-tuple"** notation:
$$A=(Q,\sum,\delta,q_0,F)$$
**0.A:**the name of **DFA**
**1.Q:**a **finite** set of **states**
**2.**$\sum:$:a **finite** set of **input symbols**
**3.**$\delta$:a transtion function:$\delta(q,a)$
q:A state
a:An input
return:a state
**4.**$q_0:$A start state
**5.F**:A set of **final states**
####2.2.2 How a DFA Processes Strings
Suppose str1=a1a2a3...an
DFA in start state q0
state change throgh $\delta(q_i,a_k)=q_j$
if $q_j\in F$
then str1 can be accept
####2.2.3 Simper Notations for DFA's
**1.A transition diagram(转换图)**
![Alt text](./1552200412833.png)
**2.A transition table(转换表)**
![Alt text](./1552200443806.png)
####2.2.4 Extending the Transition Function to Strings
**extended transition function**
$\hat\delta(q,w)$
**q** is a state
**w** is a string
return a state **p**
w=xa
有$\delta(q,w)=\delta(\hat\delta(q,x),a)=\delta(p,a)$ 

####2.2.5 The Language of a DFA
$$L(A)=\{w|\hat\delta(q_0,w) \quad is \quad in\quad F\}$$
###2.3 Nondeterministic Finite Automata(NFA)
####2.3.1 An Informal View of Nondeterministic Finite Automata
The difference between DFA and NFA is $\delta$.
In NFA $\delta$ return more than one state
NFA has the power to be **in several states** at once
![Alt text](./1552214728358.png)
![Alt text](./1552214734467.png)
####2.3.2 Definition of Nondeterministic Finite Automata
$$A=(Q,\sum,\delta,q_0,F)$$
<center>the only defference is $\delta$</center>

<h4 id="2-3-3-The-Extended-Transition-Function"><a href="#2-3-3-The-Extended-Transition-Function" class="headerlink" title="2.3.3 The Extended Transition Function"></a>2.3.3 The Extended Transition Function</h4><script type="math/tex; mode=display">\hat\delta(q,x)=\{p_1,p_2,...,p_n\}</script><script type="math/tex; mode=display">\hat\delta(q,w)=\bigcup_{i=1}^k\delta(p_i,a)=\{r_1,r_2,...,r_m\}</script><p>每个状态再输入一个a后所得到的状态的集合</p>
<h4 id="2-3-4-The-Language-of-an-NFA"><a href="#2-3-4-The-Language-of-an-NFA" class="headerlink" title="2.3.4 The Language of an NFA"></a>2.3.4 The Language of an NFA</h4><script type="math/tex; mode=display">L(A)=\{w|\hat\delta(q_0,w)\cap F!=\phi\}</script><h4 id="2-3-5-Equivalence-of-Deterministic-Finite-Automata-and-Nondeterministic-Finite-Automata-DFA与NFA的转换"><a href="#2-3-5-Equivalence-of-Deterministic-Finite-Automata-and-Nondeterministic-Finite-Automata-DFA与NFA的转换" class="headerlink" title="2.3.5 Equivalence of Deterministic Finite Automata and Nondeterministic Finite Automata(DFA与NFA的转换)"></a>2.3.5 Equivalence of Deterministic Finite Automata and Nondeterministic Finite Automata(DFA与NFA的转换)</h4><p>NFA can change to DFA<br>worst situation:<br>DFA:$2^n states$ NFA:$n states$</p>
<p><center><strong>subset construction:</strong></p>
<script type="math/tex; mode=display">N=(Q_N,\sum,\delta_N,q_0,F_N)</script><p>to</p>
<script type="math/tex; mode=display">D=(Q_D,\sum,\delta_D,q_0,F_D)</script><p>And<br><strong>L(N)=L(D)</strong><br>$Q_D$ is the subset of <strong>power set(幂集)</strong> of $Q_N$<br>&lt;/center&gt;</p>
<script type="math/tex; mode=display">S\subseteq Q_N\\\delta_D(S,a)=\bigcup_{p \quad in \quad s}\delta_N(p,a)</script><p><img src="./1552218611174.png" alt="Alt text"><br>如图。<br>3个状态，于是8行(对应最多8个状态).输入符号相同（相应空中填对应NFA输入该符号后得到的状态）<br>包含q2的也就是接受节点<br><strong>定理1:任何语言L能被一些DFA接受，那么必然也能被一些NFA接受</strong></p>
<h4 id="2-3-6-A-Bad-Case-for-the-Subset-Constuction"><a href="#2-3-6-A-Bad-Case-for-the-Subset-Constuction" class="headerlink" title="2.3.6 A Bad Case for the Subset Constuction"></a>2.3.6 A Bad Case for the Subset Constuction</h4><p>In some example,DFA has $2^n$ states</p>
<h3 id="2-4-An-Application-Text-Search"><a href="#2-4-An-Application-Text-Search" class="headerlink" title="2.4 An Application:Text Search"></a>2.4 An Application:Text Search</h3><h4 id="2-4-1-Finding-Strings-in-Text-查找字符串"><a href="#2-4-1-Finding-Strings-in-Text-查找字符串" class="headerlink" title="2.4.1 Finding Strings in Text(查找字符串)"></a>2.4.1 Finding Strings in Text(查找字符串)</h4><p><strong>Inverted-Index</strong></p>
<h4 id="2-4-2-Nondeterministic-Finite-Automata-for-Text-Search"><a href="#2-4-2-Nondeterministic-Finite-Automata-for-Text-Search" class="headerlink" title="2.4.2 Nondeterministic Finite Automata for Text Search"></a>2.4.2 Nondeterministic Finite Automata for Text Search</h4><p><img src="./1552220574671.png" alt="Alt text"></p>
<h4 id="2-4-3-A-DFA-Recognize-a-Set-of-Keyword"><a href="#2-4-3-A-DFA-Recognize-a-Set-of-Keyword" class="headerlink" title="2.4.3 A DFA Recognize a Set of Keyword"></a>2.4.3 A DFA Recognize a Set of Keyword</h4><p>Convert NFA in 2.4.2 to DFA</p>
<h3 id="2-5-Finite-Automata-With-Epsilon-Transitions"><a href="#2-5-Finite-Automata-With-Epsilon-Transitions" class="headerlink" title="2.5 Finite Automata With Epsilon-Transitions"></a>2.5 Finite Automata With Epsilon-Transitions</h3><p>A new type of Finite Automata,which allow a transition on $\epsilon$,<strong>$\epsilon-NFA’s$</strong><br><img src="./1552221777907.png" alt="Alt text"></p>
<script type="math/tex; mode=display">E=(Q,\sum,\delta,q_0,F)</script><p>$\delta(q,a),a\in\sum\cup\epsilon$</p>
<h4 id="2-5-3-Epsilon-Closures-epsilon-闭包"><a href="#2-5-3-Epsilon-Closures-epsilon-闭包" class="headerlink" title="2.5.3 Epsilon-Closures($\epsilon$-闭包)"></a>2.5.3 Epsilon-Closures($\epsilon$-闭包)</h4><script type="math/tex; mode=display">ECLOSE(s)=\{从s状态出发，沿\epsilon\text{可以达到的所有状态集合}\}</script><p><img src="./1552222298487.png" alt="Alt text"><br><img src="./1552222301495.png" alt="Alt text"></p>
<h4 id="2-5-4-Extended-Transitions-and-Languages-for-epsilon-NFA’s"><a href="#2-5-4-Extended-Transitions-and-Languages-for-epsilon-NFA’s" class="headerlink" title="2.5.4 Extended Transitions and Languages for $\epsilon$-NFA’s"></a>2.5.4 Extended Transitions and Languages for $\epsilon$-NFA’s</h4><p>w=xa<br><img src="./1552222646927.png" alt="Alt text"> (前面的x字符串最终能到达的状态集合)<br><img src="./1552222615027.png" alt="Alt text">(w字符串最终能到达的状态集合)<br><img src="./1552222622106.png" alt="Alt text">(对状态全集求闭包)</p>
<h4 id="2-5-5-Eliminating-epsilon-Transitions-消除Epsilon-DFA"><a href="#2-5-5-Eliminating-epsilon-Transitions-消除Epsilon-DFA" class="headerlink" title="2.5.5 Eliminating $\epsilon$-Transitions(消除Epsilon DFA)"></a>2.5.5 Eliminating $\epsilon$-Transitions(消除Epsilon DFA)</h4><script type="math/tex; mode=display">E=(Q_E,\sum,\delta_E,q_0,F_E)</script><script type="math/tex; mode=display">D=(Q_D,\sum,\delta_D,q_D,F_D)</script><p>$q_D=ECLOSE(q_0)$<br><img src="./1552224042626.png" alt="Alt text"><br><img src="./1552224027189.png" alt="Alt text"><br>step1:先找起始状态集合。<br>step2:遍历各输入。如果碰到有Epsilon的，加上自动转换的节点</p>
<h2 id="Chapter-3-Regular-Expressions-and-Languages-正则表达式和语言"><a href="#Chapter-3-Regular-Expressions-and-Languages-正则表达式和语言" class="headerlink" title="Chapter 3 Regular Expressions and Languages(正则表达式和语言)"></a>Chapter 3 Regular Expressions and Languages(正则表达式和语言)</h2><p>is closely related to NFA</p>
<h3 id="3-1-Regular-Expressions"><a href="#3-1-Regular-Expressions" class="headerlink" title="3.1 Regular Expressions"></a>3.1 Regular Expressions</h3><h4 id="3-1-1-The-Operators-of-Regular-Expressions"><a href="#3-1-1-The-Operators-of-Regular-Expressions" class="headerlink" title="3.1.1 The Operators of Regular Expressions"></a>3.1.1 The Operators of Regular Expressions</h4><p>1.<strong>union(并集)of two languages L and M:</strong>$L\cup M$<br>2.<strong>concatenation(链接): L.M or LM:</strong><br><img src="./1552290506177.png" alt="Alt text"><br><img src="./1552290512227.png" alt="Alt text"><br>3.<strong>closure(闭包 or star\Kleene closure)</strong>:$L^<em>$:<br>$L^</em>$is infinite union<br><img src="./1552290725137.png" alt="Alt text"><br><img src="./1552290746301.png" alt="Alt text"><br>同离散数学$L^*=L^0+L^1+L^2+…$</p>
<p>$|L^n|=|L|^n$</p>
<h4 id="3-1-2-Building-Regular-Languages"><a href="#3-1-2-Building-Regular-Languages" class="headerlink" title="3.1.2 Building Regular Languages"></a>3.1.2 Building Regular Languages</h4><p><strong>E</strong> is a Regular expression<br><strong>L(E)</strong> is the language that E describe.</p>
<script type="math/tex; mode=display">L(E+F)=L(E)\cup L(F)\\
L(EF)=L(E)L(F)\\
L(E^*)=(L(E))^*</script><p><img src="./1552291891727.png" alt="Alt text"><br><img src="./1552291907002.png" alt="Alt text"></p>
<h4 id="3-1-3-Precedence-of-Regular-Expression-Operators-操作符优先级"><a href="#3-1-3-Precedence-of-Regular-Expression-Operators-操作符优先级" class="headerlink" title="3.1.3 Precedence of Regular-Expression Operators(操作符优先级)"></a>3.1.3 Precedence of Regular-Expression Operators(操作符优先级)</h4><p>1.星号*<br>2.链接符号或.<br>3.+</p>
<h3 id="3-2-Finite-Automata-and-Regular-Expressions"><a href="#3-2-Finite-Automata-and-Regular-Expressions" class="headerlink" title="3.2 Finite Automata and Regular Expressions"></a>3.2 Finite Automata and Regular Expressions</h3><p>1.Every language defined by NFA is also defined by a regular expression<br>2.Every regular expression can defined a automata<br><img src="./1552296013936.png" alt="Alt text"></p>
<h4 id="3-2-1-From-DFA’s-to-Regular-Expression-DFA转RE"><a href="#3-2-1-From-DFA’s-to-Regular-Expression-DFA转RE" class="headerlink" title="3.2.1 From DFA’s to Regular Expression(DFA转RE)"></a>3.2.1 From DFA’s to Regular Expression(DFA转RE)</h4><p><strong>If L=L(A),then there has L=L(R)</strong><br><img src="./1552297210892.png" alt="Alt text"><br><img src="./1552297219686.png" alt="Alt text"><br><img src="./1552297331229.png" alt="Alt text"></p>
<p><strong>算法思想实际上是求i-&gt;j所以可能路径</strong><br><strong>step1</strong>:列出0阶:$R_{ij}^{(0)}$<br><img src="./1552297261706.png" alt="Alt text"></p>
<p><strong>step2</strong>:根据公式列出1阶<br><img src="./1552297368988.png" alt="Alt text"><br><strong>算法思想实际上是求i-&gt;j所以可能路径，所以本例里只需要保留</strong>$R_{12}^{(2)}$</p>
<p><center>**算法思想**
![Alt text](./1552297747851.png)
![Alt text](./1552297978544.png)
![Alt text](./1552298007180.png)
**算法时间复杂度O(n^3)**
</center></p>
<h4 id="3-2-2-Converting-DFA’s-to-RE-by-Eliminating-States-消除法DFA转RE"><a href="#3-2-2-Converting-DFA’s-to-RE-by-Eliminating-States-消除法DFA转RE" class="headerlink" title="3.2.2 Converting DFA’s to RE by Eliminating States(消除法DFA转RE)"></a>3.2.2 Converting DFA’s to RE by Eliminating States(消除法DFA转RE)</h4><p><img src="./1552300001799.png" alt="Alt text"><br>删除s后<br><img src="./1552300014229.png" alt="Alt text"><br>一直删。直到转换成2状态DFA<br><img src="./1552300478431.png" alt="Alt text"><br>这种情况两种都讨论<br><img src="./1552300560958.png" alt="Alt text"></p>
<p><img src="./1552300492607.png" alt="Alt text"><br><img src="./1552300542290.png" alt="Alt text"></p>
<h4 id="3-2-3-Converting-Regular-Expressions-to-Automata"><a href="#3-2-3-Converting-Regular-Expressions-to-Automata" class="headerlink" title="3.2.3 Converting Regular Expressions to Automata"></a>3.2.3 Converting Regular Expressions to Automata</h4><p>基于3种结构，分部构造$\epsilon-NFA$<br><img src="./1552301049991.png" alt="Alt text"><br>例子:(0+1)<em>1(0+1)<br><strong>step1:</strong>处理(0+1)<br><img src="./1552301097901.png" alt="Alt text"><br><strong>step2:</strong>加上星号<br><img src="./1552301185206.png" alt="Alt text"><br><em>*step3:</em></em>加上顺序结构<br><img src="./1552301230685.png" alt="Alt text"></p>
<h3 id="3-3-Applications-of-Regular-Expression"><a href="#3-3-Applications-of-Regular-Expression" class="headerlink" title="3.3 Applications of Regular Expression"></a>3.3 Applications of Regular Expression</h3><p>RE的一些应用。仅作了解。这里略</p>
<h3 id="3-4-Algebraic-Laws-for-Regular-Expression"><a href="#3-4-Algebraic-Laws-for-Regular-Expression" class="headerlink" title="3.4 Algebraic Laws for Regular Expression"></a>3.4 Algebraic Laws for Regular Expression</h3><p>也就交运算的交换律，链接运算的结合律。没什么可说的<br>还有同一律和吸收律<br>分配率（链接对交分配）<br>等幂律L+L=L<br>重要性质:</p>
<script type="math/tex; mode=display">(L^*)^*=L^*\\\phi^*=\epsilon\\L^+=LL^*\\
L^*=\epsilon+L+L^2+...=L^++\epsilon.
\\L?=\epsilon+L
\\(L+M)*=(L^*M^*)^*</script><p>验证运算规则：<br>证E=F<br>把E=F用具体正则表达式C、D表示。测试L(C)=L(D)<br>比如证明<br>$L^<em>=L^</em>L^<em>$<br>证明L(a</em>)=L(a<em>a</em>)</p>
<h2 id="Chapter-4-Propweties-of-Regular-Languages"><a href="#Chapter-4-Propweties-of-Regular-Languages" class="headerlink" title="Chapter 4:Propweties of Regular Languages"></a>Chapter 4:Propweties of Regular Languages</h2><h3 id="4-1-Proving-Languages-Not-to-Be-Regular-证明一个语言不是正则的"><a href="#4-1-Proving-Languages-Not-to-Be-Regular-证明一个语言不是正则的" class="headerlink" title="4.1 Proving Languages Not to Be Regular(证明一个语言不是正则的)"></a>4.1 Proving Languages Not to Be Regular(证明一个语言不是正则的)</h3><h4 id="4-1-1-The-Pumping-Lemma-for-Regular-Languages-泵引理"><a href="#4-1-1-The-Pumping-Lemma-for-Regular-Languages-泵引理" class="headerlink" title="4.1.1 The Pumping Lemma for Regular Languages(泵引理)"></a>4.1.1 The Pumping Lemma for Regular Languages(泵引理)</h4><p>若 L 是正则语言，则存在一常数 n &gt; 0 (为DFA的状态数)，对于语言 L 中每个满足|w| ≥ n的字符串w，存在一组x,y,z使得，w=xyz且：<br>1.|xy| ≤ n ；<br>2.|y| ≥ 1；<br>3.对所有的 k ≥ 0 ，字串   属于 L 。(有k个重复)</p>
<h4 id="4-2-Closure-Properties-of-RE-闭包属性"><a href="#4-2-Closure-Properties-of-RE-闭包属性" class="headerlink" title="4.2 Closure Properties of RE(闭包属性)"></a>4.2 Closure Properties of RE(闭包属性)</h4><p>正则语言进行一些运算后，还是正则语言</p>
<hr>
<p>1.<strong>union</strong>:$L\cup M$<br>2.<strong>intersection</strong>:$L\cap M$<br>3.<strong>complement(补)</strong>:$\bar{L}=\sum^*-L$<br>同时，遵循德摩根定律</p>
<hr>
<hr>
<p>4.<strong>Reversal(转置)</strong></p>
<script type="math/tex; mode=display">w^R=a_na_{n-1}...a_1</script><p>5.<strong>Homomorphisms(同构)</strong></p>
<script type="math/tex; mode=display">h(L)=h(a_1)h(a_2)...h(a_n)$$也是正则语言

6.**Inverse Homomorphisms**
$h^{-1}(L)$

----
###4.3 Decision Properties of Regular Language
研究的问题
1.语言是否是空的
2.字符串w是否在L里
3.两个描述是否是同一个语言

####4.3.1 Converting Among Representations
状态机之间的转换
#####4.3.1.1 NFA->DFA
步骤:找起始状态集合
对集合所有状态输入元素得到一组新的状态集合的集合
再对每个集合遍历输入。重复。如果遇到epsilon,要加上自动转换的状态
复杂度O(n^3)
#####4.3.1.2 DFA->NFA
O(n)
就在状态转换表里加个集合括号
#####4.3.1.3 A->RE
$O(n^34^n)$
1.公式法
2.消除法，弄成双状态
#####4.3.1.4 RE->A
O(n)
利用3种结构（顺序、闭包、多路）画出来就行
####4.3.2 Testing Emptiness of Regular Languages
如果能访问到的状态只有开始状态，那么就是空的
####4.3.3 Testing Membership in a Regular Language
使用模拟输入
###4.4 Equivalence and Minimization of Automata(相等性以及自动机的简化)
####4.4.1 Testing Equivalence of States
1.状态的相等性：如果两个状态p和q.转移函数输入w,都够接受的w相同。说明p q相等
寻找相等状态
填表算法(**filling-table**)
![Alt text](./1552396721209.png)
![Alt text](./1552396746299.png)
x表示两个状态不相等
####4.4.2 Testing Equivalence of Language
也是运用填表算法。相同就相等

###4.4.3 Minimization of DFA's
1.删除不可达点
2.分区。分区内状态相等
其实就是求商集，求一个等价类的划分
3.修改状态转移。
如图4.8的简化
![Alt text](./1552397310605.png)
##Chapter 5 Context-Free Grammars and Languages(CFG:上下文无关文法和语言)
###5.1 Context-Free Grammars
####5.1.1 An Informal Example
####5.1.2 Definition of Context-Free Grammars
4个组成部分
**<1>terminals(终止符T,类似字母表$\sum$)**的有限集合
**<2>variable(变量V)**每个变量都代表一种语言。
**<3>start symbol(开始标志S)**:One of the variables represents the language being defined
**<4>production/rules(P,一组产生函数)**:->
<center>于是</center>
$$G=(V,T,P,S)</script><p>比如01回文字符串:<br><strong>A:</strong><br>$P-&gt;\epsilon\\P-&gt;0\\P-&gt;1\\P-&gt;0P0\\P-&gt;1P1$</p>
<p><strong>V={P}</strong><br><strong>S=P</strong><br><strong>T={0,1}</strong></p>
<p>如一个变量运算的语言:<br><strong>I为变量名,E为最终需要的语言</strong><br><img src="./1552449780704.png" alt="Alt text"><br><img src="./1552449792117.png" alt="Alt text"></p>
<h4 id="5-1-3-Derivations-Using-a-Grammar"><a href="#5-1-3-Derivations-Using-a-Grammar" class="headerlink" title="5.1.3 Derivations Using a Grammar"></a>5.1.3 Derivations Using a Grammar</h4><p><img src="./1552450535610.png" alt="Alt text"><img src="./1552450543559.png" alt="Alt text"><br><img src="./1552450552414.png" alt="Alt text"><br>也就是可以把整体化成具体运算。类似f=a+b  c+f=c+a+b</p>
<p>1.自底向上<br><img src="./1552450426796.png" alt="Alt text"><br>2.自顶向下<br><img src="./1552450454521.png" alt="Alt text"></p>
<h4 id="5-1-4-Leftmost-and-Rightmost-Derivations"><a href="#5-1-4-Leftmost-and-Rightmost-Derivations" class="headerlink" title="5.1.4 Leftmost and Rightmost Derivations"></a>5.1.4 Leftmost and Rightmost Derivations</h4><p>就是一个是从左向右分解，一个从右向左分解。符号分别为</p>
<script type="math/tex; mode=display">\Rightarrow_{lm}</script><p><img src="./1552452266679.png" alt="Alt text"></p>
<script type="math/tex; mode=display">\Rightarrow_{rm}</script><p><img src="./1552452285344.png" alt="Alt text"></p>
<h4 id="5-1-5-The-Language-of-a-Grammar"><a href="#5-1-5-The-Language-of-a-Grammar" class="headerlink" title="5.1.5 The Language of a Grammar"></a>5.1.5 The Language of a Grammar</h4><p><img src="./1552452470203.png" alt="Alt text"><br>所有由终止符产生的字符串集合且w能映射到S(开始符号)或者能由S分解成w</p>
<h4 id="5-1-6-Sentential-Forms"><a href="#5-1-6-Sentential-Forms" class="headerlink" title="5.1.6 Sentential Forms"></a>5.1.6 Sentential Forms</h4><p><strong>left-sentential form</strong>:<br>比如a<em>E是left-sentential因为<br><img src="./1552455240294.png" alt="Alt text"><br>$E</em>(E+E)$是right-sentential<br><img src="./1552455480977.png" alt="Alt text"></p>
<h3 id="5-2-Parse-Tree"><a href="#5-2-Parse-Tree" class="headerlink" title="5.2 Parse Tree"></a>5.2 Parse Tree</h3><h4 id="5-2-1-Constructing-Parse-Tree"><a href="#5-2-1-Constructing-Parse-Tree" class="headerlink" title="5.2.1 Constructing Parse Tree"></a>5.2.1 Constructing Parse Tree</h4><script type="math/tex; mode=display">G=(V,T,P,S)</script><p> 1.每个内部节点都是V中的成员<br> 2.叶子节点或者包含变量，或者包含终止符，或是是epsilon.而且必须是父节点的唯一后继<br> <img src="./1552456212864.png" alt="Alt text"><img src="./1552456220122.png" alt="Alt text"><br>E=I+E和0110</p>
<h4 id="5-2-2-The-Yield-of-a-Parse-Tree"><a href="#5-2-2-The-Yield-of-a-Parse-Tree" class="headerlink" title="5.2.2 The Yield of a Parse Tree"></a>5.2.2 The Yield of a Parse Tree</h4><p>从左到右遍历叶节点能够获得一个字符串，称为<strong>the yield of a parse tree</strong></p>
<h4 id="5-2-3-Inference-Derivations-and-Parse-Trees"><a href="#5-2-3-Inference-Derivations-and-Parse-Trees" class="headerlink" title="5.2.3 Inference,Derivations,and Parse Trees"></a>5.2.3 Inference,Derivations,and Parse Trees</h4><h3 id="5-3-Applications-of-Context-Free-Grammars"><a href="#5-3-Applications-of-Context-Free-Grammars" class="headerlink" title="5.3 Applications of Context-Free Grammars"></a>5.3 Applications of Context-Free Grammars</h3><h4 id="5-3-1-Parsers"><a href="#5-3-1-Parsers" class="headerlink" title="5.3.1 Parsers"></a>5.3.1 Parsers</h4><h3 id="5-4-Ambiguity-in-Grammars-and-Languages"><a href="#5-4-Ambiguity-in-Grammars-and-Languages" class="headerlink" title="5.4 Ambiguity in Grammars and Languages"></a>5.4 Ambiguity in Grammars and Languages</h3><h4 id="5-4-1-Ambiguous-Grammars"><a href="#5-4-1-Ambiguous-Grammars" class="headerlink" title="5.4.1 Ambiguous Grammars"></a>5.4.1 Ambiguous Grammars</h4><p>如<script type="math/tex">E=E+E|E*E</script><br>对于E+E*E可展开成</p>
<script type="math/tex; mode=display">E=>E+E=>E+E*E</script><p>或</p>
<script type="math/tex; mode=display">E=>E*E=>E+E*E</script><p>于是会产生歧义</p>
<h4 id="5-4-2-Removing-Ambiguity-From-Grammars"><a href="#5-4-2-Removing-Ambiguity-From-Grammars" class="headerlink" title="5.4.2 Removing Ambiguity From Grammars"></a>5.4.2 Removing Ambiguity From Grammars</h4><p><strong>factor:运算顺序不能被任何运算符打乱的</strong><br><strong>term:不能被+打乱的</strong>:比如a<em>b. 前或者后使用+和，顺序不变。。 c+(a</em>b),(a*b)+c</p>
<h4 id="5-4-3-Leftmost-Derivations-as-a-Way-to-Express-Ambiguity"><a href="#5-4-3-Leftmost-Derivations-as-a-Way-to-Express-Ambiguity" class="headerlink" title="5.4.3 Leftmost Derivations as a Way to Express Ambiguity"></a>5.4.3 Leftmost Derivations as a Way to Express Ambiguity</h4><p>定理：一个字符串w是模糊的,当且仅当，存在不同的leftmost derivations</p>
<h4 id="5-4-4-Inherent-Ambiguity"><a href="#5-4-4-Inherent-Ambiguity" class="headerlink" title="5.4.4 Inherent Ambiguity"></a>5.4.4 Inherent Ambiguity</h4><p>一个语言L被称为<strong>Inherently Ambiguious</strong>当他所有的语法都是ambiguious时</p>
<h2 id="chapter-6-Pushdown-Automata（PDA-下推自动机）"><a href="#chapter-6-Pushdown-Automata（PDA-下推自动机）" class="headerlink" title="chapter 6 Pushdown Automata（PDA:下推自动机）"></a>chapter 6 Pushdown Automata（PDA:下推自动机）</h2><p>A Automata that can define context-free automata<br>It’s a extension of $\epsilon-$NFA<br>It’s <strong>essentially an $\epsilon-$NFA+a stack</strong><br>2版本：<br>1.accepts by entering accepts state<br>2.accepts by emptying the stack</p>
<h3 id="6-1-Definition-of-the-Pushdown-Automata"><a href="#6-1-Definition-of-the-Pushdown-Automata" class="headerlink" title="6.1 Definition of the Pushdown Automata"></a>6.1 Definition of the Pushdown Automata</h3><h4 id="6-1-1-Informal-Introduction"><a href="#6-1-1-Informal-Introduction" class="headerlink" title="6.1.1 Informal Introduction"></a>6.1.1 Informal Introduction</h4><p>PDA can remember an infinite amount of information<br><strong>PDA recognize all and only context-free languages</strong></p>
<h4 id="6-1-2-The-Formal-Definition-of-Pushdown-Automata"><a href="#6-1-2-The-Formal-Definition-of-Pushdown-Automata" class="headerlink" title="6.1.2 The Formal Definition of Pushdown Automata"></a>6.1.2 The Formal Definition of Pushdown Automata</h4><script type="math/tex; mode=display">P=(Q,\sum,\Gamma,\delta,q_0,Z_0,F)</script><p><center><b>Q:有限状态集合
$\sum$:输入符号
$q_0:$开始状态
$F$:结束\接受状态
$\delta:$状态转换函数:$\delta(q,a,X):q是一个状态,a是一个输入或者空串,X是一个堆栈标志$
**！！！双返回值，一个二元组（状态，代替栈顶栈元素,若为$\epsilon$则pop）**
$\Gamma:$栈字母表，存储允许入栈的符号
$Z_0:开始符号:$初始时栈里一般包含一个标志，然后没有其他的了
</b>
$Z_0$标志栈底元素
</center><br>如回文串的<br><img src="./1552564524788.png" alt="Alt text"></p>
<h4 id="6-1-3-A-Graphical-Notation-for-PDA’s"><a href="#6-1-3-A-Graphical-Notation-for-PDA’s" class="headerlink" title="6.1.3 A Graphical Notation for PDA’s"></a>6.1.3 A Graphical Notation for PDA’s</h4><p><img src="./1552564660901.png" alt="Alt text"></p>
<h4 id="6-1-4-Instantaneous-Descriptions-of-a-PDA"><a href="#6-1-4-Instantaneous-Descriptions-of-a-PDA" class="headerlink" title="6.1.4 Instantaneous Descriptions of a PDA"></a>6.1.4 Instantaneous Descriptions of a PDA</h4><p>转换过程如图<br><img src="./1552565118851.png" alt="Alt text"></p>
<p><strong>定理1</strong><br>如果$\epsilon(q,a,X)$返回$(p,\alpha)$<br>则$(q,aw,X\beta)$与$(p,w,\alpha \beta)$相同<br>记<img src="./1552565365666.png" alt="Alt text"></p>
<p><strong>定理2</strong><br>如果<img src="./1552565510342.png" alt="Alt text"><br>那么<img src="./1552565516046.png" alt="Alt text"><br>(相当于把输入了一半。然后把q替换成得到的新状态，总字符串消去已经输入的alpha,还有w需要输入。堆栈的话也把X替换成得到的新的符号)</p>
<p>上面两个定理转换为人话就是:<br>如果对两个不同的状态，输入，堆栈内容 迁移函数得到结果相同。<br>那输入后面同时加上相同字符串$w$,堆栈替换内容同时在后面加相同符号，也相同</p>
<p>定理3<br>如果<br><img src="./1552565859807.png" alt="Alt text"><br>则<br><img src="./1552565866152.png" alt="Alt text"></p>
<p>也就是对两个不同状态，两个末尾字符串相同的不同字符串，不同堆栈状态迁移等效的话。<br>那么字符串去掉后面相同部分后也是等效的<br>(很好理解,相当于自动机从两个不同状态迁移一个中间状态下，再输入w后的迁移是等效的。那么显然不输入w时，仅从起始状态到达这个中间状态也是等效的)</p>
<h3 id="6-2-The-Languages-of-a-PDA"><a href="#6-2-The-Languages-of-a-PDA" class="headerlink" title="6.2 The Languages of a PDA"></a>6.2 The Languages of a PDA</h3><p>判断一个字符串可以被结束<br>1.能够到达接受状态<br>或者<br>2.能够清空栈</p>
<h4 id="6-2-1-Acceptance-by-Final-State"><a href="#6-2-1-Acceptance-by-Final-State" class="headerlink" title="6.2.1 Acceptance by Final State"></a>6.2.1 Acceptance by Final State</h4><p>如<img src="./1552566491973.png" alt="Alt text"></p>
<h4 id="6-2-2-Acceptance-by-Empty-Stack"><a href="#6-2-2-Acceptance-by-Empty-Stack" class="headerlink" title="6.2.2 Acceptance by Empty Stack"></a>6.2.2 Acceptance by Empty Stack</h4><p>定义<br><img src="./1552566541595.png" alt="Alt text"><br>也就是消费完字符串后能够清空栈<br>N(P)表示所有能让自动机P清空栈的字符串w的集合</p>
<h4 id="6-2-3-From-Empty-Stack-to-Final-State"><a href="#6-2-3-From-Empty-Stack-to-Final-State" class="headerlink" title="6.2.3 From Empty Stack to Final State"></a>6.2.3 From Empty Stack to Final State</h4><p>转换空栈类型PDA到最终状态型PDA<br>如<img src="./1552567019932.png" alt="Alt text">检测if-else不匹配的自动机。<br><img src="./1552567023472.png" alt="Alt text"><br>$注P_N$只有6元组，没有最终状态<br>转换方式<img src="./1552567335960.png" alt="Alt text"><br>开始时使用自动转换，把栈顶替换成ZX<br>然后<strong>中间是空栈类型PDA状态机模块</strong>。如果能够接受一个字符串的话相当于,中间这个模块能够把Z弹出(因为如6.5,这个空栈类型状态机就是初始是Z，然后栈空后结束)。<strong>于是经过中间模块如果能弹出Z。得到X。那么就向结束状态迁移</strong></p>
<p>如果栈顶是X_0的话就开始pop</p>
<h4 id="6-2-4-From-Final-State-to-Empty-Stack"><a href="#6-2-4-From-Final-State-to-Empty-Stack" class="headerlink" title="6.2.4 From Final State to Empty Stack"></a>6.2.4 From Final State to Empty Stack</h4><p>原理图<br><img src="./1552567785447.png" alt="Alt text"><br>也是分成3个模块。<br><strong>左边那个模块是自动转换</strong>，自动让栈顶变成ZX（同6.2.3)<br><strong>中间那个是终态类型PDA状态机模块</strong>，<strong>如果能到达终态的话</strong>，就出栈，并迁移到p(模块3)一直弹栈就行</p>
<h3 id="6-3-Equivalence-of-PDA’s-and-CFG’s-下推自动机和上下文无关文法的等价"><a href="#6-3-Equivalence-of-PDA’s-and-CFG’s-下推自动机和上下文无关文法的等价" class="headerlink" title="6.3 Equivalence of PDA’s and CFG’s (下推自动机和上下文无关文法的等价)"></a>6.3 Equivalence of PDA’s and CFG’s (下推自动机和上下文无关文法的等价)</h3><p><img src="./1552568829342.png" alt="Alt text"></p>
<h4 id="6-3-1-From-Grammars-to-Pushdown-Automata"><a href="#6-3-1-From-Grammars-to-Pushdown-Automata" class="headerlink" title="6.3.1 From Grammars to Pushdown Automata"></a>6.3.1 From Grammars to Pushdown Automata</h4><p>如<img src="./1552568952346.png" alt="Alt text"><br>转换成PDA<br>首先写出输入标志集合<img src="./1552568990062.png" alt="Alt text"><br>弄出迁移函数<br><img src="./1552569026463.png" alt="Alt text"><br>对于每项都构造一个空串到自身的转换函数。栈顶替换成相应的右侧元素<br>然后操作原子值。各格式$\delta(q,x,x)={(q,\delta)}$也就是到自身的弹栈</p>
<h4 id="6-3-2-From-PDA’s-to-Grammars"><a href="#6-3-2-From-PDA’s-to-Grammars" class="headerlink" title="6.3.2 From PDA’s to Grammars"></a>6.3.2 From PDA’s to Grammars</h4><p>如转换这个<img src="./1552570231381.png" alt="Alt text"><br><img src="./1552570323413.png" alt="Alt text"><br><img src="./1552570331330.png" alt="Alt text"><br><img src="./1552570342685.png" alt="Alt text"><br><img src="./1552570414623.png" alt="Alt text">(如果r\p也是状态的话。。一共n^2个可能)</p>
<p><img src="./1552570427188.png" alt="Alt text"><br>用简单的标识代换<img src="./1552570469782.png" alt="Alt text"><br><img src="./1552570479835.png" alt="Alt text"></p>
<p>于是<br><img src="./1552570498412.png" alt="Alt text"></p>
<p>方法:</p>
<blockquote>
<p>$Z$替换成$[qZq_i]$.q_i为任意一个状态</p>
<h3 id="6-4-Deterministic-Pushdown-Automata-确定的下推自动机-DPDA"><a href="#6-4-Deterministic-Pushdown-Automata-确定的下推自动机-DPDA" class="headerlink" title="6.4 Deterministic Pushdown Automata(确定的下推自动机:DPDA)"></a>6.4 Deterministic Pushdown Automata(确定的下推自动机:DPDA)</h3><p>如果迁移函数返回的pair只有一组，那么就是确定的</p>
<h4 id="6-4-2-RL-and-DPDA"><a href="#6-4-2-RL-and-DPDA" class="headerlink" title="6.4.2 RL and DPDA"></a>6.4.2 RL and DPDA</h4><p>如果L是正则语言，那么L=L(P)是某些DPDA<br>设∑为有穷字母表，∑<em>为其Kleene闭包（见作用代数）。那么称字符串集L∈∑</em>为正规语言，当且仅当满足下列条件之一：<br>L可以被一个确定有穷自动机识别；<br>L可以被一个非确定有穷自动机识别；<br>L可以用正则表达式表达；<br>L可以用正则文法生成；<br>L可以由前缀文法生成；</p>
</blockquote>
<h4 id="6-4-4-DPDA’s-and-Ambiguous-Grammars"><a href="#6-4-4-DPDA’s-and-Ambiguous-Grammars" class="headerlink" title="6.4.4 DPDA’s and Ambiguous Grammars"></a>6.4.4 DPDA’s and Ambiguous Grammars</h4><p>如果L=N(P)是某些DPDA<br>那么L拥有非模糊的文法</p>
<p>推论<br>如果L=N(P)是某些DPDA<br>那么L拥有非模糊的上下文无关文法(CFG)</p>
<h2 id="Chapter-7-Properties-of-CFL-Context-Free-Languages"><a href="#Chapter-7-Properties-of-CFL-Context-Free-Languages" class="headerlink" title="Chapter 7 Properties of CFL(Context-Free Languages)"></a>Chapter 7 Properties of CFL(Context-Free Languages)</h2><p>first task:simplify CFG(context-free grammars)</p>
<h3 id="7-1-Normal-Forms-for-CFG"><a href="#7-1-Normal-Forms-for-CFG" class="headerlink" title="7.1 Normal Forms for CFG"></a>7.1 Normal Forms for CFG</h3><p><strong>Chomsky Normal Form</strong><br>A-&gt;BC<br>A-&gt;a<br><strong>step1:</strong>eliminate <strong>useless symbols</strong><br><strong>step2</strong>:eliminate <strong>$\epsilon-productions$</strong><br><strong>step3</strong>:eliminate <strong>unit productions</strong></p>
<h4 id="7-1-1-Eliminating-Useless-Symbols"><a href="#7-1-1-Eliminating-Useless-Symbols" class="headerlink" title="7.1.1 Eliminating Useless Symbols"></a>7.1.1 Eliminating Useless Symbols</h4><p>一个标志X<br>是<br><strong>generating的</strong>如果能推导一个终止字符串w<br><strong>reachable的</strong>如果存在$\alpha$、$\beta$。S能推导出$\alpha X\beta$</p>
<p>例子:</p>
<p><center>$S\rightarrow AB | a\\A\rightarrow b$
B不是**generating**的，于是可以消除
要消除B的话。需要消掉S->AB
于是变成
$S\rightarrow  a\\A\rightarrow b$
然后。只有$S$和$a$是**reachable**的了
于是还可以继续删**unreachable**的
只剩**S->a**了
</center></p>
<h4 id="7-1-2-Computing-the-Generating-and-Reachable-Symbols"><a href="#7-1-2-Computing-the-Generating-and-Reachable-Symbols" class="headerlink" title="7.1.2 Computing the Generating and Reachable Symbols"></a>7.1.2 Computing the Generating and Reachable Symbols</h4><p>如何判断是不是<strong>generating</strong>的:<br>1.显然T中的元素都是<strong>generating</strong>的<br>2.A-&gt;$\alpha$.如果$alpha$中所有标志都是<strong>generating</strong>的，那么A也是</p>
<p>寻找<strong>reachable集合:</strong>从S出发遍历每个符号</p>
<h4 id="7-1-3-Eliminating-E-Productions"><a href="#7-1-3-Eliminating-E-Productions" class="headerlink" title="7.1.3 Eliminating E-Productions"></a>7.1.3 Eliminating E-Productions</h4><p><center>**step1:寻找nullable变量**:
1.产生式包含$epsilon$的是nullable变量
2.产生式包含nullable变量的是nullable变量
**step4:把每个nullable变量做替换(空和非空2种情况)**。注意S不能为空
例子:
$S\rightarrow AB\\A\rightarrow aAA|\epsilon\\B\rightarrow bBB|\epsilon$
首先A、B是nullable的，然后S包含AB，所以也是nullable的
于是先对S进行操作。每个nullable变量作2种代换
得到$S\rightarrow A|B|AB$
同样对$A\rightarrow aAA|\epsilon$操作得到$A\rightarrow aAA|aA|a$
B操作略
得到的新上下文无关语言$L(G_1)$记为$L(G_1)=L(G)-\{\epsilon\}$
</center></p>
<h4 id="7-1-4-Eliminating-Unit-Productions"><a href="#7-1-4-Eliminating-Unit-Productions" class="headerlink" title="7.1.4 Eliminating Unit Productions"></a>7.1.4 Eliminating Unit Productions</h4><p><strong>A unit production</strong> is production likes $A\rightarrow B$,both A and B are variable<br>消除unit production如<img src="./1552658630566.png" alt="Alt text"><br><img src="./1552658641348.png" alt="Alt text"><br>展开算法<br>从二元组（E,E）开始<br><img src="./1552658989874.png" alt="Alt text"><br>其实就是逆操作。吧A-&gt;B形式的全部展开<br>得到<img src="./1552659435755.png" alt="Alt text"></p>
<h4 id="7-1-5-Chomsky-Normal-Form-CNF"><a href="#7-1-5-Chomsky-Normal-Form-CNF" class="headerlink" title="7.1.5 Chomsky Normal Form(CNF)"></a>7.1.5 Chomsky Normal Form(CNF)</h4><p>A-&gt;BC<br>A-&gt;a<br>的格式</p>
<p><center><br><img src="./1552660387043.png" alt="Alt text"><br><strong>step1:</strong>找所有终止符,如果没有A-&gt;a这样的形式的话，单独拿一个变量名来生成他。比如<br>上面例子的终止符，需要全部拿新变量命名<br><img src="./1552660430073.png" alt="Alt text"><br><strong>step2:</strong>变量名代换<br><img src="./1552660484570.png" alt="Alt text"><br><strong>step3:</strong>代换。变成AB形式<br><img src="./1552660598184.png" alt="Alt text"></p>
<p><strong>Unit Pair(单位对)</strong><br>(A,A)是单位对（因为A是A的零步推导）<br>A-&gt;B<br>(A,B)也是单位对<br>&lt;/center&gt;</p>
<h3 id="7-2-The-Pumping-Lemma-for-CFL-Context-Free-Language"><a href="#7-2-The-Pumping-Lemma-for-CFL-Context-Free-Language" class="headerlink" title="7.2 The Pumping Lemma for CFL(Context-Free Language)"></a>7.2 The Pumping Lemma for CFL(Context-Free Language)</h3><p>正则语言的泵引理:</p>
<blockquote>
<p>若 L 是正规语言，则存在一常数 n &gt; 0 使得语言 L 中每个字串 w 的 |w| ≥ n，而当 w = xyz 时：<br>|xy| ≤ n ，<br>|y| ≥ 1 ，且<br>对所有的 k ≥ 0 ，字串 xy^kz 属于 L 。n为对于DFA状态数<br>证明:一个足够长的如果w属于正则语言L。那么存在一个状态数为n的DFA来识别他.|w|&gt;n  于是存在重复的状态.记为y^k.</p>
</blockquote>
<p>本章说的是上下文无关语言(CFL)的泵引理</p>
<h4 id="7-2-1-The-Size-of-Parse-Tree"><a href="#7-2-1-The-Size-of-Parse-Tree" class="headerlink" title="7.2.1 The Size of Parse Tree"></a>7.2.1 The Size of Parse Tree</h4><p>推出一个pumping lemma的第一步是观测语法树的形状和大小</p>
<script type="math/tex; mode=display">G=(V,T,P,S)</script><p><strong>定理1:如果G是CNF(Chomsky-Normal-From),有一个语法分析树,最长路径为n.生成terminal字符串w</strong>那么有$|w|\le 2^{n-1}$<br>….这。。显然就是n叉树的性质吧…Chomsky最多度2(A-&gt;BC).所以这里按二叉树的性质来。路径最长为n.相当于n层。</p>
<h4 id="7-2-2-Statement-of-the-Pumping-Lemma"><a href="#7-2-2-Statement-of-the-Pumping-Lemma" class="headerlink" title="7.2.2 Statement of the Pumping Lemma"></a>7.2.2 Statement of the Pumping Lemma</h4><p>类似正则语言的泵引理。不过分成5部分。然后Pump 2和4部分<br><strong>定理1:L是上下文无关语言（CFL），存在一个常数n（任意字符串z长度大于等于n）,有z=uvwxy</strong></p>
<p><center>有<br><strong>1.</strong>$|vwx|\le n$  (干掉开头 结尾)<br><strong>2.</strong>$vx\ne \phi$ (2、4不都为空.pump掉的字符串至少一个不为空)<br><strong>3.</strong>对于所有$i\ge 0$,$uv^iwx^iy\in L$.也就是pump掉的字符串重复几次都没关系，都还是同一种语言</p>
<p>&lt;/center&gt;<br>步骤:<br>1.选择一个n(并不确定，考虑所有可能的n)<br>2.选择z.|z|&gt;n<br>3.把z分解成uvwxy，只有|vwy|小于n.vx至少一个不为空即可<br>4.如果能够选择i.使v x重复i次还是不属于L。那么就证了不是上下文无关语言</p>
<h4 id="7-2-3-Applications-of-the-Pumping-Lemma-for-CFL’s"><a href="#7-2-3-Applications-of-the-Pumping-Lemma-for-CFL’s" class="headerlink" title="7.2.3 Applications of the Pumping Lemma for CFL’s"></a>7.2.3 Applications of the Pumping Lemma for CFL’s</h4><p>略</p>
<h3 id="7-3-Closure-Properties-of-CFL"><a href="#7-3-Closure-Properties-of-CFL" class="headerlink" title="7.3 Closure Properties of CFL"></a>7.3 Closure Properties of CFL</h3><h4 id="7-3-1-Substitutions"><a href="#7-3-1-Substitutions" class="headerlink" title="7.3.1 Substitutions"></a>7.3.1 Substitutions</h4><script type="math/tex; mode=display">w=a_1a_2...a_n\\s(w)=s(a_1)s(a_2)...s(a_n)</script><p>比如定义$s(0)=\{a^nb^n|n\ge 1\}$<br>$s(1)={aa,bb}$<br>那么$s(01)=s(0)s(1)={a^nb^naa 或  a^nb^{n+2}}$<br><strong>定理:L是CFL，s是一个$\sum$上的substitution,那么s(L)也是CFL</strong></p>
<h4 id="7-3-2-Applications-of-the-Substitution-Theorem"><a href="#7-3-2-Applications-of-the-Substitution-Theorem" class="headerlink" title="7.3.2 Applications of the Substitution Theorem"></a>7.3.2 Applications of the Substitution Theorem</h4><p><center>**CFL对下列运算封闭!!!**
<b>并集+
连接运算
闭包运算*,还有闭包+
同构运算(加个函数)
</b>
</center></p>
<h4 id="7-3-3-Reversal-转置"><a href="#7-3-3-Reversal-转置" class="headerlink" title="7.3.3 Reversal(转置)"></a>7.3.3 Reversal(转置)</h4><p><strong>上下文无关语言L,反转后$L^R$也是CFL</strong></p>
<h4 id="7-3-4-Intersection-With-a-Regular-Language-和正则语言的交"><a href="#7-3-4-Intersection-With-a-Regular-Language-和正则语言的交" class="headerlink" title="7.3.4 Intersection With a Regular Language(和正则语言的交)"></a>7.3.4 Intersection With a Regular Language(和正则语言的交)</h4><p><strong>上下文无关语言（CFL）L与正则语言（RE） R的交仍是CFL</strong>(…因为RE也是CFL)</p>
<script type="math/tex; mode=display">L\cap R为CFL</script><h4 id="7-3-5-Inverse-Homomorphism"><a href="#7-3-5-Inverse-Homomorphism" class="headerlink" title="7.3.5 Inverse Homomorphism"></a>7.3.5 Inverse Homomorphism</h4><p><strong>如果L是CFL，h是一个homomorphism,那么$h^{-1}(L)$也是CFL</strong></p>
<h3 id="7-4-Decision-Properties-of-CLF’s"><a href="#7-4-Decision-Properties-of-CLF’s" class="headerlink" title="7.4 Decision Properties of CLF’s"></a>7.4 Decision Properties of CLF’s</h3><h4 id="7-4-1-Complexity-of-Converting-Among-CFG’s-and-PDA’s-上下文无关文法和下推自动机转换的复杂度"><a href="#7-4-1-Complexity-of-Converting-Among-CFG’s-and-PDA’s-上下文无关文法和下推自动机转换的复杂度" class="headerlink" title="7.4.1 Complexity of Converting Among CFG’s and PDA’s(上下文无关文法和下推自动机转换的复杂度)"></a>7.4.1 Complexity of Converting Among CFG’s and PDA’s(上下文无关文法和下推自动机转换的复杂度)</h4><p>O(n^3)</p>
<h4 id="7-4-2-Running-Time-of-Conversion-to-Chomsky-Normal-Form"><a href="#7-4-2-Running-Time-of-Conversion-to-Chomsky-Normal-Form" class="headerlink" title="7.4.2 Running Time of Conversion to Chomsky Normal Form"></a>7.4.2 Running Time of Conversion to Chomsky Normal Form</h4><p>1.发现reachable\generating 标志需要O(n)<br>2.构造pair和消除unit production需要O(n^2)<br>3.代替标志需要O（n）</p>
<p>于是需要O(n^2)</p>
<h4 id="7-4-3-Testing-Emptiness-of-CFL’s"><a href="#7-4-3-Testing-Emptiness-of-CFL’s" class="headerlink" title="7.4.3 Testing Emptiness of CFL’s"></a>7.4.3 Testing Emptiness of CFL’s</h4><p>L is empty <strong>if and only if S is not generating</strong></p>
<h4 id="7-4-4-Testing-Membership-in-a-CFL"><a href="#7-4-4-Testing-Membership-in-a-CFL" class="headerlink" title="**7.4.4 Testing Membership in a CFL"></a>**7.4.4 Testing Membership in a CFL</h4><p>O(n^3)<br>1.通过w构造一个表<img src="./1553078934636.png" alt="Alt text"><br>表项$X_{ij}$是由A=&gt;$a_ia_{i+1}…a_j$的变元A的集合<br>关心的是S是否属于$X_{1n}$,是的话就说明w属于L</p>
<p>构造:从下到上。每个项需要O(n)<br>计算方法：<br>对于$X_{ij}$,已经知道所有比$a_i….a_j$短的串和他们的真前缀、后缀<br>1.肯定是由A-&gt;BC形式推导出来的，B推导$a_i…a_k$,C推导$a_{k+1}…a_j$<br><img src="./1553079506496.png" alt="Alt text"></p>
<h2 id="Chapter-8-Introdution-to-Tuling-Machines"><a href="#Chapter-8-Introdution-to-Tuling-Machines" class="headerlink" title="Chapter 8 Introdution to Tuling Machines"></a>Chapter 8 Introdution to Tuling Machines</h2><h3 id="8-1-Problems-That-Computer-Cannot-Solve"><a href="#8-1-Problems-That-Computer-Cannot-Solve" class="headerlink" title="8.1 Problems That Computer Cannot Solve"></a>8.1 Problems That Computer Cannot Solve</h3><h4 id="8-1-2-The-Hypothetical-“Hello-World”"><a href="#8-1-2-The-Hypothetical-“Hello-World”" class="headerlink" title="8.1.2 The Hypothetical “Hello,World”"></a>8.1.2 The Hypothetical “Hello,World”</h4><p><img src="./1552740160353.png" alt="Alt text"><br>P:program<br>I:Input<br>H是一个程序判断程序P和输入I是否能输出hello world</p>
<p>如果<img src="./1552740703075.png" alt="Alt text">会怎样?<br>H_2作为自己的输入。如果输出yes的话，表明能输出hello world,但是输出了yes.如果输出了hello,world的话，又应该输出yes..</p>
<h4 id="8-1-3-Reducing-One-Problem-to-Another"><a href="#8-1-3-Reducing-One-Problem-to-Another" class="headerlink" title="8.1.3 Reducing One Problem to Another"></a>8.1.3 Reducing One Problem to Another</h4><p>A problem that cannot be solved by computer is called <strong>undecidable.</strong><br><img src="./1552741038378.png" alt="Alt text"><br>难题转换<br>从P1构造P2，再解决P2</p>
<h3 id="8-2-The-Turing-Machine"><a href="#8-2-The-Turing-Machine" class="headerlink" title="8.2 The Turing Machine"></a>8.2 The Turing Machine</h3><p><strong>Essentially a finite automaton that has a single tape of infinite length on which it may read and write data</strong><br>(本质是一个有限自动机，有一条无限长的带子，可以在上面读写数据)</p>
<h4 id="8-2-1-The-Quest-探索-to-Decide-All-Mathematical-Questions"><a href="#8-2-1-The-Quest-探索-to-Decide-All-Mathematical-Questions" class="headerlink" title="8.2.1 The Quest(探索) to Decide All Mathematical Questions"></a>8.2.1 The Quest(探索) to Decide All Mathematical Questions</h4><h4 id="8-2-2-Notation-for-the-Turing-Machine"><a href="#8-2-2-Notation-for-the-Turing-Machine" class="headerlink" title="8.2.2 Notation for the Turing Machine"></a>8.2.2 Notation for the Turing Machine</h4><p><img src="./1552741876775.png" alt="Alt text"><br>The machine consists of a finite control, which can be in any of a finite set of states<br>initially hold a special symbol called the <strong>blank.</strong> The <strong>blank</strong> is a tape symbol, but not an input symbol</p>
<script type="math/tex; mode=display">M=(Q,\sum,\Gamma,\delta,q_0,B,F)</script><p><strong>Q:</strong>有限控制的状态集合<br><strong>$\sum$</strong>:输入标志集合<br><strong>$\Gamma$</strong>:纸带上标志的完全集合，一般$\sum$是其子集<br><strong>$\delta$</strong>转换函数,输入(q,X),q是当前状态，X是tape标志<br>返回(p,Y,D) p是新状态，Y是cell字符(在gamma里)，表示在当前扫描单元里写入的数据,D是方向（左或右）<br><strong>q0:</strong>起始状态(finite control的)<br><strong>B:</strong>blank标志。属于gamma不属于sum<br><strong>F:</strong>接受状态</p>
<h4 id="8-2-3-Instantaneous-Descriptions-for-Turing-Machines"><a href="#8-2-3-Instantaneous-Descriptions-for-Turing-Machines" class="headerlink" title="8.2.3 Instantaneous Descriptions for Turing Machines"></a>8.2.3 Instantaneous Descriptions for Turing Machines</h4><p>3种不同情况<br><img src="./1552743418690.png" alt="Alt text"><br><img src="./1552743686447.png" alt="Alt text"><br>原位置右边被替换成Y,然后移动<br>(原位置右边，相当于当前Finite control指向)</p>
<h4 id="8-2-4-Transition-Diagrams-for-Turing-Machines"><a href="#8-2-4-Transition-Diagrams-for-Turing-Machines" class="headerlink" title="8.2.4 Transition Diagrams for Turing Machines"></a>8.2.4 Transition Diagrams for Turing Machines</h4><p><img src="./1552744400560.png" alt="Alt text"><br>左边是当前值/新值 方向</p>
<h4 id="8-2-5-The-Language-of-a-Turing-Machine"><a href="#8-2-5-The-Language-of-a-Turing-Machine" class="headerlink" title="8.2.5 The Language of a Turing Machine"></a>8.2.5 The Language of a Turing Machine</h4><p>L(M)<br>Turing machine is often called <strong>the recursively enumerable Languages</strong> or <strong>RE languages</strong></p>
<h4 id="8-2-6-Turing-Machines-and-Halting-图灵机和停机"><a href="#8-2-6-Turing-Machines-and-Halting-图灵机和停机" class="headerlink" title="8.2.6 Turing Machines and Halting(图灵机和停机)"></a>8.2.6 Turing Machines and Halting(图灵机和停机)</h4><p>图灵机无路可走的情况,函数对于某个输入没有定义。无法转移<br>一般假设图灵机在接受状态下总是停机的<br><strong>无论是否接受，都能停机的图灵机成为可递归的(recursive)</strong></p>
<h3 id="8-3-Programming-Techniques-for-Turing-Machines"><a href="#8-3-Programming-Techniques-for-Turing-Machines" class="headerlink" title="8.3 Programming Techniques for Turing Machines"></a>8.3 Programming Techniques for Turing Machines</h3><h4 id="8-3-1-Storage-in-the-State-存储于状态"><a href="#8-3-1-Storage-in-the-State-存储于状态" class="headerlink" title="8.3.1 Storage in the State(存储于状态)"></a>8.3.1 Storage in the State(存储于状态)</h4><p><img src="./1552745294423.png" alt="Alt text"> (下面是多道，上面是存储于状态)<br>可以在finite control里面加上有限的数据储存<br>于是state变成[q,A,B,C],不再只是q (变成了多元组)<br>比如定义<img src="./1552745428616.png" alt="Alt text"><br>state $Q$变成<img src="./1552745453305.png" alt="Alt text">。q状态集合和gamma的乘积</p>
<h4 id="8-3-2-Multiple-Tracks-多道"><a href="#8-3-2-Multiple-Tracks-多道" class="headerlink" title="8.3.2 Multiple Tracks(多道)"></a>8.3.2 Multiple Tracks(多道)</h4><p>相当于多条纸带。。和8.13的图差不多<br>input 标志变成[B,0] [B,1]之类的<br>如8.13,扫描头指向的是[X,Y,Z]3元组，而不止是X</p>
<h4 id="8-3-3-Subroutines-子程序"><a href="#8-3-3-Subroutines-子程序" class="headerlink" title="8.3.3 Subroutines(子程序)"></a>8.3.3 Subroutines(子程序)</h4><blockquote>
<p>A Turing-machine subroutine is <strong>a set of states</strong> that perform some useful process<br>包含初始状态和返回状态</p>
</blockquote>
<p>如一个乘法程序。输入$0^n10^m1$在末尾输出$0^{mn}$<br>算法是每次n-1,在末尾输出一个m个0<br>copy是实现这有一步的子程序（把$0^{m-k}1q_10^n10^{(k-1)n}$变成$0^{m-k}1q_10^n10^{kn}$)<br><img src="./1553081888826.png" alt="Alt text"><br>q1是开始,选择一个0用X标记<br>q2是不停右移，找到一个B(也就是移到末尾),换成0<br>q3是一直左移，直到找到X<br>q4是恢复X为0<br>q5结束</p>
<p>完整图<br><img src="./1553082417863.png" alt="Alt text"></p>
<h3 id="8-4-Extension-to-the-Basic-Turing-Machine"><a href="#8-4-Extension-to-the-Basic-Turing-Machine" class="headerlink" title="8.4 Extension to the Basic Turing Machine"></a>8.4 Extension to the Basic Turing Machine</h3><h4 id="8-4-1-Multitape-Turing-Machines-多带图灵机"><a href="#8-4-1-Multitape-Turing-Machines-多带图灵机" class="headerlink" title="8.4.1 Multitape Turing Machines(多带图灵机)"></a>8.4.1 Multitape Turing Machines(多带图灵机)</h4><h4 id="8-4-2-Equivalence-of-One-Tape-and-Multitape-TM’s"><a href="#8-4-2-Equivalence-of-One-Tape-and-Multitape-TM’s" class="headerlink" title="8.4.2 Equivalence of One-Tape and Multitape TM’s"></a>8.4.2 Equivalence of One-Tape and Multitape TM’s</h4><p>Because the language that Single-tape Turing Machines can acccept is recursive  enumerable language,so the language that Multitape Turing Machines can accept are also recursive enumerable</p>
<h4 id="8-4-3-Running-Time-and-the-Many-Tapes-to-One-Construction"><a href="#8-4-3-Running-Time-and-the-Many-Tapes-to-One-Construction" class="headerlink" title="8.4.3 Running Time and the Many-Tapes-to-One Construction"></a>8.4.3 Running Time and the Many-Tapes-to-One Construction</h4><h4 id="8-4-4-Nondeterministic-Turing-Machines-NTM-非确定型图灵机"><a href="#8-4-4-Nondeterministic-Turing-Machines-NTM-非确定型图灵机" class="headerlink" title="8.4.4 Nondeterministic Turing Machines(NTM,非确定型图灵机)"></a>8.4.4 Nondeterministic Turing Machines(NTM,非确定型图灵机)</h4><p>也就是迁移函数返回多个三元组<br><strong>定理</strong><br>若$M_N$是非确定型图灵机，那么存在确定型图灵机$M_D,L(M_N)=L(M_D)$</p>
<h3 id="8-5-Restricted-Turing-Machines-受限图灵机"><a href="#8-5-Restricted-Turing-Machines-受限图灵机" class="headerlink" title="8.5 Restricted Turing Machines(受限图灵机)"></a>8.5 Restricted Turing Machines(受限图灵机)</h3><h4 id="8-5-1-Turing-Machines-With-Semi-infinite-Tapes-半无穷带"><a href="#8-5-1-Turing-Machines-With-Semi-infinite-Tapes-半无穷带" class="headerlink" title="8.5.1 Turing Machines With Semi-infinite Tapes (半无穷带)"></a>8.5.1 Turing Machines With Semi-infinite Tapes (半无穷带)</h4><h4 id="8-5-2-Multistack-Machines-多栈图灵机"><a href="#8-5-2-Multistack-Machines-多栈图灵机" class="headerlink" title="8.5.2 Multistack Machines(多栈图灵机)"></a>8.5.2 Multistack Machines(多栈图灵机)</h4><p><img src="./1552746706164.png" alt="Alt text"><br>双堆栈PDA能接受图灵机能接受的语言</p>
<h4 id="8-5-3-Counter-Machines-计数器机器"><a href="#8-5-3-Counter-Machines-计数器机器" class="headerlink" title="8.5.3 Counter Machines(计数器机器)"></a>8.5.3 Counter Machines(计数器机器)</h4><p>其是受限的多堆栈机器。<br>栈底是Z_0<br>其他符号都是X<br>单计数器（实质是PDA）所以能接受CFL<br>多计数器实质是多栈图灵机，可以recursive enumerable语言</p>
<h4 id="8-5-4-The-Power-of-Counter-Machines"><a href="#8-5-4-The-Power-of-Counter-Machines" class="headerlink" title="8.5.4 The Power of Counter Machines"></a>8.5.4 The Power of Counter Machines</h4><h3 id="8-6-Turing-Machines-and-Computer"><a href="#8-6-Turing-Machines-and-Computer" class="headerlink" title="8.6 Turing Machines and Computer"></a>8.6 Turing Machines and Computer</h3><h4 id="8-6-1-Simulating-a-Turing-Machines-by-Computer"><a href="#8-6-1-Simulating-a-Turing-Machines-by-Computer" class="headerlink" title="8.6.1 Simulating a Turing Machines by Computer"></a>8.6.1 Simulating a Turing Machines by Computer</h4><h4 id="8-6-2-Simulating-a-Computer-by-a-Turing-Machines"><a href="#8-6-2-Simulating-a-Computer-by-a-Turing-Machines" class="headerlink" title="8.6.2 Simulating a Computer by a Turing Machines"></a>8.6.2 Simulating a Computer by a Turing Machines</h4><h2 id="Chapter-9-Undecidability"><a href="#Chapter-9-Undecidability" class="headerlink" title="Chapter 9 Undecidability"></a>Chapter 9 Undecidability</h2><h3 id="9-1-A-Language-That-Is-Not-Recursively-Enumerable"><a href="#9-1-A-Language-That-Is-Not-Recursively-Enumerable" class="headerlink" title="9.1 A Language That Is Not Recursively Enumerable"></a>9.1 A Language That Is Not Recursively Enumerable</h3><h4 id="9-1-1-Enumerating-the-Binary-Strings-枚举二进制串"><a href="#9-1-1-Enumerating-the-Binary-Strings-枚举二进制串" class="headerlink" title="9.1.1 Enumerating the Binary Strings(枚举二进制串)"></a>9.1.1 Enumerating the Binary Strings(枚举二进制串)</h4><p>把字符串用二进制数代替<br>空串:1st<br>0:2 nd<br>1:3 rd<br>00: 4th<br>01: 5th<br>……<br>其实就是$1\omega$代表的整数$i$</p>
<h4 id="9-1-2-Codes-for-Turing-Machines"><a href="#9-1-2-Codes-for-Turing-Machines" class="headerlink" title="9.1.2 Codes for Turing Machines"></a>9.1.2 Codes for Turing Machines</h4><p>图灵机编码<br>例子<br><img src="./1552795934386.png" alt="Alt text"><br><img src="./1552795939351.png" alt="Alt text"><br>把更改转换函数,$R$用$D_2$代替,$L$用$D_1$代替。0用$X_1$,1用$X_2$,B的话用X3<br>然后每行改成写成$0^n10^i10^j10^k10^l$分布代表5个下标<br>比如第一行<br>转换后<br>$\delta(q_1,1)=(q_3,0,R) 变为[0][100][1000][10][100]$<br>$\delta(q_3,0)=(q_1,1,R)变为[000][10][10][100][100]$<br>$\delta(q_3,1)=(q_2,0,R)变为[000][100][100][10][100]$<br>$\delta(q_3,B)=(q_3,1,L)变为[000][1000][1000][100][10]$<br>然后把4行连起来，中间用11连接<br>$M=[0][100][1000][10][100]11[000][10][10][100][100]11[000][100][100][10][100]11[000][1000][1000][100][10]$<br>去掉中括号</p>
<h4 id="9-1-3-The-Diagonalization-Language-对角化语言"><a href="#9-1-3-The-Diagonalization-Language-对角化语言" class="headerlink" title="9.1.3 The Diagonalization Language(对角化语言)"></a>9.1.3 The Diagonalization Language(对角化语言)</h4><p>M可以被编码成$\omega_i$<br>从$\omega_i$恢复成图灵机的话,如果不是合法编码，那只有一个状态，没有任何转换<br><strong>定义:</strong><br><strong>The Diagonalization Language $L_d$</strong> is the set that include all string s not in $L(M_i)$.也就是所有不能被图灵机识别的字符串</p>
<p><strong>对角线说明M_i是否接受w_i</strong></p>
<p><img src="./1552797135088.png" alt="Alt text"><br>this table show that if $M_i$ can accept $\omega_j$<br>i th row can be seen as the <strong>characteristic vector(特征向量)</strong> of $M_i$<br>对应行的特征向量取反，就是$L_d$了</p>
<h4 id="9-1-4-Proof-That-L-d-Is-Not-Recursively-Enumerable"><a href="#9-1-4-Proof-That-L-d-Is-Not-Recursively-Enumerable" class="headerlink" title="9.1.4 Proof That $L_d$ Is Not Recursively Enumerable"></a>9.1.4 Proof That $L_d$ Is Not Recursively Enumerable</h4><p>略</p>
<h3 id="9-2-An-Undecidable-Problem-That-Is-RE"><a href="#9-2-An-Undecidable-Problem-That-Is-RE" class="headerlink" title="9.2 An Undecidable Problem That Is RE"></a>9.2 An Undecidable Problem That Is RE</h3><p>现在已经得到了$L_d$(不能被图灵机接受)<br>下一个目标提炼RE语言的结构<br>RE语言可以分成两类<br>一类是不管怎样都能自动停机的<br>一类是不当的输入下可能一直运行的</p>
<h4 id="9-2-1-Recursive-Languages"><a href="#9-2-1-Recursive-Languages" class="headerlink" title="9.2.1 Recursive Languages"></a>9.2.1 Recursive Languages</h4><p>只要L=L(M)对某些图灵机成立而且对于一个输入w，如果w是在L中的话最终会停机且在accept态,w不在L中最终也能停机，即使不在终态。那么就是recursive的<br><strong>halt(停机)</strong><br><img src="./1552798270354.png" alt="Alt text"><br>可以看到R是RE的子集</p>
<h4 id="9-2-2-Complements-of-Recursive-and-RE-languages"><a href="#9-2-2-Complements-of-Recursive-and-RE-languages" class="headerlink" title="9.2.2 Complements of Recursive and RE languages"></a>9.2.2 Complements of Recursive and RE languages</h4><p>如果L是recursive语言，$\bar L$也是<br><img src="./1552798670402.png" alt="Alt text"><br>如果L和L的补都是RE的，那么L是R的<br><img src="./1552798679821.png" alt="Alt text"></p>
<h4 id="9-2-3-The-Universal-Language"><a href="#9-2-3-The-Universal-Language" class="headerlink" title="9.2.3 The Universal Language"></a>9.2.3 The Universal Language</h4><p>$L_u$是一个集合，包含所有能表示成图灵机M的字符串M,且能被接受的字符串。。(M,w)<br><img src="./1552799436528.png" alt="Alt text"></p>
<h4 id="9-2-4-Undecidability-of-the-Universal-Language"><a href="#9-2-4-Undecidability-of-the-Universal-Language" class="headerlink" title="9.2.4 Undecidability of the Universal Language"></a>9.2.4 Undecidability of the Universal Language</h4><p>$L_u$是<strong>RE但是不是R</strong><br>R=可判断</p>
<h3 id="9-3-Undecidable-Problems-About-Turing-Machines"><a href="#9-3-Undecidable-Problems-About-Turing-Machines" class="headerlink" title="9.3 Undecidable Problems About Turing Machines"></a>9.3 Undecidable Problems About Turing Machines</h3><h4 id="9-3-1-Reduction"><a href="#9-3-1-Reduction" class="headerlink" title="9.3.1 Reduction"></a>9.3.1 Reduction</h4><p><img src="./1552799668287.png" alt="Alt text"><br><img src="./1552799698807.png" alt="Alt text"></p>
<h4 id="9-3-2-Turing-Machines-That-Accept-the-Empty-Language"><a href="#9-3-2-Turing-Machines-That-Accept-the-Empty-Language" class="headerlink" title="9.3.2 Turing Machines That Accept the Empty Language"></a>9.3.2 Turing Machines That Accept the Empty Language</h4><p><img src="./1552799777325.png" alt="Alt text"><br>$L_e$是非RE的<br>$L_{ne}$是RE非R的<br>是RE：<br><img src="./1552799955926.png" alt="Alt text"><br>不是R<br><img src="./1552799990989.png" alt="Alt text"></p>
<h3 id="9-4-Post’s-Correspondence-Problem"><a href="#9-4-Post’s-Correspondence-Problem" class="headerlink" title="9.4 Post’s Correspondence Problem"></a>9.4 Post’s Correspondence Problem</h3><p><img src="./1553084651499.png" alt="Alt text"><br>该问题是非R的（不可判定的)<br><img src="./1553084852872.png" alt="Alt text"></p>
<h2 id="Chapter-10-Intractable-Problems"><a href="#Chapter-10-Intractable-Problems" class="headerlink" title="Chapter 10 Intractable Problems"></a>Chapter 10 Intractable Problems</h2><h3 id="10-1-P和NP"><a href="#10-1-P和NP" class="headerlink" title="10.1 P和NP"></a>10.1 P和NP</h3><p>P:确定多项式<br>NP:非确定多项式</p>
<p>P是NP的子集<br>P是能在多项式时间内解决的问题<br>NP是能在多项式时间内验证一个正确解的问题</p>
<h4 id="10-1-1-Problems-Solvable-in-Polynomial-Time"><a href="#10-1-1-Problems-Solvable-in-Polynomial-Time" class="headerlink" title="10.1.1 Problems Solvable in Polynomial Time"></a>10.1.1 Problems Solvable in Polynomial Time</h4><p>T(n)</p>
<h4 id="10-1-2-An-Example-Kruskal’s-Algorithm"><a href="#10-1-2-An-Example-Kruskal’s-Algorithm" class="headerlink" title="10.1.2 An Example : Kruskal’s Algorithm"></a>10.1.2 An Example : Kruskal’s Algorithm</h4><h4 id="10-1-3-Nondeterministic-Polynomial-Time"><a href="#10-1-3-Nondeterministic-Polynomial-Time" class="headerlink" title="10.1.3 Nondeterministic Polynomial Time"></a>10.1.3 Nondeterministic Polynomial Time</h4><h4 id="10-1-4-NP例子"><a href="#10-1-4-NP例子" class="headerlink" title="10.1.4 NP例子"></a>10.1.4 NP例子</h4><h5 id="travel-salesman-problem-旅行商问题"><a href="#travel-salesman-problem-旅行商问题" class="headerlink" title="travel salesman problem(旅行商问题)"></a>travel salesman problem(旅行商问题)</h5><p>找哈密尔顿回路(每点只遍历一次)</p>
<h4 id="10-1-5-Polynomial-Time-Reductions"><a href="#10-1-5-Polynomial-Time-Reductions" class="headerlink" title="10.1.5 Polynomial-Time Reductions"></a>10.1.5 Polynomial-Time Reductions</h4><h4 id="10-1-6-NP-Complete"><a href="#10-1-6-NP-Complete" class="headerlink" title="10.1.6 NP-Complete"></a>10.1.6 NP-Complete</h4><p><img src="./1552801029841.png" alt="Alt text"></p>
<p><img src="./1553085291992.png" alt="Alt text"><br><img src="./1553085312758.png" alt="Alt text"><br><img src="./1553085324930.png" alt="Alt text"></p>
<p>L是一个NP问题<br>所有NP问题，都可以在多项式时间能转化为他</p>
<h4 id="10-2-An-NP-C-Problem"><a href="#10-2-An-NP-C-Problem" class="headerlink" title="10.2 An NP-C Problem"></a>10.2 An NP-C Problem</h4><p><strong>Boolean Satisfiability Problem</strong>:<br><img src="./1553085533259.png" alt="Alt text"><br><img src="./1553085705539.png" alt="Alt text"><br><img src="./1553085726519.png" alt="Alt text"><br><img src="./1553085753659.png" alt="Alt text"><br><img src="./1553085841282.png" alt="Alt text"><br><img src="./1553085862772.png" alt="Alt text"><br><img src="./1553085930425.png" alt="Alt text"><br><img src="./1553086013201.png" alt="Alt text"></p>
<h2 id="Keyword"><a href="#Keyword" class="headerlink" title="Keyword"></a>Keyword</h2><p><strong>DFA(确定的有限自动机)</strong><br><strong>NFA(非确定有限自动机)</strong><br><strong>Regular Language(正则语言)</strong><br><strong>Regular Grammar(正则文法)</strong><br><strong>Regular Expression(正则表达式)</strong><br><strong>PDA(下推自动机)</strong><br><strong>Turing Machines(图灵机)</strong><br><strong>Pumping Lemma(泵引理)</strong><br><strong>Context-Free Languge(上下文无关语言)</strong><br><strong>Context-Free Grammar(上下文无关文法)</strong><br><strong>PDA(下推自动机)</strong><br><strong>DPDA(确定的下推自动机)</strong><br><strong>NPDA(非确定的下推自动机)</strong><br><strong>Transition Diagrams(转移图)</strong><br><strong>$\epsilon$-Transitions(epsilon迁移)</strong><br><strong>Parse Tress(语法分析树)</strong><br><strong>Leftmost and Rightmost Derivations(左、右推导)</strong><br><strong>Ambiguous Grammars(模糊文法)</strong><br><strong>Parsers(语法分析器)</strong><br><strong>Instantaneous Descriptions(瞬时描述 ID) and $\vdash$</strong><br><strong>Chomsky Normal Form</strong><br><strong>CYK algorithm</strong><br><strong>Recursive Enumerable</strong><br><strong>Diagonalization Language</strong><br><strong>Recursive Language</strong><br><strong>Universal Language</strong><br><strong>Post’s Correspondence Problem</strong><br><strong>P,NP,NPC,NP Hard</strong><br><strong>Traveling Salesman Problem</strong><br><strong>Boolean Satisfiability Problem</strong><br><strong>3SAT</strong><br><strong>SAT Peoblem</strong><br><strong>Polynomial-Time Reductions</strong></p>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>计算理论</category>
      </categories>
      <tags>
        <tag>自动机</tag>
        <tag>计算复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP-Word2vec 算法之Skip-Gram</title>
    <url>/2019/12/26/NLP-Word2vec%20%E7%AE%97%E6%B3%95%E4%B9%8BSkip-Gram/</url>
    <content><![CDATA[<h1 id="NLP-Word2vec-算法之Skip-Gram"><a href="#NLP-Word2vec-算法之Skip-Gram" class="headerlink" title="NLP-Word2vec 算法之Skip-Gram"></a>NLP-Word2vec 算法之Skip-Gram</h1><blockquote>
<p>转载于<a href="https://www.jianshu.com/p/da235893e4a5" target="_blank" rel="noopener">https://www.jianshu.com/p/da235893e4a5</a></p>
</blockquote>
<p>[TOC]</p>
<blockquote>
<p>Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定input word来预测上下文。而CBOW是给定上下文，来预测input word。本篇文章仅讲解Skip-Gram模型。<br><img src="./1553947716336.png" alt="Alt text"></p>
</blockquote>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>Word2Vec模型实际上分为了两个部分，<strong>第一部分为建立模型，第二部分是通过模型获取嵌入词向量</strong>。Word2Vec的整个建模过程实际上与自编码器（auto-encoder）的思想很相似，即先基于训练数据构建一个神经网络，当这个模型训练好以后，我们并不会用这个训练好的模型处理新的任务，我们真正需要的是这个模型通过训练数据所学得的参数，例如隐层的权重矩阵——后面我们将会看到这些权重在Word2Vec中实际上就是我们试图去学习的“word vectors”。基于训练数据建模的过程，我们给它一个名字叫“Fake Task”，意味着建模并不是我们最终的目的。</p>
<blockquote>
<p>上面提到的这种方法实际上会在无监督特征学习（unsupervised feature learning）中见到，最常见的就是自编码器（auto-encoder）：通过在隐层将输入进行编码压缩，继而在输出层将数据解码恢复初始状态，训练完成后，我们会将输出层“砍掉”，仅保留隐层。</p>
</blockquote>
<p>再次提一下什么是word embedding（词嵌入），一般的机器学习模型包括神经网络的输入都是数值型的，所以如果要处理词，首先需要将词转化成数值型的向量。最初的想法是构建词汇表V，然后将每一个词转化成一个1*V的一个one-hot向量，one-hot向量中文翻译就是独热，也叫独热编码，就是向量中只有一个1，其他元素都为0。但是很快研究者发现这样的表示不仅得到了大量的非常稀疏的向量或者矩阵，并且丢失了很多信息。1957年，Firth提出了一个词的意思是由他所处的环境或者说他周围的词所提供，也就是我们通常说的上下文。于是共现矩阵的理论就被提出了，共现矩阵的每个元素Xij便是单词i和单词j共同出现的次数，关于共同出现我们可以定义一个距离，当距离小于一直阈值可以判断为共同出现。</p>
<h3 id="The-Fake-Task"><a href="#The-Fake-Task" class="headerlink" title="The Fake Task"></a>The Fake Task</h3><p>我们在上面提到，训练模型的真正目的是获得模型基于训练数据学得的隐层权重。为了得到这些权重，我们首先要构建一个完整的神经网络作为我们的“Fake Task”，后面再返回来看通过“Fake Task”我们如何间接地得到这些词向量。<br>  接下来我们来看看如何训练神经网络。假如我们有一个句子<strong>“The dog barked at the mailman”</strong>。</p>
<blockquote>
<p>首先我们选句子中间的一个词作为我们的输入词，例如我们选取“dog”作为input word；</p>
<p>有了input word以后，我们再定义一个叫做skip_window的参数，它代表着我们从当前input word的一侧（左边或右边）选取词的数量。如果我们设置skip_window=2，那么我们最终获得窗口中的词（包括input word在内）就是[‘The’, ‘dog’，’barked’, ‘at’]。skip_window=2代表着选取左input word左侧2个词和右侧2个词进入我们的窗口，所以整个窗口大小span=2x2=4。另一个参数叫num_skips，它代表着我们从整个窗口中选取多少个不同的词作为我们的output word，当skip_window=2，num_skips=2时，我们将会得到两组(input word, output word) 形式的训练数据，即(‘dog’, ‘barked’)，(‘dog’, ‘the’)。</p>
<p>神经网络基于这些训练数据将会输出一个概率分布，这个概率代表着我们的词典中的每个词是output word的可能性。这句话有点绕，我们来看个栗子。第二步中我们在设置skip_window和num_skips=2的情况下获得了两组训练数据。假如我们先拿一组数据 (‘dog’, ‘barked’) 来训练神经网络，那么模型通过学习这个训练样本，会告诉我们词汇表中每个单词是“barked”的概率大小。</p>
</blockquote>
<p>首先我们选句子中间的一个词作为我们的输入词，例如我们选取“dog”作为input word；<br>有了input word以后，我们再定义一个叫做skip_window的参数，它代表着我们从当前input word的一侧（左边或右边）选取词的数量。如果我们设置skip_window=2，那么我们最终获得窗口中的词（包括input word在内）就是[‘The’, ‘dog’，’barked’, ‘at’]。skip_window=2代表着选取左input word左侧2个词和右侧2个词进入我们的窗口，所以整个窗口大小span=2x2=4。另一个参数叫num_skips，它代表着我们从整个窗口中选取多少个不同的词作为我们的output word，当skip_window=2，num_skips=2时，我们将会得到两组(input word, output word) 形式的训练数据，即(‘dog’, ‘barked’)，(‘dog’, ‘the’)。<br>神经网络基于这些训练数据将会输出一个概率分布，这个概率代表着我们的词典中的每个词是output word的可能性。这句话有点绕，我们来看个栗子。第二步中我们在设置skip_window和num_skips=2的情况下获得了两组训练数据。假如我们先拿一组数据 (‘dog’, ‘barked’) 来训练神经网络，那么模型通过学习这个训练样本，会告诉我们词汇表中每个单词是“barked”的概率大小。</p>
<p><img src="./1553948372153.png" alt="Alt text"><br>我们的模型将会从每对单词出现的次数中习得统计结果。例如，<strong>我们的神经网络可能会得到更多类似（“Soviet“，”Union“）这样的训练样本对，而对于（”Soviet“，”Sasquatch“）这样的组合却看到的很少。</strong>因此，当我们的模型完成训练后，给定一个单词”Soviet“作为输入，输出的结果中”Union“或者”Russia“要比”Sasquatch“被赋予更高的概率。</p>
<h3 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h3><p>我们如何来表示这些单词呢？<br>  首先，我们都知道神经网络只能接受数值输入，我们不可能把一个单词字符串作为输入，因此我们得想个办法来表示这些单词。最常用的办法就是基于训练文档来构建我们自己的词汇表（vocabulary）再对单词进行one-hot编码。<br>  假设从我们的训练文档中抽取出10000个唯一不重复的单词组成词汇表。我们对这10000个单词进行one-hot编码，得到的每个单词都是一个10000维的向量，向量每个维度的值只有0或者1，假如单词ants在词汇表中的出现位置为第3个，那么ants的向量就是一个第三维度取值为1，其他维都为0的10000维的向量（ants=[0, 0, 1, 0, …, 0]）。<br>  还是上面的例子，“The dog barked at the mailman”，那么我们基于这个句子，可以构建一个大小为5的词汇表（忽略大小写和标点符号）：(“the”, “dog”, “barked”, “at”, “mailman”)，我们对这个词汇表的单词进行编号0-4。那么”dog“就可以被表示为一个5维向量[0, 1, 0, 0, 0]。<br>  <strong>模型的输入如果为一个10000维的向量，那么输出也是一个10000维度（词汇表的大小）的向量，它包含了10000个概率，每一个概率代表着当前词是输入样本中output word的概率大小。</strong><br>下图是神经网络的结构</p>
<p><img src="./1553948545224.png" alt="Alt text"><br>隐层没有使用任何激活函数，但是输出层使用了sotfmax。<br>  我们基于成对的单词来对神经网络进行训练，训练样本是 ( input word, output word ) 这样的单词对，input word和output word都是one-hot编码的向量。最终模型的输出是一个概率分布。</p>
<h3 id="隐层"><a href="#隐层" class="headerlink" title="隐层"></a>隐层</h3><p>说完单词的编码和训练样本的选取，我们来看下我们的隐层。如果我们现在想用300个特征来表示一个单词（即每个词可以被表示为300维的向量）。那么隐层的权重矩阵应该为10000行，300列（隐层有300个结点）。<br>  Google在最新发布的基于Google news数据集训练的模型中使用的就是300个特征的词向量。词向量的维度是一个可以调节的超参数（在Python的gensim包中封装的Word2Vec接口默认的词向量大小为100， window_size为5）。<br>  看下面的图片，左右两张图分别从不同角度代表了输入层-隐层的权重矩阵。左图中每一列代表一个10000维的词向量和隐层单个神经元连接的权重向量。从右边的图来看，每一行实际上代表了每个单词的词向量<br><img src="./1553948805975.png" alt="Alt text"><br>所以我们最终的目标就是学习这个隐层的权重矩阵。<br>  我们现在回来接着通过模型的定义来训练我们的这个模型。上面我们提到，input word和output word都会被我们进行one-hot编码。仔细想一下，我们的输入被one-hot编码以后大多数维度上都是0（实际上仅有一个位置为1），所以这个向量相当稀疏，那么会造成什么结果呢。如果我们将一个1 x 10000的向量和10000 x 300的矩阵相乘，它会消耗相当大的计算资源，为了高效计算，它仅仅会选择矩阵中对应的向量中维度值为1的索引行（这句话很绕），看图就明白。</p>
<p><img src="./1553948857172.png" alt="Alt text"><br>们来看一下上图中的矩阵运算，左边分别是1 x 5和5 x 3的矩阵，结果应该是1 x 3的矩阵，按照矩阵乘法的规则，结果的第一行第一列元素为0 x 17 + 0 x 23 + 0 x 4 + 1 x 10 + 0 x 11 = 10，同理可得其余两个元素为12，19。如果10000个维度的矩阵采用这样的计算方式是十分低效的。<br>  为了有效地进行计算，这种稀疏状态下不会进行矩阵乘法计算，可以看到矩阵的计算的结果实际上是矩阵对应的向量中值为1的索引，上面的例子中，左边向量中取值为1的对应维度为3（下标从0开始），那么计算结果就是矩阵的第3行（下标从0开始）—— [10, 12, 19]，这样模型中的隐层权重矩阵便成了一个”查找表“（lookup table），进行矩阵计算时，直接去查输入向量中取值为1的维度下对应的那些权重值。<strong>隐层的输出就是每个输入单词的“嵌入词向量”。</strong></p>
<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><p>经过神经网络隐层的计算，ants这个词会从一个1 x 10000的向量变成1 x 300的向量，再被输入到输出层。输出层是一个softmax回归分类器，它的每个结点将会输出一个0-1之间的值（概率），这些所有输出层神经元结点的概率之和为1。<br>  下面是一个例子，训练样本为 (input word: “ants”， output word: “car”) 的计算示意图。<br><img src="./1553948914070.png" alt="Alt text"></p>
<p><img src="./1554041540061.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>NLP</title>
    <url>/2019/12/26/NLP/</url>
    <content><![CDATA[<h1 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h1><p>[TOC]</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h2><p><strong>Wordnet</strong>:<img src="./1553769956041.png" alt="Alt text"><br>日语Wordnet使用</p>
<pre><code class="lang-python">import sys
import sqlite3
from collections import namedtuple
if __name__ == &#39;__main__&#39;:
    conn = sqlite3.connect(&quot;wnjpn.db&quot;)

    cur = conn.execute(&quot;select name from sqlite_master where type=&#39;table&#39;&quot;)  # 获取数据库存在的表格
    for row in cur:
       print(row)

    cur = conn.execute(&quot;select * from word where lang=&#39;jpn&#39; limit 10&quot;)  # 获取日文单词
    # print(cur.description)
    for row in cur:
        print(row)
    cur = conn.execute(&quot;PRAGMA TABLE_INFO(word)&quot;)  # 查看word表的列名
    for row in cur:
        print(row)



# 类似语检索
def SearchSimilarWords(word):

    # 問い合わせしたい単語がWordnetに存在するか確認する
    cur = conn.execute(&quot;select wordid from word where lemma=&#39;%s&#39;&quot; % word) #sql搜索指定词

    word_id = 99999999  #temp 如果检索到相应单词的话会改变为一个正常的较小的值
    for row in cur:  #遍历搜索结果
        word_id = row[0]


    # Wordnetに存在する語であるかの判定
    if word_id==99999999:
        print(&quot;「%s」は、Wordnetに存在しない単語です。&quot; % word)
        return
    else:
        print(&quot;【「%s」の類似語を出力します】\n&quot; % word)

    # 入力された単語を含む概念を検索する
    cur = conn.execute(&quot;select synset from sense where wordid=&#39;%s&#39;&quot; % word_id)        #sense表包含着单词id和synset id
    synsets = []
    #遍历对sense的搜索结果，加入同义词集数组
    for row in cur:
        synsets.append(row[0])


    # 概念に含まれる単語を検索して画面出力する
    no = 1
    #对每个同义词集进行遍历，输出
    for synset in synsets:
        cur1 = conn.execute(&quot;select name from synset where synset=&#39;%s&#39;&quot; % synset)
        for row1 in cur1:
            print(&quot;%sつめの概念 : %s&quot; %(no, row1[0]))
        cur2 = conn.execute(&quot;select def from synset_def where (synset=&#39;%s&#39; and lang=&#39;jpn&#39;)&quot; % synset)
        sub_no = 1
        for row2 in cur2:
            print(&quot;意味%s : %s&quot; %(sub_no, row2[0]))
            sub_no += 1
        cur3 = conn.execute(&quot;select wordid from sense where (synset=&#39;%s&#39; and wordid!=%s)&quot; % (synset,word_id))
        sub_no = 1
        for row3 in cur3:
            target_word_id = row3[0]
            cur3_1 = conn.execute(&quot;select lemma from word where wordid=%s&quot; % target_word_id)
            for row3_1 in cur3_1:
                print(&quot;類義語%s : %s&quot; % (sub_no, row3_1[0]))
                sub_no += 1
        print(&quot;\n&quot;)
        no += 1
</code></pre>
<p><img src="./1553770873286.png" alt="Alt text"></p>
<h2 id="2-Word2Vec"><a href="#2-Word2Vec" class="headerlink" title="2.Word2Vec"></a>2.Word2Vec</h2><p>WordNet的一些不足（如无法判断相似性等），引入了词向量<br><strong>One-hot</strong>:热独码。仅有一个1的向量<br>在One-hot编码下。词汇独立。点乘为0</p>
<p><strong>Distribution similarity(分布相似性)</strong><br>靠上下文来表示一个词的含义</p>
<p>于是使用一个<strong>密集向量</strong>来表示一个词。可以预测文本其他词汇 </p>
<h3 id="2-1-Word2Vec"><a href="#2-1-Word2Vec" class="headerlink" title="2.1 Word2Vec"></a>2.1 Word2Vec</h3><script type="math/tex; mode=display">p(context|w_t)=...\\J=1-p(w_{-t}|w_t)</script><p>$w_{-t}$表示围绕在t中心词周围的其他单词(除t之外所以其他词汇),J为损失函数</p>
<p>Word2Vec是一个软件<br>2个算法</p>
<blockquote>
<p><strong>Skip-grams(SG):</strong><br><img src="./1553775854402.png" alt="Alt text"><br>定义一个窗口:radius m of every word<br>目标函数：<br><img src="./1553775954279.png" alt="Alt text"><br>遍历每个词汇，大小为2m的窗口,左m右m个词,然后条件概率相乘<br>$\theta$是词的向量表示,也是唯一参数<br>为了方便运算,取对数，转换求积为求和，再取个平均1/T(相当归一化处理)<br>上面其实就是似然函数<br><img src="./1553776227034.png" alt="Alt text"><br>要做的就是，通过当前的词向量来最小化似然函数<br><img src="./1553776620361.png" alt="Alt text"><br>上面为softmax模型。也就是指数某值除于所有指数和.所以某词和当前中心词的点乘结果越大，softmax结果越大<br>o是输出单词，c是中心单词<br>$u_o$是索引为o的单词对应的向量 $v_c$是中心词汇对应的向量<br><strong>Softmax</strong>是一种<strong>把数值转换成概率的方法</strong><br>关注的是单词ID在窗口的位置,当关注的是句法之类的而不是单词本身意思时，考虑距离很有用<br><img src="./1553777461604.png" alt="Alt text"><br>过程描述:<br>1.首先是一个中心词汇的one-hot向量$w_t$,然后和一个由所有中心词汇向量构成的矩阵W相乘，能够选出一列$v_c$,也就是中心词汇对应的词向量（完成了通过ont-hot-&gt;词向量的步骤)<br>2.然后和<strong>上下文的词汇表示</strong>矩阵相乘<br>3.softmax后可以预测某个位置出现哪个词,然后和实际情况比较<br><img src="./1553778122757.png" alt="Alt text"><br>对于每个单词有一个d维的小向量<br>这个矩阵就是要优化的<br><img src="./1553780057748.png" alt="Alt text"><br>第一部分求导为u_0<br><img src="./1553781011491.png" alt="Alt text"><br>转换后<br><img src="./1553780708312.png" alt="Alt text"><br>u_x是期望向量是所有上下文向量的平均，前面的是一个概率<br>优化方式<br><img src="./1553781505279.png" alt="Alt text"></p>
</blockquote>
<p>穿插的highlight paper:<br>1.计算句子向量<br><img src="./1553778493247.png" alt="Alt text"><br>对每个句子执行上面那个。a是一个常数<br><img src="./1553778567792.png" alt="Alt text"><br><img src="./1553778686770.png" alt="Alt text"></p>
<blockquote>
<p><strong>CBOW:Continuous Bag of Words</strong>:</p>
</blockquote>
<p>2个高效训练方式</p>
<blockquote>
<p>Hierachical softmax</p>
<p>Negative sampling</p>
</blockquote>
<h3 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1:"></a>Assignment 1:</h3><p><strong>Q1:Softmax:</strong><br>1.<img src="./1553782661974.png" alt="Alt text"></p>
<blockquote>
<p><strong>Prove:$softmax(x)=softmax(x+c)$,x is a vector and c is a constant</strong><br>begin:<br>Let $x=(x_1,x_2,…,x_n)$<br>and then we know that $softmax(x)=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})$<br>and  $softmax(x+c)=(\frac{e^{x_1+c}}{\sum_j e^{x_j+c}},\frac{e^{x_2+c}}{\sum_j e^{x_j}},…,\frac{e^{x_n+c}}{\sum_j e^{x_j+c}})=\\=(\frac{e^{x_1}e^c}{e^c\sum_j e^{x_j}},\frac{e^{x_2}e^c}{e^c\sum_j e^{x_j}},…,\frac{e^{x_n}e^c}{e^c\sum_j e^{x_j}})=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})=softmax(x)$<br>Then this question is solved</p>
</blockquote>
<p>2.softmax</p>
<pre><code class="lang-python">import numpy as np

def softmax_inrow(m):
   # print(m)
    rm=np.max(m,axis=1)
    rm_r=rm.reshape(rm.shape[0],1)
    #print(rm_r)
    m1=m-rm_r
    e1=np.exp(m1)
    sum=np.sum(e1,axis=1)
    sum=sum.reshape(sum.shape[0],1)
    e1=e1/sum
    #print(e1)
    return e1

def softmax_incoloum(m):
    # print(m)
    rm = np.max(m, axis=0)
    #rm_r = rm.reshape(rm.shape[0], 1)
    #print(rm)
    m1 = m - rm
    #print(m1)
    e1 = np.exp(m1)
    sum = np.sum(e1, axis=0)
    #sum = sum.reshape(sum.shape[0], 1)
    e1 = e1 / sum
    # print(e1)
    return e1

N=input()
D=input()
matrix=np.random.rand(int(N),int(D))
print(softmax_incoloum(matrix))
#print(softmax2(matrix))
</code></pre>
<p><strong>Q2:</strong><br><strong>2.1</strong></p>
<blockquote>
<p>As $\sigma(x)=\frac{1}{1+e^{-x}}$<br>$\sigma’(x)=\frac{e^{-x}}{(1+e^{-x})^2}\\e^{-x}=\frac{1}{\sigma(x)}-1$<br>So,$\sigma’(x)=\sigma(x)(\frac{1}{\sigma(x)}-1)=1-\sigma(x)$</p>
</blockquote>
<h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><p><img src="./1554208505388.png" alt="Alt text"><br><img src="./1554213176752.png" alt="Alt text"></p>
<p><img src="./1554214058417.png" alt="Alt text"><br><img src="./1554215908619.png" alt="Alt text"></p>
<p>词向量类似这样<br><img src="./1554296003843.png" alt="Alt text"><br>进行奇异值分解降维<br><img src="./1554296083075.png" alt="Alt text"><br><img src="./1554296093342.png" alt="Alt text"><br><img src="./1554296660432.png" alt="Alt text"><br>解决某些词过于频繁出现（如the)</p>
<p><img src="./1554375014391.png" alt="Alt text"><br><img src="./1554376252035.png" alt="Alt text"><br><img src="./1554376257901.png" alt="Alt text"><br><img src="./1554377650391.png" alt="Alt text"><br><img src="./1554378638632.png" alt="Alt text"><br><img src="./1554379654205.png" alt="Alt text"><br><img src="./1554379836126.png" alt="Alt text"></p>
<h2 id="Keyword"><a href="#Keyword" class="headerlink" title="Keyword"></a>Keyword</h2><p><strong>Wordnet</strong><br><strong>One-hot</strong><br><strong>Word Embeddings(词嵌入)</strong><br><strong>Distribution representation</strong><br><strong>Distribution similarity(分布相似性)</strong><br><strong>Skip-grams(SG)</strong><br><strong>normalization</strong><br><strong>cross-entropy(交叉熵)</strong><br><strong>softmax</strong><br><strong>bag-of-word(词袋)</strong><br><strong>backpropagation</strong><br><strong>SGD:Stochastic Gradient Descent</strong><br><strong>co-occurrence</strong><br><strong>Glove</strong><br><strong>L1 regularization</strong><br><strong>L2 regularization</strong></p>
]]></content>
  </entry>
  <entry>
    <title>L2正则化</title>
    <url>/2019/12/26/L2%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    <content><![CDATA[<h1 id="【统计学习】L0-L1-L2正则化"><a href="#【统计学习】L0-L1-L2正则化" class="headerlink" title="【统计学习】L0\L1\L2正则化"></a>【统计学习】L0\L1\L2正则化</h1><blockquote>
<p>参考:<br>[1]<a href="https://www.cnblogs.com/Peyton-Li/p/7607858.html" target="_blank" rel="noopener">https://www.cnblogs.com/Peyton-Li/p/7607858.html</a><br>[2]<a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995</a></p>
</blockquote>
<h1 id="0-简介"><a href="#0-简介" class="headerlink" title="0.简介"></a>0.简介</h1><p><img src="./1555081516545.png" alt="Alt text"><br>其中第一项是损失函数的计算。也就是真实值与估计值的误差。后面的$\Omega$就是正则项。<br>我们训练希望让真实值与估计值的误差尽可能的小。也就是模型尽可能拟合训练数据。<strong>但是，我们不仅希望模型训练误差小，测试误差也小（也就是泛化能力强），而复杂的模型可能会产生过拟合（也就是过度拟合训练数据，但是整体数据集上不能很好的拟合）</strong>，于是我们加上第二项，也就是<strong>正则化项（regularizer）或者惩罚项（penalty term）</strong>，这是一个约束项，目的是去约束模型，让其变得简单。</p>
<p>规格化函数$Omega$有很多种，常见的有<strong>零范数、一范数、二范数、迹范数、Frobenius范数和核范数</strong>等等</p>
<h2 id="一、L0范数与L1范数"><a href="#一、L0范数与L1范数" class="headerlink" title="一、L0范数与L1范数"></a>一、L0范数与L1范数</h2><p><strong>L0范数是指向量中的非零个数</strong>，如果用L0来规格化一个<strong>参数矩阵</strong>的话就是<strong>希望W的大部分元素都为0。</strong>，也就是让W的参数是稀疏的。</p>
<p>但是会发现。各类文章中提到的更多是<strong>L1范数</strong>。为什么大家都用L1而不是L0呢？<br>这也是这节的题目把L0和L1放在一起的原因，因为他们有着某种不寻常的关系。<br> L1范数是指向量中各个元素绝对值之和，也叫<strong>“稀疏规则算子”（Lasso regularization）</strong>，同L0一样，都能使得参数矩阵稀疏化。</p>
<p> Q：为什么L1会使W变得稀疏呢？<br> 因为L1范数是L0范数的<strong>最优凸近似</strong>，<strong>任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏</strong></p>
<blockquote>
<p>W的L1范数是绝对值，|w|在w=0处不可微</p>
</blockquote>
<p>因为L0难以优化（优化问题很难求解，NP难问题），因此人们更多使用L1范数</p>
<p>总结:<strong>L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</strong></p>
<p><strong>参数稀疏的好处</strong><br>1.特征选择((Feature Selection)<br>有些影响较小，或者没有影响的特性，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。</p>
<p>2.可解释性<br>通过观察权值。可以知道哪些特征更有用，或者说只由哪些特征决定</p>
<p><img src="./1555082630892.png" alt="Alt text"></p>
<blockquote>
<p>彩色实线是的等值线，黑色实线是L1正则的等值线。二维空间（权重向量只有和）上，L1正则项的等值线是方形，方形与的等值线相交时相交点为顶点的概率很大，所以或等于零的概率很大。所以使用L1正则项的解具有稀疏性。</p>
</blockquote>
<h2 id="L2范数"><a href="#L2范数" class="headerlink" title="L2范数"></a>L2范数</h2><p>使用L2范数的回归，可以叫<strong>岭回归（Ridge Regression）或者“权值衰减（weight decay）”</strong><br>它的强大功效是改善机器学习里面一个非常重要的问题：<strong>过拟合</strong></p>
<p>  L2范数是指向量各元素的平方和然后求平方根。<strong>我们让L2范数的规则项||W||2最小</strong>，<strong>可以使得W的每个元素都很小</strong>，<strong>都接近于0</strong>，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。<br><img src="./1555082551370.png" alt="Alt text"></p>
<blockquote>
<p>彩色实线是$J_0$的等值线，黑色实线是$L2$正则的等值线。二维空间（权重向量只有和）上，L2正则项的等值线是圆，与的等值线相交时或等于零的概率很小。所以使用L2正则项的解<strong>不具有稀疏性</strong>。在求解过程中，L2通常倾向让权值尽可能小，最后构造一个所有参数都比较小的模型。因为<strong>一般认为参数值小的模型比较简单</strong>，能适应不同的数据集，也在一定程度上避免了过拟合现象。参数足够小，数据偏移得多一点也不会对结果造成什么影响，可以说“抗扰动能力强”。</p>
</blockquote>
<h3 id="Q-A"><a href="#Q-A" class="headerlink" title="Q\A"></a>Q\A</h3><p><strong>Q1:为什么通过L1正则、L2正则能够防止过拟合</strong><br>　　解释：<br>　　过拟合产生的原因通常是因为参数比较大导致的，通过添加正则项，假设某个参数比较大，目标函数加上正则项后，也就会变大，因此该参数就不是最优解了。<br>　　问：为什么过拟合产生的原因是参数比较大导致的？<br>　　答：过拟合，就是拟合函数需要顾忌每一个点，当存在噪声的时候，原本平滑的拟合曲线会变得波动很大。在某些很小的区间里，函数值的变化很剧烈，这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以<strong>只有系数足够大，才能保证导数值很大。</strong></p>
<p>！！！正则化可以看做是事前分布的对应。<br>L2正则化是让权重w服从一个均值为0,方差为$\sigma_0^2$的高斯分布。方差越小对应惩罚系数越大。<br>L1正则化是让其满足Laplace分布。</p>
<h1 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h1><h3 id="ill-condition"><a href="#ill-condition" class="headerlink" title="ill-condition"></a>ill-condition</h3>]]></content>
  </entry>
  <entry>
    <title>Framework</title>
    <url>/2019/12/26/Framework/</url>
    <content><![CDATA[<p>A#Optimization Algorithm</p>
<blockquote>
<p>SGD -&gt; SGDM -&gt; NAG -&gt;AdaGrad -&gt; AdaDelta -&gt; Adam -&gt; Nadam</p>
</blockquote>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p><strong>Before we begin, we should define some definition:</strong></p>
<center>
+ **The parameters wait to be optimized:** $\theta$
+ **target function:** $f(\theta)$
+ **Gradient:** $g_t=\nabla f(\theta)$
+ **First order momentum:** $m_t$
+ **Second order momentum:** $V_t$
+ **calculate current Gradient:**$\eta_t=\alpha \cdot\frac{m}{\sqrt{V_t}}$
+ **Update:** $\theta_{t+1}=\theta_{t}-\eta_t$
</center>

<h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><blockquote>
<p>the most simple optimization algorithm</p>
</blockquote>
<p><strong>Update:</strong><br>Because SGD doesn’t use momentum, so<br><strong>$m_t=g_t,V_t=I^2$</strong></p>
<h2 id="SGDM-SGD-with-Momentum"><a href="#SGDM-SGD-with-Momentum" class="headerlink" title="SGDM(SGD with Momentum)"></a>SGDM(SGD with Momentum)</h2><p>$m_t=\beta_1\cdot m_{t-1}+(1-\beta_1)\cdot g_t$</p>
<p>$\eta_t=\alpha\cdot g_t$</p>
<blockquote>
<p>t时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定</p>
</blockquote>
<h2 id="Nesterov-Accelerated-Gradient-NAG"><a href="#Nesterov-Accelerated-Gradient-NAG" class="headerlink" title="Nesterov Accelerated Gradient(NAG)"></a>Nesterov Accelerated Gradient(NAG)</h2><p><img src="./1559457618332.png" alt="Alt text"><br>NAG在步骤1，不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向：<br>然后用下一个点的梯度方向，与历史累积动量相结合，计算步骤2中当前时刻的累积动量。</p>
<h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><blockquote>
<p>The beginning of using Second order momentum<br><img src="./1559457861853.png" alt="Alt text"><br><img src="./1559457867210.png" alt="Alt text">二阶动量越大，学习率就越小。<br>也存在一些问题：因为$\sqrt{V_t} $是单调递增的，会使得学习率单调递减至0，可能会使得训练过程提前结束，即便后续还有数据也无法学到必要的知识。</p>
</blockquote>
<h2 id="AdaDelta-RMSProp"><a href="#AdaDelta-RMSProp" class="headerlink" title="AdaDelta / RMSProp"></a>AdaDelta / RMSProp</h2><p>由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。</p>
<p><img src="./1559457958436.png" alt="Alt text"></p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><blockquote>
<p>Adam 运用上了一阶动量和二阶动量</p>
</blockquote>
<script type="math/tex; mode=display">g_t=J(\theta)\\m_t=\beta_1\cdot m_{t-1}+(1-\beta_1)\cdot g_t\\V_t=\beta_2 \cdot V_{t-1}+(1-\beta_2)g_t^2\\\theta_t=\theta_{t-1}-\alpha\frac{m}{\sqrt{v}}</script><p><img src="./1559456137180.png" alt="Alt text"></p>
<h2 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h2><p>…继续进化,加上Nesterov<br><img src="./1559458112502.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>DNS Working Principle</title>
    <url>/2019/12/26/DNS%20Working%20Principle/</url>
    <content><![CDATA[<h2 id="DNS-Working-Principle"><a href="#DNS-Working-Principle" class="headerlink" title="DNS Working Principle"></a>DNS Working Principle</h2><h3 id="What’s-is-DNS"><a href="#What’s-is-DNS" class="headerlink" title="What’s is DNS"></a>What’s is DNS</h3><p>　<strong>DNS(Domain Name System)</strong>，Domain System，which is a service of Internet.It a kind of <strong>distributed database</strong> that mapping between Domain Name and IP Address.So that people can access the Internet more convenient.DNS use TCP and UDP’s port 53.Currently,the limit of each grade domain is not over 63 characters,And the total length of domain can not over 253 characters.</p>
<p>它是因特网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。</p>
<h3 id="DNS-Working-Principle-1"><a href="#DNS-Working-Principle-1" class="headerlink" title="DNS Working Principle"></a>DNS Working Principle</h3><p><img src="./1553254601223.png" alt="Alt text"></p>
<p>　　当我们请求一个域名时，直到获取到IP地址，整个过程是如何工作的？以请求www.codecc.xyz为例：</p>
<p>　　1、首先，我们的主机会去查找本地的hosts文件和本地DNS解析器缓存，如果hosts文件和本地DNS缓存存在www.codecc.xyz和IP的映射关系，则完成域名解析，请求该IP地址，否则进入第二步。</p>
<p>　　2、当hosts和本地DNS解析器缓存都没有对应的网址映射关系，则会根据机器(/etc/reslove.conf)配置的本地DNS服务器进行查询，此服务器收到查询时，如果要查询的域名在本地配置区域资源或者缓存中存在映射关系，则跳到步骤9，将解析结果直接返回给客户机。</p>
<p>　　PS：一二步骤为递归查询，其余步骤为迭代查询</p>
<p>　　3、若本地DNS服务器不存在该域名的映射关系，就把请求发送至13台根DNS服务器。</p>
<p>　　4、根DNS服务器会判断这个域名(.xyz)由谁来授权管理，并返回一个负责该顶级域的DNS服务器的一个IP给本地DNS服务器。</p>
<p>　　5、本地DNS服务器收到该IP后，会再将查询请求发送至(.xyz)所在的DNS服务器。</p>
<p>　　6、如果(.xyz)的DNS服务器无法解析该域名，就会去判断这个二级域名(codecc.xyz)的管理者，返回一个负责该二级域的DNS服务器的IP给本地DNS服务器。</p>
<p>　　7、本地DNS服务器收到该IP后，会再次将查询请求发送至(codecc.xyz)所在的DNS服务器。</p>
<p>　　8、(codecc.xyz)的DNS服务器会存有www.codecc.xzy的映射关系，将解析后的IP返回给本地DNS服务器</p>
<p>　　9、本地DNS服务器根据查询到的解析IP发送给客户机，至此，DNS解析完成。</p>
]]></content>
  </entry>
  <entry>
    <title>Deep Learning</title>
    <url>/2019/12/26/Deep%20Learning/</url>
    <content><![CDATA[<h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><p>[TOC]</p>
<h2 id="Pre-Notation"><a href="#Pre-Notation" class="headerlink" title="Pre:Notation"></a>Pre:Notation</h2><p>$e^{(i)}$:Standard basis vector [0,0,0,…,1,0,0,0] with a 1 at position i<br><strong>A:</strong>Matrix<br><em>A</em>:tensor (a tensor is some numbers extend in n dimension,which called “n dimension tensor”.For example,scalar is 1 dimension tensor and matrix is 2 dimension tensor)<br><img src="./1553170250861.png" alt="Alt text"><br><img src="./1553170270670.png" alt="Alt text"><br><img src="./1553170275443.png" alt="Alt text"><br><img src="./1553170278918.png" alt="Alt text"><br><img src="./1553170290435.png" alt="Alt text">(某节点的父节点)<br><img src="./1553170513943.png" alt="Alt text"><br><img src="./1553171301511.png" alt="Alt text"><br><img src="./1553171317238.png" alt="Alt text"><br><img src="./1553171323867.png" alt="Alt text"><br><img src="./1553171328365.png" alt="Alt text"></p>
<p><strong>Element-wise (Hadamard) product:矩阵点乘</strong></p>
<h2 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1:Introduction"></a>Chapter 1:Introduction</h2><p><img src="./1553172557929.png" alt="Alt text"></p>
<p><strong>representation learning</strong><br><strong>factors of variation</strong><br><strong>MLP:multilayer perceptron</strong><br><strong>Logistic Regression</strong></p>
<h2 id="Chapter-1-Linear-Algebra"><a href="#Chapter-1-Linear-Algebra" class="headerlink" title="Chapter 1:Linear Algebra"></a>Chapter 1:Linear Algebra</h2><p><strong>Hadamard product:</strong>$A\odot B$<br><strong>norm(范数)</strong></p>
<script type="math/tex; mode=display">\Vert x\Vert_p=(\sum_i |x_i|^p)^{\frac{1}{p}}</script><p><strong>Euclidean norm:欧几里得范数，也就是L2范数</strong><br>L1范数就是张量各元素绝对值相加。<br>L2范数就是各元素绝对值平方和再开方<br><strong>max norm：最大范数.也就是具有最大幅值元素的绝对值</strong><br><strong>SVD:singular value decomposition:奇异值分解</strong></p>
]]></content>
  </entry>
  <entry>
    <title>Database</title>
    <url>/2019/12/26/Database/</url>
    <content><![CDATA[<h1 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h1><h2 id="范式分解"><a href="#范式分解" class="headerlink" title="范式分解"></a>范式分解</h2><h3 id="3NF"><a href="#3NF" class="headerlink" title="3NF:"></a>3NF:</h3><p>求最小函数依赖F<br>不在F中的属性单独拿出来做一个关系<br>其他的左右合起来就行</p>
<h3 id="BCNF"><a href="#BCNF" class="headerlink" title="BCNF"></a>BCNF</h3><p>求最新函数依赖F<br>求候选键<br>分析F中每个函数依赖<br>如果不符合BC范式（左边存在非候选键的）<br>分解成2个关系<br>左右合并作为一个分解。然后第二个关系要去掉第一个关系右边项</p>
<h3 id="判断无损分解"><a href="#判断无损分解" class="headerlink" title="判断无损分解"></a>判断无损分解</h3><p>画表。<img src="./1560830921138.png" alt="Alt text"><br>一次分析每个依赖里面 a__i的。然后把对应右边关系的行，干成a_k.某行全a后就是无损分解</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>ACID特性(原子、一致、隔离、持久性)</p>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>保证正确调度、事务的隔离性、数据库一致性</p>
<h3 id="潜在的不一致性"><a href="#潜在的不一致性" class="headerlink" title="潜在的不一致性"></a>潜在的不一致性</h3><h4 id="丢失修改"><a href="#丢失修改" class="headerlink" title="丢失修改"></a>丢失修改</h4><p>一个事务读后，另一个事务修改并写回了，然后之前那个事务又把修改过后的数据写进去（读后写）</p>
<h4 id="读脏数据"><a href="#读脏数据" class="headerlink" title="读脏数据"></a>读脏数据</h4><p>读一个修改过的结果。。之后那个事务rollback了</p>
<h4 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h4><p>1读取数据后，2更新，1无法再现结果<br>1类：修改后，再读不同值<br>2类：2删除了记录，再次读，1发现读不到<br>3类：2添加了记录，再次读，发现多了一些记录<br>2、3也称为幻影现象</p>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><h4 id="X、S"><a href="#X、S" class="headerlink" title="X、S"></a>X、S</h4><p>X是排他 S是共享<br>X优先级最高。不能再加任何锁，直到释放<br>S只能+S锁 （有s锁不能加X锁，所以也叫读锁）</p>
<h3 id="3级锁协议"><a href="#3级锁协议" class="headerlink" title="3级锁协议"></a>3级锁协议</h3><h4 id="1级"><a href="#1级" class="headerlink" title="1级"></a>1级</h4><p>读取前，加X锁，<strong>事务完成</strong>后释放<br>（读数据不加锁，所以不能避免不可重复读和脏数据）</p>
<h4 id="2级"><a href="#2级" class="headerlink" title="2级"></a>2级</h4><p>1级+读取前先加S锁。<strong>读完就释放S</strong><br>（可以防止丢失修改，脏数据，但是不能防止不可重复读）</p>
<h4 id="3级"><a href="#3级" class="headerlink" title="3级"></a>3级</h4><p>1级+加S，直到<strong>事务结束释放</strong><br>全部能防</p>
<h4 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h4><p>一个事务总是不能在一个数据项上加锁。-》采用先来先服务</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>等待另一个锁对象<br>都是<strong>死锁预防</strong><br>方法：一次封锁（一次把需要锁的锁上，破坏占有并等待），顺序封锁（破除循环等待）</p>
<p>DBMS使用更多的是诊断并解除</p>
<h4 id="检测并发调度正确性"><a href="#检测并发调度正确性" class="headerlink" title="检测并发调度正确性"></a>检测并发调度正确性</h4><p>可串行性是并行事务正确性的唯一准则<br>（凼且晋档结果与某一次序串行地执行结果相同）</p>
<h3 id="2段锁协议"><a href="#2段锁协议" class="headerlink" title="2段锁协议"></a>2段锁协议</h3><p>在读写前先加锁<br>在释放锁后不能再加任何锁</p>
<p><strong>所有遵循两段锁的事物并行结果一定是正确的</strong><br>可能死锁<br>一次封锁法满足2段锁协议</p>
<p>遵循3级封锁必然遵循2段锁</p>
<h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p>锁强度  <strong>X&gt;S+IX&gt;S=IX&gt;IS</strong><br>IS与X不共存<br>IX与只与IS IX不互斥</p>
<p>封锁方法：  申请：自上而下  释放：自下而上</p>
<h2 id="事务恢复"><a href="#事务恢复" class="headerlink" title="事务恢复"></a>事务恢复</h2><p>原则  已经做完的redo,做到一半的undo.redo从上到下扫描。undo从下到上扫描<br><img src="./1560868291623.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>CS224N-NLP Assignment individual solution</title>
    <url>/2019/12/26/CS224N-NLP%20Assignment%20individual%20solution/</url>
    <content><![CDATA[<h1 id="CS224N-NLP-Assignment-individual-solution"><a href="#CS224N-NLP-Assignment-individual-solution" class="headerlink" title="CS224N-NLP Assignment individual solution"></a>CS224N-NLP Assignment individual solution</h1><h2 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1:"></a>Assignment 1:</h2><p><strong>Q1:Softmax:</strong><br>1.<img src="./1553782661974.png" alt="Alt text"></p>
<blockquote>
<p><strong>Prove:$softmax(x)=softmax(x+c)$,x is a vector and c is a constant</strong><br>begin:<br>Let $x=(x_1,x_2,…,x_n)$<br>and then we know that $softmax(x)=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})$<br>and  $softmax(x+c)=(\frac{e^{x_1+c}}{\sum_j e^{x_j+c}},\frac{e^{x_2+c}}{\sum_j e^{x_j}},…,\frac{e^{x_n+c}}{\sum_j e^{x_j+c}})=\\=(\frac{e^{x_1}e^c}{e^c\sum_j e^{x_j}},\frac{e^{x_2}e^c}{e^c\sum_j e^{x_j}},…,\frac{e^{x_n}e^c}{e^c\sum_j e^{x_j}})=(\frac{e^{x_1}}{\sum_j e^{x_j}},\frac{e^{x_2}}{\sum_j e^{x_j}},…,\frac{e^{x_n}}{\sum_j e^{x_j}})=softmax(x)$<br>Then this question is solved</p>
</blockquote>
<p>2.softmax</p>
<pre><code class="lang-python">import numpy as np

def softmax_inrow(m):
   # print(m)
    rm=np.max(m,axis=1)
    rm_r=rm.reshape(rm.shape[0],1)
    #print(rm_r)
    m1=m-rm_r
    e1=np.exp(m1)
    sum=np.sum(e1,axis=1)
    sum=sum.reshape(sum.shape[0],1)
    e1=e1/sum
    #print(e1)
    return e1

def softmax_incoloum(m):
    # print(m)
    rm = np.max(m, axis=0)
    #rm_r = rm.reshape(rm.shape[0], 1)
    #print(rm)
    m1 = m - rm
    #print(m1)
    e1 = np.exp(m1)
    sum = np.sum(e1, axis=0)
    #sum = sum.reshape(sum.shape[0], 1)
    e1 = e1 / sum
    # print(e1)
    return e1

N=input()
D=input()
matrix=np.random.rand(int(N),int(D))
print(softmax_incoloum(matrix))
#print(softmax2(matrix))
</code></pre>
<p><strong>Q2:</strong><br><strong>2.1:</strong>对sigma求导，并利用sigma函数来表示其导数</p>
<blockquote>
<p>As $\sigma(x)=\frac{1}{1+e^{-x}}$<br>$\sigma’(x)=\frac{e^{-x}}{(1+e^{-x})^2}\\e^{-x}=\frac{1}{\sigma(x)}-1$<br>So,$\sigma’(x)=\sigma(x)(1-\sigma(x))$</p>
</blockquote>
<p><strong>2.2:求softmax作用于$\theta$下,ont-hot和softmax$\theta$交叉熵的梯度</strong></p>
<blockquote>
<p>solution:<br>We know that $CE(y,\hat y)=-\sum_iy_ilog(\hat y_i)$<br>and let $y=(s_1,s_2,…,s_n)$<br>$\theta=(d_1,d_2,…,d_n)$<br>and then $\frac{\partial CE}{\partial d_i}=\frac{\partial CE}{\partial s_k}\frac{\partial s_k}{\partial d_i}$<br>First we consider $\frac{\partial CE}{\partial s_k}$<br>$\frac{\partial CE}{\partial s_k}=\frac{\partial (-\sum_k y_klog(s_k))}{\partial s_k}=-\sum_k y_k\frac{1}{s_k}$<br>and then we consider $\frac{\partial s_k}{\partial d_i}$<br>there are two situations need to consider:<br>when $k=i$<br>$\frac{\partial s_k}{\partial d_i}=\frac{\partial (  \frac{e^z_j}{\sum_ke^z_k}   )}{\partial s_k}=\frac{\partial s_i}{\partial d_i}=s_i-s_i^2$<br>when $k!=i$<br>$\frac{\partial s_k}{\partial d_i}=\frac{\partial (  \frac{e^z_j}{\sum_ke^z_k}   )}{\partial s_k}=-s_is_j$<br>so $\frac{\partial CE}{\partial d_i}=\frac{\partial CE}{\partial s_k}\frac{\partial s_k}{\partial d_i}=-\frac{y_i}{s_i}s_i(1-s_i)+\sum_{i!=j}y_jy_s=s_i-y_i=s_i-1$<br>i.e. <img src="./1553856612131.png" alt="Alt text"></p>
<p>It’s say that the $softmax(\theta)$ minus 1 in element i(i is the label of right prediction),then we get the gradient</p>
</blockquote>
<p><strong>2.3</strong><br><img src="./1553855679457.png" alt="Alt text"><br>loss function使用上述的交叉熵$CE(y,\hat y)$<br>h-&gt;y^激活函数为softmax<br>x-&gt;h激活函数为sigma<br>求梯度<br>$\hat y=softmax(W_2h+b_2)$<br>$h=\sigma(W_1x+b_1)$</p>
<blockquote>
<p>solution:<br>similar to 2.2<br>i is the position index right prediction<br>$\frac{\partial CE}{\partial x_i}=\frac{\partial CE}{\partial \hat y_k}\frac{\partial \hat y_k}{\partial h_j}\frac{\partial h_j}{\partial x_i}$<br>similar to 2.2, $\frac{\partial CE}{\partial x_i}=W_2(\hat y_i-y_i)\frac{\partial h_j}{\partial x_i}$<br>consider $\frac{\partial h_j}{\partial x_i}$<br>if j=1,then $\frac{\partial h_j}{\partial x_i}=W_1\sigma’(W_1x+b)$,else $\frac{\partial h_j}{\partial x_i}=0$<br>so  $\frac{\partial CE}{\partial x_i}=W_2(\hat y_i-y_i)-\sigma’(W_1x+b_1)_iW_1$</p>
</blockquote>
<p><strong>2.4</strong>(在2.3之前先做这题，把维度搞清楚)<br><strong>assuming the input is D x -dimensional, the output is D y -dimensional, and there are H hidden units</strong></p>
<blockquote>
<p>x’s shape is $(M,D_x)$ and $W_1$’s shape is $(D_x,H)$,and $W_2$’s shape is $(H,D_y)$,$b_1$’s shape ‘(1,H)$b_2$’s shape (1,Dy) ‘<br>so there are $H(D_x+1)+D_y(H+1)$ parameters we need to train’</p>
</blockquote>
<p><strong>2.5</strong></p>
<pre><code class="lang-python">import numpy as np

def sigmoid(m):
    t=1.0/(1+np.exp(-m))
    return t

def sigmoid_gradient(x):
    return sigmoid(x)*(1.0-sigmoid(x))
</code></pre>
<p><strong>2.6</strong></p>
<pre><code class="lang-python">import numpy as np
import random
def gradcheck_naive(f, x):
    &quot;&quot;&quot; Gradient check for a function f.
        Arguments:
        f -- a function that takes a single argument and outputs the
             cost and its gradients
        x -- the point (numpy array) to check the gradient at
    &quot;&quot;&quot;

    rndstate = random.getstate()
    random.setstate(rndstate)
    fx, grad = f(x)  # Evaluate function value at original point,获取函数值和梯度
    h = 1e-4  # Do not change this!

    it = np.nditer(x, flags=[&#39;multi_index&#39;], op_flags=[&#39;readwrite&#39;])  #一个迭代器，flags=[&#39;multi_index&#39;]表示对a进行多重索引，op_flags=[&#39;readwrite&#39;]表示不仅可以对x进行read（读取），还可以write（写入）
    while not it.finished:  #开始迭代
        ix = it.multi_index   #获取迭代到的索引，是(a,b)

        # Try modifying x[ix] with h defined above to compute
        # numerical gradients. Make sure you call random.setstate(rndstate)
        # before calling f(x) each time. This will make it possible
        # to test cost functions with built in randomness later.

        ### YOUR CODE HERE:
        x[ix] += h

        random.setstate(rndstate)
        new_f1 = f(x)[0]

        x[ix] -= 2 * h

        random.setstate(rndstate)
        new_f2 = f(x)[0]

        x[ix] += h

        numgrad = (new_f1 - new_f2) / (2 * h)
        ### END YOUR CODE


#比较梯度
        # Compare gradients
        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))
        if reldiff &gt; 1e-5:
            print
            &quot;Gradient check failed.&quot;
            print
            &quot;First gradient error found at index %s&quot; % str(ix)
            print
            &quot;Your gradient: %f \t Numerical gradient: %f&quot; % (
                grad[ix], numgrad)
            return

        it.iternext()  # Step to next dimension

    print(&quot;Gradient check passed!&quot;)
</code></pre>
<p><strong>反向传播梯度计算</strong><br><img src="./1553946699826.png" alt="Alt text"></p>
<p><strong>反向传播梯度计算</strong></p>
<pre><code class="lang-python">
反向传播:
def forward_back_prop(data, labels, params, dimensions):
    &quot;&quot;&quot;
           2个隐层的神经网络的前向运算和反向传播
    &quot;&quot;&quot;
    if len(data.shape) &gt;= 2:
        (N, _) = data.shape

    ### 展开每一层神经网络的参数
    ofs = 0
    Dx, H, Dy = (dimensions[0], dimensions[1], dimensions[2])  #获取3个超参数

#获取所有参数
    W1 = np.reshape(params[ofs:ofs + Dx * H], (Dx, H)) #取出w1,大小Dx * H
    ofs += Dx * H #偏移增加
    b1 = np.reshape(params[ofs:ofs + H], (1, H))
    ofs += H
    W2 = np.reshape(params[ofs:ofs + H * Dy], (H, Dy))
    ofs += H * Dy
    b2 = np.reshape(params[ofs:ofs + Dy], (1, Dy))



    ### 前向传播
    h = sigmoid(np.dot(data,W1) + b1)
    yhat = softmax_inrow(np.dot(h,W2) + b2)
    ### END

    ### 反向传播
    cost = np.sum(-np.log(yhat[labels == 1])) / data.shape[0]  #-ylog(hat_y) (仅取q的项)，然后求平均

    d3 = (yhat - labels) / data.shape[0]
    gradW2 = np.dot(h.T, d3)   #根据公式来，计算gradW2
    gradb2 = np.sum(d3, 0, keepdims=True)


    dh = np.dot(d3, W2.T)
    grad_h = sigmoid_gradient(h) * dh

    gradW1 = np.dot(data.T, grad_h)
    gradb1 = np.sum(grad_h, 0)
    ### END

    ### Stack gradients (do not modify)
    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(),
                           gradW2.flatten(), gradb2.flatten()))
    return cost,grad
</code></pre>
<h3 id="3-word2vec"><a href="#3-word2vec" class="headerlink" title="3.word2vec"></a>3.word2vec</h3><p><img src="./1553957081013.png" alt="Alt text"><br>因为<img src="./1553957203608.png" alt="Alt text"><br>$dsoftmax/dx_o(softmax关于输入向量的梯度)=\hat y-y$<br>链式法则。图中$\hat y=softmax(U^Tv_c)$<br>所以<img src="./1553957378451.png" alt="Alt text"><br>分类讨论。就得<img src="./1553957404306.png" alt="Alt text"></p>
<p><img src="./1554043286463.png" alt="Alt text"></p>
<p><img src="./1554043272986.png" alt="Alt text"></p>
<p>(b)类似a<br><img src="./1553958439129.png" alt="Alt text"></p>
<p>一样。求导就行<br><img src="./1554003540795.png" alt="Alt text"><br><img src="./1554003569566.png" alt="Alt text"><br><img src="./1554004432769.png" alt="Alt text"></p>
<p><img src="./1554040774886.png" alt="Alt text"></p>
<pre><code class="lang-python">import numpy as np
import random

from q1_softmax import softmax_inrow
from q2_gradcheck import gradcheck_naive
from q2_sigmoid import sigmoid, sigmoid_gradient

#normalize:x每个元素都除以各行平方和的平方根。
def normalizeRows(x):
    &quot;&quot;&quot; Row normalization function
    Implement a function that normalizes each row of a matrix to have
    unit length.
    &quot;&quot;&quot;

    ### YOUR CODE HERE
    temp_x=x
    temp_x=np.square(x)

    norm=np.sum(temp_x,axis=1)

    norm=np.sqrt(norm)
    #print(x)
   #print(norm)
    print((x/norm))
    ### END YOUR CODE
    return (x/norm)

#target是目标的位置
def softmaxCostAndGradient(predicted, target, outputVectors, dataset):
    &quot;&quot;&quot; Softmax cost function for word2vec models
        Implement the cost and gradients for one predicted word vector
        and one target word vector as a building block for word2vec
        models, assuming the softmax prediction function and cross
        entropy loss.
        Arguments:
        predicted -- numpy ndarray, predicted word vector (\hat{v} in
                     the written component)
        target -- integer, the index of the target word
        outputVectors -- &quot;output&quot; vectors (as rows) for all tokens
        dataset -- needed for negative sampling, unused here.
        Return:
        cost -- cross entropy cost for the softmax word prediction
        gradPred -- the gradient with respect to the predicted word
               vector  对已预测词向量的梯度
        grad -- the gradient with respect to all the other word
               vectors  对其他所有词向量的梯度
        We will not provide starter code for this function, but feel
        free to reference the code you previously wrote for this
        assignment!
        &quot;&quot;&quot;
    #target是目标位置
    ### YOUR CODE HERE



    # 计算预测结果
    v_hat = predicted  #已经预测的词向量（中心词向量）
    z = np.dot(outputVectors, v_hat)   #预测得分。也就是输出词向量和中心词向量点乘(可以得到结果得分)
    preds = softmax_inrow(z)     #对预测得分softmax

    cost = -np.log(preds[target])  #计算损失

    # 计算梯度
    z = preds.copy()    #预测得分  (其实就是hat_y)
    z[target] -= 1.0    #梯度为 hat^y-y
    #z相当于^y
    grad = np.outer(z, v_hat) #外积 # dJ/dU  hat_y*u_w  v_hat其实就是v_c 计算输出词向量矩阵的梯度
    # np.outer函数:
    # ①对于多维向量，全部展开变为一维向量
    # ②第一个参数表示倍数，使得第二个向量每次变为几倍
    # ③第一个参数确定结果的行，第二个参数确定结果的列

    gradPred = np.dot(outputVectors.T, z) #dJ/dv_c
    ### END YOUR CODE


    return cost, gradPred, grad

def getNegativeSamples(target, dataset, K):
    &quot;&quot;&quot; Samples K indexes which are not the target &quot;&quot;&quot;

    indices = [None] * K
    for k in range(K):
        newidx = dataset.sampleTokenIdx()
        while newidx == target:
            newidx = dataset.sampleTokenIdx()
        indices[k] = newidx
    return indices
def negSamplingCostAndGradient(predicted, target, outputVectors, dataset,
                               K=10):
    &quot;&quot;&quot; Negative sampling cost function for word2vec models

    Implement the cost and gradients for one predicted word vector
    and one target word vector as a building block for word2vec
    models, using the negative sampling technique. K is the sample
    size.

    Note: See test_word2vec below for dataset&#39;s initialization.

    Arguments/Return Specifications: same as softmaxCostAndGradient
    &quot;&quot;&quot;
    # Sampling of indices is done for you. Do not modify this if you
    # wish to match the autograder and receive points!
    #为每个窗口取k个负样本
    indices = [target]
    indices.extend(getNegativeSamples(target, dataset, K))

#初始化
    grad = np.zeros(outputVectors.shape)
    gradPred = np.zeros(predicted.shape)
    cost = 0

    z = sigmoid(np.dot(outputVectors[target],predicted))

    cost -= np.log(z)
    grad[target] += predicted*(z-1.0)
    gradPred = outputVectors[target] * (z-1.0)

    #最小化这些词随中心词出现在中心词附近的概率
    for k in range(K):
        sample = indices[k+1]
        z = sigmoid(np.dot(outputVectors[sample],predicted))
        cost -= np.log(1.0-z)
        grad[sample] += predicted*z
        gradPred += outputVectors[sample] * z
    return cost, gradPred, grad


def skipgram(currentWord, C, contextWords, tokens, inputVectors, outputVectors,
             dataset, word2vecCostAndGradient=softmaxCostAndGradient):
    &quot;&quot;&quot; Skip-gram model in word2vec

    Implement the skip-gram model in this function.

    Arguments:
    currentWord -- a string of the current center word
    C -- integer, context size
    contextWords -- list of no more than 2*C strings, the context words
    tokens -- a dictionary that maps words to their indices in
              the word vector list
    inputVectors -- &quot;input&quot; word vectors (as rows) for all tokens
    outputVectors -- &quot;output&quot; word vectors (as rows) for all tokens
    word2vecCostAndGradient -- the cost and gradient function for
                               a prediction vector given the target
                               word vectors, could be one of the two
                               cost functions you implemented above.

    Return:
    cost -- the cost function value for the skip-gram model
    grad -- the gradient with respect to the word vectors
    &quot;&quot;&quot;
    cost = 0.0
    gradIn = np.zeros(inputVectors.shape)
    gradOut = np.zeros(outputVectors.shape)

    cword_idx = tokens[currentWord]

    v_hat = inputVectors[cword_idx]
    #skipgram即根据当前词预测一定范围内的上下文词汇，选择让概率分部值最大的向量
    for i in contextWords:#对于窗口中的每个单词
        idx = tokens[i] #target的下标(要预测的单词的下标)
        c_cost,c_grad_in,c_grad_out = word2vecCostAndGradient(v_hat,idx,outputVectors,dataset)
        #更新cost、grad 即使用k个单词来训练这个向量
        cost += c_cost
        gradOut += c_grad_out
        gradIn[cword_idx] += c_grad_in
    return cost, gradIn, gradOut
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>CS224n Assignment1</title>
    <url>/2019/12/26/CS224n%20Assignment1/</url>
    <content><![CDATA[<h1 id="CS224n-Assignment1"><a href="#CS224n-Assignment1" class="headerlink" title="CS224n Assignment1"></a>CS224n Assignment1</h1><h2 id="Pre-Import"><a href="#Pre-Import" class="headerlink" title="Pre Import"></a>Pre Import</h2><pre><code class="lang-python"># All Import Statements Defined Here
# Note: Do not add to this list.
# All the dependencies you need, can be installed by running .
# ----------------
import sys
assert sys.version_info[0]==3
assert sys.version_info[1] &gt;= 5
from gensim.models import KeyedVectors
from gensim.test.utils import datapath
import pprint
import matplotlib.pyplot as plt
plt.rcParams[&#39;figure.figsize&#39;] = [10, 5]
import nltk
nltk.download(&#39;reuters&#39;)
from nltk.corpus import reuters
import numpy as np
import random
import scipy as sp
from sklearn.decomposition import TruncatedSVD
from sklearn.decomposition import PCA
START_TOKEN = &#39;&lt;START&gt;&#39;
END_TOKEN = &#39;&lt;END&gt;&#39;
np.random.seed(0)
random.seed(0)
# ----------------
</code></pre>
<h2 id="Part1-Count-Based-Word-Vectors-10-points-基于计数的词向量-10分"><a href="#Part1-Count-Based-Word-Vectors-10-points-基于计数的词向量-10分" class="headerlink" title="Part1:Count-Based Word Vectors (10 points)(基于计数的词向量 (10分))"></a>Part1:Count-Based Word Vectors (10 points)(基于计数的词向量 (10分))</h2><p>读取google 词向量预训练数据的函数</p>
<pre><code class="lang-python">def read_corpus(category=&quot;crude&quot;):
    &quot;&quot;&quot; Read files from the specified Reuter&#39;s category.
        Params:
            category (string): category name
        Return:
            list of lists, with words from each of the processed files
    &quot;&quot;&quot;
    files = reuters.fileids(category)
    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]
</code></pre>
<h3 id="Question-1-Implement-distinct-words-code-2-points"><a href="#Question-1-Implement-distinct-words-code-2-points" class="headerlink" title="Question 1:Implement distinct_words [code] (2 points)"></a>Question 1:Implement distinct_words [code] (2 points)</h3><p>Write a method to work out the distinct words (word types) that occur in the corpus. You can do this with for loops, but it’s more efficient to do it with Python list comprehensions. In particular, this may be useful to flatten a list of lists. If you’re not familiar with Python list comprehensions in general, here’s more information.</p>
<p>You may find it useful to use Python sets to remove duplicate words.</p>
<blockquote>
<p>就是完成 distinct_words函数，找出一个语料库内不重复的词的集合。可以利用python集合类型完成</p>
</blockquote>
<pre><code class="lang-python">def distinct_words(corpus):
    &quot;&quot;&quot; Determine a list of distinct words for the corpus.
        Params:
            corpus (list of list of strings): corpus of documents
        Return:
            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python &#39;sorted&#39; function)
            num_corpus_words (integer): number of distinct words across the corpus
    &quot;&quot;&quot;
    # ------------------
    # Write your implementation here.
    corpus_words = []
    num_corpus_words = -1

    corpus_words=sorted(list(set(itertools.chain.from_iterable(corpus))))
   # print(corpus_words)
    num_corpus_words=len(corpus_words)

    # ------------------
    return corpus_words, num_corpus_words
</code></pre>
<h3 id="Question-1-2-Implement-compute-co-occurrence-matrix-code-3-points"><a href="#Question-1-2-Implement-compute-co-occurrence-matrix-code-3-points" class="headerlink" title="Question 1.2: Implement compute_co_occurrence_matrix [code] (3 points)"></a>Question 1.2: Implement compute_co_occurrence_matrix [code] (3 points)</h3><p>Write a method that constructs a co-occurrence matrix for a certain window-size  n  (with a default of 4), considering words  n  before and  n  after the word in the center of the window. Here, we start to use numpy (np) to represent vectors, matrices, and tensors. If you’re not familiar with NumPy, there’s a NumPy tutorial in the second half of this cs231n Python NumPy tutorial.</p>
<blockquote>
<p>就是完成计算共现矩阵的函数</p>
</blockquote>
<pre><code class="lang-python">def compute_co_occurrence_matrix(corpus, window_size=4):
    &quot;&quot;&quot; Compute co-occurrence matrix for the given corpus and window_size (default of 4).

        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller
              number of co-occurring words.

              For example, if we take the document &quot;START All that glitters is not gold END&quot; with window size of 4,
              &quot;All&quot; will co-occur with &quot;START&quot;, &quot;that&quot;, &quot;glitters&quot;, &quot;is&quot;, and &quot;not&quot;.

        Params:
            corpus (list of list of strings): corpus of documents
            window_size (int): size of context window
        Return:
            M (numpy matrix of shape (number of corpus words, number of corpus words)):
                Co-occurence matrix of word counts.
                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.
            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.
    &quot;&quot;&quot;

    words, num_words = distinct_words(corpus)
    M = None
    word2Ind = {}

    # ------------------
    # Write your implementation here.
    i=0
    for v_c in words:
        #print(v_c,num_words)
        word2Ind.update({v_c: i})
        i=i+1

    M=np.zeros((num_words,num_words))
    for str in corpus:
        for i_v_c in range(len(str)):
            for i_c_o in range(window_size):
                # print(i_c_o)
                if (i_v_c - i_c_o - 1 &gt;= 0):
                    # print(str[i_v_c])
                    M[word2Ind[str[i_v_c]]][word2Ind[str[i_v_c - i_c_o - 1]]] = M[word2Ind[str[i_v_c]]][word2Ind[
                        str[i_v_c - i_c_o - 1]]] + 1
                if (i_v_c + i_c_o + 1 &lt; len(str)):
                    # print(str[i_v_c])
                    M[word2Ind[str[i_v_c]]][word2Ind[str[i_v_c + i_c_o + 1]]] = M[word2Ind[str[i_v_c]]][word2Ind[
                        str[i_v_c + i_c_o + 1]]] + 1
    #print(word2Ind)
    #M=np.matrix([num_words,num_words])

    return M, word2Ind
</code></pre>
<h3 id="Question-1-3-Implement-reduce-to-k-dim-code-1-point"><a href="#Question-1-3-Implement-reduce-to-k-dim-code-1-point" class="headerlink" title="Question 1.3: Implement reduce_to_k_dim [code] (1 point)"></a>Question 1.3: Implement reduce_to_k_dim [code] (1 point)</h3><p>Construct a method that performs dimensionality reduction on the matrix to produce k-dimensional embeddings. Use SVD to take the top k components and produce a new matrix of k-dimensional embeddings.</p>
<p>Note: All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. So please use sklearn.decomposition.TruncatedSVD.</p>
<blockquote>
<p>完成SVD降维函数。要求用sklearn提供的svd函数。所以很简单，直接调用就行<br>``` python<br>def reduce_to_k_dim(M, k=2):<br>    “”” Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)<br>        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:</p>
<pre><code>        - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html
</code></pre></blockquote>
<pre><code>    Params:
        M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurence matrix of word counts
        k (int): embedding size of each word after dimension reduction
    Return:
        M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.
                In terms of the SVD from math class, this actually returns U * S
&quot;&quot;&quot;    
n_iters = 10     # Use this parameter in your call to `TruncatedSVD`
M_reduced = None
print(&quot;Running Truncated SVD over %i words...&quot; % (M.shape[0]))

    # ------------------
    # Write your implementation here.
    pca=PCA(n_components=k)
    M_reduced = pca.fit_transform(M)

    # ------------------
print(&quot;Done.&quot;)
return M_reduced
</code></pre><pre><code>

###Question 1.4: Implement plot_embeddings [code] (1 point)
Here you will write a function to plot a set of 2D vectors in 2D space. For graphs, we will use Matplotlib (plt).

For this example, you may find it useful to adapt this code. In the future, a good way to make a plot is to look at the Matplotlib gallery, find a plot that looks somewhat like what you want, and adapt the code they give.

&gt;也就是根据指定的词和降维到2维后的词向量矩阵，进行绘制2D图像
``` python
def plot_embeddings(M_reduced, word2Ind, words):
    &quot;&quot;&quot; Plot in a scatterplot the embeddings of the words specified in the list &quot;words&quot;.
        NOTE: do not plot all the words listed in M_reduced / word2Ind.
        Include a label next to each point.

        Params:
            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings
            word2Ind (dict): dictionary that maps word to indices for matrix M
            words (list of strings): words whose embeddings we want to visualize
    &quot;&quot;&quot;

    # ------------------
    # Write your implementation here.
    i=0
    print(words)
    print(M_reduced)
    for x in words:
        plt.scatter(M_reduced[word2Ind[x]][0],M_reduced[word2Ind[x]][1],marker=&#39;x&#39;,c=&#39;r&#39;,)
        plt.annotate(x, xy=(M_reduced[word2Ind[x]][0],M_reduced[word2Ind[x]][1]), xytext=(M_reduced[word2Ind[x]][0],M_reduced[word2Ind[x]][1]))
        i=i+1
    plt.show()
    # ------------------
</code></pre><p><img src="./1557206203763.png" alt="Alt text"></p>
<h3 id="Question-1-5-Co-Occurrence-Plot-Analysis-written-3-points"><a href="#Question-1-5-Co-Occurrence-Plot-Analysis-written-3-points" class="headerlink" title="Question 1.5: Co-Occurrence Plot Analysis [written] (3 points)"></a>Question 1.5: Co-Occurrence Plot Analysis [written] (3 points)</h3><p>Now we will put together all the parts you have written! We will compute the co-occurrence matrix with fixed window of 4, over the Reuters “crude” corpus. Then we will use TruncatedSVD to compute 2-dimensional embeddings of each word. TruncatedSVD returns U*S, so we normalize the returned vectors, so that all the vectors will appear around the unit circle (therefore closeness is directional closeness). Note: The line of code below that does the normalizing uses the NumPy concept of broadcasting. If you don’t know about broadcasting, check out Computation on Arrays: Broadcasting by Jake VanderPlas.</p>
<p>Run the below cell to produce the plot. It’ll probably take a few seconds to run. What clusters together in 2-dimensional embedding space? What doesn’t cluster together that you might think should have? Note: “bpd” stands for “barrels per day” and is a commonly used abbreviation in crude oil topic articles.</p>
<blockquote>
<p>就是对真正的语料库结果进行分析。直接运行贴结果就行</p>
</blockquote>
<pre><code class="lang-python"># -----------------------------------------------------------------
# Run Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions
# Note: This may take several minutes
# -----------------------------------------------------------------

# -----------------------------------
# Run Cell to Load Word Vectors
# Note: This may take several minutes
# -----------------------------------
wv_from_bin = load_word2vec()
M, word2Ind = get_matrix_of_vectors(wv_from_bin)
M_reduced = reduce_to_k_dim(M, k=2)
words = [&#39;barrels&#39;, &#39;bpd&#39;, &#39;ecuador&#39;, &#39;energy&#39;, &#39;industry&#39;, &#39;kuwait&#39;, &#39;oil&#39;, &#39;output&#39;, &#39;petroleum&#39;, &#39;venezuela&#39;]
plot_embeddings(M_reduced, word2Ind, words)
</code></pre>
<p><img src="./1557207028995.png" alt="Alt text"></p>
<h2 id="Part-2-Prediction-Based-Word-Vectors-15-points-基于预测的词向量-15分"><a href="#Part-2-Prediction-Based-Word-Vectors-15-points-基于预测的词向量-15分" class="headerlink" title="Part 2: Prediction-Based Word Vectors (15 points)(基于预测的词向量(15分))"></a>Part 2: Prediction-Based Word Vectors (15 points)(基于预测的词向量(15分))</h2><h3 id="Reducing-dimensionality-of-Word2Vec-Word-Embeddings"><a href="#Reducing-dimensionality-of-Word2Vec-Word-Embeddings" class="headerlink" title="Reducing dimensionality of Word2Vec Word Embeddings"></a>Reducing dimensionality of Word2Vec Word Embeddings</h3><blockquote>
<p>Let’s directly compare the word2vec embeddings to those of the co-occurrence matrix. Run the following cells to:<br>Put the 3 million word2vec vectors into a matrix M<br>Run reduce_to_k_dim (your Truncated SVD function) to reduce the vectors from 300-dimensional to 2-dimensional.<br>```<br>def get_matrix_of_vectors(wv_from_bin, required_words=[‘barrels’, ‘bpd’, ‘ecuador’, ‘energy’, ‘industry’, ‘kuwait’, ‘oil’, ‘output’, ‘petroleum’, ‘venezuela’]):<br>    “”” Put the word2vec vectors into a matrix M.<br>        Param:<br>            wv_from_bin: KeyedVectors object; the 3 million word2vec vectors loaded from file<br>        Return:<br>            M: numpy matrix shape (num words, 300) containing the vectors<br>            word2Ind: dictionary mapping each word to its row number in M<br>    “””<br>    import random<br>    words = list(wv_from_bin.vocab.keys())<br>    print(“Shuffling words …”)<br>    random.shuffle(words)<br>    words = words[:10000]<br>    print(“Putting %i words into word2Ind and matrix M…” % len(words))<br>    word2Ind = {}<br>    M = []<br>    curInd = 0<br>    for w in words:<br>        try:<br>            M.append(wv_from_bin.word_vec(w))<br>            word2Ind[w] = curInd<br>            curInd += 1<br>        except KeyError:<br>            continue<br>    for w in required_words:<br>        try:<br>            M.append(wv_from_bin.word_vec(w))<br>            word2Ind[w] = curInd<br>            curInd += 1<br>        except KeyError:<br>            continue<br>    M = np.stack(M)<br>    print(“Done.”)<br>    return M, word2Ind</p>
</blockquote>
<h1 id="————————————————————————————————"><a href="#————————————————————————————————" class="headerlink" title="————————————————————————————————-"></a>————————————————————————————————-</h1><h1 id="Run-Cell-to-Reduce-300-Dimensinal-Word-Embeddings-to-k-Dimensions"><a href="#Run-Cell-to-Reduce-300-Dimensinal-Word-Embeddings-to-k-Dimensions" class="headerlink" title="Run Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions"></a>Run Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions</h1><h1 id="Note-This-may-take-several-minutes"><a href="#Note-This-may-take-several-minutes" class="headerlink" title="Note: This may take several minutes"></a>Note: This may take several minutes</h1><h1 id="————————————————————————————————-1"><a href="#————————————————————————————————-1" class="headerlink" title="————————————————————————————————-"></a>————————————————————————————————-</h1><p>M, word2Ind = get_matrix_of_vectors(wv_from_bin)<br>M_reduced = reduce_to_k_dim(M, k=2)</p>
<pre><code>
###Question 2.1: Word2Vec Plot Analysis [written] (4 points)(词向量绘制解析)
![Alt text](./1557207564892.png)

###Question 2.2: Polysemous Words (2 points) [code + written] (近义词检索)
``` python
wv_from_bin.most_similar(positive=[&quot;woman&quot;,&quot;king&quot;],negative=[&quot;man&quot;],topn=10)
wv_from_bin.most_similar(positive=[&quot;remove&quot;],topn=10)
</code></pre><p><img src="./1557209736550.png" alt="Alt text"></p>
<h3 id="Question-2-3-Synonyms-amp-Antonyms-2-points-code-written"><a href="#Question-2-3-Synonyms-amp-Antonyms-2-points-code-written" class="headerlink" title="Question 2.3: Synonyms &amp; Antonyms (2 points) [code + written]"></a>Question 2.3: Synonyms &amp; Antonyms (2 points) [code + written]</h3><p><img src="./1557216892528.png" alt="Alt text"></p>
<h3 id="Question-2-4-Finding-Analogies-code-written-2-Points"><a href="#Question-2-4-Finding-Analogies-code-written-2-Points" class="headerlink" title="Question 2.4: Finding Analogies [code + written] (2 Points)"></a>Question 2.4: Finding Analogies [code + written] (2 Points)</h3><pre><code class="lang-python">wv_from_bin.most_similar(positive=[&quot;woman&quot;,&quot;king&quot;],negative=[&quot;man&quot;],topn=10)
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>Computer Network——Review From Keywords</title>
    <url>/2019/12/26/Computer%20Network%E2%80%94%E2%80%94Review%20From%20Keywords/</url>
    <content><![CDATA[<h1 id="Computer-Network——Review-From-Keywords"><a href="#Computer-Network——Review-From-Keywords" class="headerlink" title="Computer Network——Review From Keywords"></a>Computer Network——Review From Keywords</h1><blockquote>
<p><a href="https://sakuyui.github.io/2019/04/21/Computer" target="_blank" rel="noopener">https://sakuyui.github.io/2019/04/21/Computer</a> Network——Review From Keywords/   (持续更新)</p>
</blockquote>
<p>[TOC]</p>
<h2 id="Keyword"><a href="#Keyword" class="headerlink" title="Keyword"></a>Keyword</h2><h3 id="Internet-因特网"><a href="#Internet-因特网" class="headerlink" title="Internet(因特网)"></a>Internet(因特网)</h3><blockquote>
<p><strong>Internet</strong> is a global network of all computers that communicative with each other in public languages.It’s a logical network formed by many small subnet.<br>因特网是由所有使用公用语言相互通信的计算机组成的全球网络,是由许多小的子网组成的逻辑网络。</p>
</blockquote>
<p>[extend]<br><strong>Q1:因特网概念的实质是什么?</strong><br>全球信息资源的总汇<br><strong>Q2:计算机设备可以有多个IP地址吗？为什么？什么设备在internet上一定有多个IP地址</strong><br>可以，插多个网卡爱有几个有几个。路由器<br><strong>Q3:一个网段可否赋予不止一个 IP 地址？一个接口可否赋予多个 IP 地址？</strong><br>可以</p>
<h3 id="hosts-end-system-主机-终端系统"><a href="#hosts-end-system-主机-终端系统" class="headerlink" title="hosts/end system(主机\终端系统)"></a>hosts/end system(主机\终端系统)</h3><blockquote>
<p>hosts is same to end system.It refer to all the devices like computer、cell phone、Web cams which being connected to the internet<br>主机和终端系统概念相同，是指所有像计算机、手机、网络摄像头之类的连接到互联网的设备</p>
</blockquote>
<h3 id="ISP-Internet-Service-Provider-因特网服务提供商"><a href="#ISP-Internet-Service-Provider-因特网服务提供商" class="headerlink" title="ISP(Internet Service Provider:因特网服务提供商)"></a>ISP(Internet Service Provider:因特网服务提供商)</h3><blockquote>
<p>Provide the service of accessing the internet<br>提供互联网的接入服务</p>
</blockquote>
<h3 id="Protocol-协议"><a href="#Protocol-协议" class="headerlink" title="Protocol(协议)"></a>Protocol(协议)</h3><blockquote>
<p>Protocol defines the format and the order of messages exchanged between two or more communicating entities.<br>协议定义了两个或多个通信实体间消息的传输格式和流程</p>
</blockquote>
<p><strong>协议的3大要素:</strong><br>synax:语法<br>sematic:语义<br>asynchonomious:同步</p>
<h3 id="API-Application-Programming-Interface-应用程序编程接口"><a href="#API-Application-Programming-Interface-应用程序编程接口" class="headerlink" title="API(Application Programming Interface:应用程序编程接口)"></a>API(Application Programming Interface:应用程序编程接口)</h3><blockquote>
<p>API is a series of functions that have been predefined, programmer can use them when programming no need to consider how these functions work inside.<br>API是预定义的一系列函数。程序员可以在编程中使用，不用管这些函数的内部实现。</p>
</blockquote>
<h3 id="Network-Edge-Network-Core-网络边缘-网络核心"><a href="#Network-Edge-Network-Core-网络边缘-网络核心" class="headerlink" title="Network Edge/Network Core(网络边缘/网络核心)"></a>Network Edge/Network Core(网络边缘/网络核心)</h3><blockquote>
<p><strong>Network Edge</strong> is the devices that in the edge(No more devices connect to them),It main refer to hosts.<br>网络边缘是指在边缘的设备(没有其他的设备来连接他了)，一般是指主机</p>
<p><strong>Network Core</strong> is those devices live switchers and routers,which not in network edge. They take an important role in network interconnection.<br>网络核心是指不在网络边缘的那些设备，比如路由器和交换机。他们对网络的互联起着重要作用</p>
</blockquote>
<h3 id="Transmission-rate-Bandwidth-Throughput-传输速率、带宽、吞吐量"><a href="#Transmission-rate-Bandwidth-Throughput-传输速率、带宽、吞吐量" class="headerlink" title="Transmission rate/Bandwidth/Throughput(传输速率、带宽、吞吐量)"></a>Transmission rate/Bandwidth/Throughput(传输速率、带宽、吞吐量)</h3><blockquote>
<p><strong>Transmission rate:</strong><br>两个设备间数据流动的物理速率。单位bps<br><strong>Bandwidth:</strong><br>数字信道上单位时间内从一端传到另一端的最大数据量.单位bps<br><strong>Throughput</strong><br>实际传输速率(单位时间内流过某个端口实际的数据量),单位也是bps</p>
</blockquote>
<h3 id="Client-Server-服务器-客户端"><a href="#Client-Server-服务器-客户端" class="headerlink" title="Client/Server(服务器/客户端)"></a>Client/Server(服务器/客户端)</h3><blockquote>
<p><strong>Client</strong> is the hosts that initiate a connection.<br><strong>Server</strong> is the hosts that open some ports and wait for clients connect.And then it can provide some services to client.<br>客户端是指主动建立连接的主机<br>服务器是指开放着一些端口，等待着连接的主机。而且能为客户端提供一些服务。</p>
</blockquote>
<p>[Extend]<br><strong>服务器和客户端的不同点:</strong><br>1.建立连接上:服务器被动连接，客户端是主动建立连接<br>2.一般来说服务器是一直开机的主机<br>3.一般来说服务器有恒定的ip地址，或者有恒定的域名能映射到其IP地址，方便客户端找到它。<br>4.一般来说服务器能为客户端提供一些客户端所需的服务</p>
<h3 id="CS-Circuit-Switching-电路交换"><a href="#CS-Circuit-Switching-电路交换" class="headerlink" title="CS(Circuit Switching:电路交换)"></a>CS(Circuit Switching:电路交换)</h3><blockquote>
<p>It’s a kind of switch way that communicate by setting up a actual link,which mainly used in telephone network<br>其是一种通过建立实际链路进行通信的交换方式</p>
</blockquote>
<p><strong>电路交换的3个过程:</strong><br>连接建立<br>信息传输<br>连接拆除</p>
<h4 id="Multiplexing-and-Demultiplexing-复用和解复用"><a href="#Multiplexing-and-Demultiplexing-复用和解复用" class="headerlink" title="Multiplexing and Demultiplexing(复用和解复用)"></a>Multiplexing and Demultiplexing(复用和解复用)</h4><blockquote>
<p>Multiplexing and demultiplexing<br>In <strong>Circuit Switching</strong> it’s says informations can transport asynchronously by using <strong>TDM</strong> or <strong>FDM</strong> and receive side can get the information it need.<br>在电路交换中复用和解复用是指各信息能在信道上异步地传输（通过TDM或FDM）（也就是复用），接收端可以相应地获取是传给自己的信息（解复用）</p>
<p>In <strong>Datagram Switching</strong> it’s<br><strong>将点到点的网络层协议扩展到进程到进程(端到端)的传输层协议</strong>的技术<br><strong>复用:</strong>在源端中<strong>传输层</strong>从不同的socket中将数据片收集起来，加上头信息封装成datagram给网络层<br>(Gathering data from multiple sockets, enveloping data with header)<br><strong>解复用:</strong>接收端<strong>传输层</strong>根据信息把各segment传给相应的socket<br><img src="./1555758159292.png" alt="Alt text"></p>
</blockquote>
<h4 id="TDM-Time-Division-Multiplexing-时分复用"><a href="#TDM-Time-Division-Multiplexing-时分复用" class="headerlink" title="TDM(Time Division Multiplexing:时分复用)"></a>TDM(Time Division Multiplexing:时分复用)</h4><blockquote>
<p>TDM是指将时间分片并编号，用户只占用指定编号的时间片（slot）</p>
</blockquote>
<p>缺点:利用率不高</p>
<h4 id="FDM-Frequency-Division-Multiplexing-频分复用"><a href="#FDM-Frequency-Division-Multiplexing-频分复用" class="headerlink" title="FDM(Frequency Division Multiplexing:频分复用)"></a>FDM(Frequency Division Multiplexing:频分复用)</h4><blockquote>
<p>FDM是指将频域划分。每个用户占用一个频域。</p>
</blockquote>
<p>缺点:信息要丢容易一起丢。</p>
<h3 id="Store-and-forward-存储转发"><a href="#Store-and-forward-存储转发" class="headerlink" title="Store-and-forward(存储转发)"></a>Store-and-forward(存储转发)</h3><blockquote>
<p>是指将数据包收齐后才转发</p>
</blockquote>
<h3 id="End-to-End-Point-to-Point"><a href="#End-to-End-Point-to-Point" class="headerlink" title="End-to-End/Point-to-Point"></a>End-to-End/Point-to-Point</h3><blockquote>
<p><strong>End-to-End</strong> is the feature of transport layer.It’s said that set up a link between source side and destination side before transmission.And sender participate in the transport fully.<br>端到端是传输层的特性。是指在传输之前建立一条链路。且发送端全程参与传输过程</p>
<p><strong>Point-to-Point</strong> is say that every devices send the packets to next device which connect directly,until the packet arrive destination<br>点到点是指每个设备将包发给下一个直连设备，直到包到达接收端</p>
</blockquote>
<p><strong>不同点</strong><br>1.端到端发送端全程参与传输流程，点到点发送端将包发出去后就不管了<br>2.如果目标设备关机或故障。端到端传输不能实现。<br>3.点到点发出去后不知道接收端有没有收到包<br>4.链路建立后端到端知道对方一定能收到<br>5.点到点节约发送方资源<br>6.端到端传输延迟小</p>
<h3 id="Protocol-Stack-协议栈"><a href="#Protocol-Stack-协议栈" class="headerlink" title="Protocol Stack(协议栈)"></a>Protocol Stack(协议栈)</h3><blockquote>
<p>The collection of protocols in same layer<br>同一层所有协议的集合</p>
</blockquote>
<h3 id="Best-effort-尽力而为"><a href="#Best-effort-尽力而为" class="headerlink" title="Best effort(尽力而为)"></a>Best effort(尽力而为)</h3><blockquote>
<p>IP\UDP\以太网等都是尽力而为服务<br>发送端只负责把数据包发送出去，然后不保证对方能收到,或者包没被破坏.</p>
</blockquote>
<p>因特网是一种尽力而为网络。因为对于数据包的转发，只尽最大努力，不保证接收端一定能无损地收到。包可能会在传输过程中被丢弃或收到损坏。</p>
<h3 id="Statistical-Multiplexing-统计复用"><a href="#Statistical-Multiplexing-统计复用" class="headerlink" title="Statistical Multiplexing(统计复用)"></a>Statistical Multiplexing(统计复用)</h3><blockquote>
<p>不同于传统的复用。只对有需求的终端分配时隙</p>
</blockquote>
<h3 id="Bottleneck-link-瓶颈链路"><a href="#Bottleneck-link-瓶颈链路" class="headerlink" title="Bottleneck link(瓶颈链路)"></a>Bottleneck link(瓶颈链路)</h3><blockquote>
<p>Bottleneck linke</p>
</blockquote>
<h3 id="IP-Spoofing-IP欺骗"><a href="#IP-Spoofing-IP欺骗" class="headerlink" title="*IP Spoofing(IP欺骗)"></a>*IP Spoofing(IP欺骗)</h3><p>就是伪装成另一个IP进行数据发送</p>
<h3 id="Man-in-the-middle-attacks-中间人攻击"><a href="#Man-in-the-middle-attacks-中间人攻击" class="headerlink" title="*Man-in-the-middle attacks(中间人攻击)"></a>*Man-in-the-middle attacks(中间人攻击)</h3><p>未授权的实体将自己置于两个通讯系统之间并试图截获正在传递的信息</p>
<h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><blockquote>
<p>In essence it’s a set of APIs.Through these API two end point can establish connection between each other,and each side is called a “Socket”<br>Socket本质上是一组API。通过这些API，两个终端间可以建立起连接。每一端为一个socket.(其是对TCP/IP的封装)</p>
</blockquote>
<h3 id="P2P-Point-to-Point"><a href="#P2P-Point-to-Point" class="headerlink" title="P2P(Point-to-Point)"></a>P2P(Point-to-Point)</h3><blockquote>
<p>在P2P中没有了中心服务器的概念。每个主机都可以是服务器（并不是说没了服务器的概念），资源可以在各个主机间传递。</p>
</blockquote>
<h4 id="BitTorrent-比特流"><a href="#BitTorrent-比特流" class="headerlink" title="BitTorrent(比特流)"></a>BitTorrent(比特流)</h4><blockquote>
<p>BitTorrent是P2P的一种文件传输协议。</p>
<h5 id="Tracker"><a href="#Tracker" class="headerlink" title="Tracker"></a>Tracker</h5><p>Tracker is a server that maintain information of downloader and offer these information to downloader. Make downloader interconnected.<br>Tracker是一个服务器维持着下载者的信息并把这些信息提供给下载者。让下载者相互连接起来传输数据</p>
</blockquote>
<h5 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h5><p>1.用户打开.torrent文件<br>2.连接上tracker.<br>3.获得peer表<br>4.找peer要数据</p>
<p>选块原则:rarest first(稀有优先)</p>
<h5 id="tit-for-tat-针锋相对"><a href="#tit-for-tat-针锋相对" class="headerlink" title="tit-for-tat(针锋相对)"></a>tit-for-tat(针锋相对)</h5><p>一个peer只传块给当前传块给它速率最快的top4(每10秒重新评估)<br>每30秒随机找一个peer传块给它</p>
<h3 id="HTTP-Hyper-Text-Transfer-Protocol-超文本传输协议"><a href="#HTTP-Hyper-Text-Transfer-Protocol-超文本传输协议" class="headerlink" title="HTTP(Hyper Text Transfer Protocol:超文本传输协议)"></a>HTTP(Hyper Text Transfer Protocol:超文本传输协议)</h3><p>端口:80<br>一种发布、接受html文件的协议</p>
<h3 id="RTT-Round-Trip-Time-往返时延"><a href="#RTT-Round-Trip-Time-往返时延" class="headerlink" title="RTT(Round-Trip Time:往返时延)"></a>RTT(Round-Trip Time:往返时延)</h3><p>表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延;</p>
<h3 id="Web-Cache-Proxy-Server-Web缓存或者代理服务器"><a href="#Web-Cache-Proxy-Server-Web缓存或者代理服务器" class="headerlink" title="Web Cache/Proxy Server(Web缓存或者代理服务器)"></a>Web Cache/Proxy Server(Web缓存或者代理服务器)</h3><blockquote>
<p>一般用来起到加速作用。也就是网络请求先发给代理服务器。如果代理服务器存在主机所需资源的话，直接回应主机，否则由代理服务器发请求于目的地。</p>
</blockquote>
<p>加速原理：局域网内带宽非常高。所以由代理服务器直接提供主机资源可以起到加速作用。就算是代理服务器没有的资源，由代理服务器代发请求也是很快的。对于没有的资源代理服务器会向目的地发送请求。获取相应资源后，缓存，并发给主机。</p>
<h3 id="GET-POST"><a href="#GET-POST" class="headerlink" title="GET/POST"></a>GET/POST</h3><blockquote>
<p>GET和POST都是发送http请求的方法</p>
</blockquote>
<p>不同点:<br><strong>Get:</strong>一个请求只发一个包。参数直接显示在请求url上。只能进行url编码,请求会被缓存,请求有长度限制<br>优点：效率高<br><strong>POST:</strong>一个请求会发两个包（先发header再发数据）,可以进行各种编码，无长度限制，不会被缓存。</p>
<h3 id="FTP-File-Transfer-Protocol-文件传输协议"><a href="#FTP-File-Transfer-Protocol-文件传输协议" class="headerlink" title="FTP(File Transfer Protocol:文件传输协议)"></a>FTP(File Transfer Protocol:文件传输协议)</h3><blockquote>
<p>一种用于文件传输的应用层协议。有两个连接(也就是带外传输技术)，一个端口为<strong>20(传数据)</strong>,一个为<strong>21(控制)</strong>.</p>
</blockquote>
<h3 id="User-agent-用户代理"><a href="#User-agent-用户代理" class="headerlink" title="User agent(用户代理)"></a>User agent(用户代理)</h3><blockquote>
<p>一个方便用户接收邮件的东西。相当于一个邮件阅读器。具有<strong>编辑</strong>，<strong>创作</strong>，<strong>浏览</strong>功能</p>
</blockquote>
<h3 id="SMTP-Simple-Mail-Transfer-Protocol"><a href="#SMTP-Simple-Mail-Transfer-Protocol" class="headerlink" title="SMTP(Simple Mail Transfer Protocol)"></a>SMTP(Simple Mail Transfer Protocol)</h3><p>端口:25<br>用来发简单邮件的</p>
<h3 id="MIME-Multipurpose-Internet-Mail-Extensions-多用途因特网邮件拓展"><a href="#MIME-Multipurpose-Internet-Mail-Extensions-多用途因特网邮件拓展" class="headerlink" title="MIME(Multipurpose Internet Mail Extensions:多用途因特网邮件拓展)"></a>MIME(Multipurpose Internet Mail Extensions:多用途因特网邮件拓展)</h3><p>可以传输带有多媒体等的邮件</p>
<h3 id="IMAP-Internet-Mail-Access-Protocol-Internet-邮件访问协议"><a href="#IMAP-Internet-Mail-Access-Protocol-Internet-邮件访问协议" class="headerlink" title="IMAP(Internet Mail Access Protocol:Internet 邮件访问协议)"></a>IMAP(Internet Mail Access Protocol:Internet 邮件访问协议)</h3><p>收邮件的协议</p>
<h3 id="POP3-Post-Office-Protocol-3-邮局协议3"><a href="#POP3-Post-Office-Protocol-3-邮局协议3" class="headerlink" title="POP3(Post Office Protocol 3:邮局协议3)"></a>POP3(Post Office Protocol 3:邮局协议3)</h3><p>也是用来收邮件的协议。<br>有<strong>下载删除模式</strong>和<strong>下载保留模式</strong>。前者下载邮件后就会在服务器上删除。当换一台主机后就没办法访问已接受的邮件。</p>
<p><strong>与IMAP</strong>的不同<br>POP3允许邮件客户端（Mail client）下载服务器上的邮件。但是在客户端上的操作不会反馈到邮件服务器上（如移动邮件，标记已读等）。<br>IMAP下客户端的操作会反馈到服务器上<br><img src="./1555762665040.png" alt="Alt text"></p>
<h3 id="Pull-push-protocol"><a href="#Pull-push-protocol" class="headerlink" title="Pull/push protocol"></a>Pull/push protocol</h3><blockquote>
<p>pull protocol如HTTP,是用来“拉取数据”的协议。<br>push protocol如SMTP是用来“推”数据到服务器的协议</p>
</blockquote>
<h3 id="DNS-Domain-Name-System-域名系统"><a href="#DNS-Domain-Name-System-域名系统" class="headerlink" title="DNS(Domain Name System:域名系统)"></a>DNS(Domain Name System:域名系统)</h3><blockquote>
<p>是一个将域名和IP地址相互映射的<strong>分布式</strong>数据库，使人们更好地访问互联网</p>
</blockquote>
<p><strong>DNS服务器的类型：</strong><br>Root server（根服务器）<br><strong>TLD(Top Layer Domain) server</strong> （顶层域DNS）<br><strong>Authoritative DNS</strong> server(权威DNS)  :组织、部门之类的DNS服务器</p>
<p><strong>local DNS server</strong>（本地DNS）由各大运行商提供</p>
<p><strong>采用分布式而不是中心化DNS服务器的原因</strong><br>！！！(一般的中心化方案都会有以下缺点)<br>1.单点失效（single point fail）<br>2.拥塞量（traffic volume）<br>3.与中心数据库的距离<br>4,维护难(Maintenance)</p>
<h3 id="RRs-Resource-records"><a href="#RRs-Resource-records" class="headerlink" title="RRs(Resource records)"></a>RRs(Resource records)</h3><blockquote>
<p>也就是DNS数据库中的记录，其是一个四元组(Name,Value,Type,TTL)</p>
</blockquote>
<h3 id="DHTs-Distibution-Hash-Tables-分布式哈希表"><a href="#DHTs-Distibution-Hash-Tables-分布式哈希表" class="headerlink" title="DHTs(Distibution Hash Tables:分布式哈希表)"></a>DHTs(Distibution Hash Tables:分布式哈希表)</h3><blockquote>
<p>一种分布式存储方<br>在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。</p>
</blockquote>
<p><strong>BitTorrent</strong>可以选用DHTs作为分布式tracker</p>
<h3 id="UDP-User-Datagram-Protocol-用户数据报协议"><a href="#UDP-User-Datagram-Protocol-用户数据报协议" class="headerlink" title="UDP(User Datagram Protocol:用户数据报协议)"></a>UDP(User Datagram Protocol:用户数据报协议)</h3><blockquote>
<p>UDP是一种传输层协议，提供<strong>connectionless</strong>,<strong>unreliable</strong>,<strong>best-effort服务</strong>，其可由二元组标识(source port,dest port)<br>使用UDP传输不需要事先建立连接(connectionless)。其是不可靠的，尽力而为的服务。发出包后无确认机制，拥塞控制、流量控制等（unreliable),不保证对方一定能收到（best-effort).一般用于流媒体、游戏等loss-tolerant,且对bandwidth-sensitive的应用.因为UDP不用建立连接，没有拥塞控制、流量控制等机制，所以传输时延小。可以提供高效服务<br><img src="./1555765803225.png" alt="Alt text"><br>length=len(header(64bits)+data)  单位是B,最大长度65535(2^16-1)<br><strong>FIN</strong>:结束连接用的<br><strong>SYN</strong>:建立连接用的<br>RST:重置连接<br>ACK标识ack有效</p>
</blockquote>
<p>UDP长度项为16bit,单位为字节。最大长度65535(2^16-1),是指整个包的大小（头+数据）</p>
<p><strong>使用UDP进行可靠传输</strong>：<br>可以在应用层实现</p>
<p>UDP,使用二元组(ip，port)标识,无连接。<br><strong>应用层控制更加精细，能容忍丢失，不希望过分延迟</strong><br><strong>无需建立连接</strong><br><strong>首部开销少</strong></p>
<p><strong>UDP是端到端</strong><br><img src="./1553257256426.png" alt="Alt text"></p>
<h3 id="TCP-Transmission-Control-Protocol-传输控制协议"><a href="#TCP-Transmission-Control-Protocol-传输控制协议" class="headerlink" title="TCP(Transmission Control Protocol:传输控制协议)"></a>TCP(Transmission Control Protocol:传输控制协议)</h3><blockquote>
<p>TCP是一种传输层协议，提供connection-orient,reliable服务。在传输之前需要通过3次握手建立连接。且有确认，重传，拥塞控制、流量控制等机制保障可靠传输。其需要一个4元组标识（source ip,source port,dest ip,dest port)<br><img src="./1555765978243.png" alt="Alt text"><br>对于TCP协议来说，整个包的最大长度是由<strong>最大传输大小（MSS，Maxitum Segment Size）决定</strong>，MSS就是TCP数据包每次能够传输的最大数据分段。为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以<strong>往往MSS为1460</strong>。 通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。</p>
</blockquote>
<p><strong>header length:一般来说options为空，所以20字节</strong></p>
<h3 id="ARQ-protocol-Automatic-Repeat-reQuest-自动重传请求"><a href="#ARQ-protocol-Automatic-Repeat-reQuest-自动重传请求" class="headerlink" title="ARQ protocol(Automatic Repeat reQuest:自动重传请求)"></a>ARQ protocol(Automatic Repeat reQuest:自动重传请求)</h3><blockquote>
<p>接收方请求发送方重传出错的数据报文来恢复出错的报文，是通信中用于处理信道所带来差错的方法之一</p>
</blockquote>
<h3 id="Stop-and-wait（停等）"><a href="#Stop-and-wait（停等）" class="headerlink" title="Stop-and-wait（停等）"></a>Stop-and-wait（停等）</h3><blockquote>
<p>是rdt2.0引入的方式。也就是发出包后，一直等ACK或者NAK到达<br><img src="./1555767506217.png" alt="Alt text"><br><img src="./1555767494332.png" alt="Alt text"></p>
</blockquote>
<h3 id="Alternating-bit-protocol-交替位协议"><a href="#Alternating-bit-protocol-交替位协议" class="headerlink" title="Alternating-bit protocol(交替位协议)"></a>Alternating-bit protocol(交替位协议)</h3><blockquote>
<p>指rdt3.0,也就是交替地等待序号为0/1的包</p>
</blockquote>
<h3 id="GBN-GO-BACK-N"><a href="#GBN-GO-BACK-N" class="headerlink" title="GBN(GO-BACK-N)"></a>GBN(GO-BACK-N)</h3><blockquote>
<p>GBN也叫<strong>Sliding Window</strong>协议。任何时刻包会有4种状态：<strong>已确认</strong>、<strong>已发送尚未确认</strong>.<strong>可用，未发送</strong>、<strong>不可用</strong><br>窗口内包含<strong>已发送尚未确认</strong>.<strong>可用，未发送</strong>的数据。<br>GBN的算法是。只接受当前需要的包（也就是按顺序的包）。顺序不对的包全部丢弃，并发一个ack回去，指明当前需要的包。<img src="./1555767299586.png" alt="Alt text"><br>窗口大小必须=$2^n-1$</p>
</blockquote>
<h3 id="SR-Selective-Repeat-选择重传"><a href="#SR-Selective-Repeat-选择重传" class="headerlink" title="SR(Selective Repeat:选择重传)"></a>SR(Selective Repeat:选择重传)</h3><blockquote>
<p>也是利用窗口的一种缓冲方式。。不同于GBN。SR会缓存接受到的包。<br>过程:<br>sender:<br>1.如果有可以发送的包，就发送<br>2.timeout:重发包<br>3.收到ack,标记为acked<br>4.如果是最小序号的ack.就滑动窗口</p>
</blockquote>
<p>receiver:<br>1.发送ack<br>2.对于乱序版，缓存<br>3.同样，缓存的包能连起来了就移动窗口</p>
<p>窗口大小必须<strong>小于1/2 seq号的取值范围</strong></p>
<h3 id="three-way-handshake"><a href="#three-way-handshake" class="headerlink" title="three-way handshake"></a>three-way handshake</h3><blockquote>
<p>也就是TCP建立连接的三次握手<br>这种感觉<br><img src="./1555768094902.png" alt="Alt text"></p>
<p>关闭连接<img src="./1555768229276.png" alt="Alt text"></p>
</blockquote>
<h3 id="MSS-Maximum-segment-size-最大段长度"><a href="#MSS-Maximum-segment-size-最大段长度" class="headerlink" title="MSS(Maximum segment size:最大段长度)"></a>MSS(Maximum segment size:最大段长度)</h3><h3 id="MTU-Maximum-Transmission-unit-最大传输单元"><a href="#MTU-Maximum-Transmission-unit-最大传输单元" class="headerlink" title="MTU(Maximum Transmission unit:最大传输单元)"></a>MTU(Maximum Transmission unit:最大传输单元)</h3><p>一般取<strong>1460B</strong></p>
<h3 id="Checksum-校验和"><a href="#Checksum-校验和" class="headerlink" title="Checksum(校验和)"></a>Checksum(校验和)</h3><blockquote>
<p>Checksum（校验和）是在UDP\TCP\IP头部中存在的，用来对包进行校验的信息</p>
</blockquote>
<p>计算方式。首先包里检验和部分填0.<br>16bit（2个字节）相加。（数据部分为奇数字节的话，后面补0）。进位的话，则将高于16字节的进位部分的值加到最低位上<br>最终结果取反码</p>
<p>[注]<br><strong>对于UDP</strong>：伪首部也要加上(12字节)<br><img src="./1555768669347.png" alt="Alt text"></p>
<p>UDP’s checksum=伪首部+首部+数据<br><img src="./1555768703001.png" alt="Alt text"></p>
<p><strong>对于TCP:</strong><br>同样加上伪首部</p>
<p><img src="./1555768776750.png" alt="Alt text"></p>
<p><strong>IP校验和只校验20字节的IP报头</strong><br><strong>ICMP校验和覆盖整个报文(ICMP报头+ICMP数据)</strong><br><strong>UDP和TCP校验和不仅覆盖整个报文，而且还有12个字节的IP伪首部，包括源IP地址(4字节)、目的IP地址(4字节)、协议(2字节)、TCP/UDP包长(2字节)</strong></p>
<h3 id="Congestion-Control-拥塞控制"><a href="#Congestion-Control-拥塞控制" class="headerlink" title="Congestion Control(拥塞控制)"></a>Congestion Control(拥塞控制)</h3><h4 id="slow-start-慢启动"><a href="#slow-start-慢启动" class="headerlink" title="slow start(慢启动)"></a>slow start(慢启动)</h4><p>慢启动的算法如下(cwnd全称Congestion Window)：</p>
<blockquote>
<p>1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。</p>
<p>2）每当收到一个ACK，cwnd++; 呈线性上升</p>
<p>3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升</p>
<p>4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）</p>
</blockquote>
<p>所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。<br><img src="./1554633935412.png" alt="Alt text"></p>
<h3 id="Congestion-Avoidance-拥塞避免"><a href="#Congestion-Avoidance-拥塞避免" class="headerlink" title="Congestion Avoidance(拥塞避免)"></a>Congestion Avoidance(拥塞避免)</h3><h4 id="拥塞避免状态"><a href="#拥塞避免状态" class="headerlink" title="拥塞避免状态"></a>拥塞避免状态</h4><p>前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会<strong>进入“拥塞避免算法”。</strong>一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：</p>
<p>1）收到一个ACK时，cwnd = cwnd + 1/cwnd</p>
<p>2）当每过一个RTT时，<strong>cwnd = cwnd + 1</strong></p>
<p>这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法</p>
<h4 id="拥塞状态"><a href="#拥塞状态" class="headerlink" title="拥塞状态"></a>拥塞状态</h4><p>前面我们说过，当丢包的时候，会有两种情况：</p>
<p><strong>1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。</strong></p>
<p>sshthresh =  cwnd /2<br>cwnd 重置为 1<br>进入<strong>慢启动过程</strong></p>
<p>(窗口大小重置1,ssthresh减半)</p>
<p><strong>2）Fast Retransmit(快速重传)算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。</strong></p>
<blockquote>
<p>这个情况，还能收到3个重复ack,说明网络状况不算太糟糕。所以窗口不是置1，而是减半<br>TCP Tahoe的实现和RTO超时一样。<br>TCP Reno的实现是：<br>cwnd = cwnd /2<br>sshthresh = cwnd<br>进入快速恢复算法——Fast Recovery<br>上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd&lt;=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。</p>
</blockquote>
<h3 id="Fast-recovery-快恢复"><a href="#Fast-recovery-快恢复" class="headerlink" title="Fast recovery(快恢复)"></a>Fast recovery(快恢复)</h3><p>这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：</p>
<p><strong>cwnd = cwnd /2</strong><br><strong>sshthresh = cwnd</strong><br>然后，真正的Fast Recovery算法如下：</p>
<p>cwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）<br>重传Duplicated ACKs指定的数据包<br>如果再收到 duplicated Acks，那么cwnd = cwnd +1<br>如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。<br>如果你仔细思考一下上面的这个算法，你就会知道，上面这个算法也有问题，那就是——它依赖于3个重复的Acks。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。</p>
<h3 id="Flow-control-流量控制"><a href="#Flow-control-流量控制" class="headerlink" title="Flow control(流量控制)"></a>Flow control(流量控制)</h3><blockquote>
<p>保证接收方可用窗口大小大于或等于当前数据大小</p>
</blockquote>
<h3 id="End-to-end-Congestion-control-amp-Network-assisted-Congestion-control"><a href="#End-to-end-Congestion-control-amp-Network-assisted-Congestion-control" class="headerlink" title="End-to-end Congestion control&amp;Network-assisted Congestion control"></a>End-to-end Congestion control&amp;Network-assisted Congestion control</h3><p><strong>End-to-End 型：如靠TCP解决拥塞</strong><br><strong>网络协助型:网络层组件（如路由器）可以对拥塞状态进行反馈，从而进行控制.比如ATM ABR，带有标识符CI(拥塞)和NI(不算拥塞)进行拥塞控制.</strong></p>
<h3 id="RM-cells-Resource-management-cells"><a href="#RM-cells-Resource-management-cells" class="headerlink" title="RM cells(Resource-management cells)"></a>RM cells(Resource-management cells)</h3><blockquote>
<p>在ATM ABR 中可以用来传递拥塞相关信息的包块（ATM ABR中有data cells和rm cells).RM cell中包含CI NI EFCI ER等域</p>
</blockquote>
<h3 id="EFCI-Explicit-Forward-Congestion-Indication-明确转发拥塞指示"><a href="#EFCI-Explicit-Forward-Congestion-Indication-明确转发拥塞指示" class="headerlink" title="EFCI(Explicit Forward Congestion Indication:明确转发拥塞指示):"></a>EFCI(Explicit Forward Congestion Indication:明确转发拥塞指示):</h3><p>在data cell中。中途交换机能够把这位置1.如果目的方看见很多数据包这位为1的话。发个RM包给接收方。CI=1.告诉接收方拥塞了</p>
<h3 id="CI-Congestion-indication"><a href="#CI-Congestion-indication" class="headerlink" title="CI(Congestion indication)"></a>CI(Congestion indication)</h3><h3 id="NI-No-increase"><a href="#NI-No-increase" class="headerlink" title="NI(No increase)"></a>NI(No increase)</h3><h3 id="ER-Explicit-Rate-明确速率"><a href="#ER-Explicit-Rate-明确速率" class="headerlink" title="ER(Explicit Rate:明确速率)"></a>ER(Explicit Rate:明确速率)</h3><h3 id="ATM-Asynchronous-Transfer-Mode-异步传输模式"><a href="#ATM-Asynchronous-Transfer-Mode-异步传输模式" class="headerlink" title="ATM(Asynchronous Transfer Mode:异步传输模式)"></a>ATM(Asynchronous Transfer Mode:异步传输模式)</h3><blockquote>
<p>ATM一种包交换技术，与以太网、令牌环网、FDDI等网咯使用的可变长度包技术不同ATM使用<strong>53字节固定长度</strong>的单元(cell)进行交换。采用电路交换的方式，</p>
</blockquote>
<h3 id="AIMD-Additive-Increase-Multiplicative-Decrease-和式增加，积式减少"><a href="#AIMD-Additive-Increase-Multiplicative-Decrease-和式增加，积式减少" class="headerlink" title="AIMD(Additive Increase Multiplicative Decrease:和式增加，积式减少)"></a>AIMD(Additive Increase Multiplicative Decrease:和式增加，积式减少)</h3><blockquote>
<p>就是收到AKC的时候cwnd+1,看到Loss或者timeout就cwnd/2了</p>
</blockquote>
<h3 id="NAT-Network-Address-Translation-网络地址转换"><a href="#NAT-Network-Address-Translation-网络地址转换" class="headerlink" title="NAT(Network Address Translation:网络地址转换)"></a>NAT(Network Address Translation:网络地址转换)</h3><blockquote>
<p>可以将一个公网地址映射到局域网地址的技术</p>
<h3 id="IP-Internet-Protocol-互联网协议"><a href="#IP-Internet-Protocol-互联网协议" class="headerlink" title="IP(Internet Protocol:互联网协议)"></a>IP(Internet Protocol:互联网协议)</h3></blockquote>
<h3 id="VC-Virtual-Circuit-虚电路"><a href="#VC-Virtual-Circuit-虚电路" class="headerlink" title="VC(Virtual Circuit:虚电路)"></a>VC(Virtual Circuit:虚电路)</h3><blockquote>
<p>是分组交换的两种传输方式中的一种,不同于数据报网络。其提供的是面向连接的服务，工作模式类似于电路交换不过线路是虚拟的<br>过程1.建立虚电路<br>2.传输数据<br>3.虚电路释放</p>
</blockquote>
<p><strong>VC的组成:</strong><br>1.path(路径)<br>2.VC number(VC号)<br>3.entries(实体)</p>
<p>转发表类似:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Incoming Interface</th>
<th style="text-align:right">Incoming VC num</th>
<th style="text-align:center">Outgoing Interface</th>
<th>Outgoing VC num</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:right">16</td>
<td style="text-align:center">2</td>
<td>22</td>
</tr>
</tbody>
</table>
</div>
<p>VC号经过转发表后可以被改变</p>
<h3 id="prefix-前缀"><a href="#prefix-前缀" class="headerlink" title="prefix(前缀)"></a>prefix(前缀)</h3><blockquote>
<p>prefix是指网络号部分。比如  xxxx.xxx.xxx.xxx/y,前缀就是指前y位.</p>
</blockquote>
<h3 id="Forwarding-amp-Routing-转发和路由"><a href="#Forwarding-amp-Routing-转发和路由" class="headerlink" title="Forwarding &amp; Routing(转发和路由)"></a>Forwarding &amp; Routing(转发和路由)</h3><blockquote>
<p>转发是将一个口进来的包，选择从那个口扔出去（选择口）<br>路由是选择路径发包（选路），这路径是根据路由算法决定的</p>
</blockquote>
<h3 id="ABR-Avaliable-Bit-rate-可用比特率"><a href="#ABR-Avaliable-Bit-rate-可用比特率" class="headerlink" title="ABR(Avaliable Bit rate:可用比特率)"></a>ABR(Avaliable Bit rate:可用比特率)</h3><blockquote>
<p>只需指定峰值（Peak）和谷值（Minimum）信元速率</p>
<h3 id="CBR-Constant-Bit-rate-固定比特率"><a href="#CBR-Constant-Bit-rate-固定比特率" class="headerlink" title="CBR(Constant Bit rate:固定比特率)"></a>CBR(Constant Bit rate:固定比特率)</h3><p>有固定的带宽（速率）要求，适用实时的话音和视频信号传输。<br><img src="./1555772354155.png" alt="Alt text"></p>
</blockquote>
<h3 id="Qos-Quality-of-Service-服务质量"><a href="#Qos-Quality-of-Service-服务质量" class="headerlink" title="Qos(Quality of Service:服务质量)"></a>Qos(Quality of Service:服务质量)</h3><blockquote>
<p>指一个网络能够利用各种基础技术，为指定的网络通信提供更好的服务能力</p>
<h3 id="ICMP-Internet-Control-Message-Protocol-互联网控制消息协议"><a href="#ICMP-Internet-Control-Message-Protocol-互联网控制消息协议" class="headerlink" title="ICMP(Internet Control Message Protocol:互联网控制消息协议)"></a>ICMP(Internet Control Message Protocol:互联网控制消息协议)</h3><p>ICMP是IP的子协议，用来发送控制消息.</p>
</blockquote>
<p><strong>ping的原理就是发ICMP echo类型的包，然后等对方回应</strong></p>
<p>ICMP也可以进行重定向（<strong>Redirect</strong>)<br>比如:<br><img src="./1555772921436.png" alt="Alt text"><br>1.H1目前路由表是要找R1。于是需要发个ICMP echo包到R1<br>2.在这之前先发个ARP请求R1 MAC地址。R1收到ARP后回应<br>3.把MAC地址装到Datagram发出去<br>4.显然,R1发现这ICMP echo包不是发给他的（要找R2的）于是就转发给R2<br>5.然后R1发一个ICMP redirect给主机<br>6.R2收到被R1转发的ICMP echo包了，但是不知道PC MAC地址。于是ARP来一波<br>7.主机应答ARP<br>8.R2获取到MAC后，就把能ICMP respond发给主机了</p>
<h3 id="IPv4-amp-v6"><a href="#IPv4-amp-v6" class="headerlink" title="IPv4&amp;v6"></a>IPv4&amp;v6</h3><blockquote>
<p>就是ip版本为4和6的协议</p>
</blockquote>
<p><strong>不同点</strong><br>v6:<br>1.IP地址升级到了128bit(V4是32bit)</p>
<blockquote>
<p><strong>v4-&gt;v6地址转换方法</strong>:前面96为全部置0就行</p>
</blockquote>
<p>2.去掉了checksum<br>3.固定首部为40B(基本首部)<br>4.增强了安全性<br>5.增强了对QoS的支持<br>6.对任播(<strong>anycast</strong>)的支持<br>7.v4的options变成了拓展首部</p>
<h3 id="IPv6-payload-IPv6有效负荷"><a href="#IPv6-payload-IPv6有效负荷" class="headerlink" title="IPv6 payload(IPv6有效负荷)"></a>IPv6 payload(IPv6有效负荷)</h3><blockquote>
<p>就是整个v6包去掉基本首部(40B)</p>
</blockquote>
<h3 id="HOL-blocking"><a href="#HOL-blocking" class="headerlink" title="HOL blocking"></a>HOL blocking</h3><blockquote>
<p>就是指队列中排在前面的包阻碍了后面包的转发</p>
</blockquote>
<h3 id="TTL-Time-to-Live-生存时间"><a href="#TTL-Time-to-Live-生存时间" class="headerlink" title="TTL(Time to Live:生存时间)"></a>TTL(Time to Live:生存时间)</h3><blockquote>
<p>在IPv4中，是<strong>包头的一个8 bit字段</strong>，指定该包允许通过的<strong>最大网段数量</strong>,Max=255.可以用来防止路由环路(包无限循环地转发)</p>
</blockquote>
<h3 id="TOS-Type-of-Service-服务类型"><a href="#TOS-Type-of-Service-服务类型" class="headerlink" title="*TOS(Type-of-Service:服务类型)"></a>*TOS(Type-of-Service:服务类型)</h3><h3 id="AQM-Active-queue-management-主动队列管理"><a href="#AQM-Active-queue-management-主动队列管理" class="headerlink" title="AQM(Active queue management:主动队列管理)"></a>AQM(Active queue management:主动队列管理)</h3><blockquote>
<p><strong>AQM</strong>指路由器在缓存耗尽之前有计划地丢弃一部分分组。就可以提早通知发送方降低发送速率，避免可能出现的危险</p>
</blockquote>
<p><strong>Extend:</strong><br><strong>常见的队列管理方式是：队尾丢弃（缓冲区满后所有到达包都会被丢弃）</strong><br>会出现3个问题<br><strong>1.死锁</strong></p>
<h4 id="2-全局同步（Global-Synchronization"><a href="#2-全局同步（Global-Synchronization" class="headerlink" title="2.全局同步（Global Synchronization)"></a><strong>2.全局同步（Global Synchronization)</strong></h4><blockquote>
<p>指短时间内包被大量丢弃，然后由于TCP自适应功能，窗口大小急剧减小，然后网络又变好了，窗口又开始增大，又造成拥塞</p>
</blockquote>
<p><strong>3.满队列</strong></p>
<h3 id="RED-Random-Early-Detection-随机早期检测"><a href="#RED-Random-Early-Detection-随机早期检测" class="headerlink" title="*RED(Random Early Detection:随机早期检测)"></a>*RED(Random Early Detection:随机早期检测)</h3><blockquote>
<p>RED是指通过监控路由器<strong>输出端口队列的平均长度</strong>来探测拥塞，一旦发现拥塞逼近，就<strong>随机地选择连接来通知拥塞</strong>，使他们在队列溢出导致丢包之前减小拥塞窗口，降低发送数据速度，从而缓解网络拥塞</p>
</blockquote>
<h3 id="subnet-子网"><a href="#subnet-子网" class="headerlink" title="subnet(子网)"></a>subnet(子网)</h3><blockquote>
<p>子网可以由路由器划分。一般在路由器正常连接下每一个接口都是一个子网。子网可以通过配置的不同的网络号进行区分。</p>
</blockquote>
<h3 id="subnet-mask-子网掩码"><a href="#subnet-mask-子网掩码" class="headerlink" title="subnet mask(子网掩码)"></a>subnet mask(子网掩码)</h3><blockquote>
<p>子网掩码就是将网络位全部置1，主机位全部置0的结果</p>
</blockquote>
<h3 id="CIDR-Classless-Inter-Domain-Routing-无类别域间路由"><a href="#CIDR-Classless-Inter-Domain-Routing-无类别域间路由" class="headerlink" title="CIDR(Classless Inter-Domain Routing:无类别域间路由)"></a>CIDR(Classless Inter-Domain Routing:无类别域间路由)</h3><blockquote>
<p>也就是不分ABCD类网络了。具体网络号是前多少位由 xxxx.xxx.xxx.xxx/yy 中的yy决定</p>
</blockquote>
<p><strong>CIDR可以有效提高IP地址利用率</strong></p>
<h3 id="DHCP-Dynamic-Host-Configuration-Protocol-动态主机配置协议"><a href="#DHCP-Dynamic-Host-Configuration-Protocol-动态主机配置协议" class="headerlink" title="DHCP(Dynamic Host Configuration Protocol:动态主机配置协议)"></a>DHCP(Dynamic Host Configuration Protocol:动态主机配置协议)</h3><blockquote>
<p>DHCP是一个网络层的协议，用来动态获取IP地址</p>
</blockquote>
<p>实现原理:<br>首先需要一台DHCP服务器<br>然后<br>step 1.Host不知道DHCP服务器在哪。于是发个<strong>广播</strong>-<strong>dhcp discover</strong>(dhcp发现)。(注:源IP地址全0，因为还没IP)<br>step 2.dhcp服务器收到这个广播包，于是发个<strong>DHCP offer</strong>(..这是实际上已经得到一个地址了)<br>step 3:host发个request,告诉DHCP这个IP地址他要用了（还是广播包），如果不发request直接用的话，DHCP服务器不知道刚才发的包host有没有收到。所以再来一轮的相互确认。<br>step 4:dhcp发个ack，表明已经收到请求，可以使用那个地址。</p>
<h3 id="ICANN-Internet-Corporation-for-Assign-Names-and-Numbers-互联网名称与数字地址分配机构"><a href="#ICANN-Internet-Corporation-for-Assign-Names-and-Numbers-互联网名称与数字地址分配机构" class="headerlink" title="ICANN(Internet Corporation for Assign Names and Numbers:互联网名称与数字地址分配机构)"></a>ICANN(Internet Corporation for Assign Names and Numbers:互联网名称与数字地址分配机构)</h3><blockquote>
<p>ICANN负责：<strong>分配MAC</strong>，<strong>管理DNS</strong>，<strong>管理IP空间</strong>等</p>
</blockquote>
<h3 id="plug-and-play-protocol-即插即用协议"><a href="#plug-and-play-protocol-即插即用协议" class="headerlink" title="plug-and-play protocol(即插即用协议)"></a>plug-and-play protocol(即插即用协议)</h3><h4 id="UPnP-Universal-Plug-and-Play-通用即插即用"><a href="#UPnP-Universal-Plug-and-Play-通用即插即用" class="headerlink" title="UPnP(Universal Plug and Play:通用即插即用)"></a>UPnP(Universal Plug and Play:通用即插即用)</h4><blockquote>
<p>UPnP 是各种各样的智能设备、无线设备和个人电脑等实现遍布全球的对等网络连接（P2P）的结构<br><strong>与NAT的关系：</strong>NAT需要UPnP支持，支持UPnP的软件可以自动映射需要的接口</p>
</blockquote>
<h3 id="dual-stack-双协议栈"><a href="#dual-stack-双协议栈" class="headerlink" title="dual-stack(双协议栈)"></a>dual-stack(双协议栈)</h3><blockquote>
<p>双协议栈是指在一个节点上同时支持ipv4和ipv6</p>
</blockquote>
<h3 id="tunnel-隧道"><a href="#tunnel-隧道" class="headerlink" title="tunnel(隧道)"></a>tunnel(隧道)</h3><blockquote>
<p>隧道是一种封装技术，能够把ipv6数据包封到ipv4包里，ipv4的包封到ipv6里进行传输。从而实现包在不同协议版本的设备上传输。<strong>（注：使用隧道技术时，另一个协议是作为链路层协议。（来自课本课后习题））</strong></p>
</blockquote>
<h3 id="ARP-Address-Resolution-Protocol-地址解析协议"><a href="#ARP-Address-Resolution-Protocol-地址解析协议" class="headerlink" title="ARP(Address Resolution Protocol:地址解析协议)"></a>ARP(Address Resolution Protocol:地址解析协议)</h3><blockquote>
<p>ARP是一个网络层协议，能够将IP地址解析为设备的MAC地址。</p>
<p>具体过程见另一篇文章<br><a href="https://sakuyui.github.io/2019/04/07/[转]TCP、IP、ARP协议之间的工作关系/" target="_blank" rel="noopener">https://sakuyui.github.io/2019/04/07/[转]TCP、IP、ARP协议之间的工作关系/</a><br>或<br><a href="https://www.cnblogs.com/itsad/p/8250503.html" target="_blank" rel="noopener">https://www.cnblogs.com/itsad/p/8250503.html</a></p>
</blockquote>
<p>简单说就是<br>对于一个传输层的包<br>到了网络层，IP协议拿到后，先加上个目的地的IP地址<br>然后判断是否在同一网段<br><strong>在同一网段的话</strong>：<br>1.让ARP协议去获取MAC地址。<br>2.ARP拿到后先看看<strong>ARP缓存</strong>里有没有，没有的话就广播，有的话就直接拿来用了<br><strong>不在同一网段的话</strong>:<br>将包发给默认网关</p>
<p><strong>[Extend]</strong><br>路由器隔离广播域，但是ARP仍能正常工作。因为代理ARP（<strong>Proxy ARP</strong>）的存在.代理ARP也就是，路由收到不同网段的ARP请求后，会拿自己的MAC地址返回。</p>
<p><strong>路由有隔离广播域的作用</strong><br><strong>路由每一个口是一个广播域</strong><br><strong>交换机每一个口是一个冲突域</strong></p>
<h3 id="RARP-Reverse-Address-Resolution-Protocol-反向地址转换协议"><a href="#RARP-Reverse-Address-Resolution-Protocol-反向地址转换协议" class="headerlink" title="RARP(Reverse Address Resolution Protocol:反向地址转换协议)"></a>RARP(Reverse Address Resolution Protocol:反向地址转换协议)</h3><blockquote>
<p>与ARP相反。RARP是根据MAC地址从<strong>网关上的ARP表</strong>或者<strong>缓存</strong>中获取<strong>IP地址</strong>的协议</p>
</blockquote>
<h3 id="LS-Link-State-链路状态"><a href="#LS-Link-State-链路状态" class="headerlink" title="LS(Link-State:链路状态)"></a>LS(Link-State:链路状态)</h3><blockquote>
<p>LS是一种路由算法类型。<strong>OSPF</strong>就是典型的LS算法。其向邻居通告的是路由状态，是一种全局性的算法，每个节点都知道链路的所有信息</p>
</blockquote>
<p>*详细见OSPF</p>
<h3 id="DV-Distance-Vector-距离向量"><a href="#DV-Distance-Vector-距离向量" class="headerlink" title="DV(Distance-Vector:距离向量)"></a>DV(Distance-Vector:距离向量)</h3><blockquote>
<p>距离向量也是一种路由算法。典型的有<strong>RIP、BGP</strong>等，其向邻居通告的是自己的路由表，邻居通过得到的路由表，对自己路由表进行调整。是一种<strong>分布式</strong>算法</p>
</blockquote>
<p>*详细见RIP,具体描述基本也就RIP那些</p>
<h3 id="IGP-Interior-Gateway-Protocol-内部网关协议"><a href="#IGP-Interior-Gateway-Protocol-内部网关协议" class="headerlink" title="IGP(Interior Gateway Protocol:内部网关协议)"></a>IGP(Interior Gateway Protocol:内部网关协议)</h3><blockquote>
<p>是在一个AS(自治系统)内交换路由信息的协议。RIP与OSPF都是IGP协议</p>
<h3 id="RIP-Routing-Information-Protocol"><a href="#RIP-Routing-Information-Protocol" class="headerlink" title="RIP(Routing Information Protocol)"></a>RIP(Routing Information Protocol)</h3><p>是基于路由向量的一个内部网关协议(IGP),基于距离向量算法。<br>RIP对于距离数的是<strong>跳数</strong><br>使用RIP的路由器将自己的路由表发给所有邻居。邻居收到路由表后。跳数+1后，<strong>对于相同开销：不处理</strong>,<strong>对于开销比当前路由表小的：更新路由表</strong>，<strong>对于得到的路由表中是通过自己到达的项：要强制更新自己路由表（这也是路由震荡产生的原因之一）</strong></p>
</blockquote>
<p><strong>RIP3个过程</strong><br>1.wait(等待)<br>2.recompute(重计算)<br>3.notify(通知,<strong>一般每隔30秒</strong>)</p>
<p><strong>RIP具有慢收敛的特性。坏消息传得慢，可能会出现路由震荡</strong><br><strong>应对路由震荡的措施</strong></p>
<h4 id="1-Split-Horizon-水平分割"><a href="#1-Split-Horizon-水平分割" class="headerlink" title="1.Split Horizon(水平分割)"></a>1.Split Horizon(水平分割)</h4><blockquote>
<p>从一个接口收到的路由信息，发送刷新报文时不会发回给这个接口。</p>
<h4 id="2-Poisoned-Reverse-毒性反转"><a href="#2-Poisoned-Reverse-毒性反转" class="headerlink" title="2.Poisoned Reverse(毒性反转)"></a>2.Poisoned Reverse(毒性反转)</h4><p>类似水平分割。不过保留了从某接口得到的路由信息，发回给该接口时置成16（无穷大）</p>
<h4 id="3-Triggered-Update-触发刷新"><a href="#3-Triggered-Update-触发刷新" class="headerlink" title="3.Triggered Update(触发刷新)"></a>3.Triggered Update(触发刷新)</h4><p>检测到崩溃立即发送刷新报文，而不等到计时器结束</p>
</blockquote>
<h3 id="OSPF-Open-Shortest-Path-First-开放式最短路径优先"><a href="#OSPF-Open-Shortest-Path-First-开放式最短路径优先" class="headerlink" title="OSPF(Open Shortest Path First:开放式最短路径优先)"></a>OSPF(Open Shortest Path First:开放式最短路径优先)</h3><blockquote>
<p>OSPF是基于链路状态的路由算法。其一般通过djskra算法计算某节点到所有节点的cost,每个节点都有相同的信息，且知道从它到每个节点的cost,是一种全局性的算法。节点发送的是与所有邻居的<strong>链路状态</strong>,而且是发给所有<strong>节点</strong></p>
</blockquote>
<p><strong>RIP与OSPF的不同</strong><br>0.<strong>how(如何计算):</strong>RIP计算的是跳数，OSPF计算的是链路开销<br>1.<strong>What(发什么):</strong>RIP发的是自己的路由表,而OSPF发的是<strong>与所有邻居的链路状态</strong><br>2.<strong>Who(发给谁):</strong>RIP是发给邻居，OSPF是发给所有节点<br>3.<strong>When(什么时候发)</strong>:RIP是每隔一定时间（一般30秒），OSPF是链路状态改变时才会发</p>
<p><strong>OSPF直接由IP携带</strong></p>
<h3 id="Hierarchical-Routing-分层路由"><a href="#Hierarchical-Routing-分层路由" class="headerlink" title="Hierarchical Routing(分层路由)"></a>Hierarchical Routing(分层路由)</h3><h4 id="ASs-Autonomous-Systems-自治系统"><a href="#ASs-Autonomous-Systems-自治系统" class="headerlink" title="ASs(Autonomous Systems:自治系统)"></a>ASs(Autonomous Systems:自治系统)</h4><blockquote>
<p>AS是处于一个管理机构控制之下的路由器和网络群组，AS里<strong>所有路由器必须运行相同的路由协议</strong>，<strong>并分配AS编号(ASN:Autonomous System Number)</strong></p>
</blockquote>
<h4 id="IS-IS-Intermediate-system-to-intermediate-system-中间系统到中间系统"><a href="#IS-IS-Intermediate-system-to-intermediate-system-中间系统到中间系统" class="headerlink" title="IS-IS(Intermediate system to intermediate system:中间系统到中间系统)"></a>IS-IS(Intermediate system to intermediate system:中间系统到中间系统)</h4><blockquote>
<p>一种<strong>内部网关协议(IGP)</strong>,基于<strong>LS</strong></p>
</blockquote>
<h3 id="BGP-Border-Gateway-Protocol-边界网关协议"><a href="#BGP-Border-Gateway-Protocol-边界网关协议" class="headerlink" title="BGP(Border Gateway Protocol:边界网关协议)"></a>BGP(Border Gateway Protocol:边界网关协议)</h3><blockquote>
<p>BGP是一种运行在<strong>TCP</strong>上的一种自治系统路由协议(<strong>唯一一个运行与TCP上的</strong>).可以用来使自治系统间相互访问。其是一种外部网关协议</p>
</blockquote>
<p>route=prefix+attribute<br>attribute=AS-PATH+NEXT-HOP+origin+local-preference</p>
<p>议(严格来讲,BGP不是路由协议)。BGP产生的原因是为了在不同自治系统(AS)之间进行路由转发</p>
<h4 id="AS-PATH"><a href="#AS-PATH" class="headerlink" title="AS-PATH"></a>AS-PATH</h4><blockquote>
<p>AS-PATH是BGP属性的一部分。是一些AS号的集合，每当经过一个AS，就加上一个AS号。AS号越短越优先<br>还能用来防止环路。如果收到的BUG路由包含自己的AS号，那就丢弃</p>
</blockquote>
<p>As号叠加得越多，说明经过的AS越多，那么这个路由的优先级也越低。</p>
<p>相反，经过的AS越少，那么说明路由越优先.</p>
<p>如果具有相同的AS路径长度，优先级由来源决定<strong>（IBGP&lt;EBGP&lt;INCOMPLETE）</strong></p>
<h4 id="eBGP-edge-BGP"><a href="#eBGP-edge-BGP" class="headerlink" title="eBGP(edge BGP)"></a>eBGP(edge BGP)</h4><blockquote>
<p>用于边界的BGP协议，用于在不同自治系统之间</p>
</blockquote>
<h4 id="iBGP-internal-BGP"><a href="#iBGP-internal-BGP" class="headerlink" title="iBGP(internal BGP)"></a>iBGP(internal BGP)</h4><blockquote>
<p>用于AS内部的BGP协议</p>
</blockquote>
<p>因为BGP本身不发现路由，所以需要iBGP来总结通过IGP（内部网关协议）计算得到的路由<br><strong>就是BGP本身不生产路由，直接拿现成的路由拿来用的,为了总结AS内IGP产生的路由，就需要iBGP的存在，然后交到eBGO那</strong></p>
<p>Q:为什么有了IGP还要iBGP<br>1.IGP处理能力有限<br>2,BGP控制能力&gt;&gt;IGP<br>3.BGP可以靠路由属性防止环路</p>
<h3 id="Hot-Potato-热土豆"><a href="#Hot-Potato-热土豆" class="headerlink" title="Hot-Potato(热土豆)"></a>Hot-Potato(热土豆)</h3><blockquote>
<p>AS内某个节点收到包后，如果有多个边界网关可以选择，都可以到达目的地的话，往最近的那个网关传（如何衡量近就靠IGP了）</p>
<h3 id="Uncontrolled-Flooding-无控制洪范"><a href="#Uncontrolled-Flooding-无控制洪范" class="headerlink" title="Uncontrolled Flooding(无控制洪范)"></a>Uncontrolled Flooding(无控制洪范)</h3><p>Uncontrolled Flooding是指节点收到一个广播包后，就把广播包副本发给每个邻居节点（除了来源那个邻居）<br>会形成广播风暴</p>
<h3 id="Controlled-Flooding-受控洪范"><a href="#Controlled-Flooding-受控洪范" class="headerlink" title="Controlled Flooding(受控洪范)"></a>Controlled Flooding(受控洪范)</h3><p>受控洪范是指，节点记录已收到的广播包，收到一个广播包，如果发现已经收到过的话，就不flooding了</p>
</blockquote>
<h3 id="Spanning-Tree-Broadcast-生成树广播"><a href="#Spanning-Tree-Broadcast-生成树广播" class="headerlink" title="Spanning Tree Broadcast(生成树广播)"></a>Spanning Tree Broadcast(生成树广播)</h3><blockquote>
<p>利用生成树进行广播的方式。广播包只沿建立好的生成树传播</p>
</blockquote>
<h3 id="RPF-Reverse-Path-Forward-反向路径转发"><a href="#RPF-Reverse-Path-Forward-反向路径转发" class="headerlink" title="RPF(Reverse Path Forward:反向路径转发)"></a>RPF(Reverse Path Forward:反向路径转发)</h3><blockquote>
<p>只转发沿最短路径到来的广播包</p>
</blockquote>
<h3 id="IGMP-Internet-Group-Manage-Protocol-Internel组管理协议"><a href="#IGMP-Internet-Group-Manage-Protocol-Internel组管理协议" class="headerlink" title="IGMP(Internet Group Manage Protocol:Internel组管理协议)"></a>IGMP(Internet Group Manage Protocol:Internel组管理协议)</h3><blockquote>
<p>其是运行在主机与组播路由器上的协议。允许一个主机指定他想加入的分组，组播路由器上保存有一张表，记录路由各个接口上有哪些组成员</p>
</blockquote>
<p><strong>每个网段有唯一查询器（组播路由器）</strong><br><strong>新主机主动发报告</strong><br><strong>主机离开后，路由器会看看还有没有人</strong></p>
<h3 id="IGMP-snoop-IGMP嗅探"><a href="#IGMP-snoop-IGMP嗅探" class="headerlink" title="IGMP snoop(IGMP嗅探)"></a>IGMP snoop(IGMP嗅探)</h3><blockquote>
<p>IGMP Snoop是在链路层的协议。可以在交换机上建立转发表项，把组播包发到相应的的接口。如果交换机不知道IGMP snoop或者未打开IGMP snoop,将按广播包处理</p>
</blockquote>
<p><strong>链路层广播包：MAC地址全FF</strong><br><img src="./1555932150666.png" alt="Alt text"></p>
<h3 id="shared-Tree-共享树"><a href="#shared-Tree-共享树" class="headerlink" title="shared Tree(共享树)"></a>shared Tree(共享树)</h3><blockquote>
<p>所有组成员使用相同的树</p>
<h3 id="Source-Tree-源树"><a href="#Source-Tree-源树" class="headerlink" title="Source Tree(源树)"></a>Source Tree(源树)</h3><p>每个组成员的树不同</p>
</blockquote>
<p><img src="./1555811383785.png" alt="Alt text"></p>
<h3 id="PIM-Protocol-Independent-multicast-独立组播协议"><a href="#PIM-Protocol-Independent-multicast-独立组播协议" class="headerlink" title="PIM(Protocol Independent multicast:独立组播协议)"></a>PIM(Protocol Independent multicast:独立组播协议)</h3><h4 id="PIM-DM"><a href="#PIM-DM" class="headerlink" title="PIM-DM"></a>PIM-DM</h4><blockquote>
<p>独立组播协议的的一种模式-密集模式。使用源树。</p>
</blockquote>
<h4 id="PIM-SM"><a href="#PIM-SM" class="headerlink" title="PIM-SM"></a>PIM-SM</h4><blockquote>
<p>独立组播协议的一种模式-稀疏模式，使用共享树</p>
<p><strong>DM与SM的不同：</strong><br>1.Dense:假设大部分主机参与组，比较密集分配。先发广播消息，不参与的向上游发剪枝消息<br>Sparse:提出加入请求，才可以接收组播消息</p>
</blockquote>
<h3 id="DVMRP-Distance-Vector-Muiticast-Routing-Protocol-距离向量多播路由协议"><a href="#DVMRP-Distance-Vector-Muiticast-Routing-Protocol-距离向量多播路由协议" class="headerlink" title="DVMRP(Distance-Vector Muiticast Routing Protocol:距离向量多播路由协议)"></a>DVMRP(Distance-Vector Muiticast Routing Protocol:距离向量多播路由协议)</h3><blockquote>
<p>是一个内部网关路由协议,依赖单目标广播协议的机制.<br><strong>具有RPF(反向路径转发)的基于source的树</strong><br><strong>利用剪枝</strong><br>与PM-DM的异同<br>同:都用RPM技术构建以源为根的广播树<br>异:PIM完全独立于单播协议，DVMRP依赖单播协议</p>
</blockquote>
<h3 id="RPM-Reverse-Path-Multicasting-反向路径多目标广播"><a href="#RPM-Reverse-Path-Multicasting-反向路径多目标广播" class="headerlink" title="*RPM(Reverse Path Multicasting:反向路径多目标广播)"></a>*RPM(Reverse Path Multicasting:反向路径多目标广播)</h3><h3 id="FEC-Forward-Error-Correction"><a href="#FEC-Forward-Error-Correction" class="headerlink" title="FEC(Forward Error Correction)"></a>FEC(Forward Error Correction)</h3><blockquote>
<p>接受方能检测并纠错的能力</p>
<h3 id="LLC-Logical-Link-Control-逻辑链路控制"><a href="#LLC-Logical-Link-Control-逻辑链路控制" class="headerlink" title="LLC(Logical Link Control:逻辑链路控制)"></a>LLC(Logical Link Control:逻辑链路控制)</h3><p>LLC是数据链路层的上层部分，通过LLC子层为网络层提供统一的接口</p>
<h3 id="MAC-Medium-Access-Control-介质访问控制"><a href="#MAC-Medium-Access-Control-介质访问控制" class="headerlink" title="MAC(Medium Access Control:介质访问控制)"></a>MAC(Medium Access Control:介质访问控制)</h3><p>主要解决信道分配和信道竞争问题。除此之外，还有<strong>数据帧收集(Data Frames assemble )</strong>,<strong>数据帧拆卸(Data Frames Disassemble)</strong>,<strong>错误探测(Error detection)</strong>,<strong>地址解析等功能(Address Resolution)</strong>。是LLC的<strong>子层</strong></p>
</blockquote>
<p><strong>MAC地址:是一个48bit的硬件地址，由ICANN分配</strong></p>
<h3 id="CSMA-Carriage-Sense-Multiple-Access-载流监听多路访问"><a href="#CSMA-Carriage-Sense-Multiple-Access-载流监听多路访问" class="headerlink" title="CSMA(Carriage Sense Multiple Access:载流监听多路访问)"></a>CSMA(Carriage Sense Multiple Access:载流监听多路访问)</h3><blockquote>
<p>CSMA是一个数据链路层的协议。可以让一个信道被多个节点使用。<br>工作方式为.1.不坚持型:如果检测到信道繁忙就等待一个随机时间,idel就直接传<br>2.1-坚持型：检测到繁忙就一直等到信道空闲,然后马上发（可能会冲突，因为其他节点可能也在等，然后空闲后一起发就炸了）<br>3.P-坚持型,前两个的结合。检测到空闲的话以p的概率传。忙的话一直等</p>
</blockquote>
<h3 id="CSMA-CD-CSMA-with-Collision-Detection-带冲突检测的CSMA"><a href="#CSMA-CD-CSMA-with-Collision-Detection-带冲突检测的CSMA" class="headerlink" title="CSMA/CD(CSMA with Collision Detection:带冲突检测的CSMA)"></a>CSMA/CD(CSMA with Collision Detection:带冲突检测的CSMA)</h3><blockquote>
<p>也就是带有冲突检测的CSMA。工作流程为:<br>发送-》检测冲突，不冲突的话就完成。冲突的话冲突count++,大于16就算失败。否则的话随机等待一个时间重发</p>
</blockquote>
<h3 id="CSMA-CA-带冲突避免的CSMA"><a href="#CSMA-CA-带冲突避免的CSMA" class="headerlink" title="CSMA/CA(带冲突避免的CSMA)"></a>CSMA/CA(带冲突避免的CSMA)</h3><blockquote>
<p>一般用在无线网<br>802.11局域网在使用CSMA/CA的同时，还使用停止等待协议。这是因为无线信道的通信质量远不如有线信道的，因此无线站点每通过无线局域网发送完一帧后，要等到收到对方的确认帧后才能继续发送下一帧。这叫做链路层确认。</p>
<h4 id="虚拟载波监听-Virtual-Carrier-Sense"><a href="#虚拟载波监听-Virtual-Carrier-Sense" class="headerlink" title="虚拟载波监听(Virtual Carrier Sense)"></a>虚拟载波监听(Virtual Carrier Sense)</h4><p>是让源站把它要占用信道的时间(包括目的站发回确认帧所需的时间)及时通知给所有其他站，以便使其他所有站在这一段时间都停止发送数据<br><img src="./1556022351373.png" alt="Alt text"></p>
</blockquote>
<h4 id="退避算法"><a href="#退避算法" class="headerlink" title="退避算法"></a>退避算法</h4><blockquote>
<p><strong>信道从忙态转为空闲时，各站就要执行退避算法</strong><br>设置了一个退避计时器(backoff timer)。站点每经历一个时隙的时间就检测一次信道。这可能发生两种情况:若检测到信道空闲，退避计时一器就继续倒计时;若检测到信道忙，就<strong>冻结退避计时器的剩余时间，重新等待信道变为空闲</strong>并再<strong>经过时间DIFS后</strong></p>
</blockquote>
<h3 id="Self-learning-自学习"><a href="#Self-learning-自学习" class="headerlink" title="Self-learning(自学习)"></a>Self-learning(自学习)</h3><blockquote>
<p>自学习就是交换机收到一个包后，会登记包的来源，放到交换表里。然后查表里有没有目的方的信息，没有的话就广播，有的话就往相应口发。</p>
</blockquote>
<h3 id="polling-池化"><a href="#polling-池化" class="headerlink" title="polling(池化)"></a>polling(池化)</h3><blockquote>
<p>master机让slaves机轮流发消息</p>
<h3 id="VLAN-Virtual-LAN-虚拟局域网"><a href="#VLAN-Virtual-LAN-虚拟局域网" class="headerlink" title="VLAN(Virtual LAN:虚拟局域网)"></a>VLAN(Virtual LAN:虚拟局域网)</h3><p>VLAN是组逻辑上的设备和用户，可以形成自己的广播域</p>
</blockquote>
<h3 id="Collision-domain-冲突域"><a href="#Collision-domain-冲突域" class="headerlink" title="Collision domain(冲突域)"></a>Collision domain(冲突域)</h3><blockquote>
<p>交换机每个接口构成一个冲突域</p>
<h3 id="Enthernet-以太网"><a href="#Enthernet-以太网" class="headerlink" title="Enthernet(以太网)"></a>Enthernet(以太网)</h3><p>以太网（Ethernet）是一种计算机局域网技术,标准拓扑结构为总线型拓扑.是目前应用最普遍的局域网技术，取代了其他局域网标准如令牌环、FDDI和ARCNET</p>
<h3 id="Token-Ring-令牌环"><a href="#Token-Ring-令牌环" class="headerlink" title="Token Ring(令牌环)"></a>Token Ring(令牌环)</h3><p>也是一种局域网计算。使用一个特殊的帧叫做“令牌”，谁有令牌谁有传输权</p>
</blockquote>
<p><strong>工作机制:</strong><br>（1）首先进行环的初始化（建立一逻辑环），然后产生一空令牌，在环上流动。<br>（2）希望发送帧的站必须等待，直到它检测到空令牌的到来。<br>（3）想发送的站拿到空令牌后，首先将其置为忙状态，该站紧接着向令牌的后面发送一个数据帧。<br>（4）当令牌忙时，由于网上无空令牌，所有想发送数据帧的站必须等待。<br>（5）数据沿途经过的每个站环接口都将该帧的目地地址和本站的地址相比较，如果地址符合，则将帧放入接收缓冲区，再送入本站，同时帧将在环上继续流动；若地址不符合，环接口只将数据帧转发。<br>（6）发送的帧沿环循环一周后再回到发送站，由发送站将该帧从环上移去，同时释放令牌（将其状态改为“闲”）发到下一站 [2]  。<br><img src="./1555844784293.png" alt="Alt text"></p>
<h3 id="Fragmentation-分片"><a href="#Fragmentation-分片" class="headerlink" title="Fragmentation(分片)"></a>Fragmentation(分片)</h3><blockquote>
<p>Fragmentation是指IP包的大小&gt;MTU时，分段传送<br>IP包头中  <strong>flag=(保留位,DF,MF)</strong><br><strong>flag=1(MF=1 DF=0)</strong>代表还有分片<br><strong>flag=0(MF=0 DF=0)</strong>代表所有分片已经收完</p>
<p>Example:<br><strong>MTU=1500</strong> 且 <strong>datagram size=4000B</strong><br>求分段数量，大小，还有标志,偏移</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Fragment(片段)</th>
<th style="text-align:right">Bytes</th>
<th style="text-align:center">ID</th>
<th>Offset</th>
<th>Flag</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Fragment1</td>
<td style="text-align:right">1480</td>
<td style="text-align:center"></td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:left">Fragment2</td>
<td style="text-align:right">1480</td>
<td style="text-align:center"></td>
<td>185</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:left">Fragment3</td>
<td style="text-align:right">3980-1480-1480</td>
<td style="text-align:center"></td>
<td>370</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>片段数=(Datagram Size-20)/(MTU-20) 向上取整<br>flag在最后一片=0，其余为1<br><strong>注意，偏移单位为8bit….所以上表第2片偏移是1480/8=185,第3片偏移是(1480+1480)/8=370</strong></p>
<p><strong>不能整除8的话，就取最大能整除8的</strong></p>
<h3 id="PDU-Protocol-Data-Unit-协议数据单元"><a href="#PDU-Protocol-Data-Unit-协议数据单元" class="headerlink" title="PDU(Protocol Data Unit:协议数据单元)"></a>PDU(Protocol Data Unit:协议数据单元)</h3><blockquote>
<p>协议数据单元是指对等层传输的数据单元，如应用层为message,传输层为segment,网络层为datagram,数据链路层为frame</p>
</blockquote>
<h3 id="SNMP-Simple-Network-Management-Protocol-简单网络管理协议"><a href="#SNMP-Simple-Network-Management-Protocol-简单网络管理协议" class="headerlink" title="SNMP(Simple Network Management Protocol:简单网络管理协议)"></a>SNMP(Simple Network Management Protocol:简单网络管理协议)</h3><blockquote>
<p>SNMP是TCP/IP协议簇的一个应用层协议,是一种在IP网络中管理网络节点（如服务器、工作站、路由器、交换机等）的标准协议</p>
</blockquote>
<h3 id="Channel-Partitioning-信道划分"><a href="#Channel-Partitioning-信道划分" class="headerlink" title="Channel Partitioning(信道划分)"></a>Channel Partitioning(信道划分)</h3><blockquote>
<p>MAC层进行多路访问的一种方式。将信道划分，然后分配信道给节点使用</p>
<h4 id="TDMA-Time-Division-Multiple-Access-时分多路访问"><a href="#TDMA-Time-Division-Multiple-Access-时分多路访问" class="headerlink" title="TDMA(Time Division Multiple Access:时分多路访问)"></a>TDMA(Time Division Multiple Access:时分多路访问)</h4><h4 id="FDMA-Frequency-Division-Multiple-Access：频分多路访问"><a href="#FDMA-Frequency-Division-Multiple-Access：频分多路访问" class="headerlink" title="FDMA(Frequency Division Multiple Access：频分多路访问)"></a>FDMA(Frequency Division Multiple Access：频分多路访问)</h4></blockquote>
<h3 id="Random-Access-Protocol-随机访问协议"><a href="#Random-Access-Protocol-随机访问协议" class="headerlink" title="Random Access Protocol(随机访问协议)"></a>Random Access Protocol(随机访问协议)</h3><blockquote>
<p>链路层的访问协议类型之一，不同于信道划分。其专注于如何探测冲突和如何从冲突中恢复<br>典型Random Access Protocol有<strong>ALOHA,slot ALOHA,CSMA,CSMA/CD,CSMA/CA</strong><br>效率上CSMA&gt;ALOHA&gt;slot ALOHA</p>
<h4 id="slot-ALOHA"><a href="#slot-ALOHA" class="headerlink" title="slot ALOHA"></a>slot ALOHA</h4><p>是对纯ALOHA协议的一个改进，思想是用时钟来统一用户的数据发送。改进之处在于，它把<strong>频道在时间上分段，每个传输点只能在一个分段的开始处进行传送。用户每次必须等到下一个时间片才能开始发送数据</strong>，每次传送的数据必须少于或者等于一个频道的一个时间分段。这样很大的减少了传输频道的冲突。从而避免了用户发送数据的随意性，<strong>减少了数据产生冲突的可能性</strong>，<strong>提高了信道的利用率。</strong>(简述:在每个时隙如果没冲突，在下一个时隙就继续发，如果发现冲突的话，下次开始以p概率重发，直到成功)<br><img src="./1555846424319.png" alt="Alt text"></p>
</blockquote>
<p>优点:<br>简单、单节点的话可以快速传播</p>
<p>缺点:<br>有空闲时隙<br>传输需要时间可以小于划分的时隙<br>会冲突<br>浪费时隙</p>
<h3 id="pure-ALOHA"><a href="#pure-ALOHA" class="headerlink" title="pure ALOHA"></a>pure ALOHA</h3><blockquote>
<p>就是不划分时隙。。纯的ALOHA。节点间没有同步性</p>
</blockquote>
<p><img src="./1555846417274.png" alt="Alt text"></p>
<h3 id="Q-描述五层模型，各层的作用"><a href="#Q-描述五层模型，各层的作用" class="headerlink" title="Q:描述五层模型，各层的作用"></a>Q:描述五层模型，各层的作用</h3><p><strong>1.应用层:</strong>是与用户交互的接口，是五层模型中的最高一层，能够提供文件传输(FTP)、电子邮件(SMTP\MIME\IMAP\POP3)、网页访问(HTTP)、简单网络管理(SNMP)、远程访问(Telnet)等应用</p>
<p><strong>2.传输层:</strong>可以实现端到端的数据传输，具有<strong>缓冲</strong>作用。传输层有TCP协议，可以进行可靠的端到端传输，UDP协议可以进行不可靠传输</p>
<p><strong>3.网络层</strong>:主要功能是转发和路由。转发是指，选择接口将包发出，路由是指根据路由算法决定包的传播路径。除此之外还有建立和拆除网络连接，分段，流量控制等功能。具有的协议有IP、ICMP、IGMP、ARP、RARP等</p>
<p><strong>4.数据链路层:</strong>主要协议有CSMA,CSMA/CD CA,PPP等.主要功能为<strong>成帧(Framing)</strong>,检错纠错,<strong>链路接入</strong>,可靠交付<br><strong>4.1 MAC层</strong>:主要解决信道的分配和信道竞争问题。除此之外还有错误检测、数据包收集和分发、地址解析等功能<br><strong>5.物理层</strong>:定义了物理传输的一些规范。为数据传输提供实体。</p>
<h3 id="SBR-Signal-to-Noise-Ratio-信噪比"><a href="#SBR-Signal-to-Noise-Ratio-信噪比" class="headerlink" title="SBR(Signal-to-Noise Ratio:信噪比)"></a>SBR(Signal-to-Noise Ratio:信噪比)</h3><blockquote>
<p>信号与噪声的相对测量</p>
</blockquote>
<h3 id="CDMA-Code-Division-Multiple-Address-码分多址"><a href="#CDMA-Code-Division-Multiple-Address-码分多址" class="headerlink" title="CDMA(Code Division Multiple Address:码分多址)"></a>CDMA(Code Division Multiple Address:码分多址)</h3><blockquote>
<p>CDMA属于信道划分协议的一族。保证多个发送方信号不相互干扰<br>用比特乘一个编码</p>
</blockquote>
<h3 id="CSMA-CA"><a href="#CSMA-CA" class="headerlink" title="CSMA/CA"></a>CSMA/CA</h3><p><img src="./1555936480050.png" alt="Alt text"></p>
<h3 id="FDDI-光纤分布式数据接口"><a href="#FDDI-光纤分布式数据接口" class="headerlink" title="FDDI(光纤分布式数据接口)"></a>FDDI(光纤分布式数据接口)</h3><blockquote>
<p>访问方法与令牌环类似。不过使用定时令牌<br>FDDI令牌沿网络环路从一个结点向另一个结点移动，如果某结点不需要传输数据，FDDI将获取令牌并将其发送到下一个结点中。如果处理令牌的结点需要传输，那么在指定的称为“目标令牌循环时间”（Target Token Rotation Time，TTRT）的时间内，它可以按照用户的需求来发送尽可能多的帧。因为FDDI采用的是定时的令牌方法，所以在给定时间中，<strong>来自多个结点的多个帧</strong>（多令牌）可能都在网络上，以为用户提供高容量的通信。</p>
</blockquote>
<h3 id="Frame-Relay-帧中继"><a href="#Frame-Relay-帧中继" class="headerlink" title="Frame Relay:帧中继"></a>Frame Relay:帧中继</h3><blockquote>
<p>帧中继是一种数据包交换通信网络.采用高速虚电路</p>
</blockquote>
<h3 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h3><p><img src="./1556015867367.png" alt="Alt text"></p>
<p><strong>1.曼切斯特:</strong><br>1朝向左 0朝向右<br><strong>2.差分曼切斯特</strong><br>1平0跳</p>
<h3 id="指数退避算法"><a href="#指数退避算法" class="headerlink" title="指数退避算法"></a>指数退避算法</h3><blockquote>
<p>退避算法是在在单个信道的基于竞争的介质的一种访问控制（MAC）协议。每当一个以上的节点在同一时刻试图访问介质的时候，它会导致分组碰撞。如果相撞的节点试图再次访问信道，在节点做及时同步的时候数据包将发生碰撞。因此，节点需要时间位差。为了产生这种位差，退避算法（例如二进制指数退避（BEB）） 。例如，在BEB算法中，每当一个节点的传输涉及在与另一个节点的传输发生碰撞，两个节点都将选择一个随机的等待时间，在下次再次尝试前需要等待选择的随机时间。如果他们在这样的尝试都没有成功，他们自己的竞争窗口增加一倍，在发射前再次选择等待一个随机时间。这个过程将被重复一定次数的尝试。如果经过数次尝试之后都失败了，那么其传输的数据包将被从传输队列中移除。</p>
</blockquote>
<pre><code>  二进制退避技术（Binary Exponential Back off）. 指在遇到重复的冲突时，站点将重复传输，但在每一次冲突之后，随着时延的平均值将加倍。二进制指数退避算法提供了一个处理重负荷的方法。尝试传输的重复失败导致更长的退避时间，这将有助于负荷的平滑。如果没有这样的退避，以下状况可能发生：两个或多站点同时尝试传输，这将导致冲突，之后这些站点又立即尝试重传，导致一个新冲突。
</code></pre><p><img src="./1555943592926.png" alt="Alt text"><br><img src="./1555943898461.png" alt="Alt text"><br> FDDI 采用令牌传递的方式解决共享信道冲突问题,与共享式以太网的 CSMA/CD 的效率 相比在理论上要稍高一点 (但仍远比不上交换式以太网) </p>
<p><img src="./1556033881815.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>Computer Networking</title>
    <url>/2019/12/26/Computer%20Networking/</url>
    <content><![CDATA[<h1 id="Computer-Networking"><a href="#Computer-Networking" class="headerlink" title="Computer Networking"></a>Computer Networking</h1><p>[TOC]</p>
<h2 id="Chapter-1-Computer-Networks-and-the-Internet"><a href="#Chapter-1-Computer-Networks-and-the-Internet" class="headerlink" title="Chapter 1 Computer Networks and the Internet"></a>Chapter 1 Computer Networks and the Internet</h2><h3 id="1-1-What-Is-the-Internet"><a href="#1-1-What-Is-the-Internet" class="headerlink" title="1.1 What Is the Internet"></a>1.1 What Is the Internet</h3><h4 id="1-1-1-A-Nuts-and-Bolts-Description"><a href="#1-1-1-A-Nuts-and-Bolts-Description" class="headerlink" title="1.1.1  A Nuts-and-Bolts Description"></a>1.1.1  A Nuts-and-Bolts Description</h4><p><strong>hosts</strong> or <strong>end systems</strong><br><img src="./1552814289131.png" alt="Alt text"><br><strong>ISP: Internet Services Provider</strong><br><strong>transmission rate</strong> measured in <strong>bits/second(b/s)</strong><br><strong>Packet switching(包交换/分组交换)</strong>  is a method of grouping data that is transmitted over a digital network into packets. Packets are made of a header and a payload. Data in the header are used by networking hardware to direct the packet to its destination where the payload is extracted and used by application software.<br><strong>Packet switches</strong> include <strong>routers(路由)</strong> and <strong>link-layer switches(数据链路层的交换机)</strong><br><strong>TCP(Transmission Control Protocol )</strong><br><strong>IP(Internet Protocol)</strong></p>
<h4 id="1-1-3-What-Is-a-Protocol"><a href="#1-1-3-What-Is-a-Protocol" class="headerlink" title="1.1.3 What Is a Protocol?"></a>1.1.3 What Is a Protocol?</h4><blockquote>
<p>A <strong>protocol</strong> defines the format and the order of messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other event.(协议定义了信息在两个网络实体间交换信息的格式以及一系列操作)</p>
</blockquote>
<h3 id="1-2-The-Network-Edge-网络边缘"><a href="#1-2-The-Network-Edge-网络边缘" class="headerlink" title="1.2 The Network Edge(网络边缘)"></a>1.2 The Network Edge(网络边缘)</h3><p>也就是hosts.靠近用户端那部分.也叫端系统</p>
<h4 id="1-2-1-Access-Networks"><a href="#1-2-1-Access-Networks" class="headerlink" title="1.2.1 Access Networks"></a>1.2.1 Access Networks</h4><p><img src="./1552815927223.png" alt="Alt text"><br><strong>DSL(Digital subscriber line)</strong><br><strong>Cable</strong><br><strong>FTTH(Fiber to the home)</strong><br><strong>Wifi</strong><br><strong>3G and LTE</strong></p>
<h4 id="1-2-2-Physical-Media"><a href="#1-2-2-Physical-Media" class="headerlink" title="1.2.2 Physical Media"></a>1.2.2 Physical Media</h4><p><strong>Twisted-Pair Copper Wire:</strong>双绞线<br><strong>Copper Wire:</strong>同轴电缆<br><strong>Fiber Optics:</strong>光纤<br><strong>Terrestrial Radio Channels</strong>:陆地无线电信道<br><strong>Terrestrial Radio Channels</strong>:卫星无线电信道</p>
<h3 id="1-3-The-Network-Core"><a href="#1-3-The-Network-Core" class="headerlink" title="1.3 The Network Core"></a>1.3 The Network Core</h3><p><img src="./1552816480837.png" alt="Alt text"></p>
<h4 id="1-3-1-Packet-Switching"><a href="#1-3-1-Packet-Switching" class="headerlink" title="1.3.1 Packet Switching"></a>1.3.1 Packet Switching</h4><p>time $L/R$</p>
<blockquote>
<p><strong>Store-and-Forward Transmission（存储转发）</strong><br>存储转发：在往下一个地方发包之前，先收到完整包再说,于是<strong>传输时延=$N\frac{L}{R}$</strong></p>
</blockquote>
<h4 id="1-3-2-Circuit-Switching-电路交换"><a href="#1-3-2-Circuit-Switching-电路交换" class="headerlink" title="1.3.2 Circuit Switching(电路交换)"></a>1.3.2 Circuit Switching(电路交换)</h4><p><strong>FDM(频分复用:Frequency-Division Multiplexing)</strong><br><strong>TDM(时分复用:Time-Division Multiplexing)</strong><br><img src="./1552817178382.png" alt="Alt text"></p>
<h4 id="1-3-3-A-Network-of-Networks-网络的网络"><a href="#1-3-3-A-Network-of-Networks-网络的网络" class="headerlink" title="1.3.3 A Network of Networks(网络的网络)"></a>1.3.3 A Network of Networks(网络的网络)</h4><p><img src="./1552817851732.png" alt="Alt text"><br> <strong>IXP(Internet Exchange Point)</strong></p>
<h3 id="1-4-Delay-Loss-and-Throughput-in-Packet-Switched-Networks-分组交换网络的延迟-丢包和吞吐量"><a href="#1-4-Delay-Loss-and-Throughput-in-Packet-Switched-Networks-分组交换网络的延迟-丢包和吞吐量" class="headerlink" title="1.4 Delay,Loss,and Throughput in Packet-Switched Networks(分组交换网络的延迟\丢包和吞吐量)"></a>1.4 Delay,Loss,and Throughput in Packet-Switched Networks(分组交换网络的延迟\丢包和吞吐量)</h3><h4 id="1-4-1-Delay"><a href="#1-4-1-Delay" class="headerlink" title="1.4.1 Delay"></a>1.4.1 Delay</h4><blockquote>
<p><strong>Delay Types:</strong><br><strong>Nodal processing delay(节点处理时延)</strong><br>The time required to examine the packet’s header and determine where to direct(检查包头，决定发送方向)</p>
<p><strong>queuing delay(排队时延)</strong></p>
<p>transmission delay(传输时延)<br>将大小L的分组推出需要的时间 T=L/R  （R=10Mbps,100Mbps之类的）,与路由器距离无关</p>
<p>propagation delay(传播时延)<br>取决线路速率，等于距离/线路速率<br><img src="./1552818160886.png" alt="Alt text"></p>
</blockquote>
<p>于是<br><img src="./1552818665795.png" alt="Alt text"></p>
<h4 id="1-4-2-Queuing-Delay-and-Packet-Loss"><a href="#1-4-2-Queuing-Delay-and-Packet-Loss" class="headerlink" title="1.4.2 Queuing Delay and Packet Loss"></a>1.4.2 Queuing Delay and Packet Loss</h4><p>$a(pkt/s):$the average rate at which packets arrive at the queue.也就是每秒几个包到达<br>$La (b/s)$ the average rate at which bits arrive at the queue.<br><strong>Traffic intensity(拥塞强度)</strong></p>
<script type="math/tex; mode=display">\frac{La}{R}</script><blockquote>
<p><strong>La/R&gt;1</strong>:到达大于发出,队列不断增加<br><strong>La/R&lt;=1</strong>:取决到达的性质,如果是周期性到达，比较均匀的话（L/R秒一个）。那么不用排队。如果是同时La个数据涌来的话，只有第一个不用排队</p>
</blockquote>
<p><strong>Packet Loss</strong><br>If a packet arrived with finding a full queue,then i no way to go,and will be <strong>loss</strong> because the router <strong>drop</strong> the packet<br>(就是队列满了，包没地方去了，路由就干掉它了，然后就产生loss)</p>
<h4 id="1-4-3-End-to-End-Delay-端到端时延"><a href="#1-4-3-End-to-End-Delay-端到端时延" class="headerlink" title="1.4.3 End-to-End Delay(端到端时延)"></a>1.4.3 End-to-End Delay(端到端时延)</h4><p>前面是点到点的时延，基于节点分析的<br>现在端到端<br>suppose there are $N - 1$ routers between the <em>source host</em> and the <em>destination host</em><br>suppose for the moment that the network is uncongested (so that <em>queuing delays are negligible</em>) 忽略了排队时延<br><img src="./1552819672387.png" alt="Alt text"></p>
<h4 id="1-4-4-Throughput-in-Computer-Network"><a href="#1-4-4-Throughput-in-Computer-Network" class="headerlink" title="1.4.4 Throughput in Computer Network"></a>1.4.4 Throughput in Computer Network</h4><p>example 1<br><img src="./1552820086590.png" alt="Alt text"><br><strong>bottleneck link(瓶颈链路)</strong><br>$F: $File’s Size<br><strong>throughput</strong>:$min\{R_ 1 , R _2 , …, R _N \}$<br>$T=F/min\{R_ 1 , R _2 , …, R _N \}$</p>
<p>example 2<br><img src="./1552820376557.png" alt="Alt text"><br>$R_s&gt;&gt;R_c$<br>similarly: throughput=$min\{R_s,R_c\}$<br>If in the situation of Figure 1.20(b),R/10 is also need to be considered.<br>If $R=5Mbps,R_s=2Mbps,R_c=1Mpbs$,then $Throughput=500Kbps$</p>
<h3 id="1-5-Protocol-Layers-and-Their-Service-Models"><a href="#1-5-Protocol-Layers-and-Their-Service-Models" class="headerlink" title="1.5 Protocol Layers and Their Service Models"></a>1.5 Protocol Layers and Their Service Models</h3><h4 id="1-5-1-Layered-Architecture"><a href="#1-5-1-Layered-Architecture" class="headerlink" title="1.5.1 Layered Architecture"></a>1.5.1 Layered Architecture</h4><p><strong>Protocol Layering</strong><br><img src="./1552821184546.png" alt="Alt text"><br><strong>top-down approach</strong>(自顶向下方法)</p>
<blockquote>
<p><strong>Application Layer</strong><br>SMTP\FTP\HTTP<br>packet of information at the application layer as a <strong>message</strong></p>
<p><strong>Transport Layer</strong><br>TCP\UDP<br>transport-layer packet as a <strong>segment</strong></p>
<p><strong>Network Layer</strong><br>IP protocol<br>network-layer packets known as <strong>datagrams</strong></p>
<p><strong>Link Layer</strong><br>refer to the link layer packets as <strong>frames</strong></p>
<p><strong>Physical Layer</strong></p>
</blockquote>
<h4 id="1-5-2-Encapsulation-封装"><a href="#1-5-2-Encapsulation-封装" class="headerlink" title="1.5.2 Encapsulation(封装)"></a>1.5.2 Encapsulation(封装)</h4><p><img src="./1552821655413.png" alt="Alt text"></p>
<h2 id="Chapter-2-Application-Layer"><a href="#Chapter-2-Application-Layer" class="headerlink" title="Chapter 2 Application Layer"></a>Chapter 2 Application Layer</h2><h3 id="2-1-Principles-of-Network-Applications"><a href="#2-1-Principles-of-Network-Applications" class="headerlink" title="2.1 Principles of Network Applications"></a>2.1 Principles of Network Applications</h3><h4 id="2-1-1-Network-Application-Architecture"><a href="#2-1-1-Network-Application-Architecture" class="headerlink" title="2.1.1 Network Application Architecture"></a>2.1.1 Network Application Architecture</h4><p>C\S,P2P</p>
<h4 id="2-1-2-Processes-Communicating"><a href="#2-1-2-Processes-Communicating" class="headerlink" title="2.1.2 Processes Communicating"></a>2.1.2 Processes Communicating</h4><p><strong>Addressing:IP and Port</strong></p>
<h4 id="2-1-3-Transport-Services-Available-to-Applications"><a href="#2-1-3-Transport-Services-Available-to-Applications" class="headerlink" title="2.1.3 Transport Services Available to Applications"></a>2.1.3 Transport Services Available to Applications</h4><p>TCP<br><img src="./1552822504935.png" alt="Alt text"><br><img src="./1552822557891.png" alt="Alt text"></p>
<h3 id="2-2-The-Web-and-HTTP"><a href="#2-2-The-Web-and-HTTP" class="headerlink" title="2.2 The Web and HTTP"></a>2.2 The Web and HTTP</h3><p><img src="./1552822678266.png" alt="Alt text"><br> HTTP依靠TCP协议</p>
<h4 id="2-2-2-Non-Persistent-and-Persistent-Connections"><a href="#2-2-2-Non-Persistent-and-Persistent-Connections" class="headerlink" title="2.2.2 Non-Persistent and Persistent Connections"></a>2.2.2 Non-Persistent and Persistent Connections</h4><p> <strong>Non-Persistent</strong><br> 例如请求10个图像<br> 对于每个图像要<br> 1.向80端口建立连接<br> 2.发送请求<br> 3.服务器响应并发送文件<br> 4.服务器通知中断连接(不过等到文件传输完后才会真正断开)<br> <img src="./1552823053923.png" alt="Alt text"><br>  <strong>Persistent</strong><br>  连接后不中断</p>
<h4 id="2-2-3-HTTP-Message-Format"><a href="#2-2-3-HTTP-Message-Format" class="headerlink" title="2.2.3 HTTP Message Format"></a>2.2.3 HTTP Message Format</h4><p>  请求信息<br>  <img src="./1552823143210.png" alt="Alt text"></p>
<blockquote>
<p><strong>POST和GET的区别</strong><br>get参数通过url传递，post放在request body中。<br>get请求在url中传递的参数是有长度限制的，而post没有。<br>get不安全,因为参数直接暴露,只能进行url编码,而且记录会保留<br>POST发送2个TCP包,GET是1个</p>
</blockquote>
<h4 id="2-2-4-Cookies"><a href="#2-2-4-Cookies" class="headerlink" title="2.2.4 Cookies"></a>2.2.4 Cookies</h4><p><strong>cookie</strong> technology has four components: (Cookies的4个部件)<br>在请求和回应包头里加cookies行<br>(1) a cookie header line in the HTTP response message;<br>(2) a cookie header line in the HTTP request message;<br>文件保存在用户本地并由浏览器保管，还有一个后端数据库在服务器上<br>(3) a cookie file kept on the user’s end system and managed by the user’s browser;<br>(4) a back-end database at the Web site<br><img src="./1552823809643.png" alt="Alt text"><br>如图，首次进入时，没有记录，于是服务器在后端数据库上窗口一个新条目，保存用户信息，然后回应包中加上cookies。然后用户会保存cookies在本地,然后再请求一次获取正常网页。下次请求（只要没清理cookies)，请求头会带上相应cookies,然后服务器可以直接返回信息</p>
<h4 id="2-2-5-Web-Cache"><a href="#2-2-5-Web-Cache" class="headerlink" title="2.2.5 Web Cache"></a>2.2.5 Web Cache</h4><p><strong>Web cache</strong>—also called a <strong>proxy server</strong>.<br><img src="./1552824077608.png" alt="Alt text"><br>加速原理:<br>就是连了个proxy server.一个client发送请求先过Proxy server,这个server看看它有没有需要的数据，有的话就HTTP返回。没有的话由他来向目的网站发HTTP请求，并获得回应，之后存在本地，然后发回给client.<br>所以,<strong>不管有没有存有数据都能加速</strong>，因为server带宽是很高的</p>
<p>例子<br><img src="./1552824442929.png" alt="Alt text"><br>在两个交换机间会有较大的queuing delay<br>加上proxy server后<br><img src="./1552824497680.png" alt="Alt text"></p>
<h3 id="2-3-FTP"><a href="#2-3-FTP" class="headerlink" title="2.3 FTP"></a>2.3 FTP</h3><p><img src="./1552824681220.png" alt="Alt text"></p>
<h3 id="2-4-Electronic-Mail-in-the-Internet"><a href="#2-4-Electronic-Mail-in-the-Internet" class="headerlink" title="2.4 Electronic Mail in the Internet"></a>2.4 Electronic Mail in the Internet</h3><p>发<br><strong>SMTP</strong> port:25<br><strong>MIME</strong><br>收<br><strong>POP3</strong> port 110<br><strong>IMAP</strong><br><img src="./1552825053818.png" alt="Alt text"></p>
<h3 id="2-5-DNS"><a href="#2-5-DNS" class="headerlink" title="2.5 DNS"></a>2.5 DNS</h3><p><img src="./1552825134311.png" alt="Alt text"><br><strong>TLD(Top-level domain)</strong><br><img src="./1552825389964.png" alt="Alt text"><br><img src="./1552825403190.png" alt="Alt text"><br><strong>recursive queries and iterative queries</strong><br>图中1是递归查询，其他都是迭代查询<br>理论上任何查询都可以既是迭代也是递归的</p>
<p><strong>DNS Cache</strong><br>保持解析过的记录到本地。下次不要再重复解析了</p>
<h4 id="2-5-3-DNS-Records-and-Messages"><a href="#2-5-3-DNS-Records-and-Messages" class="headerlink" title="2.5.3 DNS Records and Messages"></a>2.5.3 DNS Records and Messages</h4><p><strong>(Name, Value, Type, TTL)</strong><br><img src="./1552825295157.png" alt="Alt text"></p>
<blockquote>
<p><strong>Type:</strong><br><strong>A:主机名到IP</strong> (relay1.bar.foo.com, 145.37.93.126, A)<br><strong>NS:主机名到DNS服务器</strong> (foo.com, dns.foo.com, NS)<br><strong>CNAME:</strong>主机到主机 (foo.com, relay1.bar.foo.com, CNAME)<br><strong>MX</strong> 邮件服务器</p>
</blockquote>
<p>TTL为记录生存时间</p>
<h3 id="2-6-P2P"><a href="#2-6-P2P" class="headerlink" title="2.6 P2P"></a>2.6 P2P</h3><p><img src="./1552826220523.png" alt="Alt text"><br>C/S下<br><img src="./1552826226759.png" alt="Alt text"><br>=&gt;<img src="./1552826231529.png" alt="Alt text"><br>P2P下每个客户端都上传<br><img src="./1552826248529.png" alt="Alt text"><br>1.一开始只有服务器有文件,服务器上传$F/u_s$<br>取下界<br><img src="./1552826416661.png" alt="Alt text"></p>
<blockquote>
<p><strong>tracker</strong><br>随机选择peer,把peer列表(包含IP)，发给需求者。尝试TCP建立连接<br>每个peer都有文件块子集，如果需求者有L个不同peer那么能获得L个块列表,然后向没有的块发请求（通过TCP）<br><strong>rarest first:</strong>决定请求哪些块的技术。选择最稀缺（peer中副本最少的块）<br><strong>DHT：Distributed Hash Table</strong><br>在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储.DHT的出现用于解决当tracker服务器不可用时，P2P客户端依然可以取得某个资源的peer。DHT解决这个问题，是因为它将原来tracker上的资源peer信息分散到了整个网络中</p>
</blockquote>
<h4 id="2-6-2-BitTorrent"><a href="#2-6-2-BitTorrent" class="headerlink" title="2.6.2 BitTorrent"></a>2.6.2 BitTorrent</h4><p>tracker:</p>
<h2 id="Chapter-3-Transport-Layer"><a href="#Chapter-3-Transport-Layer" class="headerlink" title="Chapter 3 Transport Layer"></a>Chapter 3 Transport Layer</h2><blockquote>
<p>IP:<strong>Best-effort</strong><br>不确保，只负责交付segment</p>
<h3 id="3-3-UDP"><a href="#3-3-UDP" class="headerlink" title="3.3 UDP"></a>3.3 UDP</h3><p>UDP,使用二元组(ip，port)标识,无连接。<br><strong>应用层控制更加精细，能容忍丢失，不希望过分延迟</strong><br><strong>无需建立连接</strong><br><strong>首部开销少</strong></p>
</blockquote>
<p><strong>UDP是端到端</strong><br><img src="./1553257256426.png" alt="Alt text"></p>
<p><img src="./1553257402788.png" alt="Alt text"><br><strong>checksum计算方法:</strong><br>把所有16位的字相加，如果遇到进位，则将高于16字节的进位部分的值<strong>加到</strong>最低位上,然后取反</p>
<h3 id="3-4-Principles-of-Reliable-Data-Transfer-可靠数据传输规则"><a href="#3-4-Principles-of-Reliable-Data-Transfer-可靠数据传输规则" class="headerlink" title="3.4 Principles of Reliable Data Transfer(可靠数据传输规则)"></a>3.4 Principles of Reliable Data Transfer(可靠数据传输规则)</h3><p><img src="./1553258330329.png" alt="Alt text"></p>
<h4 id="3-4-1-Building-a-Reliable-Data-Transfer-Protocol"><a href="#3-4-1-Building-a-Reliable-Data-Transfer-Protocol" class="headerlink" title="3.4.1 Building a Reliable Data Transfer Protocol"></a>3.4.1 Building a Reliable Data Transfer Protocol</h4><blockquote>
<p><strong>RDT1.0  (完全可靠的信道，Perfectly Reliable Channel)</strong><br><img src="./1553258403873.png" alt="Alt text"><br><strong>RDT2.0 (存在位错误),使用了ARQ(Automatic Repeat reQuest,自动重传请求)</strong><br>加上3种机制:<br><strong>1.Error detection(差错检测)</strong><br><strong>2.Receiver feedback(反馈)</strong><br><strong>3.Retransmission(重传)</strong></p>
</blockquote>
<p><img src="./1553258913542.png" alt="Alt text"><br><strong>也叫stop-and-wait protocol</strong></p>
<blockquote>
<p><strong>RDT2.1 在2.0上改进。使用duplicate ACKs</strong><br><img src="./1553259179385.png" alt="Alt text"><br><img src="./1553259292218.png" alt="Alt text"><br><strong>RDT2.2 </strong><br><img src="./1553259179385.png" alt="Alt text"><br><img src="./1553259442144.png" alt="Alt text"></p>
<p><strong>RDT3.0 多了定时器，能处理timeout</strong><br><img src="./1553259456805.png" alt="Alt text"><br><img src="./1553259622768.png" alt="Alt text"><br><strong>流水线:pipelined sending</strong><br><img src="./1553259673795.png" alt="Alt text"><br>Two basic approaches toward pipelined error<br>recovery can be identified: <strong>Go-Back-N</strong> and <strong>selective repeat</strong>.<br><strong>Go-Back-N(Sliding-Window protocol)</strong><br>sender响应3个事件<br>1.上层调用：先检查发送窗口有没有满，满的话返回上层<br>2.收到ACK，采用累计确认<br>3.timeout,<br>receiver:<br>收到一个序号为n的包。如果有序的话，就为n个包发个累计确认。其他情况全部丢弃<strong>为最近按序接受的包发送ack</strong></p>
<p><strong>Selective Repeat</strong></p>
<h3 id="3-5-TCP"><a href="#3-5-TCP" class="headerlink" title="3.5 TCP"></a>3.5 TCP</h3><p>TCP is said to be <strong>connection-oriented</strong><br><strong>connection</strong><br>1.设置sequence 2,设置 buff<br><strong>MSS:Maximum Segment Size</strong> 一般由 <strong>Maximum Transmission Unit</strong>设置<br><img src="./1553261213038.png" alt="Alt text"><br><strong>Reliable Data Transfer</strong><br><strong>Connection Management</strong><br><img src="./1553261682224.png" alt="Alt text"></p>
</blockquote>
<p><img src="./1553261719164.png" alt="Alt text"></p>
<blockquote>
<p><strong>Congestion Control</strong><br>1.slow start<br>窗口从1开始，指数增加，发生loss又变成1，然后重新开始,并且<strong>ssthresh(慢启动阈值)</strong>/2。大于ssthresh后进入拥塞避免<br>2.Congestion Avoidance<br>1）收到一个ACK时，cwnd = cwnd + 1/cwnd<br>2）当每过一个RTT时，cwnd = cwnd + 1<br>是一个线性上升的算法<br>3.Fast Recovery<br>该算法认为，收到<strong>3个重复AKC</strong>,说明网络不是很糟糕,<br>cwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）<br>重传Duplicated ACKs指定的数据包<br>如果再收到 duplicated Acks，那么cwnd = cwnd +1<br>如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。<br>也就是不是从1开始线性增长，而是从1/2cwnd+3MSS</p>
</blockquote>
<p><img src="./1553262655594.png" alt="Alt text"><br><img src="./1553262661785.png" alt="Alt text"></p>
<h2 id="KeyWord"><a href="#KeyWord" class="headerlink" title="KeyWord"></a>KeyWord</h2><h3 id="4"><a href="#4" class="headerlink" title="4"></a>4</h3><p><strong>RTT(round-trip time)</strong><br><strong>Traffic intensity</strong><br><strong>Encapsulation</strong><br><strong>DDOS</strong><br><strong>FQDN(绝对域名)</strong><br><strong>Kademlia</strong><br><strong>Best-effort</strong><br><strong>demultiplexing</strong><br><strong>Selective Repeat</strong><br><strong>ABR:available bit-rate</strong><br><strong>ssthresh</strong></p>
<p><strong>Fast retransmit</strong><br><strong>Routing</strong><br><strong>Forwarding</strong><br><strong>Head-of-the-line blocking</strong><br><strong>MTU</strong><br><strong>NAT</strong><br><strong>UPnP</strong><br><strong>ICMP</strong><br><strong>Link-State</strong><br><strong>Distance Vector Algorithm</strong><br><strong>OSPF</strong><br><strong>BGP</strong><br><strong>RIP</strong><br><strong>IS-IS</strong><br><strong>Poisoned Reverse</strong><br><strong>hot-potato routing</strong><br><strong>ARP</strong><br><strong>tunnel</strong><br><strong>Bellman-Ford Equation</strong></p>
<p><strong>Network Edge</strong><br><strong>Network Core</strong><br><strong>HFC(Hybrid Fiber Coaxial)</strong><br><strong>Circuit switching</strong><br><strong>C/S</strong><br><strong>B/S</strong><br><strong>Web Cache</strong><br><strong>Cookies</strong><br><strong>tit-for-tat</strong><br><strong>optimistically unchoke</strong> &amp;<strong>Choking</strong><br><strong>Socket</strong><br><strong>MSS</strong><br><strong>MAC</strong><br><strong>CBR&amp;ABR</strong><br><strong>HOL</strong><br><strong>DHCP</strong><br><strong>Link-State&amp;Vector Distance</strong><br><strong>IPV6 AND IPV4</strong><br><strong>OSPF AND RIP</strong><br><strong>BGP</strong><br><strong>Reverse Path Forward</strong><br><strong>flooding&amp; controled flooding</strong><br><strong>PIM</strong><br><strong>share tree &amp; source tree</strong><br><strong>ICMP Pinglo25</strong><br><strong>BitTorrent</strong><br><strong>best effort</strong></p>
]]></content>
  </entry>
  <entry>
    <title>Beta分布与最大后验估计(MAP)</title>
    <url>/2019/12/26/Beta%E5%88%86%E5%B8%83%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1(MAP)/</url>
    <content><![CDATA[<h1 id="Beta分布与最大后验估计-MAP"><a href="#Beta分布与最大后验估计-MAP" class="headerlink" title="Beta分布与最大后验估计(MAP)"></a>Beta分布与最大后验估计(MAP)</h1><h2 id="Beta分布"><a href="#Beta分布" class="headerlink" title="Beta分布"></a>Beta分布</h2><ul>
<li>二次分布:<strong>抛n次硬币出现k次正面的概率</strong><script type="math/tex; mode=display">P(S=k)=C_n^kp^k(1-p)^{n-k}</script></li>
<li>几何分布:<strong>抛第t次时，该次为第一次出现正面的概率</strong><script type="math/tex; mode=display">P(T=t)=(1-p)^{t-1}p</script></li>
<li>帕斯卡分布:<strong>抛第t次时,第k次出现正面</strong><script type="math/tex; mode=display">P(Y_k=t)=C_{t-1}^{k-1}p^{k-1}(1-p)^{t-k}p</script></li>
</ul>
<p>可以发现以上可以用一个统一分布来描述</p>
<script type="math/tex; mode=display">B(x|\alpha,\beta)=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}</script><p>a,b为形状参数<br>B为归一化函数</p>
<h3 id="理解1"><a href="#理解1" class="headerlink" title="理解1"></a>理解1</h3><p>首先抛开B。看看简单的变体$f(x|\alpha,\beta)=x^\alpha(1-x)^\beta$<br>对于贝叶斯主义者，不应该使用频率主义，要把概率当做随机变量。<br>如抛出7次正面，3次反面。概率分布是关于X的函数.</p>
<p>$f(x|7,3)=x^7(1-x)^3$<br>该函数在0.7处取得最大值，说明极有可能正面概率是0.7</p>
<p>几种特殊分布<br>1.a=b=1时为均匀分布，a=b时</p>
<p><strong>用于贝叶斯推断</strong><br>在推断中，我们往往在意模型的参数，对于贝叶斯主义来说，这些参数不是一个确定的值，而是服从某个分布。记参数为[随机变量]$\theta$</p>
<p>现在我们有了一个观察$X=(X_1,X_2,….,X_n)$<br>这些观察可以看做是在$\theta$下的条件分布<br>于是现在该有的东西都有了，我们可以利用贝叶斯求出在x下\theta的概率 (后验概率,通过观察而得到的)<br><img src="./1570541866056.png" alt="Alt text"></p>
<p><strong>共轭先验(Conjugate prior):</strong><br><img src="./1570542071006.png" alt="Alt text"><br><img src="./1570542323768.png" alt="Alt text"><br><img src="./1570542332548.png" alt="Alt text"><br><img src="./1570542352805.png" alt="Alt text"><br><img src="./1570542374236.png" alt="Alt text"></p>
<h2 id="Beta分布下的MAP-最大后验估计"><a href="#Beta分布下的MAP-最大后验估计" class="headerlink" title="Beta分布下的MAP(最大后验估计)"></a>Beta分布下的MAP(最大后验估计)</h2><p>考虑最大后验公式</p>
<script type="math/tex; mode=display">argmax_\theta \quad log(D|\theta)+log p(\theta)</script><p>其中$\theta$ 服从Beta分布 (要运用贝叶斯的观点,参数不是一个定值,也是服从某个概率分布的)</p>
<script type="math/tex; mode=display">Beta(\theta;a,b)=\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{a-1}(1-\theta)^{b-1}</script><p>于是,有</p>
<script type="math/tex; mode=display">\log p(\theta)=C+(a-1)log \theta+(b-1)log(1-\theta)</script><p>最左边的是进行概率归一化用，是一个常数。因此取对数得到C</p>
<p>接下来  <script type="math/tex">log p(D|\theta)=log L(\theta)</script><br>与似然函数相同，又$L(\theta)=\prod\theta^{x_n}(1-\theta)^{1-x_n}$<br>这里假设X服从的是伯努利分布 x_n=1 或 0</p>
<script type="math/tex; mode=display">log L(\theta)=\sum_{i=1}^nx_ilog\theta+(1-x_i)log(1-\theta)</script><p>于是有</p>
<script type="math/tex; mode=display">\quad log(D|\theta)+log p(\theta)=\\((\sum_{n=1}^Nx_n+a-1)log \theta)+((\sum_{n=1}^N(1-x_n)+b-1)log (1-\theta))+C</script>]]></content>
  </entry>
  <entry>
    <title>【统计学习】逐步回归(Step Regression and) 和 分段回归(Stagewise regression)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92(Step%20Regression%20and)%20%E5%92%8C%20%E5%88%86%E6%AE%B5%E5%9B%9E%E5%BD%92(Stagewise%20regression)/</url>
    <content><![CDATA[<h1 id="【统计学习】-逐步回归-Step-Regression-and-和-分段回归-Stagewise-regression"><a href="#【统计学习】-逐步回归-Step-Regression-and-和-分段回归-Stagewise-regression" class="headerlink" title="【统计学习】*逐步回归(Step Regression and) 和 分段回归(Stagewise regression)"></a>【统计学习】*逐步回归(Step Regression and) 和 分段回归(Stagewise regression)</h1><blockquote>
<p>Enter：所有X一次性全部进入<br>Forward：X一个一个进，每次进入P-value最小的X，直到未进入的X都不significant<br>Backward：所有的X先一次性进入，然后一个一个剔除，每次剔除P-value最大的X，直到保留的X全都significant<br>Stepwise：X一个一个进，但是进入新的X以后，会重新审查所有已进入X的P-value，如果进入新的X导致原来的X的P-value从significant变成不significant，则把原来的X剔除。</p>
</blockquote>
<h2 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h2><script type="math/tex; mode=display">A=QR</script><p>在ols(最小二乘)中要计算$（X^TX)^{−1}$，可以通过矩阵分解简化计算，将X分解成QR乘积的形式，其中Q是一个$N∗(p+1)$的正交矩阵，也就是X的列空间的一组正交基，R是一个上三角矩阵，于是，$\hatβ=（X^TX)^{−1}X^Ty=R^{−1}Qy，\hat y=QQ^Ty$</p>
<hr>
<h2 id="子集选择"><a href="#子集选择" class="headerlink" title="子集选择"></a>子集选择</h2><p>有两个原因导致我们对最小二乘法（ols）的估计不满意：<br>1.第一个原因是<strong>预测精度（accuracy）</strong>，最小二乘法估计通常具有低偏差（bias）和高方差（var），我们想要通过使某些系数收缩或者设置为零，牺牲一些偏差来换取方差的减小，这样一来可以提升预测的精度。<br>2.第二个原因是<strong>解释（interpretation）</strong>，当有大量的自变量的时候，我们希望确定一个表现出最强影响的较小子集。</p>
<p>以下是三种子集选择的方法</p>
<h3 id="最优子集选择（best-subset-selection）"><a href="#最优子集选择（best-subset-selection）" class="headerlink" title="最优子集选择（best-subset selection）"></a>最优子集选择（best-subset selection）</h3><p>最优子集选择，顾名思义，就是便利所有可能的预测子的集合然后在训练集上进行ols确定参数，最后选取在测试集上表现最好的集合作为最优子集。</p>
<h3 id="前向-后向逐步选择（forward-backwards-stepwise-selection）"><a href="#前向-后向逐步选择（forward-backwards-stepwise-selection）" class="headerlink" title="前向/后向逐步选择（forward/backwards-stepwise selection）"></a>前向/后向逐步选择（forward/backwards-stepwise selection）</h3><p>当预测子的数量变大时，最优子集选择就变得不可行了。这时候考虑使用逐步选择的算法。类似分部操作回归 </p>
<blockquote>
<p>前向逐步选择算法<strong>首先选择截距</strong>（由1构成的N维列向量），然后<strong>每次向当前集合中添加能使得残差平方和RSS变得最小的预测子</strong>，也就是选择残差向量投影后长度最大的方向。 </p>
<p>后向逐步选择算法从一个包含所有自变量出发，<strong>每次删除一个自变量</strong>，每次删除的是具有最小Z得分的自变量（参见上一篇博客 ）。<br>因为计算Z得分的时候用到了$\hatσ^2/σ^2$服从自由度为$N−p−1$的卡方分布的这个性质，所以当N&lt;=p的时候不能使用后向逐步选择，而前向逐步选择则没有这个限制。 </p>
</blockquote>
<p>还可以将前向后向逐步选择算法结合起来，在每一步的时候选择向当前集合添加或者删除一个自变量，比如说可以利用AIC准则来衡量这个选择。</p>
<h3 id="前向分段回归（Forward-Stagewise-Regression）"><a href="#前向分段回归（Forward-Stagewise-Regression）" class="headerlink" title="前向分段回归（Forward-Stagewise Regression）"></a>前向分段回归（Forward-Stagewise Regression）</h3><p>FS比前向逐步回归限制更多。首先将截距的系数设置为$\hat y$，然后将<strong>其他自变量的系数设置为零</strong>。在算法的每一步，<strong>挑选和当前残差最相关的自变量</strong>，然后算法<strong>计算当前残差关于这个自变量的简单最小二乘法的系数</strong>，随后将这个系数加到之前这个自变量的系数上，算法持续<strong>执行直到没有自变量与残差相关（相关系数很小）</strong>。与逐步选择不同的是，每次选择一个最相关的自变量并计算它的系数时，算法并不改变其他自变量的系数，而<strong>逐步回归每次增加一个自变量的时候都要重新进行一次ols更新所有自变量的系数</strong>，也正是因为这一特性，FS可能要经过比p多很多的迭代次数才能到达最终的拟合值，因此效率不是很高，但<strong>FS在高维数据中表现出色</strong>，可以降低方差。</p>
<pre><code># 前向分段回归
def stageWiseRegres(xArr, yArr, eps=0.01, numIter=100):
  xMat = mat(xArr); yMat = mat(yArr).T
  m, n = shape(xMat)  #获取矩阵形状
  # 数据标准化
  xMean = mean(xMat, 0)
  xStd = std(xMat, 0)
  xMat = (xMat-xMean)/xStd
  yMean = mean(yMat)
  yMat -= yMean
  beta = zeros((n, 1))
  mu = 0
  for i in range(numIter):
      cHat = -1
      sig = 0
      bestFeat = -1
      for j in range(n):  #遍历n个向量,寻找与RSS最相关的
          cTemp = xMat[:, j].T * (yMat - mu)  #第j列向量乘
          if abs(cTemp) &gt; cHat:
              cHat = abs(cTemp)
              sig = sign(cTemp)
              bestFeat = j
      beta[bestFeat, 0] += sig*eps
      mu += float(eps*sig)*xMat[:, bestFeat]
  return beta
</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>Forward selection: </strong>首先模型中只有一个单独解释因变量变异最大的自变量，之后尝试将加入另一自变量，看加入后整个模型所能解释的因变量变异是否显著增加（这里需要进行检疫，可以用 F-test， t-test 等等）；这一过程反复迭代，直到没有自变量再符合加入模型的条件。<br><strong>Backward elimination: </strong>与 Forward selection 相反，此时，所有变量均放入模型，之后尝试将其中一个自变量从模型中剔除，看整个模型解释因变量的变异是否有显著变化，之后将使解释量减少最少的变量剔除；此过程不断迭代，直到没有自变量符合剔除的条件。<br><strong>Bidirectional elimination: </strong>这种方法相当于将前两种结合起来。可以想象，如果采用第一种方法，每加入一个自变量，可能会使已存在于模型中的变量单独对因变量的解释度减小，当其的作用很小（不显著）时，则可将其从模型中剔除。而第三种方法就做了这么一件事，不是一味的增加变量，而是增加一个后，对整个模型中的所有变量进行检验，剔除作用不显著的变量。最终尽可能得到一个最优的变量组合。</p>
]]></content>
  </entry>
  <entry>
    <title>【信息论】Entropy、Relative Entropy,K-L distance</title>
    <url>/2019/12/26/%E3%80%90%E4%BF%A1%E6%81%AF%E8%AE%BA%E3%80%91Entropy%E3%80%81Relative%20Entropy,K-L%20distance/</url>
    <content><![CDATA[<h1 id="【信息论】Entropy、Relative-Entropy-K-L-distance"><a href="#【信息论】Entropy、Relative-Entropy-K-L-distance" class="headerlink" title="【信息论】Entropy、Relative Entropy,K-L distance"></a>【信息论】Entropy、Relative Entropy,K-L distance</h1><h1 id="Entropy-熵"><a href="#Entropy-熵" class="headerlink" title="Entropy(熵)"></a>Entropy(熵)</h1><script type="math/tex; mode=display">H(X)=-\sum_{x\in \mathscr{X}}p(x)log(p(x))=-E(log(p(x))</script><p>熵表现了信息量的多少，概率越小的样本信息量越大。其是<strong>概率对数的期望</strong><br>log底数为</p>
<ul>
<li>2：比特 bit</li>
<li>e：奈特 nat</li>
</ul>
<p><strong>为确定X的值所需的二元问题数的最小期望介于H(X)与H(X)+1之间</strong></p>
<p><strong>条件熵(Conditional Entropy)</strong>和<strong>联合熵(Joint Entropy)</strong>按照概率论方式算即可<br>不过因为这里是对数<br>所以概率中联合分布和条件分布的式子要改一改</p>
<script type="math/tex; mode=display">H(X,Y)=H(X)+H(Y|X)\\H(X,Y|Z)=H(Y|X,Z)</script><p><strong>KL散度</strong></p>
<blockquote>
<p>KL散度也叫互信息或者鉴别信息。是描述<strong>两个随机分布</strong>之间的距离的度量</p>
</blockquote>
<script type="math/tex; mode=display">D(p||q)=\sum_xp(x)\log \frac{p(X)}{q(X)}=E(\log \frac{p(X)}{q(X)})</script><p>其是两个随机变量相除的对数的期望</p>
<p><strong>互信息</strong></p>
<blockquote>
<p>互信息可以了解某个随机变量为另一个随机变量提供了多少信息量</p>
</blockquote>
<script type="math/tex; mode=display">I(X;Y)=H(X)-H(X|Y)=H(X)+H(Y)-H(X,Y)</script><p>可以看到I(X;Y)是描述Y可以为X提供多少信息的度量。也就是<strong>在知道Y的情况下X的信息量下降了多少</strong><br>特别地</p>
<script type="math/tex; mode=display">I(X;X)=H(X)</script><p>也就是说X可以为自己提供H(X)  (全部)的信息量<br>互信息的链式法则</p>
<script type="math/tex; mode=display">I(X_1,X_2,...,X_n;Y)=\sum_{i=1}^n I(X_i;Y|X_{i-1},X_{i-1},...,X_1)</script><p>解释:对于每个X_i,求是，在知道他之前的i-1个X的情况下知道Y可以为X_i提供多少信息量</p>
<p><strong>条件相对熵</strong><br>也就是p和q变成条件分布了</p>
<script type="math/tex; mode=display">D(p(y|x)||q(y|x))</script><p>链式法则</p>
<script type="math/tex; mode=display">D(p(y,x)||q(y,x))=D(p(x)||q(x))+D(p(y|x)||q(y|x))</script><p><strong>Jensen不等式</strong></p>
<script type="math/tex; mode=display">Ef(X)\ge f(EX),f为凸函数</script><p><strong>熵的独立界</strong></p>
<script type="math/tex; mode=display">H(X_1,X_2,...,X_n)\le \sum_{i=1}^n H(X_i),当且仅当X_i相互独立等号成立</script><p><strong>对数和不等式</strong></p>
<script type="math/tex; mode=display">\sum_{i=1}^n a_i\log \frac{a_i}{b_i}\ge (\sum_{i=1}^na_i)\log \frac{\sum_{i=1}^n a_i}{\sum_{i=1}^nb_i}</script><p><strong>数据处理不等式</strong></p>
<script type="math/tex; mode=display">X\rightarrow Y\rightarrow Z$$构成马尔科夫链
$$I(X;Y)\ge I(X;Z)</script><p>解释:<strong>相邻的随机过程能够提供更多的信息</strong></p>
<p><strong>Fano不等式</strong></p>
<script type="math/tex; mode=display">X\rightarrow Y\rightarrow \hat X</script><p>$\hat X$是一个估计量<br>误差概率$P_e=Pr\{\hat X!= X\}$</p>
<script type="math/tex; mode=display">H(P_e)+P_e\log (\mathscr{X})\ge H(X|Y)</script>]]></content>
  </entry>
  <entry>
    <title>【信息论】AEP(渐进均分性)&amp;随机过程熵率&amp;数据压缩</title>
    <url>/2019/12/26/%E3%80%90%E4%BF%A1%E6%81%AF%E8%AE%BA%E3%80%91AEP(%E6%B8%90%E8%BF%9B%E5%9D%87%E5%88%86%E6%80%A7)&amp;%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E7%86%B5%E7%8E%87&amp;%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<h1 id="【信息论】AEP-渐进均分性-amp-随机过程熵率-amp-数据压缩"><a href="#【信息论】AEP-渐进均分性-amp-随机过程熵率-amp-数据压缩" class="headerlink" title="【信息论】AEP(渐进均分性)&amp;随机过程熵率&amp;数据压缩"></a>【信息论】AEP(渐进均分性)&amp;随机过程熵率&amp;数据压缩</h1><h2 id="AEP"><a href="#AEP" class="headerlink" title="AEP"></a>AEP</h2><script type="math/tex; mode=display">-\frac{1}{n}\log p(X_1,X_2,...,X_n)\rightarrow H(X),依概率</script><p>证明很简单。就是X_i与X_j是相互独立的，然后就可以把联合分布展开出来，就变成均值公式了，依概率后就是期望了</p>
<h2 id="典型集"><a href="#典型集" class="headerlink" title="典型集"></a>典型集</h2><p>是序列$(x_1,x_2,…,x_n)\in \mathscr{X}$的集合</p>
<script type="math/tex; mode=display">H(X)-\epsilon\le -\frac{1}{n}\log p(x_1,x_2,...,x_n)\le H(X)+\epsilon</script><p>典型集的概率近似为1</p>
<p>典型集的大小为$2^{n(H+\epsilon)}$<br>于是典型序列需要${n(H+\epsilon)}+2\approx nH$bit来描述(每个变量都约需要H来描述,个数为n的序列就是nH)<br>加2是因为<br>1.为了防止非整数长度，加了个1<br>2.为了表示是典型集，加一个标志位</p>
<h2 id="最小概率集"><a href="#最小概率集" class="headerlink" title="最小概率集"></a>最小概率集</h2><script type="math/tex; mode=display">a_n\doteq b_n$$表示
$$\lim_{n\rightarrow n}\frac{1}{n}\log\frac{a_n}{b_n}=0</script><p>最小概率集</p>
<script type="math/tex; mode=display">|B_\delta^{(n)}|\doteq 2^{nH}</script><h2 id="随机过程熵率"><a href="#随机过程熵率" class="headerlink" title="随机过程熵率"></a>随机过程熵率</h2><p><strong>平稳随机过程:</strong><br>联合分布随时间下标位移不变<br>（就是某序列的联合分布，序列里全部随机变量下标加上相同时间后，这个联合分布的概率还是不变）</p>
<h3 id="求解平稳概率"><a href="#求解平稳概率" class="headerlink" title="求解平稳概率"></a>求解平稳概率</h3><p>解<script type="math/tex">\mu P=\mu</script><br>即可。$P$是概率转移矩阵<br>$\mu$是平稳概率矩阵。要求的是$\mu$<br>$\sum\mu_i=1$<br>某时刻状态n的熵</p>
<script type="math/tex; mode=display">H(X_n)=H(\mu_1,\mu_2,...)</script><h3 id="熵率"><a href="#熵率" class="headerlink" title="熵率"></a>熵率</h3><center>
两种定义方式
$H(\mathscr{X})=\lim_{n\rightarrow\infty}\frac{1}{n}H(X_1,X_2,...,X_n)$
$H'(\mathscr{X})=\lim_{n\rightarrow\infty}H(X_n|X_1,X_2,...,X_{n-1})$
对于平稳随机过程两者相等
</center>


<p>马尔科夫链函数(隐马尔可夫模型)</p>
<script type="math/tex; mode=display">H(Y_n|X_{n-1},...,Y_1,X_1)\le H(\mathscr{Y}) \le H(Y_n|Y_{n-1},...,Y_1)</script><p>Y_i是X_i加了个映射。服从p(y|x)<br>可以看到<br>1.H(y)的不确定度小于”知道前n-1个状态下,y_n状态的不确定度””<br>2.但是H(y)的不确定度又大于知道前n-1个y而且又知道x_1的情况下y_n状态的不确定度</p>
<h2 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h2><h3 id="Kraft不等式"><a href="#Kraft不等式" class="headerlink" title="Kraft不等式"></a>Kraft不等式</h3><p>对于即时码（可以自动划分的）<br>有</p>
<script type="math/tex; mode=display">\sum D^{-l_i}\le 1</script><p>证明过程就是画颗树。然后剪枝，计算就行</p>
<h3 id="香农码"><a href="#香农码" class="headerlink" title="香农码"></a>香农码</h3><p>非最优<br>平均码长$L=\sum p_il_i$<br>香农取$l_i=log_D\frac{1}{p_i}向上取整$</p>
<h3 id="Huffman码"><a href="#Huffman码" class="headerlink" title="Huffman码"></a>Huffman码</h3><p>最优</p>
<h3 id="偏码"><a href="#偏码" class="headerlink" title="偏码"></a>偏码</h3><p>如果真实分布为p(x)<br>却使用了非真实分布q(x)<br>那么不等式需要加个<strong>KL散度</strong>作为惩罚项</p>
<script type="math/tex; mode=display">H(p)+D(p||q)\le L\le H(p)+D(p||q)+1</script><h3 id="随机过程"><a href="#随机过程" class="headerlink" title="随机过程"></a>随机过程</h3><p>对于平稳过程。L_n码长依概率逼近于熵率<br>否则<br>$\frac{H(X_1,X_2,…,X_n)}{n}\le L_n\le\frac{H(X_1,X_2,…,X_n)}{n}+\frac{1}{n}$</p>
<h2 id="博弈论"><a href="#博弈论" class="headerlink" title="博弈论"></a>博弈论</h2><p><strong>双倍率</strong></p>
<script type="math/tex; mode=display">W(b,p)=\sum_{k=1}^mp_k\log b_ko_k</script><p>b表示投资比例向量。合为1<br>p_k表示第k个博弈事件成功概率<br>o_k表示k th博弈成功收益(为投资比例的相对值)</p>
<p><strong>按比例博弈是最优的</strong></p>
<script type="math/tex; mode=display">W*(p)=\max_b W(b,p)=\sum p_i\log o_i-H(p)</script><p>移向可以发现存在<strong>守恒定律</strong><br><strong>双倍率和熵率之和为常数</strong></p>
<p><strong>边信息</strong><br>由边信息Y，导致的双倍率增量为</p>
<script type="math/tex; mode=display">\Delta W=I(X;Y)</script>]]></content>
  </entry>
  <entry>
    <title>【统计学习】Shrinkage Method</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Shrinkage%20Method/</url>
    <content><![CDATA[<h1 id="【统计学习】Shrinkage-Method"><a href="#【统计学习】Shrinkage-Method" class="headerlink" title="【统计学习】Shrinkage Method"></a>【统计学习】Shrinkage Method</h1><h2 id="岭回归-Ridge-Regression"><a href="#岭回归-Ridge-Regression" class="headerlink" title="岭回归(Ridge Regression)"></a>岭回归(Ridge Regression)</h2><blockquote>
<p><strong>岭回归(英文名：ridge regression, Tikhonov regularization)</strong>是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。</p>
</blockquote>
<h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><p>岭回归在最小二乘法的基础上加上了一个<strong>L2惩罚项</strong>(正则化项。也就是使用了L2正则化)(<strong>关于L2正则化可以看另一篇文章</strong>)<br><strong>Loss Function:</strong></p>
<script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m[(  (h_\theta(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^n\theta_j^2   )]</script>]]></content>
  </entry>
  <entry>
    <title>【统计学习】SVM(支持向量机)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91SVM(%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA)/</url>
    <content><![CDATA[<h1 id="【统计学习】SVM-支持向量机"><a href="#【统计学习】SVM-支持向量机" class="headerlink" title="【统计学习】SVM(支持向量机)"></a>【统计学习】SVM(支持向量机)</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h2><blockquote>
<p>支持向量积是通过在二维空间确定一条直线，或者在三维空间确定一个平面或者在高维空间确定一个超平面，使确定的直线\平面\超平面到两类数据的距离最大的分类方式。其只适用于二分类。</p>
</blockquote>
<p><img src="./1555853665952.png" alt="Alt text"><br>可以这么理解。旁边的2类数据点是两个村庄。现在我们要在中间修一条路，把两个村庄隔开。这条路越宽越好。</p>
<p>支持向量积在处理分类问题时有3种解决方案。</p>
<ul>
<li>线性可分——使用<strong>硬间隔</strong></li>
<li>近似线性科峰——使用<strong>软间隔</strong></li>
<li>线性不可分——使用<strong>核技巧</strong></li>
</ul>
<h2 id="2-线性可分——使用硬间隔"><a href="#2-线性可分——使用硬间隔" class="headerlink" title="2 线性可分——使用硬间隔"></a>2 线性可分——使用硬间隔</h2><p><img src="./1555855157933.png" alt="Alt text"></p>
<p>我们希望确定一条直线将两类区分开来。<br>首先我们需要有个直线的表达式</p>
<script type="math/tex; mode=display">y=W^Tx+b \tag{2.1.1}</script><center>
这个表达式既可以表示直线也可以表示平面也可以表示超平面
之后，想之前说的。我们希望直线离两类的间隔尽可能大。
直线到两类的距离是相等的，于是我们可以
$$
\begin{cases}
W^Tx+b<-1 ,& \text{负类}\\
W^Tx+b>1,& \text{正类}
\end{cases}\tag{2.1.2}
$$
至于为什么是-1和1.只是为了方便。如果是2和-2也可以。不过两边同除2就变成
$0.5W^Tx+0.5b=±1$,又变成1了.对后面优化的优化没有影响。所以为了方便。直接取1.
下面。需要求个间隔,这个间隔很好求，根据平行直线的距离公式即可
$$margin=\rho=\frac{2}{||W||} \tag{2.1.3}$$
$||W||$相当于$\sqrt{w_1^2+w_2^2+...}$
于是现在我们得到一个优化问题
$$\max_{W,b} \rho=\max_{W,b} \rho^2=\min_{W,b}\frac{1}{2}||W||^2\tag{2.1.4}$$
也就是在求1/2||W||最小下W,b的值
然后还有个约束条件
$$
\begin{cases}
W^Tx_i+b\le -1 ,& \text{y_i=-1}\\
W^Tx_i+b\ge 1,& \text{y_i=+1}
\end{cases}\tag{2.1.5}
$$
这个约束表示，对于所有输入数据$x_i$都是能分类的(y=±1),也就是我们现在要修一条最宽的路把两个地区分开，输入一个点，不能让他在这路上。
当然这个约束条件还可以再简洁点，观察可以很容易发现可以写成
$$y_i(W^Tx_u+b)\ge 1 \tag{2.1.6}$$
现在我们已经得到了一个带约束的优化问题，经过优化后就可以得到$\hat W和\hat b$
具体如何优化。见第2.1
</center>

<h3 id="2-1-优化"><a href="#2-1-优化" class="headerlink" title="2.1 优化"></a>2.1 优化</h3><center>
总结一下，到目前我们得到了一个带不等式约束条件的优化问题
$$
\begin{cases}
\max_{W,b}\frac{1}{2}||W||^2\\
s.t.\quad y_i(W^Tx_i+b)\ge 1 
\end{cases}\tag{2.1.7}
$$
可以使用拉格朗日乘子法解决
$$L(W,b,\alpha)=\frac{1}{2}||W||^2-\sum_i\alpha_i[y_i(W^Tx_i+b)-1]\tag{2.1.8}$$
对于给定的W,b.
$$
\begin{cases}
max_\alpha L=+\infty,不满足约束\\
max_\alpha L=\frac{1}{2}||W|| ,满足约束
\end{cases}\tag{2.1.9}
$$
>解释：在不满足约束时，$[y_i(W^Tx+b)-1]!=0$,且$\alpha$不定,因此，对此进行最大化优化的话，调整$\alpha$我们可以得到无穷大值

<center>
于是，现在我们得到一个等价的优化目标
$$\min_{W,b}\max_\alpha L(W,b,\alpha) \tag{2.1.10}$$
根据拉格朗日对偶性。我们转换为求其对偶问题
$$\max_\alpha \min_{W,b}L(W,b,\alpha) \tag{2.1.11}$$
先来解决$\min_{W,b}L(W,b,\alpha) $
求对W,b的梯度：
$$\nabla_wL(W,b,\alpha)=0=>||W||=\sum_i\alpha_iy_ix_i \tag{2.1.12}$$
$$\nabla_b L(W,b,\alpha)=0=>\sum_i\alpha_iy_i=0\tag{2.1.13}$$
代入原式就得
$$L(W,b,\alpha)=\sum_i{\alpha_i}-\frac{1}{2}\sum_{i,i=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j$$
然后取负数求min
$$\min_\alpha (\sum_i{\alpha_i}-\frac{1}{2}\sum_{i,i=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j)$$
约束条件
$$\alpha_i\ge0$$
$$\sum_{i=1}^n\alpha_iy_i=0$$
接下来进行优化，就可以得到$\hat \alpha$
然后得到$\hat W=\sum_{i=1}^n\hat\alpha_iy_ix_i$
<center>
</center>

<h4 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h4><script type="math/tex; mode=display">乘子非负:\alpha_i\ge0\\约束条件:y_i(W^Tx_i+b)-1\ge0\\互补条件:\alpha_i(y_i(W^Tx_i+b)-1)=0</script><p>!!$\alpha_i不可能全为0,不然\frac{2}{||W||}=\infty$</p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Principle Component Regression(主成分回归)&amp;Partial Least Squares Regression(偏最小二乘回归)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Principle%20Component%20Regression(%E4%B8%BB%E6%88%90%E5%88%86%E5%9B%9E%E5%BD%92)&amp;Partial%20Least%20Squares%20Regression(%E5%81%8F%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92)/</url>
    <content><![CDATA[<h1 id="【统计学习】Principle-Component-Regression-主成分回归-amp-Partial-Least-Squares-Regression-偏最小二乘回归"><a href="#【统计学习】Principle-Component-Regression-主成分回归-amp-Partial-Least-Squares-Regression-偏最小二乘回归" class="headerlink" title="【统计学习】Principle Component Regression(主成分回归)&amp;Partial Least Squares Regression(偏最小二乘回归)"></a>【统计学习】Principle Component Regression(主成分回归)&amp;Partial Least Squares Regression(偏最小二乘回归)</h1><h2 id="1-简介-amp-PCA"><a href="#1-简介-amp-PCA" class="headerlink" title="1.简介&amp;PCA"></a>1.简介&amp;PCA</h2><p>除了对全部特征进行筛选和压缩——这些都是针对原特征本身，那么是否可以把多个特征组合成少数的几个新特征，使模型更加简洁？特别是多个特征之间往往还存在多重共线性关系。两种方法都将新的预测变量（称为<strong>组件(Components)</strong>）构建为<strong>原始预测变量的线性组合</strong>，但它们以不同的方式构造这些组件。</p>
<p><strong>PCA(主成分分析)</strong>的核心是<strong>降维</strong>,把高维空间上的多个特征组合成少数几个无关的主成分.</p>
<p>举个例子，在二维平面中，如果大部分的点都在一条直线附近，那么可以直接用这条直线当作一维坐标轴来反映原始数据？<br>在三维空间中，如果大部分的点都在一个平面附近，就可以直接用这个平面当作二维平面来反映原始数据</p>
<p><strong>第一主成分</strong>是高维空间上的一个向量，所有的点沿着这条线波动最大，或者说所有的点到直线的距离的平方和最小。如下图所示，所有的点沿着绿色直线的波动最大，它就代表着第一主成分向量。<img src="./1555133796962.png" alt="Alt text"></p>
<p>有了第一主成分，还可以依次往后选择主成分，各主成分之间是<strong>相互正交的向量</strong>。如下左图所示，右图是左图的旋转，以第一主成分作为x轴，第二主成分作为y轴与之垂直。<br><img src="./1555133926809.png" alt="Alt text"></p>
<p>我们定义<strong>主成分是原特征的线性组合</strong>，即：</p>
<script type="math/tex; mode=display">Z_1=\phi_{11}X_1+\phi_{21}X_2+..+\phi_{p1}X_p</script><p>找到一组Φ（其平方和为1），使Z1的方差最大，它的优化问题变成：<br><img src="./1555134035793.png" alt="Alt text"><br>第一主成分确定之后，如果是二维空间那么第二主成分就可以通过正交关系直接确定；对于<strong>高维空间</strong>，一个向量的正交向量可以有无数个，则<strong>在其正交向量中继续优化</strong>上式至最大值；之后的主成分依次类推。</p>
<h2 id="Principle-Components-Analysis-PCA"><a href="#Principle-Components-Analysis-PCA" class="headerlink" title="Principle Components Analysis(PCA)"></a>Principle Components Analysis(PCA)</h2><center>在某坐标有一个点
$$a=[
  \begin{matrix}
   x\\ y
  \end{matrix} ]=xe_1+ye_2
$$
在不同的坐标系中,x,y的坐标会不同
但a到原点的距离不因为坐标轴改变而改变
对于$$a=[
  \begin{matrix}
   X_1\\ Y_1
  \end{matrix} ]
  $$
  $$
b=[
  \begin{matrix}
   X_2\\ Y_2
  \end{matrix} ]
$$
其实就是尽可能分配给X_1和X_2
也就是$X_1^2+X_2^2=
\sum_{i=1}^2X_i^2$最大
![Alt text](./1555167382039.png)
![Alt text](./1555167390344.png)
![Alt text](./1555167406192.png)
![Alt text](./1555167442044.png)
![Alt text](./1555167455719.png)
![Alt text](./1555167468878.png)
![Alt text](./1555167485918.png)
**由于协方差矩阵奇异值分解和P差不多（只不过每个奇异值都/n),因此一般直接分解协方差矩阵**
</center>



<blockquote>
<p><strong>PCA具体算法步骤</strong>:<br>设有<strong>M个N维</strong>数据:<br>将原始数据按列组成<strong>N行M列矩阵X</strong><br>将X的每一行进行<strong>零均值化</strong>，即减去每一行的均值<br>求出<strong>X的协方差矩阵C</strong><br>求出<strong>协方差矩阵C的特征值及对应的特征向量</strong>，C的特征值就是Y的每维元素的方差，也是D的对角线元素，从大到小沿对角线排列构成D。<strong><br>将</strong>特征向量按对应特征值大小<strong>从上到下按行排列成矩阵，根据实际业务场景，</strong>取前R行组成矩阵P<strong>
</strong>Y=PX即为降到R维**后的目标矩阵</p>
</blockquote>
<p>//2</p>
<blockquote>
<p>对数据进行<strong>归一化处理（代码中并不是这么做的，而是直接减去均值）<br>计算</strong>归一化后的数据集的协方差矩阵<strong><br>计算</strong>协方差矩阵的特征值和特征向量<strong>
</strong>保留最重要的k个特征（通常k要小于n<strong>）。也能够自己制定。也能够选择一个阈值，然后通过前k个特征值之和减去后面n-k个特征值之和大于这个阈值，则选择这个k
</strong>找出k个特征值相应的特征向量<strong>
</strong>将m <em> n的数据集乘以k个n维的特征向量的特征向量（n </em> k）,得到最后降维的数据。**<br>事实上PCA的本质就是对角化协方差矩阵。有必要解释下为什么将特征值按从大到小排序后再选。</p>
</blockquote>
<p>首先，要明确特征值表示的是什么？在线性代数里面我们求过无数次了。那么它详细有什么意义呢？对一个n*n的对称矩阵进行分解。我们能够求出它的特征值和特征向量，就会产生n个n维的正交基，每一个正交基会相应一个特征值。</p>
<p>然后把矩阵投影到这N个基上，此时特征值的模就表示矩阵在该基的投影长度。</p>
<p>特征值越大。说明矩阵在相应的特征向量上的方差越大。样本点越离散。越easy区分，信息量也就越多。因此。特征值最大的相应的特征向量方向上所包括的信息量就越多，假设某几个特征值非常小。那么就说明在该方向的信息量非常少，我们就能够删除小特征值相应方向的数据，仅仅保留大特征值方向相应的数据，这样做以后数据量减小。但实用的信息量都保留下来了。PCA就是这个原理。</p>
<pre><code>def PCA(Xmat,k):
#求平均值
average=np.mean(Xmat,axis=0)
m,n=np.shape(Xmat) #获取输入矩阵形状
data_adjust = []
avgs = np.tile(average, (m, 1)) #复制均值成矩阵，后面相减
#中心化
data_adjust=Xmat-avgs

#协方差矩阵
covX = np.cov(data_adjust.T)  # 计算协方差矩阵
print(covX)


#进行奇异值分解（直接分解协方差矩阵）
featValue, featVec = np.linalg.eig(covX)  # 求解协方差矩阵的特征值和特征向量

index = np.argsort(-featValue)  # 依照featValue进行从大到小排序
finalData = []
if k &gt; n:
    print
    &quot;k must lower than feature number&quot;
    return
else:
    # 注意特征向量时列向量。而numpy的二维矩阵(数组)a[m][n]中，a[1]表示第1行值
    selectVec = np.matrix(featVec.T[index[:k]])  # 所以这里须要进行转置 ,选择前K行
    print(selectVec)
    finalData = data_adjust * selectVec.T
    reconData = (finalData * selectVec) + average
    print(finalData)
    print(data_adjust)
return finalData, reconData
</code></pre><h2 id="PCR-Principle-Component-Regression"><a href="#PCR-Principle-Component-Regression" class="headerlink" title="PCR(Principle Component Regression)"></a>PCR(Principle Component Regression)</h2><h2 id="Partial-Least-Square-Regression-偏最小二乘"><a href="#Partial-Least-Square-Regression-偏最小二乘" class="headerlink" title="Partial Least Square Regression(偏最小二乘)"></a>Partial Least Square Regression(偏最小二乘)</h2><p>偏最小二乘，是基于因变量为多个，自变量为多个。<strong>先同时求二者的主成分，使两个主成分的相关性达到最大</strong>，然后求各个<strong>因变量与自变量的主成分之间的回归方程</strong>。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]<a href="https://blog.csdn.net/qq_19600291/article/details/83823994" target="_blank" rel="noopener">https://blog.csdn.net/qq_19600291/article/details/83823994</a><br>[2]<a href="https://www.jianshu.com/p/d090721cf501?from=timeline" target="_blank" rel="noopener">https://www.jianshu.com/p/d090721cf501?from=timeline</a></p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Model Inference(模型推断)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Model%20Inference(%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%96%AD)/</url>
    <content><![CDATA[<h2 id="【统计学习】Model-Inference-模型推断"><a href="#【统计学习】Model-Inference-模型推断" class="headerlink" title="【统计学习】Model Inference(模型推断)"></a>【统计学习】Model Inference(模型推断)</h2><blockquote>
<p><strong>集成学习</strong>通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统、基于委员会的学习等。集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。</p>
</blockquote>
<h3 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h3><blockquote>
<p>Bootstap是一种再抽样算法,把样本看作总体，进行再抽样得到新的样本</p>
</blockquote>
<p>从大小为n的原始训练<strong>数据集D</strong>中<strong>随机选择n个样本点</strong>组成一个<strong>新的</strong>训练集，这个选择过程<strong>独立重复B次</strong>，然后<strong>用这B个数据集对模型统计量进行估计（如均值、方差等）</strong>。由于原始数据集的大小就是n，所以这B个新的训练集中不可避免的会存在重复的样本。<br>统计量的<strong>估计值定义为独立的B个训练集上的估计值θ_b</strong>的平均</p>
<script type="math/tex; mode=display">\theta=\frac{1}{B} \sum_{b=1}^B \theta_b</script><h3 id="Maximum-Likelihood-最大似然"><a href="#Maximum-Likelihood-最大似然" class="headerlink" title="Maximum Likelihood(最大似然)"></a>Maximum Likelihood(最大似然)</h3><blockquote>
<p>似然估计必须已知分布。思想是现在有一个样本$X_1,X_2,…,X_n$,找出是怎样的参数最可能产生这样的样本。方式是根据已知分布和样本求出似然函数，并最大化似然函数</p>
</blockquote>
<script type="math/tex; mode=display">argmax_\theta L(\theta;X)</script><h3 id="Beyesian-Model-贝叶斯模型"><a href="#Beyesian-Model-贝叶斯模型" class="headerlink" title="Beyesian Model(贝叶斯模型)"></a>Beyesian Model(贝叶斯模型)</h3><p><img src="./1556245413572.png" alt="Alt text"></p>
<blockquote>
<p>就是为了找到对于某个输入$x$下每类正确的概率，先找到某类下，出现各个输入的概率，然后利用贝叶斯公式求出。</p>
</blockquote>
<h3 id="EM算法-Expection-Maxinum"><a href="#EM算法-Expection-Maxinum" class="headerlink" title="EM算法(Expection Maxinum)"></a>EM算法(Expection Maxinum)</h3><p>EM算法见另一篇</p>
<h3 id="Bagging-套袋"><a href="#Bagging-套袋" class="headerlink" title="Bagging(套袋)"></a>Bagging(套袋)</h3><blockquote>
<p>类似Bootstrap,都是一种再抽样模型。bagging方法是从大小为n的原始训练数据集<strong>D</strong>中随机选择<strong>n′(n′&lt;n)个样本点</strong>组成一个新的训练集，这个<strong>选择过程独立重复B次</strong>。然后，每一个新的训练集都被独立的用于训练一个<strong>子分类器</strong>，最终分类器的分类结果由这些<strong>子分类器投票决定。</strong>(对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）)</p>
</blockquote>
<h3 id="Boosting-提升法"><a href="#Boosting-提升法" class="headerlink" title="Boosting(提升法)"></a>Boosting(提升法)</h3><blockquote>
<p>Re: <a href="https://www.cnblogs.com/willnote/p/6801496.html" target="_blank" rel="noopener">https://www.cnblogs.com/willnote/p/6801496.html</a><br>Boosting是一种框架算法，拥有系列算法，如<strong>AdaBoost，GradientBoosting，LogitBoost</strong>等算法。<br>Boosting系列算法的主要区别在于其<strong>三要素</strong>选取的函数不同</p>
<h4 id="算法模型"><a href="#算法模型" class="headerlink" title="算法模型"></a>算法模型</h4><h5 id="函数模型"><a href="#函数模型" class="headerlink" title="函数模型:"></a>函数模型:</h5><p>叠加式模型</p>
</blockquote>
<script type="math/tex; mode=display">F(x)=\sum_{i=1}^nf_i(x;\theta_i)</script><h5 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h5><blockquote>
<p>选择某种函数作为优化目标</p>
</blockquote>
<script type="math/tex; mode=display">E\{F(x)\}=E\{\sum_{i=1}^nf_i(x;\theta_i)\}</script><h5 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h5><script type="math/tex; mode=display">\theta_m^*=argmax_{\theta_m}E\{\sum_{i=1}^{m-1}f_i(x;\theta_i^*)+f_m(x;\theta_m)\}</script><p><img src="./1556324734105.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Model Assessment(模型评估)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Model%20Assessment(%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0)/</url>
    <content><![CDATA[<h3 id="【统计学习】Model-Assessment-模型评估"><a href="#【统计学习】Model-Assessment-模型评估" class="headerlink" title="【统计学习】Model Assessment(模型评估)"></a>【统计学习】Model Assessment(模型评估)</h3><h3 id="Hold-out-留出法"><a href="#Hold-out-留出法" class="headerlink" title="Hold-out(留出法)"></a>Hold-out(留出法)</h3><p>Divide samples to two parts-<strong>Test samples、Train samples</strong> randomly. And then assess the result. To increase the reliability of result , we often repeat this process several times.And take the <strong>average</strong> of assessment.<br>就是分成2部分，测试集和训练集，随机地划分。并对结果进行评估。评估会进行多次，然后取平均值。</p>
<script type="math/tex; mode=display">D=S\bigcup T,S\bigcap T=\emptyset</script><p><strong>S很大时，结果会不够稳定准确，S很小时，会丧失保真性（fidelity）</strong></p>
<h3 id="k-fold-cross-validation-k折交叉验证"><a href="#k-fold-cross-validation-k折交叉验证" class="headerlink" title="k-fold cross validation(k折交叉验证)"></a>k-fold cross validation(k折交叉验证)</h3><p>Divide samples to k similar parts,</p>
<script type="math/tex; mode=display">D=D_1\cup D_2\cup D_3...,D_i\cap D_j=\emptyset</script><p>Everytime use k-1 subsets as Train set ,the rest set as Test set,and take the same operation on k set,then calculate the average as the assess result.  </p>
<p>每次用k-1个子集作为训练集，剩下一个作为测试集，对K个集合都执行这样的操作，然后取平均值</p>
<h3 id="Leave-One-Out-留一法"><a href="#Leave-One-Out-留一法" class="headerlink" title="Leave-One-Out(留一法)"></a>Leave-One-Out(留一法)</h3><p>in k-fold cross validation ,k=m</p>
<h3 id="bootstrapping-自助法"><a href="#bootstrapping-自助法" class="headerlink" title="bootstrapping(自助法)"></a>bootstrapping(自助法)</h3><p>自助法：以自助采样（bootstrap sampling）为基础产生数据集，即随机从D中选择一个样本的拷贝，重复m次，作为训练集。不被采样到的概率再取极限得</p>
<script type="math/tex; mode=display">\lim_{m→∞}(1−\frac{1}{m})^m=1/e≈0.368</script><p>即，约有36.8%未被采样，并将它作为测试集。这样产生的测试结果称为<strong>“包外估计”（out-of-bagestimate）</strong>。</p>
<p>由于自助法产生的数据集改变了初始数据集的分布，这会引入估计误差。因此，当数据量足够时，留出法与交叉验证法更常用。</p>
<blockquote>
<p>自助法的要点是：<strong>①假定观察值便是总体；②由这一假定的总体抽取样本，即再抽样。</strong>由原始数据经过再抽样所获得的与原始数据集含量相等的样本称为<strong>再抽样样本(resamples)</strong>或<strong>自助样本(bootstrapsamples)</strong></p>
</blockquote>
<h3 id="度量"><a href="#度量" class="headerlink" title="度量"></a>度量</h3><h4 id="RMSE-Root-Mean-Squared-Error-均方根误差"><a href="#RMSE-Root-Mean-Squared-Error-均方根误差" class="headerlink" title="RMSE(Root Mean Squared Error:均方根误差)"></a>RMSE(Root Mean Squared Error:均方根误差)</h4><blockquote>
<p>误差均值开根号</p>
<script type="math/tex; mode=display">RMSE=\sqrt{   \frac{\sum_{i=1}^n(p_i-a_i)^2}{n}   }</script><h4 id="RSE-Relative-Squared-Error-相对平方误差"><a href="#RSE-Relative-Squared-Error-相对平方误差" class="headerlink" title="RSE(Relative Squared Error:相对平方误差)"></a>RSE(Relative Squared Error:相对平方误差)</h4><script type="math/tex; mode=display">RSE=\frac{\sum_{i=1}^n(p_i-a_i)^2}{\sum_{i=1}^n(\overline{a}-a_i)^2}</script><h4 id="MAE-Mean-Absolute-Error-平均绝对误差"><a href="#MAE-Mean-Absolute-Error-平均绝对误差" class="headerlink" title="MAE(Mean Absolute Error:平均绝对误差)"></a>MAE(Mean Absolute Error:平均绝对误差)</h4><script type="math/tex; mode=display">MAE=\frac{\sum_{i=1}^n|p_i-a_i|}{n}</script><h4 id="RAE-Relative-Absolute-Error-相对绝对误差"><a href="#RAE-Relative-Absolute-Error-相对绝对误差" class="headerlink" title="RAE(Relative Absolute Error:相对绝对误差)"></a>RAE(Relative Absolute Error:相对绝对误差)</h4><script type="math/tex; mode=display">RAE=\frac{\sum_{i=1}^n|p_i-a_i|}{\sum_{i=1}^n|\overline{a}-a_i|}</script></blockquote>
<h4 id="residual-残差"><a href="#residual-残差" class="headerlink" title="residual(残差)"></a>residual(残差)</h4><blockquote>
<p>观测值和预测值的差</p>
<script type="math/tex; mode=display">e_i=y_i-\hat y_i</script></blockquote>
<h4 id="standardized-residual-标准化残差"><a href="#standardized-residual-标准化残差" class="headerlink" title="standardized residual(标准化残差)"></a>standardized residual(标准化残差)</h4><blockquote>
<p>用残差除于标准差</p>
<script type="math/tex; mode=display">Z_i=\frac{e_i}{\sigma}</script></blockquote>
<h4 id="Coefficient-of-Determination-决定系数"><a href="#Coefficient-of-Determination-决定系数" class="headerlink" title="Coefficient of Determination(决定系数)"></a>Coefficient of Determination(决定系数)</h4><p><img src="./1556185761557.png" alt="Alt text"><br>R2描述了回归模型所解释的因变量方差在总方差中的比例。R2很大，即自变量和因变量之间存在线性关系，如果回归模型是“完美的”，SSE为零，则R2为1。R2小，则自变量和因变量之间存在线性关系的证据不令人信服。如果回归模型完全失败，SSE等于SST，没有方差可被回归解释，则R2为零。</p>
<h4 id="Confusion-Matrix-混淆矩阵"><a href="#Confusion-Matrix-混淆矩阵" class="headerlink" title="Confusion Matrix(混淆矩阵)"></a>Confusion Matrix(混淆矩阵)</h4><p><img src="./1556185896758.png" alt="Alt text"></p>
<blockquote>
<p>对角线数值越大，说明模型越好</p>
<h3 id="Bayesian-information-criterion-贝叶斯信息度量"><a href="#Bayesian-information-criterion-贝叶斯信息度量" class="headerlink" title="Bayesian information criterion(贝叶斯信息度量)"></a>Bayesian information criterion(贝叶斯信息度量)</h3><p><script type="math/tex">BIC=2ln(f(y∣θ_k ))−Klog(n)</script>。选择模型时选择BIC最大的模型。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Logistic Regression</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Logistic%20Regression/</url>
    <content><![CDATA[<h1 id="【统计学习】Logistic-Regression"><a href="#【统计学习】Logistic-Regression" class="headerlink" title="【统计学习】Logistic Regression"></a>【统计学习】Logistic Regression</h1><h2 id="1-Function"><a href="#1-Function" class="headerlink" title="1.Function"></a>1.Function</h2><script type="math/tex; mode=display">g(x)=\frac{1}{1+e^{-x}}\\h_\theta(x)=g(\theta^Tx)</script><p>将直接的线性函数使用函数g后映射到0~1之间（&gt;0.5为正类，小于0.5为负类）<br><img src="./1555506369471.png" alt="Alt text"></p>
<h2 id="cost-function"><a href="#cost-function" class="headerlink" title="cost function"></a>cost function</h2><p><img src="./1555507318067.png" alt="Alt text"><br>因为平方差不是凸函数，所以寻找另一个凸函数作为loss.<br>性质<br>1.如果$h_\theta=1$说明正好是预测的，于是loss=0;<br>可以合并<br><img src="./1555507609298.png" alt="Alt text"></p>
<p>2.多分类问题<br>训练多个分类器，每个把某类当做正类，其余当做父类。<br>最后分别计算概率</p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Linear Model with Least Squares</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Linear%20Model%20with%20Least%20Squares/</url>
    <content><![CDATA[<h1 id="【统计学习】Linear-Model-with-Least-Squares"><a href="#【统计学习】Linear-Model-with-Least-Squares" class="headerlink" title="【统计学习】Linear Model with Least Squares"></a>【统计学习】Linear Model with Least Squares</h1><h2 id="Basis-Linear-Model"><a href="#Basis-Linear-Model" class="headerlink" title="Basis Linear Model"></a>Basis Linear Model</h2><script type="math/tex; mode=display">RSS(\beta)=\sum_{i=1}^{N}(y_i-x_i^T\beta)^2\\=(y-X\beta)^T(y-X\beta)</script><p><center>对$\beta$求导<br>$X^T(y-X\beta)=0\\\hat{\beta}=(X^TX)^{-1}X^Ty$</p>
<h2 id="Matrix-Deduction"><a href="#Matrix-Deduction" class="headerlink" title="Matrix Deduction"></a>Matrix Deduction</h2><p><img src="./1554637888487.png" alt="Alt text"><br><img src="./1554637896329.png" alt="Alt text"><br><img src="./1554637912287.png" alt="Alt text"><br><img src="./1554638038976.png" alt="Alt text"><br><img src="./1554638060320.png" alt="Alt text"></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np;</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成两个满足高斯分布的数据集</span></span><br><span class="line">c=[]</span><br><span class="line">x1=np.random.normal(<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">y1=np.random.normal(<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">x2=np.random.normal(<span class="number">12</span>,<span class="number">5</span>,<span class="number">100</span>)</span><br><span class="line">y2=np.random.normal(<span class="number">12</span>,<span class="number">5</span>,<span class="number">100</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    c.append([x1[i],y1[i],<span class="number">0</span>])</span><br><span class="line">    c.append([x2[i],y2[i],<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#线性回归</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算参数beta</span></span><br><span class="line">c=(np.matrix(c))</span><br><span class="line">y=c[:,[<span class="number">2</span>]]</span><br><span class="line">X=np.matrix(c[:,[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">bt=np.dot(X.T,X)</span><br><span class="line">bt=np.linalg.pinv(bt)</span><br><span class="line">bt=np.dot(bt,X.T)*y</span><br><span class="line">print(bt)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对样本的预测</span></span><br><span class="line">haty=X*bt</span><br><span class="line">print(haty)</span><br><span class="line">plt.plot()</span><br><span class="line"></span><br><span class="line">print(bt)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制模拟分类边界</span></span><br><span class="line">simulate_X=np.arange(<span class="number">-24</span>,<span class="number">24</span>,<span class="number">0.5</span>)</span><br><span class="line">S_X=[]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> simulate_X:</span><br><span class="line">    S_X.append([x,(<span class="number">0.5</span>-x*bt[<span class="number">0</span>,<span class="number">0</span>])/bt[<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line">S_X=np.matrix(S_X)</span><br><span class="line">plt.plot(S_X[:,<span class="number">0</span>],S_X[:,<span class="number">1</span>])</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(x1,y1)</span><br><span class="line">plt.scatter(x2,y2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="./1554642681389.png" alt="Alt text"></p>
<h2 id="似然估计方式"><a href="#似然估计方式" class="headerlink" title="似然估计方式"></a>似然估计方式</h2><p>首先定义 数据集因变量y、参数$\omega$、数据集自变量X</p>
<script type="math/tex; mode=display">
\begin{equation*}
X=\begin{bmatrix}
x_1^T\\
x_2^T\\
...\\
x_N^T
\end{bmatrix}=\begin{bmatrix}
1&x_{11}&x_{12}&...&x_{1K}\\
1&x_{21}&x_{22}&...&x_{2K}\\
...\\
1&x_{N1}&x_{N2}&...&x_{NK}
\end{bmatrix} 
\end{equation*}\quad
y=\begin{bmatrix}
y_1\\
y_2\\
...\\
y_N
\end{bmatrix} \quad \omega=\begin{bmatrix}
\omega_0\\
\omega_1\\
...\\
\omega_K
\end{bmatrix}</script><p><center><br>可以定义预测误差</p>
<script type="math/tex; mode=display">\epsilon=y_n-\langle {x_n},{\omega}\rangle</script><p>并且误差$\epsilon$服从$\mu=0,\sigma^2$的高斯分布<br>也就是 $N((y_n-\langle x_n,\omega\rangle);0,\sigma^2)$<br>到这里可以写出似然函数</p>
<script type="math/tex; mode=display">L(\omega,D)=\prod_{n=1}^N \frac{1}{\sqrt{2\pi}\sigma}exp\{-\frac{( (y_n-\langle x_n,\omega\rangle) )^2}{2\sigma^2}\}</script><p>对数化</p>
<script type="math/tex; mode=display">log L(\omega,D)=-\frac{N}{2}log(2\pi \sigma^2)-\frac{1}{2\sigma^2}\sum_{n=1}^N(y_n-\langle x_n,\omega \rangle)^2</script><p>优化该函数</p>
<script type="math/tex; mode=display">\hat{\omega}=argmax_\omega  logL(\omega,D)\\=argmax_\omega  (-\frac{N}{2}log(2\pi \sigma^2)-\frac{1}{2\sigma^2}\sum_{n=1}^N(y_n-\langle x_n,\omega \rangle)^2)\\=argmin_\omega \quad \sum_{n=1}^N(y_n-\langle x_n,\omega \rangle)^2\\</script><p><center>矩阵表示，也就是</p>
<script type="math/tex; mode=display">argmin_\omega\quad (y-X\omega)^T(y-X\omega)</script><p>有<img src="./1570792231243.png" alt="Alt text"></p>
<p><center>对$\omega$求偏导可得</p>
<script type="math/tex; mode=display">(X^TX)\omega=X^Ty</script><p>于是<script type="math/tex">\hat\omega=(X^TX)^{-1}X^Ty</script></p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】K-Nearest Neighbors(KNN)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91K-Nearest%20Neighbors(KNN)/</url>
    <content><![CDATA[<h1 id="【统计学习】K-Nearest-Neighbors-KNN"><a href="#【统计学习】K-Nearest-Neighbors-KNN" class="headerlink" title="【统计学习】K-Nearest Neighbors(KNN)"></a>【统计学习】K-Nearest Neighbors(KNN)</h1><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>1.算出输入点与每个点的距离<br>2.对距离排序<br>3.选出最邻近K个点进行投票<br>4.分到投票数最多的类</p>
<h2 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h2><p>K最邻近分类模型属于“基于记忆”的非参数局部模型，这种模型并不是立即利用训练数据建立模型，数据也不再被函数和参数所替代。在对测试样例进行类别预测的时候，找出和其距离最接近的K个样例，以其中数量最多的类别作为该样例的类预测结果。<br>其属于<strong>生成模型</strong><br>K 值会对算法的结果产生重大影响。K值较小意味着只有与输入实例较近的训练实例才会对预测结果起作用，容易发生过拟合；如果 K 值较大，优点是可以减少学习的估计误差，缺点是学习的近似误差增大，这时与输入实例较远的训练实例也会对预测起作用，是预测发生错误。在实际应用中，K 值一般选择一个较小的数值，通常采用交叉验证的方法来选择最有的 K 值。随着训练实例数目趋向于无穷和 K=1 时，误差率不会超过贝叶斯误差率的2倍，如果K也趋向于无穷，则误差率趋向于贝叶斯误差率。</p>
<p><img src="./1554638483056.png" alt="Alt text"><br>$L_d$距离就是相减d次方和再开d次方</p>
<blockquote>
<p>[以下内容转于<a href="https://zhuanlan.zhihu.com/p/25994179" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25994179</a>]<br><img src="./1554638812148.png" alt="Alt text"><br><img src="./1554638828367.png" alt="Alt text"><br><img src="./1554638844823.png" alt="Alt text"><br>数据的归一化很重要</p>
</blockquote>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p><img src="./1554645864885.png" alt="Alt text"></p>
<pre><code class="lang-python">import numpy as np;
import seaborn as sns
import math
import pandas as pd
import matplotlib.pyplot as plt






#距离计算函数
def ComputeEuclideanDistance(x,y):
    tx=np.matrix(x).T
    ty=np.matrix(y).T
    return math.sqrt((tx-ty).T*(tx-ty))

#获取K个近邻点
def getNeighbors(dataset,curx, k):
    neighbors=[]
    x_withdis=[]
    for d in dataset:
        #print(d)
        x_withdis.append(   [d[0,0] ,d[0,1],d[0,2] , (ComputeEuclideanDistance(d[:, [0, 1]], curx))] )
    x_withdis=np.array(x_withdis)
    sarg=np.argsort(x_withdis[:,3])  #对距离排序
    #print(np.matrix(x_withdis[sarg]))
    for a in range(k):
        neighbors.append(x_withdis[sarg[a]])

    return np.matrix(neighbors)

#生成两个满足高斯分布的数据集
c=[]
x1=np.random.normal(1,10,100)
y1=np.random.normal(1,10,100)
x2=np.random.normal(12,5,100)
y2=np.random.normal(12,5,100)
for i in range(100):
    c.append([x1[i],y1[i],0])
    c.append([x2[i],y2[i],1])




c=np.matrix(c)
#print(c)

plt.scatter(x1,y1)
plt.scatter(x2,y2)

verge=[]
for r in np.arange(-24,24,0.5):
    for j in np.arange(-24,30,0.5):

        n = getNeighbors(c, [r, j], 5)
        c_0 = 0
        c_1 = 0
        #投票
        for i in n:
            if (i[0, 2] == 1):
                c_1 = c_1 + 1
            else:
                c_0 = c_0 + 1
        if (abs(c_0-c_1)&lt;=1):
            verge.append([r,j])
            #print([r,j,0])
            #plt.scatter(r,j,marker=&#39;x&#39;,c=&#39;b&#39;)
    print(r)
verge=np.matrix(verge)
plt.plot(verge[:,0],verge[:,1])
plt.show()
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】K-Means</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91K-Means/</url>
    <content><![CDATA[<h3 id="【统计学习】K-Means"><a href="#【统计学习】K-Means" class="headerlink" title="【统计学习】K-Means"></a>【统计学习】K-Means</h3><script type="math/tex; mode=display">J_e=\sum_i^c\sum_{x\in D_i }||x-m_i||^2\\m_i=\frac{1}{n_i}\sum_{x\in D_i}x</script><p>该公式假设类别分布是球形的。否则可能和主观感觉不太一样<br><img src="./1556548733764.png" alt="Alt text"></p>
<h3 id="算法条件"><a href="#算法条件" class="headerlink" title="算法条件"></a>算法条件</h3><p><strong>K-Means算法的特点是类别的个数是人为给定的，如果让机器自己去找类别的个数，我们有AP聚类算法，</strong><br><strong>K-Means的一个重要的假设是：数据之间的相似度可以使用欧氏距离度量</strong>，如果不能使用欧氏距离度量，要先把数据转换到能用欧氏距离度量，这一点很重要。<br><img src="./1556549291539.png" alt="Alt text"></p>
<h3 id="算法简述"><a href="#算法简述" class="headerlink" title="算法简述"></a>算法简述</h3><p>K-Means的著名解释</p>
<blockquote>
<p>有<strong>四个牧师</strong>(指定类别个数-s1)去郊区布道，一开始牧师们<strong>随意选了几个布道点(随机初始化-s2)</strong>，并且把这几个布道点的情况公告给了郊区所有的居民，于是<strong>每个居民到离自己家最近的布道点去听课</strong>(计算欧氏距离-s3)。<br>听课之后，大家觉得距离太远了，于是每个<strong>牧师统计了一下自己的课上所有的居民的地址，搬到了所有地址的中心地带</strong>，并且在海报上<strong>更新了自己的布道点的位置</strong>(布道点改变，向所有类别中心移动-s4)。<br>牧师每一次移动不可能离所有人都更近，有的人发现A牧师移动以后自己还不如去B牧师处听课更近，<strong>于是每个居民又去了离自己最近的布道点(第二轮迭代)</strong>……<br>就这样，牧师每个礼拜更新自己的位置，居民根据自己的情况选择布道点，最终稳定了下来。</p>
</blockquote>
<p>随机生成的类别(s1)<br><img src="./1556549637504.png" alt="Alt text"><br>随机生成k个点，并对每个点进行分类(s2)<br><img src="./1556549674918.png" alt="Alt text"><br><img src="./1556549727086.png" alt="Alt text"><br><img src="./1556549761822.png" alt="Alt text"></p>
<p>伪代码</p>
<pre><code>function K-Means(输入数据，中心点个数K)
获取输入数据的维度Dim和个数N
随机生成K个Dim维的点
while(算法未收敛)
    对N个点：计算每个点属于哪一类。
    对于K个中心点：
        1，找出所有属于自己这一类的所有数据点
        2，把自己的坐标修改为这些数据点的中心点坐标
end
输出结果：
end
</code></pre><h3 id="算法实现和优化"><a href="#算法实现和优化" class="headerlink" title="算法实现和优化"></a>算法实现和优化</h3><h4 id="作用于数据压缩"><a href="#作用于数据压缩" class="headerlink" title="作用于数据压缩"></a>作用于数据压缩</h4><p>比如图片，每一个点都可以视作是一个三维向量（点？）（<strong>RGB三通道图片</strong>），那么，使用K-Means算法对这些点进行聚类，我们就很容易得到几个中心点和几类，把同一类的数据点（像素点）用中心点表示就可以得到压缩后的图片，以上分别是把3通道×每通道8bit=24bit的像素点压缩为1bit，2bit，3bit和4bit的效果，可以看到，虽然信息损失了6倍，但是对画质的影响没有想象的大。</p>
<p><img src="./1556550065401.png" alt="Alt text"><br><img src="./1556550289472.png" alt="Alt text"><br><img src="./1556550306032.png" alt="Alt text"><br><img src="./1556550323999.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】EM Algorithm(EM算法)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91EM%20Algorithm(EM%E7%AE%97%E6%B3%95)/</url>
    <content><![CDATA[<h2 id="【统计学习】EM-Algorithm-EM算法"><a href="#【统计学习】EM-Algorithm-EM算法" class="headerlink" title="【统计学习】EM Algorithm(EM算法)"></a>【统计学习】EM Algorithm(EM算法)</h2><blockquote>
<p>和贝叶斯方法一样，必须是知道了分布下，才能使用。其可以用来处理一类含有隐变量的问题。一般用于无监督分类。同时还有一些进化的算法。<br>对于已知分布，分布参数未知，且含有隐变量的问题(如200个人的男女生身高数据，分别为$M\sim N(\mu_1,\sigma^2)$和$F\sim N(\mu,\sigma^2)$(已知分布，参数未知),但只有身高数据,不知道哪个身高是男是女的。现在我们要对其进行分类。分出对于某个身高到底是男还是女的   这样的问题。这个问题中包含了隐变量Z={男、女})<br>解决此类问题的思想是，首先随机初始化分布的参数。然后由该参数下，似然估计出隐变量的分布<strong>(E步)</strong>。然后再由隐变量的分布似然估计出参数<strong>(M步)</strong>…..这样一直迭代。结果会一次比一次好(证明略)，会靠近真实值，但未必最终能取到真实值</p>
</blockquote>
<h3 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h3><p>为了解决这个问题我们先从简单的开始<br>现在有一个男生的身高样本集合（200个样本）$X\sim N(\mu,\sigma^2)$<br>参数未知。<br>那么我们可以用最大似然估计来估计参数。<br><img src="./1556251316926.png" alt="Alt text"><br>分布图<br><img src="./1556251420266.png" alt="Alt text"></p>
<pre><code class="lang-python">import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import math
def getdatas1():
    d=np.random.normal(172,8,200)
    return d

d1=getdatas1()
d2=pd.DataFrame(d1,columns=[&#39;身高&#39;])
print(d2)
sns.distplot(d2)
plt.show()
#似然估计
hat_mu=np.mean(d2)
hat_sigma=math.sqrt(np.mean(np.power(d2-hat_mu,2)))
print([hat_mu,hat_sigma])
</code></pre>
<p>似然估计结果:</p>
<script type="math/tex; mode=display">[\mu:   171.736039 , \sigma:8.311671773061763]</script><p>现在考虑复杂一些的情况。现在女生的身高数据也加了进来<br>服从另一个正态分布。<br>于是现在的情况是</p>
<script type="math/tex; mode=display">M\sim N(\mu_1,\sigma_1^2),F\sim (\mu_2,\sigma_2^2)\tag{M为男,F为女}</script><p>现在数据集大概这样<br><img src="./1556252714589.png" alt="Alt text"><br>现在讨论两个问题<br><strong>1.根据数据集，如何估算出两个分布的参数</strong><br>这个问题很好办。把相同性别的数据取出来，然后像上面一样进行似然估计就可以了</p>
<p><strong>给定一个身高数据，如何其判断性别</strong><br>知道两个分布的参数后，这个也很好办，只需要利用似然估计，判断属于哪一类的可能性更大就行<br>也就是判断$\frac{1}{\sqrt{2\pi}\sigma_1}exp\{\frac{(x_i-\mu_1)^2}{2\sigma_1^2}\}$和$\frac{1}{\sqrt{2\pi}\sigma_2}exp\{\frac{(x_i-\mu_2)^2}{2\sigma_2^2}\}$哪个更大。</p>
<h3 id="EM-Algorithm"><a href="#EM-Algorithm" class="headerlink" title="EM Algorithm"></a>EM Algorithm</h3><p>现在把情况再弄复杂点。还是男女生的身高数据，还是服从两个分布且参数未知</p>
<script type="math/tex; mode=display">M\sim N(\mu_1,\sigma_1^2),F\sim (\mu_2,\sigma_2^2)\tag{M为男,F为女}</script><p>不过现在数据集连性别标签也没有了。大概这样子<br><img src="./1556253139183.png" alt="Alt text"><br>数据集除了一堆身高数据，没什么有用信息了。但是问题还是一样。根据数据集估计分布的参数，并且分类。<br>这要怎么办呢?<br>这是一个<strong>先有鸡还是先有蛋</strong>的问题。<br>如果我们知道分布参数，我们就可以得到性别的分布（或者说对数据进行性别的分类），但是要知道分布参数，又需要先知道性别的分布才能对参数进行似然估计<br>如果我们知道性别分布，我们就可以对参数进行估计，但是对参数进行估计，又先需要知道性别的分布…</p>
<p>现在多了一个<strong>隐变量:</strong>性别。</p>
<p>所以要怎么解决呢?</p>
<p>既然不知道分布的参数，那我们随机初始化吧~</p>
<script type="math/tex; mode=display">先说一下真实值:M\sim N(172,8),F\sim N(160,8)</script><p>现在我们随机假设一下参数</p>
<script type="math/tex; mode=display">M\sim N(200,5),F\sim N(140,3)</script><p>进行概率估计后<br><img src="./1556254790199.png" alt="Alt text"></p>
<pre><code class="lang-python">import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import sklearn.utils as skr
import math

def getposibility(x,mu,sigma):
    return (1/(math.sqrt(2*math.pi)*sigma))*math.pow(math.e,(-(x-mu)*(x-mu))/(2*sigma*sigma)  )

def getdatas1():
    d1=np.random.normal(172,8,200)
    d2 = np.random.normal(160, 8, 200)
    return d1,d2


&#39;&#39;&#39;
d1=getdatas1()
d2=pd.DataFrame(d1,columns=[&#39;身高&#39;])
print(d2)
sns.distplot(d2)
plt.show()
#似然估计
hat_mu=np.mean(d2)
hat_sigma=math.sqrt(np.mean(np.power(d2-hat_mu,2)))
print([hat_mu,hat_sigma])
&#39;&#39;&#39;
M,F=getdatas1()
M2=pd.DataFrame(M,columns=[&quot;身高&quot;])
#M2[&#39;性别&#39;]=&#39;男&#39;
#print(M2)
F2=pd.DataFrame(F,columns=[&quot;身高&quot;])
#F2[&#39;性别&#39;]=&#39;女&#39;


d=pd.concat([M2,F2],axis=0)
#data=skr.shuffle(d)
print(d)

#EM
curmu1=140
curmu2=200
cursigma1=5
cursigma2=3

for k in range(100):
    gl_m = []
    gl_f = []
    m_r_sg=[]
    f_r_sg=[]
    for x in d[&#39;身高&#39;]:
        lm=getposibility(x, curmu1, cursigma1)
        fm=getposibility(x, curmu2, cursigma2)
        m_multiple_sg=lm*x
        f_multiple_sg=fm*x
        gl_m.append(lm/(lm+fm))
        gl_f.append(fm/(fm+lm))
        m_r_sg.append(m_multiple_sg)
        f_r_sg.append(f_multiple_sg)


    # lsd=pd.DataFrame({&#39;男&#39;:{},&#39;女&#39;:{}})
    d[&#39;男&#39;] = gl_m
    d[&#39;女&#39;] = gl_f
    d[&#39;M_m_p&#39;]=m_r_sg
    d[&#39;F_m_p&#39;]=f_r_sg
    print(d)

    lsm1 = np.mean(d[(d[&#39;男&#39;] &gt; d[&#39;女&#39;])][&#39;身高&#39;])
    sig1 = np.sqrt(np.mean(np.power((d[(d[&#39;男&#39;] &gt; d[&#39;女&#39;])][&#39;身高&#39;] - lsm1), 2)))
    ksm2 = np.mean(d[(d[&#39;男&#39;] &lt; d[&#39;女&#39;])][&#39;身高&#39;])
    sig2 = np.sqrt(np.mean(np.power((d[(d[&#39;男&#39;] &lt; d[&#39;女&#39;])][&#39;身高&#39;] - ksm2), 2)))

   # lsm1 = np.mean(d[(d[&#39;男&#39;] &gt; d[&#39;女&#39;])][&#39;身高&#39;])
    &#39;&#39;&#39;
    lsm1=np.mean(d[&#39;M_m_p&#39;])/np.mean(d[&#39;男&#39;])
    ksm2=np.mean(d[&#39;F_m_p&#39;])/np.mean(d[&#39;女&#39;])
    eff_fcMs=[]
    for x in d:
        eff_fc_M=(d[&#39;身高&#39;]-lsm1)*(d[&#39;身高&#39;]-lsm1)*d[&#39;M_m_p&#39;]
        eff_fcMs.append(eff_fc_M)
    print(eff_fcMs)
    d[&#39;eff_fcMs&#39;]=eff_fcMs
    print(d)
    sig1 = np.sqrt(np.sum(   d.apply(lambda x:x[&#39;M_m_p&#39;]* np.power(x[&#39;身高&#39;] - lsm1, 2) )    ,axis=1 ))
    sig2= np.sqrt(np.multiply(d[&#39;F_m_p&#39;], np.power((d[&#39;身高&#39;] - ksm2, 2))))
&#39;&#39;&#39;

    if (np.count_nonzero(d[(d[&#39;男&#39;] &lt; d[&#39;女&#39;])][&#39;身高&#39;]) == 0):
        ksm2 = 0
        sig2 = 0

    print([lsm1, sig1, ksm2, sig2])
    curmu1 = lsm1
    curmu2 = ksm2
    cursigma1 = sig1
    cursigma2 = sig2
    input()
</code></pre>
<p><img src="./1556291018593.png" alt="Alt text"></p>
<p><img src="./1556291105477.png" alt="Alt text"><br>经过迭代，可以发现离真实值很近了</p>
<p>上面用的是普通版本的EM（也就是根据概率分类后再似然估计参数）<br>在实际一般用优化版的EM，也就是把每个数据都用上。观测值乘概率加权求和后再除于概率和.均值与方差都这么做</p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Curse of dimensionality(维度灾难)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Curse%20of%20dimensionality(%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE)/</url>
    <content><![CDATA[<h1 id="【统计学习】Curse-of-dimensionality-维度灾难"><a href="#【统计学习】Curse-of-dimensionality-维度灾难" class="headerlink" title="【统计学习】Curse of dimensionality(维度灾难)"></a>【统计学习】Curse of dimensionality(维度灾难)</h1><blockquote>
<p>参考原文 <a href="https://blog.csdn.net/zbc1090549839/article/details/38929215" target="_blank" rel="noopener">https://blog.csdn.net/zbc1090549839/article/details/38929215</a></p>
</blockquote>
<p><strong>MSE（均方误差）</strong><br><strong>RMSE （均方根误差）</strong><br><strong>MAE（平均绝对误差）</strong></p>
<h2 id="维度灾难简介"><a href="#维度灾难简介" class="headerlink" title="维度灾难简介"></a>维度灾难简介</h2><p><img src="./1554721939166.png" alt="Alt text"><br>当特征增多（也就是维数增加时） 分类器性能逐渐上升，但是到达某点后开始下降。</p>
<h2 id="维度灾难原因和过拟合"><a href="#维度灾难原因和过拟合" class="headerlink" title="维度灾难原因和过拟合"></a>维度灾难原因和过拟合</h2><blockquote>
<p>维度为1时（一个特征）<br><img src="./1554722553778.png" alt="Alt text"><br>维度为2时，依然没办法很好分类<br><img src="./1554722578872.png" alt="Alt text"><br>再加一个特征，此时很容易找到一个平面进行分类<br><img src="./1554722611884.png" alt="Alt text"><br><img src="./1554722636068.png" alt="Alt text"></p>
</blockquote>
<p>从1维到3维，给我们的感觉是：维数越高，分类性能越优。然而，在Figure 1中，我们说维数过高将导致一定的问题：具体来说，在一维特征空间下，我们假设一个维度的宽度为5个单位，这样样本密度为10/5=2;在2维特征空间下，10个样本所分布的空间大小5<em>5=25，这样样本密度为10/25=0.4;在3维特征空间下，10个样本分布的空间大小为5</em>5*5=125，样本密度就为10/125=0.08.</p>
<p>如果我们继续增加特征数量，<strong>随着维度的增加，样本将变得越来越稀疏</strong>，在这种情况下，也更容易找到一个超平面将目标分开。然而，如果我们将高维空间向低维空间投影，高维空间隐藏的问题将会显现出来：</p>
<blockquote>
<p><strong>也就是随着维数增加，样本密度变得越来越小。高维空间隐藏的问题开始显现出来</strong></p>
</blockquote>
<p>1.过多的特征导致过拟合<img src="./1554722795968.png" alt="Alt text"><br>高维空间训练形成的分类器，相当于在低维空间的一个复杂的非线性分类器，这种分类器过多的强调了训练集的准确率甚至于对一些错误/异常的数据</p>
<p>也进行了学习，而正确的数据却无法覆盖整个特征空间。为此，这样得到的分类器在对新数据进行预测时将会出现错误。这种现象称之为过拟合，同时也是<strong>维灾难的直接体现</strong></p>
<p>在换个角度来解释维数灾难，下图展示了由于高维而带来的数据稀疏性问题：假设有一个特征，它的取值范围<strong>D</strong>在0到1之间均匀分布，并且对狗和猫来说其值都是唯一的，我们现在利用这个特征来设计分类器。如果我们的训练数据覆盖了取值范围的20%(e.g 0到0.2)，那么所使用的训练数据就占总样本量的20%。<br>上升到二维情况下，<strong>要覆盖二维特征空间20%的面积，则需要在每个维度上取得45%的取值范围</strong>。<br>在三维情况下，<strong>要覆盖特征空间20%的体积，则需要在每个维度上取得58%的取值范围…</strong><br>在维度接近一定程度时，要取得同样的训练样本数量，则几乎要在每个维度上取得接近100%的取值范围，或者增加总样本数量，但样本数量也总是有限的。<br><img src="./1554723013344.png" alt="Alt text"><br>在分类中我们使用的特征数量越多，那么由于高维下数据的稀疏性我们不得不需要更多的训练数据来对分类器的参数进行估计(高维数下分类器参数的估计将变得更加困难)。维数灾难造成的另外一个影响是：数据的稀疏性致使数据的分布在空间上是不同(实际上，数据在高维空间的中心比在边缘区域具备更大的稀疏性，数据更倾向于分布在空间的边缘区域)</p>
<p>假设一个正方形代表二维特征空间，特征空间的平均值是这个正方形的中心，到这个中心距离为一个单位距离的样本分布在一个单位圆中。不在这个单位圆的样本相对于中心更接近正方形的边角。这些样本因为特征值差距很大（如对角的样本）而很难分类。由图9可以看出，如果样本都落在内切圆中，分类将会简单很多：<br><img src="./1554723296490.png" alt="Alt text"><br>有意思的是如果我们一直增加维度，那正方形（超立方体）中的圆（超球面）的体积是如何变化的呢？超立方体的体积始终保持1^d = 1，这个d维超立方体内切超球面的体积（半径为0.5）可以用如下公式计算：<br><img src="./1554723354731.png" alt="Alt text"><br><img src="./1554723362986.png" alt="Alt text"></p>
<p>可以看出随着维度趋于无穷，<strong>超球面的体积趋于0，然而超立方体体积没有变化</strong>。这解释了分类问题中的维度灾难：<strong>在高纬空间中，大多数训练样本处于超立方体的边角处</strong>。上面也提到过，边角处的样本相对于位于超球面内的样本更难分类。可以从下图中看出来，下图展示了二维正方形、三维立方体、和有着2^8 = 256个角的八维的超立方体：<br><img src="./1554723413740.png" alt="Alt text"><br><img src="./1554723485372.png" alt="Alt text"><br>对于一个8维的超立方体，大约98%的数据分布在它的256个角处。因此，当特征空间维度趋于无穷大，样本到中点的最大和最小欧几里得距离的差，比上样本到中点的最小欧几里得距离趋于0：</p>
<h2 id="如何避免维度灾难"><a href="#如何避免维度灾难" class="headerlink" title="如何避免维度灾难"></a>如何避免维度灾难</h2><p>1.训练集样本越少，越应该用少量的特征，如果N个训练样本足够覆盖一个一维的特征空间（区间大小为一个单位），那么 需要N^2个样本去覆盖一个同样密度的二维的特征空间，需要N^3个样本去覆盖三维的特征空间。换句话说，就是<strong>训练样本多少需要随着维度指数增长。</strong></p>
<p>2.那些精确计算非线性决策边界的分类器（如神经网络、KNN分类器、决策树）不会泛化的很好，而且容易发生过拟合。因此在用这些分类器的时候应该少用一些纬度。如果一个分类器泛化能力很好（如朴素贝叶斯，线性分类器），由于分类器本身表现能力差一些，那么纬度可以高一些。图6显示<strong>在高纬度空间用一个简单的分类器，就相当于在低纬度空间用一个复杂的分类器。</strong></p>
<p>3.一个非常重要的探测和避免分类训练过程中过拟合的方法是<strong>交叉验证</strong>。交叉验证方法将原始训练数据分成一个或多个训练数据子集。在分类训练中，一个子集用来测试分类结果的准确性，剩下的子集用来进行参数估计。如果分类结果在训练集合和测试集合上相差很多，那么就是产生了过拟合。很多类型的交叉验证如k折交叉验证和留一交叉验证可以用于可提供的训练数据很少的情况。</p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Concept of Generative Modeling(GM) and Discriminative Modeling(DM)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Concept%20of%20Generative%20Modeling(GM)%20and%20Discriminative%20Modeling(DM)/</url>
    <content><![CDATA[<h1 id="【统计学习】Concept-of-Generative-Modeling-GM-and-Discriminative-Modeling-DM"><a href="#【统计学习】Concept-of-Generative-Modeling-GM-and-Discriminative-Modeling-DM" class="headerlink" title="【统计学习】Concept of Generative Modeling(GM) and Discriminative Modeling(DM)"></a>【统计学习】Concept of Generative Modeling(GM) and Discriminative Modeling(DM)</h1><h2 id="Generative-Modeling-GM-生成模型"><a href="#Generative-Modeling-GM-生成模型" class="headerlink" title="Generative Modeling(GM:生成模型)"></a>Generative Modeling(GM:生成模型)</h2><p>生成模型是根据联合概率分布$P(X,Y)$然后求出概率分布$P(Y|X)$的模型</p>
<script type="math/tex; mode=display">P(Y|X)=\frac{P(X,Y)}{P(X)}</script><h3 id="典型GM"><a href="#典型GM" class="headerlink" title="典型GM"></a>典型GM</h3><h4 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h4><p>首先想办法弄出$P(X|Y)$<br>然后根据条件概率公式干出联合概率$P(X,Y)$<br>最后求出$P(Y|X)$</p>
<h4 id="HMM-隐马尔科夫模型"><a href="#HMM-隐马尔科夫模型" class="headerlink" title="HMM(隐马尔科夫模型)"></a>HMM(隐马尔科夫模型)</h4><p>就是一个马尔科夫网络。状态隐藏。只能观察到输出</p>
<h2 id="Discriminative-Modeling-DM-判别模型"><a href="#Discriminative-Modeling-DM-判别模型" class="headerlink" title="Discriminative Modeling(DM:判别模型)"></a>Discriminative Modeling(DM:判别模型)</h2><p>判别模型是由训练数据直接学习决策函数f(X)或者条件概率分布P(X,Y)作为预测的模型，模型关心的是对给定的输入X，应该预测什么样的输出Y</p>
<h3 id="典型DM"><a href="#典型DM" class="headerlink" title="典型DM:"></a>典型DM:</h3><h4 id="K-Nearest-K近邻"><a href="#K-Nearest-K近邻" class="headerlink" title="K-Nearest(K近邻)"></a>K-Nearest(K近邻)</h4><p>take K neighborhood of certain input X.Then vote to decide which is the output y.</p>
<h4 id="Neural-Network-神经网络"><a href="#Neural-Network-神经网络" class="headerlink" title="Neural Network(神经网络)"></a>Neural Network(神经网络)</h4><h4 id="Decision-tree-决策树"><a href="#Decision-tree-决策树" class="headerlink" title="Decision tree(决策树)"></a>Decision tree(决策树)</h4><h4 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM(支持向量机)"></a>SVM(支持向量机)</h4><h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h4><h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><p>集成学习的一种方法</p>
<h4 id="Conditional-Random-Field-CRF-条件随机场"><a href="#Conditional-Random-Field-CRF-条件随机场" class="headerlink" title="Conditional Random Field(CRF:条件随机场)"></a>Conditional Random Field(CRF:条件随机场)</h4><p>CRF主要用于序列标注，可以简单理解为对序列的每一帧都进行分类</p>
<h4 id="Perceptron-感知机"><a href="#Perceptron-感知机" class="headerlink" title="Perceptron(感知机)"></a>Perceptron(感知机)</h4><blockquote>
<p>神经网络早期的主要成果是感知机，Perceptron，这是一种01化的神经元模型<br><img src="./1557926335388.png" alt="Alt text"><br><img src="./1557926361049.png" alt="Alt text"></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Common optimization method(常见优化方法)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Common%20optimization%20method(%E5%B8%B8%E8%A7%81%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95)/</url>
    <content><![CDATA[<h2 id="【统计学习】Common-optimization-method-常见优化方法"><a href="#【统计学习】Common-optimization-method-常见优化方法" class="headerlink" title="【统计学习】Common optimization method(常见优化方法)"></a>【统计学习】Common optimization method(常见优化方法)</h2><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><script type="math/tex; mode=display">h(\theta)=\sum_{j=0}^n \theta_jx_j</script><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m (y^i-h_\theta (x^i))^2</script><h4 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h4><p>(1)First,calculate partial derivation $J(\theta)$ with respect to $\theta$</p>
<script type="math/tex; mode=display">\frac{\partial J(\theta)}{\partial \theta_j}=-\frac{1}{m}\sum_{i=1}^m (y^i-h_\theta(x^i))x_j^i</script><p>(2)Update<br><img src="./1556325360571.png" alt="Alt text"></p>
<p>It will get a global optimum solution.But each iteration it will use all the data of training dataset.This will be very slow if m very big</p>
<h4 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h4><blockquote>
<p>和 BGD 的一次用所有数据计算梯度相比，SGD 每次更新时对每个样本进行梯度更新，对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余，<strong>而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。</strong></p>
</blockquote>
<pre><code>for i in range(nb_epochs):  #迭代
   np.random.shuffle(data)  #随机打乱
   for example in data:   #迭代每条数据
   params_grad = evaluate_gradient(loss_function, example, params) #评估梯度
   params = params - learning_rate * params_grad
</code></pre><h4 id="Mini-Batch-Gradient-Descent-（MBGD）"><a href="#Mini-Batch-Gradient-Descent-（MBGD）" class="headerlink" title="Mini-Batch Gradient Descent （MBGD）"></a>Mini-Batch Gradient Descent （MBGD）</h4><blockquote>
<p>MBGD 每一次利用一小批样本，即 n 个样本进行计算，这样它可以降低参数更新时的方差，收敛更稳定，另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。</p>
</blockquote>
<pre><code class="lang-python">for i in range(nb_epochs):
  np.random.shuffle(data)
  for batch in get_batches(data, batch_size=50):   #取出50个数据作为一批
    params_grad = evaluate_gradient(loss_function, batch, params)
    params = params - learning_rate * params_grad
</code></pre>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><blockquote>
<p>牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。</p>
</blockquote>
<p><img src="./1556326579515.png" alt="Alt text"><br><img src="./1556326594204.png" alt="Alt text"><br><img src="./1556326827601.png" alt="Alt text"></p>
<p><img src="./1556326977957.png" alt="Alt text"></p>
<h4 id="Quasi-Newton-Methods"><a href="#Quasi-Newton-Methods" class="headerlink" title="Quasi-Newton Methods"></a>Quasi-Newton Methods</h4><p><img src="./1556327035178.png" alt="Alt text"></p>
<h4 id="Nesterov-Accelerated-Gradient"><a href="#Nesterov-Accelerated-Gradient" class="headerlink" title="Nesterov Accelerated Gradient"></a>Nesterov Accelerated Gradient</h4><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p><img src="./1556327284978.png" alt="Alt text"></p>
<h3 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h3><p><img src="./1556327420591.png" alt="Alt text"></p>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p><img src="./1556327657982.png" alt="Alt text"></p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><blockquote>
<p>一般Adam最优，不仅存储过去梯度平方，还存储过去梯度<br><img src="./1556327780461.png" alt="Alt text"></p>
</blockquote>
<h3 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a>算法选择</h3><p><img src="./1556326639616.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Boosting族算法</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Boosting%E6%97%8F%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="【统计学习】Boosting族算法"><a href="#【统计学习】Boosting族算法" class="headerlink" title="【统计学习】Boosting族算法"></a>【统计学习】Boosting族算法</h2><blockquote>
<p>和bagging不同的是，分类器是串行的。必须先生成第一个再生成第二个。。。<br><img src="./1557063634839.png" alt="Alt text"><br>D2解决错误<br><img src="./1557063714197.png" alt="Alt text"><br>D3解决争端<br><img src="./1557063776838.png" alt="Alt text"></p>
</blockquote>
<p>boosting分类器比bagging少得多<br><img src="./1557064027038.png" alt="Alt text"></p>
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p><img src="./1557063475709.png" alt="Alt text"></p>
<p>用原始数据集训练得到k个分类器，然后用结果二次训练得到分类器的权重。    </p>
<h3 id="Adboost"><a href="#Adboost" class="headerlink" title="Adboost"></a>Adboost</h3><blockquote>
<p>Addictive Model<br>AdaBoost是最著名的Boosting族算法。<strong>开始时，所有样本的权重相同</strong>，训练得到第一个基分类器。从第二轮开始，每轮开始前都先根据上一轮基分类器的分类效果调整每个样本的权重，<strong>上一轮分错的样本权重提高，分对的样本权重降低</strong>。之后根据新得到样本的权重指导本轮中的基分类器训练，即在考虑样本不同权重的情况下得到本轮错误率最低的基分类器。重复以上步骤直至训练到约定的轮数结束，每一轮训练得到一个基分类器。<br>可以想象到，远离边界（超平面）的样本点总是分类正确，而分类边界附近的样本点总是有大概率被弱分类器（基分类器）分错，所以权值会变高，即边界附近的样本点会在分类时得到更多的重视。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">符号</th>
<th style="text-align:right">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">$D=\{(\vec {x_i)},y_i\,\in[1,m]\}$</td>
<td style="text-align:right">训练集，共m个样本</td>
</tr>
<tr>
<td style="text-align:left">$T$</td>
<td style="text-align:right">训练轮数</td>
</tr>
<tr>
<td style="text-align:left">$D_t(x)$</td>
<td style="text-align:right">第t轮样本权重分布</td>
</tr>
<tr>
<td style="text-align:left">$h_t$</td>
<td style="text-align:right">第t轮得到的基分类器</td>
</tr>
<tr>
<td style="text-align:left">$\alpha_t$</td>
<td style="text-align:right">第t轮得到的基分类器的权重</td>
</tr>
<tr>
<td style="text-align:left">$\epsilon_t$</td>
<td style="text-align:right">第t轮$h_t$的错误率</td>
</tr>
<tr>
<td style="text-align:left">$P_A(D)$</td>
<td style="text-align:right">强分类器A在数据集D上的最终准确率</td>
</tr>
</tbody>
</table>
</div>
<p><img src="./1556331112900.png" alt="Alt text"><br><img src="./1556331755956.png" alt="Alt text"><br>第一轮完成</p>
<p>接下来第二轮<br><img src="./1556331958825.png" alt="Alt text"><br><img src="./1556332391241.png" alt="Alt text"><br><img src="./1556332518463.png" alt="Alt text"></p>
<h3 id="GBDT-梯度提升树"><a href="#GBDT-梯度提升树" class="headerlink" title="GBDT(梯度提升树)"></a>GBDT(梯度提升树)</h3><blockquote>
<p>GBDT即梯度提升树，提升方法依然采用的是加法模型与前向分布算法。以决策树为基函数的提升方法称为提升树。对分类问题决策树是二叉分类树，对回归问题决策树是二叉决策树。例如前文中的例子中所使用的决策树桩即为一个根节点直接连接两个叶节点的简单决策树。<br>GBDT与Adboost最主要的区别在于两者如何识别模型的问题。Adaboost用错分数据点来识别问题，通过调整错分数据点的权重来改进模型。GBDT通过负梯度来识别问题，通过计算负梯度来改进模型。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【统计学习】Bayes classifier(贝叶斯分类器)</title>
    <url>/2019/12/26/%E3%80%90%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E3%80%91Bayes%20classifier(%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8)/</url>
    <content><![CDATA[<h1 id="【统计学习】Bayes-classifier-贝叶斯分类器"><a href="#【统计学习】Bayes-classifier-贝叶斯分类器" class="headerlink" title="【统计学习】Bayes classifier(贝叶斯分类器)"></a>【统计学习】Bayes classifier(贝叶斯分类器)</h1><p><img src="./1554648299451.png" alt="Alt text"><br><img src="./1554648315246.png" alt="Alt text"><br><img src="./1554648347075.png" alt="Alt text"><br><img src="./1554648375272.png" alt="Alt text"><br><img src="./1554648474553.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【通信原理】卷积码</title>
    <url>/2019/12/26/%E3%80%90%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E3%80%91%E5%8D%B7%E7%A7%AF%E7%A0%81/</url>
    <content><![CDATA[<h1 id="【通信原理】卷积码"><a href="#【通信原理】卷积码" class="headerlink" title="【通信原理】卷积码"></a>【通信原理】卷积码</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如下图就是一个卷积码编码器<br><img src="./1557621853499.png" alt="Alt text"><br><img src="./1557621865943.png" alt="Alt text"><br>假设输入为<br><img src="./1557621877203.png" alt="Alt text"></p>
<ul>
<li>输入第一个:1<br><img src="./1557621904367.png" alt="Alt text"><br>得到输出111</li>
<li>再输入第二个1<br><img src="./1557621924570.png" alt="Alt text"><br>得到输出110</li>
<li>输入第三位0<br><img src="./1557621951597.png" alt="Alt text"><br>得到输出100</li>
</ul>
<p><img src="./1557621965113.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【数值优化】Karush-Kuhn-Tucker(KKT) Method</title>
    <url>/2019/12/26/%E3%80%90%E6%95%B0%E5%80%BC%E4%BC%98%E5%8C%96%E3%80%91Karush-Kuhn-Tucker(KKT)%20Method/</url>
    <content><![CDATA[<h1 id="【数值优化】Karush-Kuhn-Tucker-KKT-Method"><a href="#【数值优化】Karush-Kuhn-Tucker-KKT-Method" class="headerlink" title="【数值优化】Karush-Kuhn-Tucker(KKT) Method"></a>【数值优化】Karush-Kuhn-Tucker(KKT) Method</h1><h2 id="KKT-or-generalized-Lagrange-function-KKT或增广拉格朗日法"><a href="#KKT-or-generalized-Lagrange-function-KKT或增广拉格朗日法" class="headerlink" title="KKT or generalized Lagrange function(KKT或增广拉格朗日法)"></a>KKT or generalized Lagrange function(KKT或增广拉格朗日法)</h2><p>增广拉格朗日法是为了解决带约束的优化问题而产生的<br>其为每个约束引入<strong>拉格朗日乘子</strong>$\lambda_i,\alpha_j$</p>
<script type="math/tex; mode=display">L(x,\lambda,\alpha)=f(x)+\sum_i \lambda_ig^{(i)}(x)+\sum_j \alpha_jh^{(j)}(x)</script><p>其中$g$为等式约束,$h$为不等式约束</p>
<p>然后可以解决</p>
<ul>
<li><strong>约束最小化问题</strong><script type="math/tex; mode=display">\min_x\max_\lambda\max_{\alpha,\alpha\ge0}f(x)+\sum_i \lambda_ig^{(i)}(x)+\sum_j \alpha_jh^{(j)}(x)</script></li>
<li><strong>约束最大化问题</strong><script type="math/tex; mode=display">\min_x\max_\lambda\max_{\alpha,\alpha\ge0}-f(x)+\sum_i \lambda_ig^{(i)}(x)+\sum_j \alpha_jh^{(j)}(x)</script></li>
</ul>
<p>根据KKT条件</p>
<ul>
<li>1.梯度为0</li>
<li>2.约束条件: 不等式乘子非负,且各约束条件满足</li>
<li>3.乘子互补$\alpha \odot h(x)=0$.也就是要么不等式约束乘子为0，要么不等式约束条件为0</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】SMT,Seq2seq,Attention</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91SMT,Seq2seq,Attention/</url>
    <content><![CDATA[<h1 id="【深層学習】SMT-Seq2seq-Attention"><a href="#【深層学習】SMT-Seq2seq-Attention" class="headerlink" title="【深層学習】SMT,Seq2seq,Attention"></a>【深層学習】SMT,Seq2seq,Attention</h1><blockquote>
<p><a href="http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf</a></p>
<h2 id="SMT-Statistic-Machine-Translation"><a href="#SMT-Statistic-Machine-Translation" class="headerlink" title="SMT(Statistic Machine Translation)"></a>SMT(Statistic Machine Translation)</h2><p>We want to consider $argmax_y P(y|x)$, where x,y are both sentence<br>It’s equate to $argmax_y P(x|y)P(y)$</p>
</blockquote>
<p><strong>Question: How to learn translation model $P(x|y)$ from the parallel corpus?</strong><br><img src="./1559567699670.png" alt="Alt text"><br>$a$ is the alignment</p>
<h3 id="alignment"><a href="#alignment" class="headerlink" title="alignment"></a>alignment</h3><p><img src="./1559567741326.png" alt="Alt text"><br><img src="./1559567745211.png" alt="Alt text"><br><img src="./1559567750230.png" alt="Alt text"><br><img src="./1559567756881.png" alt="Alt text"><br><img src="./1559567769809.png" alt="Alt text"><br><img src="./1559567777152.png" alt="Alt text"></p>
<h3 id="Learning-alignment-for-SMT"><a href="#Learning-alignment-for-SMT" class="headerlink" title="Learning alignment for SMT"></a>Learning alignment for SMT</h3><p><img src="./1559567820355.png" alt="Alt text"></p>
<h3 id="Decoding-for-SMT"><a href="#Decoding-for-SMT" class="headerlink" title="Decoding for SMT"></a>Decoding for SMT</h3><p><img src="./1559567835831.png" alt="Alt text"></p>
<h2 id="Neural-Machine-Translation-NMT-i"><a href="#Neural-Machine-Translation-NMT-i" class="headerlink" title="Neural Machine Translation (NMT) i"></a>Neural Machine Translation (NMT) i</h2><h3 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h3><p>it involves <strong>two RNNs.</strong><br><img src="./1559568075034.png" alt="Alt text"><br>其实就是一个RNN（编码器）连另一个RNN（解码器）<br>（第二段的RNN是每个时刻的输出作为下一时刻的输入）</p>
<p>seq2seq除了能解决机器翻译外还能解决很多NLP任务</p>
<ul>
<li>Summerization (缩句)</li>
<li>Dialogue </li>
<li>Parsing</li>
<li>Code generation</li>
<li>etc.</li>
</ul>
<p><img src="./1559568473829.png" alt="Alt text"><br><img src="./1559568499066.png" alt="Alt text"></p>
<h3 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h3><p><img src="./1559568771108.png" alt="Alt text"></p>
<h4 id="step"><a href="#step" class="headerlink" title="step"></a>step</h4><p>beam size=2,所以可以两边都分裂<br><img src="./1559568860124.png" alt="Alt text"><br>beam size=2所以选择两条最可能路线继续分裂<br><img src="./1559568878338.png" alt="Alt text"><br><img src="./1559568965704.png" alt="Alt text"><br><img src="./1559568995055.png" alt="Alt text"><br><img src="./1559569005330.png" alt="Alt text"><br><img src="./1559569010153.png" alt="Alt text"><br><img src="./1559569016520.png" alt="Alt text"><br><img src="./1559569020641.png" alt="Alt text"><br><img src="./1559569026902.png" alt="Alt text"><br><img src="./1559569031290.png" alt="Alt text"><br><img src="./1559569038673.png" alt="Alt text"><br><img src="./1559569044804.png" alt="Alt text"></p>
<h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>seq2seq has Information bottleneck problem<br><img src="./1559570258423.png" alt="Alt text"><br><img src="./1559570301218.png" alt="Alt text"><br><img src="./1559570352724.png" alt="Alt text"><br><img src="./1559570358134.png" alt="Alt text"><br><img src="./1559570367115.png" alt="Alt text"><br><img src="./1559570380721.png" alt="Alt text"><br><img src="./1559570430835.png" alt="Alt text"><br><img src="./1559570463111.png" alt="Alt text"><br><img src="./1559570473428.png" alt="Alt text"><br><img src="./1559570485249.png" alt="Alt text"><br><img src="./1559570495803.png" alt="Alt text"><br><img src="./1559570507587.png" alt="Alt text"></p>
<h4 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h4><p><img src="./1559570553416.png" alt="Alt text"><br><img src="./1560003588452.png" alt="Alt text"><br><img src="./1560003595269.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】RNN-Recurrent Neural Network</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91RNN-Recurrent%20Neural%20Network/</url>
    <content><![CDATA[<h1 id="【深層学習】RNN-Recurrent-Neural-Network"><a href="#【深層学習】RNN-Recurrent-Neural-Network" class="headerlink" title="【深層学習】RNN-Recurrent Neural Network"></a>【深層学習】RNN-Recurrent Neural Network</h1><h2 id="RNN’s-structure"><a href="#RNN’s-structure" class="headerlink" title="RNN’s structure"></a>RNN’s structure</h2><p><img src="./1558188846457.png" alt="Alt text"></p>
<p><img src="./1558159123475.png" alt="Alt text"><br>如果去掉图中的w，那么这个图就是一个普通的全连接神经网络。<br>x代表输入，U代表输入到隐藏层的<strong>权重矩阵</strong>.V是将隐藏层值映射到输出层的权重矩阵<br>加入了w后，代表当前隐藏层的值不仅取决于当前的输入x,还<strong>取决于上一时刻的输入</strong>.每计算完一次隐藏层后，将他存储在w里，将会在下一时刻计算隐藏层时用到.用公式来具体表示就是</p>
<script type="math/tex; mode=display">O_t=g(V\cdot S_t)\\S_t=f(U\cdot X_t+W\cdot S_{t-1})</script><p>展开上面的图后就是<img src="./1558159417993.png" alt="Alt text"><br><img src="./1558160128724.png" alt="Alt text"></p>
<h3 id="N-to-1"><a href="#N-to-1" class="headerlink" title="N to 1"></a>N to 1</h3><p><img src="./1558159896091.png" alt="Alt text"></p>
<h3 id="N-to-N"><a href="#N-to-N" class="headerlink" title="N to N"></a>N to N</h3><p><img src="./1558159906398.png" alt="Alt text"></p>
<h3 id="N-to-M"><a href="#N-to-M" class="headerlink" title="N to M"></a>N to M</h3><p><img src="./1558159921439.png" alt="Alt text"><br><img src="./1558159958534.png" alt="Alt text"></p>
<p>这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。在实现问题中，我们遇到的大部分序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。而Encoder-Decoder结构先将输入数据编码成一个上下文向量c，之后在通过这个上下文向量输出预测序列。</p>
<h3 id="BPTT"><a href="#BPTT" class="headerlink" title="BPTT"></a>BPTT</h3><p><img src="./1558160773605.png" alt="Alt text"></p>
<p>另$J=\sum_{t=1}^n J_t$<br>$s_t=\phi(Ux_t+Ws_{t-1})\\o_t=\varphi(Vs_t)$<br>另$s^<em>_t=Ux_t+Ws_{t-1}\\o^</em>_t=Vs_t$</p>
<script type="math/tex; mode=display">\frac{\partial J_t}{\partial o^*_t}=\frac{\partial L_t}{\partial o_t}\frac{\partial o_t}{\partial o^*_t}=\frac{\partial L_t}{\partial o_t}*\varphi'(o_t^*)</script><p><img src="./1558161303468.png" alt="Alt text"><br><img src="./1558161311368.png" alt="Alt text"><br><img src="./1558161346096.png" alt="Alt text"></p>
<h2 id="BRNN-双向RNN"><a href="#BRNN-双向RNN" class="headerlink" title="BRNN(双向RNN)"></a>BRNN(双向RNN)</h2><blockquote>
<p>RNN 中对于当前时刻 t 通常会考虑之前时刻的信息而没有考虑下文的信息，Bidirectional RNNs 克服了这一缺点，其引入了对下文的考虑，其结构如下：</p>
</blockquote>
<p><img src="./1558188894909.png" alt="Alt text"><br>可见 BRNN 引入了一套额外的隐层，但是输入与输出层是共享的，多了一个隐层意味着多了三套参数分别为  $U′、V′、W′  $。BRNN 的训练算法类似于 RNN ，forward pass 的过程如下：<br><img src="./1558188929237.png" alt="Alt text"></p>
<h3 id="Gradient-clipping-solution-for-exploding-gradient"><a href="#Gradient-clipping-solution-for-exploding-gradient" class="headerlink" title="Gradient clipping: solution for exploding gradient"></a>Gradient clipping: solution for exploding gradient</h3><p><img src="./1559813147905.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】NLP by CNNs</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91NLP%20by%20CNNs/</url>
    <content><![CDATA[<h1 id="【深層学習】NLP-by-CNNs"><a href="#【深層学習】NLP-by-CNNs" class="headerlink" title="【深層学習】NLP by CNNs"></a>【深層学習】NLP by CNNs</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="./1559815358440.png" alt="Alt text"><br>用卷积神经网络处理自然语言<br><img src="./1559815613245.png" alt="Alt text"><br>之后池化(最大池化)<br><img src="./1559815629276.png" alt="Alt text"><br><strong>stride</strong>:步长<br><strong>K-maxpooling</strong><br><img src="./1559815844993.png" alt="Alt text"><br><strong>卷积核膨胀dilation </strong><br>就是卷积核间隔开<br><img src="./1559815916997.png" alt="Alt text"></p>
<h2 id="use"><a href="#use" class="headerlink" title="use"></a>use</h2><p><img src="./1559816094837.png" alt="Alt text"><br><img src="./1559816181525.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】CS224N-Assignment 3</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91CS224N-Assignment%203/</url>
    <content><![CDATA[<h1 id="【深層学習】CS224N-Assignment-3"><a href="#【深層学習】CS224N-Assignment-3" class="headerlink" title="【深層学習】CS224N-Assignment 3"></a>【深層学習】CS224N-Assignment 3</h1><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="PyTorch使用"><a href="#PyTorch使用" class="headerlink" title="PyTorch使用"></a>PyTorch使用</h3><h4 id="Model-模型类"><a href="#Model-模型类" class="headerlink" title="Model 模型类"></a>Model 模型类</h4><pre><code class="lang-python">class ParserModel(nn.Module):
    &quot;&quot;&quot; Feedforward neural network with an embedding layer and single hidden layer.
    The ParserModel will predict which transition should be applied to a
    given partial parse configuration.

    PyTorch Notes:
        - Note that &quot;ParserModel&quot; is a subclass of the &quot;nn.Module&quot; class. In PyTorch all neural networks
            are a subclass of this &quot;nn.Module&quot;.
        - The &quot;__init__&quot; method is where you define all the layers and their respective parameters
            (embedding layers, linear layers, dropout layers, etc.).
        - &quot;__init__&quot; gets automatically called when you create a new instance of your class, e.g.
            when you write &quot;m = ParserModel()&quot;.
        - Other methods of ParserModel can access variables that have &quot;self.&quot; prefix. Thus,
            you should add the &quot;self.&quot; prefix layers, values, etc. that you want to utilize
            in other ParserModel methods.
        - For further documentation on &quot;nn.Module&quot; please see https://pytorch.org/docs/stable/nn.html.
    &quot;&quot;&quot;

#初始化函数，也就是给模型初始化好各种参数。隐藏层大小，类别数，dropout率,输入的embeddings,还有维度
    def __init__(self, embeddings, n_features=36,
        hidden_size=200, n_classes=3, dropout_prob=0.5):
        &quot;&quot;&quot; Initialize the parser model.

        @param embeddings (Tensor): word embeddings (num_words, embedding_size)
        @param n_features (int): number of input features
        @param hidden_size (int): number of hidden units
        @param n_classes (int): number of output classes
        @param dropout_prob (float): dropout probability
        &quot;&quot;&quot;
        super(ParserModel, self).__init__()
        self.n_features = n_features
        self.n_classes = n_classes
        self.dropout_prob = dropout_prob
        self.embed_size = embeddings.shape[1]
        self.hidden_size = hidden_size
        self.pretrained_embeddings = nn.Embedding(embeddings.shape[0], self.embed_size)
        self.pretrained_embeddings.weight = nn.Parameter(torch.tensor(embeddings))

        ### YOUR CODE HERE (~5 Lines)
        ### TODO:
        ###     1) Construct `self.embed_to_hidden` linear layer, initializing the weight matrix
        #创建一个输入embed到隐藏层的线性函数
        self.embed_to_hidden = nn.Linear(self.embed_size * self.n_features, self.hidden_size)   #隐藏层
        #初始化权重矩阵
        nn.init.xavier_uniform_(self.embed_to_hidden.weight, gain=1)
        ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)
        ###     2) Construct `self.dropout` layer.
        #设置隐藏层dropout
        self.dropout = nn.Dropout(p=self.dropout_prob)
        ###     3) Construct `self.hidden_to_logits` linear layer, initializing the weight matrix
        #隐藏层到输出logits层
        self.hidden_to_logits = nn.Linear(self.hidden_size, self.n_classes)
        #初始化权重
        nn.init.xavier_uniform_(self.hidden_to_logits.weight, gain=1)
        ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)
        ###
        ### Note: Here, we use Xavier Uniform Initialization for our Weight initialization.
        ###         It has been shown empirically, that this provides better initial weights
        ###         for training networks than random uniform initialization.
        ###         For more details checkout this great blogpost:
        ###             http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization 
        ### Hints:
        ###     - After you create a linear layer you can access the weight
        ###       matrix via:
        ###         linear_layer.weight
        ###
        ### Please see the following docs for support:
        ###     Linear Layer: https://pytorch.org/docs/stable/nn.html#torch.nn.Linear
        ###     Xavier Init: https://pytorch.org/docs/stable/nn.html#torch.nn.init.xavier_uniform_
        ###     Dropout: https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout


        ### END YOUR CODE
#从输入tokens映射到嵌入向量，并返回嵌入向量
    def embedding_lookup(self, t):
        &quot;&quot;&quot; Utilize `self.pretrained_embeddings` to map input `t` from input tokens (integers)
            to embedding vectors.

            PyTorch Notes:
                - `self.pretrained_embeddings` is a torch.nn.Embedding object that we defined in __init__
                - Here `t` is a tensor where each row represents a list of features. Each feature is represented by an integer (input token).
                - In PyTorch the Embedding object, e.g. `self.pretrained_embeddings`, allows you to
                    go from an index to embedding. Please see the documentation (https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding)
                    to learn how to use `self.pretrained_embeddings` to extract the embeddings for your tensor `t`.

            @param t (Tensor): input tensor of tokens (batch_size, n_features)

            @return x (Tensor): tensor of embeddings for words represented in t
                                (batch_size, n_features * embed_size)
        &quot;&quot;&quot;
        ### YOUR CODE HERE (~1-3 Lines)
        ### TODO:
        ###     1) Use `self.pretrained_embeddings` to lookup the embeddings for the input tokens in `t`.
        x = self.pretrained_embeddings(t)
        ###     2) After you apply the embedding lookup, you will have a tensor shape (batch_size, n_features, embedding_size).
        ###         Use the tensor `view` method to reshape the embeddings tensor to (batch_size, n_features * embedding_size)
        ###
        x = x.view(x.size()[0], -1)  # shape (batch_size, n_features * embedding_size)
        ### Note: In order to get batch_size, you may need use the tensor .size() function:
        ###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.size
        ###
        ###  Please see the following docs for support:
        ###     Embedding Layer: https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding
        ###     View: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view


        ### END YOUR CODE
        return x

#前向传播
    def forward(self, t):
        &quot;&quot;&quot; Run the model forward.

            Note that we will not apply the softmax function here because it is included in the loss function nn.CrossEntropyLoss

            PyTorch Notes:
                - Every nn.Module object (PyTorch model) has a `forward` function.
                - When you apply your nn.Module to an input tensor `t` this function is applied to the tensor.
                    For example, if you created an instance of your ParserModel and applied it to some `t` as follows,
                    the `forward` function would called on `t` and the result would be stored in the `output` variable:
                        model = ParserModel()
                        output = model(t) # this calls the forward function
                - For more details checkout: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward

        @param t (Tensor): input tensor of tokens (batch_size, n_features)

        @return logits (Tensor): tensor of predictions (output after applying the layers of the network)
                                 without applying softmax (batch_size, n_classes)
        &quot;&quot;&quot;
        ###  YOUR CODE HERE (~3-5 lines)
        ### TODO:
        ###     1) Apply `self.embedding_lookup` to `t` to get the embeddings
        ###     2) Apply `embed_to_hidden` linear layer to the embeddings
        ###     3) Apply relu non-linearity to the output of step 2 to get the hidden units.
        ###     4) Apply dropout layer to the output of step 3.
        ###     5) Apply `hidden_to_logits` layer to the output of step 4 to get the logits.
        ###
        ### Note: We do not apply the softmax to the logits here, because
        ### the loss function (torch.nn.CrossEntropyLoss) applies it more efficiently.
        ###
        ### Please see the following docs for support:
        ###     ReLU: https://pytorch.org/docs/stable/nn.html?highlight=relu#torch.nn.functional.relu


        x = self.embedding_lookup(t) #生成向量输入
        #扔到网络里
        x = self.embed_to_hidden(x)
        x = F.relu(x)
        x = self.dropout(x)
        logits = self.hidden_to_logits(x)
        ### END YOUR CODE
        return logits
</code></pre>
<h3 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h3><pre><code class="lang-python">def train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005):
    &quot;&quot;&quot; Train the neural dependency parser.

    @param parser (Parser): Neural Dependency Parser
    @param train_data ():
    @param dev_data ():
    @param output_path (str): Path to which model weights and results are written.
    @param batch_size (int): Number of examples in a single batch
    @param n_epochs (int): Number of training epochs
    @param lr (float): Learning rate
    &quot;&quot;&quot;
    best_dev_UAS = 0


    ### YOUR CODE HERE (~2-7 lines)
    ### TODO:
    ###      1) Construct Adam Optimizer in variable `optimizer`
    #定义优化器
    optimizer = optim.Adam(model.parameters())


    ###      2) Construct the Cross Entropy Loss Function in variable `loss_func`
    #定义损失函数类型
    loss_func = torch.nn.CrossEntropyLoss()
    ###
    ### Hint: Use `parser.model.parameters()` to pass optimizer
    ###       necessary parameters to tune.
    ### Please see the following docs for support:
    ###     Adam Optimizer: https://pytorch.org/docs/stable/optim.html
    ###     Cross Entropy Loss: https://pytorch.org/docs/stable/nn.html#crossentropyloss


    ### END YOUR CODE

    for epoch in range(n_epochs):
        print(&quot;Epoch {:} out of {:}&quot;.format(epoch + 1, n_epochs))
        dev_UAS = train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size)
        if dev_UAS &gt; best_dev_UAS:
            best_dev_UAS = dev_UAS
            print(&quot;New best dev UAS! Saving model.&quot;)
            torch.save(parser.model.state_dict(), output_path)
        print(&quot;&quot;)
</code></pre>
<h3 id="train-for-epoch（对一个epoch进行训练）"><a href="#train-for-epoch（对一个epoch进行训练）" class="headerlink" title="train_for_epoch（对一个epoch进行训练）"></a>train_for_epoch（对一个epoch进行训练）</h3><blockquote>
<p>epoch：迭代次数，1个epoch等于使用训练集中的全部样本训练一次；一个epoch = 所有训练样本的一个正向传递和一个反向传递<br>iteration：中文翻译为迭代，1个iteration等于使用batchsize个样本训练一次；一个迭代 = 一个正向通过+一个反向通过<br>batchsize：中文翻译为批大小（批尺寸）。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练；</p>
</blockquote>
<pre><code>def train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size):
    &quot;&quot;&quot; Train the neural dependency parser for single epoch.

    Note: In PyTorch we can signify train versus test and automatically have
    the Dropout Layer applied and removed, accordingly, by specifying
    whether we are training, `model.train()`, or evaluating, `model.eval()`

    @param parser (Parser): Neural Dependency Parser
    @param train_data ():
    @param dev_data ():
    @param optimizer (nn.Optimizer): Adam Optimizer
    @param loss_func (nn.CrossEntropyLoss): Cross Entropy Loss Function
    @param batch_size (int): batch size
    @param lr (float): learning rate

    @return dev_UAS (float): Unlabeled Attachment Score (UAS) for dev data
    &quot;&quot;&quot;
    parser.model.train() # Places model in &quot;train&quot; mode, i.e. apply dropout layer
    n_minibatches = math.ceil(len(train_data) / batch_size)
    loss_meter = AverageMeter()

    with tqdm(total=(n_minibatches)) as prog:
        for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):
            optimizer.zero_grad()   # remove any baggage in the optimizer
            loss = 0. # store loss for this batch here
            train_x = torch.from_numpy(train_x).long()
            train_y = torch.from_numpy(train_y.nonzero()[1]).long()

            ### YOUR CODE HERE (~5-10 lines)
            ### TODO:
            ###      1) Run train_x forward through model to produce `logits`
            logist=model(train_x) #通过模型获取结果
            optimizer.zero_grad() #初始化梯度
            loss=loss_func(logist,train_y) #让模型计算损失
            loss.backward()  #反向传播
            optimizer.step() #优化

            ###      2) Use the `loss_func` parameter to apply the PyTorch CrossEntropyLoss function.
            ###         This will take `logits` and `train_y` as inputs. It will output the CrossEntropyLoss
            ###         between softmax(`logits`) and `train_y`. Remember that softmax(`logits`)
            ###         are the predictions (y^ from the PDF).
            ###      3) Backprop losses
            ###      4) Take step with the optimizer
            ### Please see the following docs for support:
            ###     Optimizer Step: https://pytorch.org/docs/stable/optim.html#optimizer-step


            ### END YOUR CODE
            prog.update(1)
            loss_meter.update(loss.item())

    print (&quot;Average Train Loss: {}&quot;.format(loss_meter.avg))

    print(&quot;Evaluating on dev set&quot;,)
    parser.model.eval() # Places model in &quot;eval&quot; mode, i.e. don&#39;t apply dropout layer
    dev_UAS, _ = parser.parse(dev_data)
    print(&quot;- dev UAS: {:.2f}&quot;.format(dev_UAS * 100.0))
    return dev_UAS
</code></pre><blockquote>
<p>基于图的算法：<br>创建一个矩阵，每个元素表示a与b依存的概率。然后在这个矩阵中找出一颗最小生成树</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】CS224N-Assignment 2 Individual Solution</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91CS224N-Assignment%202%20Individual%20Solution/</url>
    <content><![CDATA[<h1 id="【深層学習】CS224N-Assignment-2-Individual-Solution"><a href="#【深層学習】CS224N-Assignment-2-Individual-Solution" class="headerlink" title="【深層学習】CS224N-Assignment 2 Individual Solution"></a>【深層学習】CS224N-Assignment 2 Individual Solution</h1><p><img src="./1558015343155.png" alt="Alt text"><br><img src="./1558015400965.png" alt="Alt text"><br><img src="./1558015449945.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【深層学習】BackProp</title>
    <url>/2019/12/26/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%80%91BackProp/</url>
    <content><![CDATA[<h1 id="【深層学習】BackProp"><a href="#【深層学習】BackProp" class="headerlink" title="【深層学習】BackProp"></a>【深層学習】BackProp</h1><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p><img src="./1558615569497.png" alt="Alt text"><br>普通求导<br><img src="./1558615587913.png" alt="Alt text"><br>神经网络示意图<br><img src="./1558615597108.png" alt="Alt text"><br>现在让我们对底层单个元素求导<br><img src="./1558615732856.png" alt="Alt text"><br>因为$W_{ij}$只和$z_i$相关（如图）<br><img src="./1558615788728.png" alt="Alt text"><br>结果是一个上层返回的错误信号乘上该层的梯度信号</p>
<p>写成矩阵就是<img src="./1558615864272.png" alt="Alt text"><br><img src="./1558615910889.png" alt="Alt text"><br><img src="./1558615917624.png" alt="Alt text"></p>
<h2 id="Computation-Graphs-and-Backpropagation"><a href="#Computation-Graphs-and-Backpropagation" class="headerlink" title="Computation Graphs and Backpropagation"></a>Computation Graphs and Backpropagation</h2><p><img src="./1558616048609.png" alt="Alt text"><br><img src="./1558616099848.png" alt="Alt text"><br>反向传播到需要更新的参数<img src="./1558616217465.png" alt="Alt text"><br><img src="./1558616238673.png" alt="Alt text"><br><img src="./1558616531361.png" alt="Alt text"><br><img src="./1558616535724.png" alt="Alt text"><br><img src="./1558616768864.png" alt="Alt text"><br><img src="./1558616772924.png" alt="Alt text"><br><img src="./1558616817775.png" alt="Alt text"></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><img src="./1558616927090.png" alt="Alt text"><br><img src="./1558616937112.png" alt="Alt text"><br><img src="./1558616940776.png" alt="Alt text"><br><img src="./1558616973687.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【密码学】分组密码的5种基本工作模式</title>
    <url>/2019/12/26/%E3%80%90%E5%AF%86%E7%A0%81%E5%AD%A6%E3%80%91%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E7%9A%845%E7%A7%8D%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="【密码学】分组密码的5种基本工作模式"><a href="#【密码学】分组密码的5种基本工作模式" class="headerlink" title="【密码学】分组密码的5种基本工作模式"></a>【密码学】分组密码的5种基本工作模式</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><img src="./1569292471510.png" alt="Alt text"></p>
<h2 id="ECB-Electrinic-CodeBook"><a href="#ECB-Electrinic-CodeBook" class="headerlink" title="ECB(Electrinic CodeBook)"></a>ECB(Electrinic CodeBook)</h2><p><img src="./1569292508764.png" alt="Alt text"><br>简单，扩散性不好，明文规律会反映在密文上</p>
<h2 id="CBC-Cipher-Block-Chining"><a href="#CBC-Cipher-Block-Chining" class="headerlink" title="CBC(Cipher Block Chining)"></a>CBC(Cipher Block Chining)</h2><p><img src="./1569292567732.png" alt="Alt text"><br>解密支持并行计算（解密不支持）<br>能够解密任意密文分组<br>明文的重复不会反映在密文中</p>
<h2 id="CFB-Cipher-FeedBack"><a href="#CFB-Cipher-FeedBack" class="headerlink" title="CFB(Cipher-FeedBack)"></a>CFB(Cipher-FeedBack)</h2><p><img src="./1569292739967.png" alt="Alt text"><br>长度和明文分组相等<br>解密支持并行计算<br>对噪声抵抗力小</p>
<h2 id="OFB-Output-FeedBack"><a href="#OFB-Output-FeedBack" class="headerlink" title="OFB(Output-FeedBack)"></a>OFB(Output-FeedBack)</h2><p><img src="./1569292845511.png" alt="Alt text"><br>可以先进行加解密的准备。抗噪声。不支持冰箱</p>
<h2 id="CTR-CountTeR"><a href="#CTR-CountTeR" class="headerlink" title="CTR(CountTeR)"></a>CTR(CountTeR)</h2><p><img src="./1569292903640.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【控制论】制御理論</title>
    <url>/2019/12/26/%E3%80%90%E6%8E%A7%E5%88%B6%E8%AE%BA%E3%80%91%E5%88%B6%E5%BE%A1%E7%90%86%E8%AB%96/</url>
    <content><![CDATA[<h1 id="【控制论】制御理論"><a href="#【控制论】制御理論" class="headerlink" title="【控制论】制御理論"></a>【控制论】制御理論</h1><h2 id="力学系をフィードバック制御する"><a href="#力学系をフィードバック制御する" class="headerlink" title="力学系をフィードバック制御する"></a>力学系をフィードバック制御する</h2><p><strong>微分オペレーター</strong><br>$s=\frac{d}{dt}$<br>[例]<br>$ms^2x(s)+csx(s)+kx(s)=f(s)\\x(s)=\frac{1}{ms^2+cs+k}f(s)$<br>$\frac{1}{ms^2+cs+k}$は<strong>伝達関数</strong><br><img src="./1563689259372.png" alt="Alt text"><br><strong>RLC电路</strong><br>$L\frac{d^2q(t)}{dt^2}+R\frac{dq(t)}{dt}+\frac{1}{C}q(t)=v(t)$<img src="./1563705437708.png" alt="Alt text"><br><img src="./1563708207140.png" alt="Alt text"></p>
<h2 id="制御系設計とは、複素数とラプラス変換"><a href="#制御系設計とは、複素数とラプラス変換" class="headerlink" title="制御系設計とは、複素数とラプラス変換"></a>制御系設計とは、複素数とラプラス変換</h2><p><img src="./1563708666184.png" alt="Alt text"><br><strong>AB并联=&gt;$\frac{A}{AB+1}$</strong><br><strong>Loop transfer function:化简为仅有一个函数和一个反馈环的图</strong></p>
<p><strong>閉ループ伝達関数:$\frac{L}{1+L}$</strong></p>
<h2 id="制御で用いるラプラス変換の重要な性質-LTIシステムの表現１-convolution-と伝達関数"><a href="#制御で用いるラプラス変換の重要な性質-LTIシステムの表現１-convolution-と伝達関数" class="headerlink" title="制御で用いるラプラス変換の重要な性質,LTIシステムの表現１(convolution と伝達関数)"></a>制御で用いるラプラス変換の重要な性質,LTIシステムの表現１(convolution と伝達関数)</h2><h3 id="ラプラス変換性質"><a href="#ラプラス変換性質" class="headerlink" title="ラプラス変換性質"></a>ラプラス変換性質</h3><ul>
<li><p>linear<br><img src="./1563715961800.png" alt="Alt text"></p>
</li>
<li><p>scaling<br><img src="./1563715983823.png" alt="Alt text"></p>
</li>
<li><p>delay<br><img src="./1563715995367.png" alt="Alt text"></p>
</li>
<li>move<br><img src="./1563716025557.png" alt="Alt text"></li>
<li>微分<br><img src="./1563716071396.png" alt="Alt text"></li>
<li>int<br><img src="./1563716124783.png" alt="Alt text"></li>
<li>convolution<br><img src="./1563716151814.png" alt="Alt text"><script type="math/tex; mode=display">y(t)=g(t)*u(t)=\int_0^tg(\tau)u(t-\tau)d\tau</script></li>
<li>最終値定理<br><img src="./1563769242281.png" alt="Alt text"></li>
</ul>
<h3 id="线性时不变系统-LTIシステム"><a href="#线性时不变系统-LTIシステム" class="headerlink" title="线性时不变系统(LTIシステム)"></a>线性时不变系统(LTIシステム)</h3><p><strong>インパルス応答($g(t)$)</strong>:给一个LTI一个单位脉冲信号，他的输出<br>知道impluse应答后，对于任意的信号输入，都可以利用卷积定理求输出<br><img src="./1563770061552.png" alt="Alt text"><br><strong>ステップ応答</strong>($u_s(t)$)：</p>
<h3 id="伝達関数"><a href="#伝達関数" class="headerlink" title="伝達関数"></a>伝達関数</h3><p>$G（s）=Y（s）/U（s）$<br>一般$G(s)$<br><img src="./1563770995136.png" alt="Alt text"></p>
<h2 id="附-フリーエ変換のいくつかの形式"><a href="#附-フリーエ変換のいくつかの形式" class="headerlink" title="附:フリーエ変換のいくつかの形式"></a>附:フリーエ変換のいくつかの形式</h2><ul>
<li>(连续时间(非周期)，连续频率)-&gt;傅里叶变换(FT)<script type="math/tex; mode=display">X(\omega)=\int_{-\infty}^\infty x(t)e^{-j\omega t}dt</script></li>
<li>(连续时间，离散频率）-&gt;傅里叶级数(FS)<script type="math/tex; mode=display">X(k\omega_0)=\frac{1}{T_0}\int_{-\frac{T_0}{2}}^{\frac{T_0}{2}} x(t)e^{-jk\omega_0 t}dt</script></li>
<li>(离散时间,连续频率)  -&gt;离散时间傅里叶级数 (DTFT)<script type="math/tex; mode=display">X(e^{j\omega})=\sum_{n=-\infty}^\infty x(n)e^{-j\omega n}</script></li>
<li>(离散时间,离散频率) -&gt; 离散傅里叶级数 (DFS)<script type="math/tex; mode=display">\tilde X[k]=\sum_{n=0}^{N-1} \tilde x(n)e^{-j{\frac{2\pi}{N}} kn}</script></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【矩阵论_线性代数】特征值分解，奇异值分解（SVD）</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%80%BC%E5%88%86%E8%A7%A3%EF%BC%8C%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%EF%BC%88SVD%EF%BC%89/</url>
    <content><![CDATA[<h1 id="【矩阵论-线性代数】特征值分解，奇异值分解（SVD）"><a href="#【矩阵论-线性代数】特征值分解，奇异值分解（SVD）" class="headerlink" title="【矩阵论|线性代数】特征值分解，奇异值分解（SVD）"></a>【矩阵论|线性代数】特征值分解，奇异值分解（SVD）</h1><h2 id="1-特征值分解"><a href="#1-特征值分解" class="headerlink" title="1.特征值分解"></a>1.特征值分解</h2><script type="math/tex; mode=display">Av=\lambda v\\\lambda为特征值</script><center>特征分解是分解成以下形式$$A=Q\sum Q^{-1}$$
$Q$是由**特征向量**组成的矩阵，$\sum$是特征值组成的对角矩阵,**只有方矩阵能进行这样的分解**
>**特征值和特征向量求法:**
>>**特征多项式:**$|A-\lambda E|$
>
>step1. 求出**特征多项式**
>step2. 解**特征多项式=0**，得到所有特征值
>step3. 把特征值代入线性方程组$(A-\lambda E)x=0$,求出基础解系,求解方法:先消元,然后求出限制解，在限制情况下，为自由元赋值1![Alt text](./1555129126884.png)

</center>


<h2 id="2-奇异值分解-SVD"><a href="#2-奇异值分解-SVD" class="headerlink" title="2.奇异值分解(SVD)"></a>2.奇异值分解(SVD)</h2><blockquote>
<p>奇异值分解是一个能适用于任意的矩阵的一种分解的方法。</p>
</blockquote>
<center>**分解形式：**
$$A=U\sum V^T$$
若A为M*N矩阵
$U$中向量称为**左奇异向量**，大小为**M*M**
$\sum$为**M*N**实数对角矩阵
$V^T$大小为N*N，**右奇异向量**，里面的向量是正交的

>奇异值和特征值是怎么对应起来的呢?
>$(A^TA)v_i=\lambda_iv_i,v_i为右奇异向量$

原理![Alt text](./1555130259980.png)

步骤:
step1:求$A^TA$或者$AA^T$的特征值$\lambda_1,\lambda_2...$
step2:确定$\sum$:$\sum_{ii}=\sqrt\lambda_i$,其余为0
step3:求$CC^T$的特征向量，也就是U
step4:求$C^TC$的特征向量，也就是V
</center>]]></content>
  </entry>
  <entry>
    <title>【矩阵论】矩阵微积分</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91%E7%9F%A9%E9%98%B5%E5%BE%AE%E7%A7%AF%E5%88%86/</url>
    <content><![CDATA[<h1 id="【矩阵论】矩阵微积分"><a href="#【矩阵论】矩阵微积分" class="headerlink" title="【矩阵论】矩阵微积分"></a>【矩阵论】矩阵微积分</h1><h2 id="向量序列的敛散性"><a href="#向量序列的敛散性" class="headerlink" title="向量序列的敛散性"></a>向量序列的敛散性</h2><p>$x^{(k)}$是一个向量序列</p>
<h3 id="依范数收敛"><a href="#依范数收敛" class="headerlink" title="依范数收敛"></a>依范数收敛</h3><script type="math/tex; mode=display">\lim_{k->+\infty}||x^{(k)}-x||_p=0</script><h3 id="依坐标收敛"><a href="#依坐标收敛" class="headerlink" title="依坐标收敛"></a>依坐标收敛</h3><script type="math/tex; mode=display">\lim_{k->+\infty}x^{(k)}_i=x_i</script><h2 id="矩阵序列的极限"><a href="#矩阵序列的极限" class="headerlink" title="矩阵序列的极限"></a>矩阵序列的极限</h2><p>同理</p>
<h3 id="依范数收敛-1"><a href="#依范数收敛-1" class="headerlink" title="依范数收敛"></a>依范数收敛</h3><script type="math/tex; mode=display">\lim_{k->+\infty}||A^{(k)}-A||_p=0</script><h3 id="依坐标收敛-1"><a href="#依坐标收敛-1" class="headerlink" title="依坐标收敛"></a>依坐标收敛</h3><script type="math/tex; mode=display">\lim_{k->+\infty}A^{(k)}_{ij}=A_{ij}</script><h2 id="矩阵函数"><a href="#矩阵函数" class="headerlink" title="矩阵函数"></a>矩阵函数</h2><h3 id="矩阵函数值求法"><a href="#矩阵函数值求法" class="headerlink" title="矩阵函数值求法"></a>矩阵函数值求法</h3><p>1.找特征多项式<br>2.找特征值,特征向量形成C<br>3.求C,C^{-1}<br>4.特征值代入原函数形成对角阵<br>5.$f(A)=Cdiag(…)C^{-1}$</p>
<p>A为亏损矩阵的情况:</p>
<script type="math/tex; mode=display">f(A)=T*f(J)*T^{-1}</script><p>1.先求特征值，特征多项式<br>2.找诺尔当标准型<br>3.对于代数重数不等于几何重数的，多求广义特征向量。形成T</p>
<script type="math/tex; mode=display">f(J_i(\lambda_i))=
 \left[
 \begin{matrix}
   f(\lambda_i) & f'(\lambda_i) & \frac{1}{2!}f'''(\lambda_i) &...\\
  & f(\lambda_i) & f'(\lambda)&  \frac{1}{2!}f'''(\lambda_i) \\
   & & f(\lambda_i) & f'(\lambda)\\
   ...
  \end{matrix}
  \right]</script><p><img src="./1556710060237.png" alt="Alt text"></p>
<h2 id="矩阵微积分"><a href="#矩阵微积分" class="headerlink" title="矩阵微积分"></a>矩阵微积分</h2><h3 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h3><h4 id="普通函数f对向量x求导"><a href="#普通函数f对向量x求导" class="headerlink" title="普通函数f对向量x求导"></a>普通函数f对向量x求导</h4><p>结果是一个<strong>向量</strong>，每个元素是f对x_i求导的结果</p>
<h4 id="普通函数f对矩阵A求导"><a href="#普通函数f对矩阵A求导" class="headerlink" title="普通函数f对矩阵A求导"></a>普通函数f对矩阵A求导</h4><p>结果是一个<strong>矩阵</strong>,每个元素是函数对$a_{ij}$求导的结果</p>
<h4 id="矩阵F对矩阵A求导"><a href="#矩阵F对矩阵A求导" class="headerlink" title="矩阵F对矩阵A求导"></a>矩阵F对矩阵A求导</h4><p>结果是一个<strong>矩阵的矩阵</strong><br>每个元素是矩阵F对A中元素$a_{ij}$求导得到的矩阵</p>
<h4 id="矩阵的全微分"><a href="#矩阵的全微分" class="headerlink" title="矩阵的全微分"></a>矩阵的全微分</h4><p>就是为每个元素加了一个算子d</p>
<h2 id="微分方程"><a href="#微分方程" class="headerlink" title="微分方程"></a>微分方程</h2><script type="math/tex; mode=display">\frac{d\vec x}{dt}=A\vec x</script><p>A是系数矩阵</p>
<script type="math/tex; mode=display">\vec x=(x_1(t),x_2(t),....)</script><p>每个元素是一个函数</p>
<p>这是<strong>一阶齐次线性微分方程</strong><br>解的形式必定是</p>
<script type="math/tex; mode=display">x=e^{At}x(0)</script><p>解法<br>1.求特征值和特征向量<br>2.化$e^At$为P<em>diag(…)</em>P^{-1}形式，P是已求的特征向量矩阵</p>
<p><strong>一阶非齐次线性微分方程组</strong></p>
<script type="math/tex; mode=display">\frac{dx}{dt}=Ax+f(t)\\x|_{t=t_0}=x(t_0)</script><p>1.先按齐次方程求通解<br>2.加个积分$I=\int_0^te^{At}f(z)dz$</p>
]]></content>
  </entry>
  <entry>
    <title>【矩阵论】矩阵分解</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="【矩阵论】矩阵分解"><a href="#【矩阵论】矩阵分解" class="headerlink" title="【矩阵论】矩阵分解"></a>【矩阵论】矩阵分解</h1><blockquote>
<p><strong>酉矩阵</strong>:$U^HU=UU^H=E_n$</p>
</blockquote>
<h2 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h2><p>要求:<strong>A满秩</strong></p>
<center>
目标：把矩阵分解成一个**正交矩阵Q**，一个**上三角阵R**
$$A=QR$$
在复数上推广,Q换成酉矩阵U也一样
$$A=UR$$
**分解过程:**
1.判断A是否可分解（满秩）
2.把A按列分块$A=(x_1,x_2,x_3)$,**正交化**为$y_1,y_2,y_3$,**单位化**为$z_1,z_2,z_3$
$$Q=(z_1,z_2,z_3)$$
$$\begin{equation}
R={
\left[ \begin{array}{ccc}
||y_1|| & (x_2,z_1) & (x_3,z_1)\\
0& ||y_2|| & (x_3,z_2)\\
0 & 0 & ||y_3||
\end{array}
\right ]}
\end{equation}$$
</center>

<p>原理就是</p>
<script type="math/tex; mode=display">Q=AB</script><p>B是一个映射，让A正交化<br>于是有</p>
<script type="math/tex; mode=display">A=QB^{-1}=QR</script><h2 id="满秩分解"><a href="#满秩分解" class="headerlink" title="满秩分解"></a>满秩分解</h2><p>要求：任意矩阵A,分解不唯一</p>
<center>目标:$$A=FG$$
**分解过程**
1.把A化为简化阶梯型
![Alt text](./1555945257251.png)
2.求F：找出单位列向量组成F
3.求G：找非0行
</center>


<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>要求：任意矩阵A</p>
<center>
分解过程:
1.找出奇异值：计算$A^HA$的特征值，从大到小排，开个根号就是奇异值了，然后所有**奇异值**构成对角阵$S_r$
求$C^TC$的特征向量，也就是V
求$CC^T$的特征向量，也就是U
$$A=U\sum V^H$$
</center>



<h2 id="谱分解"><a href="#谱分解" class="headerlink" title="谱分解"></a>谱分解</h2><blockquote>
<p>N阶方阵An×nAn×n的n个特征值称为A的谱（谱分解是对于单纯矩阵而言的）</p>
</blockquote>
<p>谱分解步骤：<br>1.求A的特征向量，构成矩阵$P=(X_1,X_2,…,X_n)$<br>2.求$P^{-1}$  <script type="math/tex">P^{-1}=(Y_1,Y_2,...,Y_n)^T</script></p>
<script type="math/tex; mode=display">A=\lambda_1X_1Y_1+\lambda_2X_2Y_2+...+\lambda_kX_kY_k\\=\lambda_1G_1+\lambda_2G_2+...+\lambda_nG_n</script><p>!!!!<script type="math/tex">!!! G_i是幂等阵</script></p>
<h2 id="LU分解"><a href="#LU分解" class="headerlink" title="LU分解"></a>LU分解</h2><p>方法：按行消元。成上三角矩阵U<br>原理:   <script type="math/tex">E_k...E_2E_1A=U</script></p>
<script type="math/tex; mode=display">A=(E_k...E_2E_1)^{-1}U=LU</script>]]></content>
  </entry>
  <entry>
    <title>【矩阵论】广义逆矩阵</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/</url>
    <content><![CDATA[<h1 id="【矩阵论】广义逆矩阵"><a href="#【矩阵论】广义逆矩阵" class="headerlink" title="【矩阵论】广义逆矩阵"></a>【矩阵论】广义逆矩阵</h1><blockquote>
<p>满足下列一部分或全部条件的称为广义逆矩阵（若全满足则为伪逆）</p>
<script type="math/tex; mode=display">AGA=A\\GAG=G\\(GA)^H=GA\\(AG)^H=AG</script></blockquote>
<h2 id="减号逆A"><a href="#减号逆A" class="headerlink" title="减号逆A-"></a>减号逆A-</h2><p>对于A存在A-</p>
<script type="math/tex; mode=display">AA^-A=A</script><h2 id="自反减号逆A-r"><a href="#自反减号逆A-r" class="headerlink" title="自反减号逆A_r^-"></a>自反减号逆A_r^-</h2><script type="math/tex; mode=display">A_r^-AA_r^-=A_r^-</script><script type="math/tex; mode=display">AA_r^-A=A</script><h2 id="最小范数广义逆Am"><a href="#最小范数广义逆Am" class="headerlink" title="最小范数广义逆Am-"></a>最小范数广义逆Am-</h2><script type="math/tex; mode=display">AGA=A且(GA)^T=GA</script><h2 id="最小二乘广义逆AI"><a href="#最小二乘广义逆AI" class="headerlink" title="最小二乘广义逆AI-"></a>最小二乘广义逆AI-</h2><script type="math/tex; mode=display">AGA=A且(AG)^T=AG</script><h2 id="加号逆-伪逆-A"><a href="#加号逆-伪逆-A" class="headerlink" title="加号逆\伪逆 A+"></a>加号逆\伪逆 A+</h2><p>全部满足<br><img src="./1558138129090.png" alt="Alt text"></p>
<h2 id="方程无解问题"><a href="#方程无解问题" class="headerlink" title="方程无解问题"></a>方程无解问题</h2><p>1.利用A-<br>思想：$Ax=b,x=A^{-1}b$,用A-表现类似x=Gb形式的解</p>
<script type="math/tex; mode=display">x=A^-b+(I-A^-A)z</script><p>z是与x同维任意向量。特解$x=A^-b$<br>2.利用最小二乘<br>不存在解时:<br>思想：<script type="math/tex">x=min\{||Ax-b||\}</script><br>3.利用极小范数<br>无穷多个解时:<br>思想：<script type="math/tex">x=min_{Ax=b}\{||x||\}</script></p>
]]></content>
  </entry>
  <entry>
    <title>【矩阵论】赋范线性空间与矩阵范数</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91%E8%B5%8B%E8%8C%83%E7%BA%BF%E6%80%A7%E7%A9%BA%E9%97%B4%E4%B8%8E%E7%9F%A9%E9%98%B5%E8%8C%83%E6%95%B0/</url>
    <content><![CDATA[<h1 id="【矩阵论】赋范线性空间与矩阵范数"><a href="#【矩阵论】赋范线性空间与矩阵范数" class="headerlink" title="【矩阵论】赋范线性空间与矩阵范数"></a>【矩阵论】赋范线性空间与矩阵范数</h1><h2 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h2><script type="math/tex; mode=display">||x||_p=(\sum_i |x_i|^p)^{\frac{1}{p}}</script><p>其中</p>
<script type="math/tex; mode=display">||x||_\infty=max_i|x_i|</script><p>性质</p>
<script type="math/tex; mode=display">||xy||_p\le||x||_p ||y||_p</script><script type="math/tex; mode=display">||x+y||_p\le||x||_p+||y||_p</script><h2 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h2><p>性质同向量范数<br>算法是每个元素绝对值的p次方和再开p次方</p>
<h2 id="一些矩阵范数"><a href="#一些矩阵范数" class="headerlink" title="一些矩阵范数"></a>一些矩阵范数</h2><p>$\rho$:谱半径：最大的特征值</p>
<h3 id="谱范数"><a href="#谱范数" class="headerlink" title="谱范数"></a>谱范数</h3><script type="math/tex; mode=display">||A||_2=\sqrt{\lambda_{max}(A^HA)}</script><h3 id="行范数"><a href="#行范数" class="headerlink" title="行范数"></a>行范数</h3><script type="math/tex; mode=display">||A||_\infty=\max _i\sum_j{|a_{ij}|}</script><p>找最大行和</p>
<h3 id="列范数"><a href="#列范数" class="headerlink" title="列范数"></a>列范数</h3><script type="math/tex; mode=display">||A||_1=\max _j\sum_i{|a_{ij}|}</script><p>找最大列和</p>
<h3 id="摄动分析"><a href="#摄动分析" class="headerlink" title="摄动分析"></a>摄动分析</h3><p>就是分析方程组微小的扰动是否会对解尝试重大影响。是的话就是<strong>病态矩阵</strong><br>可以利用范数分析</p>
<script type="math/tex; mode=display">A(x+\delta x)=b+\delta b\\\delta x=A^{-1}\delta b\\||\delta x||\le||A^{-1}||||b||\\\frac{||\delta x||}{||x||}\le ||A^{-1}||||A||\frac{||\delta b||}{||b||}</script>]]></content>
  </entry>
  <entry>
    <title>【矩阵论】Lambda Matrix and Jordan standard form</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91Lambda%20Matrix%20and%20Jordan%20standard%20form/</url>
    <content><![CDATA[<h1 id="【矩阵论】Lambda-Matrix-and-Jordan-standard-form"><a href="#【矩阵论】Lambda-Matrix-and-Jordan-standard-form" class="headerlink" title="【矩阵论】Lambda Matrix and Jordan standard form"></a>【矩阵论】Lambda Matrix and Jordan standard form</h1><h2 id="Lambda-Matrix"><a href="#Lambda-Matrix" class="headerlink" title="Lambda Matrix"></a>Lambda Matrix</h2><script type="math/tex; mode=display">A(\lambda)=
 \left[
 \begin{matrix}
   a_{11}(\lambda) & a_{12}(\lambda) & a_{13}(\lambda) \\
   a_{21}(\lambda) & a_{22}(\lambda) & a_{23}(\lambda)  \\
   a_{31}(\lambda) & a_{32}(\lambda) & a_{33}(\lambda) \\
   ...
  \end{matrix}
  \right] \tag{Lambda matrix}</script><p>$a_{ij}(\lambda)$为多项式函数<br>$\lambda$是一个未定元，当取具体的数时，就变成数值矩阵</p>
<h2 id="Smith-Standard-From"><a href="#Smith-Standard-From" class="headerlink" title="Smith Standard From"></a>Smith Standard From</h2><p>消元，只保留对角元素，其余全部弄成0</p>
<script type="math/tex; mode=display">A(\lambda)\backsimeq
 \left[
 \begin{matrix}
   d_{1}(\lambda) & 0 &0 ...\\
   0 & d_{2}(\lambda) & 0  ...\\
   0 & 0 & d_{3}(\lambda) ...\\
      0 & 0 & 0... & 0\\
   ...
  \end{matrix}
  \right]</script><p>其对角元素称为<strong>不变因子</strong></p>
<p><strong>Determinant factor(行列式因子):</strong></p>
<blockquote>
<p>k阶行列式因子是矩阵中所有非零的k阶子行列式首项系数为1的最大公因式<br>求法见下面<br><strong>初等因子</strong>:<br>求A的初等因子:<br>$\lambda I-A$变为Smith Standard Form，不为1的<strong>不变因子</strong>就是<strong>初等因子</strong><br>初等因子可以反推行列式因子</p>
</blockquote>
<h2 id="Jordan-Chunk"><a href="#Jordan-Chunk" class="headerlink" title="Jordan Chunk"></a>Jordan Chunk</h2><script type="math/tex; mode=display">J_i=
 \left[
 \begin{matrix}
   \lambda_i& 1 &  \\
   & \lambda_i & 1  \\
   &  & \lambda_i \\
   ...
  \end{matrix}
  \right]</script><p>初等因子只有$(\lambda-\lambda_i)^n$</p>
<h2 id="Jordan-Standard-Form"><a href="#Jordan-Standard-Form" class="headerlink" title="Jordan Standard Form"></a>Jordan Standard Form</h2><p>若尔当标准型求法<br><strong>从高到低求出</strong>$D_i$(行列式因子)<br>例子：</p>
<script type="math/tex; mode=display">A=
 \left[
 \begin{matrix}
  2 & 0 & 2 &1\\
   6 & 1 & 4 & 4\\
   10 & 0 & 0&4\\
     7 & 0 & -7 & 2\\
  \end{matrix}
  \right]</script><p>先求$D_4=det(A)=(\lambda-2)(\lambda-1)^3$<br>接下来求$D_3$:<br>先随便求两个3阶行列式。<br>比如去掉4,4的$M_{(4,4)}$<br>和去掉1,2的$M_{(1,2)}$<br>发现最大公因子为1.于是<br>$D_3=1$<br>D2\D3同理<br>于是就得到了初等因子$(\lambda-2)(\lambda-1)^3$<br>然后就可以画出矩阵了<br>可以看到$\lambda$有2个取值，于是有2个若尔当块，一块对角线上是2，一块对角线上全1</p>
<script type="math/tex; mode=display">J=
 \left[
 \begin{matrix}
  2 & 0 & 0 &0\\
   0& 1 & 1 & 0\\
  0& 0 & 1&1\\
    0 & 0 & 0 & 1\\
  \end{matrix}
  \right]</script>]]></content>
  </entry>
  <entry>
    <title>【矩阵论】Geometric Theory of Matrix(矩阵的几何理论)</title>
    <url>/2019/12/26/%E3%80%90%E7%9F%A9%E9%98%B5%E8%AE%BA%E3%80%91Geometric%20Theory%20of%20Matrix(%E7%9F%A9%E9%98%B5%E7%9A%84%E5%87%A0%E4%BD%95%E7%90%86%E8%AE%BA)/</url>
    <content><![CDATA[<h1 id="【矩阵论】Geometric-Theory-of-Matrix-矩阵的几何理论"><a href="#【矩阵论】Geometric-Theory-of-Matrix-矩阵的几何理论" class="headerlink" title="【矩阵论】Geometric Theory of Matrix(矩阵的几何理论)"></a>【矩阵论】Geometric Theory of Matrix(矩阵的几何理论)</h1><h2 id="Linear-operator-in-Linear-Space-线性空间上的线性算子"><a href="#Linear-operator-in-Linear-Space-线性空间上的线性算子" class="headerlink" title="Linear operator in Linear Space(线性空间上的线性算子)"></a>Linear operator in Linear Space(线性空间上的线性算子)</h2><p><strong>Linear Space(线性空间)</strong>:里面的元素对线性运算封闭。当里面的元素为矩阵时，也叫<strong>矩阵空间(Matrix Space)</strong><br><strong>零空间维数是0（只有0向量）</strong><br><strong>解空间</strong>:基础解系构成解空间的一组基<br><strong>自然基:</strong>相互正交的，只有一位为1的向量<br><strong>坐标变换(Coordinate transformation):</strong></p>
<script type="math/tex; mode=display">E'=EC \quad C为过渡矩阵(transition\quad matrix)\tag{基变换，右乘C}</script><script type="math/tex; mode=display">x'=C^{-1}x\tag{坐标变换,左乘C逆}</script><script type="math/tex; mode=display">V_1\cap V_2=\{0\}时V_1+V_2写成V_1\oplus V_2</script><h3 id="线性算子-linear-operator"><a href="#线性算子-linear-operator" class="headerlink" title="线性算子(linear operator)"></a>线性算子(linear operator)</h3><blockquote>
<p>就是一个线性映射（也可以用一个矩阵A来表示）</p>
</blockquote>
<script type="math/tex; mode=display">\mathscr{A}(M)\subseteq M'</script><p><strong>同构算子(isomorphism operator)</strong>:一对一映射<br>$A^H$表示共轭转置，也就是把每个元素都取共轭值，再转置</p>
<h3 id="相似矩阵"><a href="#相似矩阵" class="headerlink" title="相似矩阵"></a>相似矩阵</h3><script type="math/tex; mode=display">B=C^{-1}AC</script><blockquote>
<p>意义是A、B可以看成<strong>同一个线性变换</strong>在不同基下的矩阵</p>
</blockquote>
<p><strong>性质:</strong><br>拥有相同的特征多项式,相同的特征值</p>
<h3 id="相抵矩阵"><a href="#相抵矩阵" class="headerlink" title="相抵矩阵"></a>相抵矩阵</h3><script type="math/tex; mode=display">B=DAC</script><p>D,C都是非奇异的</p>
<h3 id="合同-相合矩阵"><a href="#合同-相合矩阵" class="headerlink" title="合同\相合矩阵"></a>合同\相合矩阵</h3><script type="math/tex; mode=display">B=C^TAC</script><h3 id="对角化"><a href="#对角化" class="headerlink" title="对角化"></a>对角化</h3><p><strong>可对角化的充分必要条件是：A有n个线性无关的特征向量。也就是各特征值几何重复度=代数重复度</strong><br><strong>亏损矩阵:</strong>n阶矩阵的特征向量&lt;n</p>
<script type="math/tex; mode=display">C^{-1}AC=diag(...)</script><p>C的求法：先求特征值，然后求出特征向量，然后按列摆在一起</p>
<h3 id="正交化"><a href="#正交化" class="headerlink" title="正交化"></a>正交化</h3><h4 id="Schmidt-orthogonalization"><a href="#Schmidt-orthogonalization" class="headerlink" title="Schmidt orthogonalization"></a>Schmidt orthogonalization</h4><p>1.$y’_1=x_1$作为第一个<br>2.$y’^2=x_2-\frac{(x_2,y’_1)}{(y’_1,y’_1)}y’_1$<br>3.$y’^3=x_3-\frac{(x_3,y’_2)}{(y’_2,y’_2)}y’_2-\frac{(x_3,y’_1)}{(y’_1,y’_1)}y’_1$<br>….</p>
<p><strong>正交矩阵:</strong></p>
<script type="math/tex; mode=display">A^TA=AA^T=I</script><h3 id="初等反射矩阵-Householder-Transformation"><a href="#初等反射矩阵-Householder-Transformation" class="headerlink" title="初等反射矩阵(Householder Transformation)"></a>初等反射矩阵(Householder Transformation)</h3><script type="math/tex; mode=display">H=I-2ww^T</script><p><img src="./1556705930429.png" alt="Alt text"></p>
<h3 id="对称变换-Symmetric-Transformation"><a href="#对称变换-Symmetric-Transformation" class="headerlink" title="对称变换(Symmetric Transformation)"></a>对称变换(Symmetric Transformation)</h3><script type="math/tex; mode=display">(\mathscr{A}(x),y)=(x,\mathscr{A}(y))</script><h3 id="正定矩阵"><a href="#正定矩阵" class="headerlink" title="正定矩阵"></a>正定矩阵</h3><p>特征值非负<br>充要条件</p>
<script type="math/tex; mode=display">A=P^HP</script><h3 id="Hermitian-Matrix"><a href="#Hermitian-Matrix" class="headerlink" title="Hermitian Matrix"></a>Hermitian Matrix</h3><script type="math/tex; mode=display">A^H=A</script><h3 id="瑞利熵"><a href="#瑞利熵" class="headerlink" title="瑞利熵"></a>瑞利熵</h3><script type="math/tex; mode=display">R(x)=\frac{x^HAx}{x^Hx}</script><p>A为<strong>Hermitian矩阵(n*n)</strong><br>性质：最大值=矩阵最大特征值，最小值=矩阵最小特征值</p>
]]></content>
  </entry>
  <entry>
    <title>【機械学習】共役事前分布</title>
    <url>/2019/12/26/%E3%80%90%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%80%91%E5%85%B1%E5%BD%B9%E4%BA%8B%E5%89%8D%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<h1 id="【機械学習】共役事前分布"><a href="#【機械学習】共役事前分布" class="headerlink" title="【機械学習】共役事前分布"></a>【機械学習】共役事前分布</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>可以用来推断模型参数</p>
<p>对于伯努利分布、二项分布。其共轭先验分布式 <strong>Beta分布</strong> (详情见BETA分布文章)</p>
<h2 id="高斯分布的共轭先验分布"><a href="#高斯分布的共轭先验分布" class="headerlink" title="高斯分布的共轭先验分布"></a>高斯分布的共轭先验分布</h2><h3 id="方差已知，均值未知-gt-高斯分布"><a href="#方差已知，均值未知-gt-高斯分布" class="headerlink" title="方差已知，均值未知-&gt;高斯分布"></a>方差已知，均值未知-&gt;高斯分布</h3><p>其未知参数$\mu$的共轭事前分布是<script type="math/tex">N(\mu|\mu_0,\sigma_0)</script> ，也是一个高斯分布</p>
<p>如何估计模型参数?<br>我们现在有观测集合D。要推断$\mu$<br>从$p(\mu|D)$出发</p>
<p>有 <script type="math/tex">p(\mu|D)\propto p(D|\mu)p(\mu)  \quad贝叶斯,MAP\\\propto exp\{-\frac{1}{2\sigma^2}\sum_{n=1}^N(x_n-x)^2-\frac{1}{2\sigma_0^2}(\mu-\mu_0)^2\}</script><br>因为$p(\mu)$服从$N(\mu|\mu_0,\sigma_0)$,因此有$p(\mu)\propto exp\{\frac{1}{2\sigma_0^2}(\mu-\mu_0)^2\}$<br>因此能得到上式<br>之后<script type="math/tex">\propto exp\{-\frac{1}{2}\{\frac{N}{\sigma^2}+\frac{1}{\sigma_0^2}\}\mu^2+\{\frac{\mu_0}{\sigma_0^2}+\frac{\sum_{n=1}^Nx_n}{\sigma^2}\}\mu\}</script></p>
<p>注意到   对于 $exp\{ {-\frac{(\mu-\mu_N)^2}{2\sigma_N^2} }\}$<br>$\mu$的一次项系数是$\frac{\mu_N}{\sigma_N^2}$,二次系数是$\frac{-1}{2\sigma_N^2}$<br>于是即可根据上式子求出$\mu_N$和$\sigma_N^2$(事后分布的参数)</p>
<h4 id="方差已知的多维分布"><a href="#方差已知的多维分布" class="headerlink" title="方差已知的多维分布"></a>方差已知的多维分布</h4><p>也一样。记住多维正态分布</p>
<script type="math/tex; mode=display">p(D|\mu,\sum)=\prod_{n=1}^N \frac{1}{(2\pi)^{(K/2)}det(\sum)^{1/2}}exp\{-\frac{1}{2}(x_n-\mu)^T\Sigma^{-1}(x_n-\mu) \}</script><p>指数的部分是一个二次型。</p>
<h3 id="平均已知，方差未知"><a href="#平均已知，方差未知" class="headerlink" title="平均已知，方差未知"></a>平均已知，方差未知</h3><p>此时的共轭事前分布是逆Gammr分布<br>$p(\lambda|a,b)=\frac{1}{\Gamma(a)}b^a\lambda^{a-1}exp(-b\lambda)$</p>
<p>其次$p(x_n|\lambda)$是高斯分布$N(x_n|\mu,\lambda^{-1})$<br>之后也是$p(\lambda|D)\propto p(D|\lambda)p(\lambda|a_0,b_0)$<br><strong>共轭事前分布乘上$p(\lambda|D)$</strong><br>然后与gamma分布比较，得出两个参数a_N b_N</p>
<h4 id="多维下"><a href="#多维下" class="headerlink" title="多维下"></a>多维下</h4><p>需要使用高维gamma分布</p>
<h3 id="平均，方差都未知"><a href="#平均，方差都未知" class="headerlink" title="平均，方差都未知"></a>平均，方差都未知</h3><p>此时 $p(\mu|\lambda)\sim N(\mu|\mu_0,\lambda^{-1})$<br>$p(\lambda)$是$Gam(\lambda|a,b)$</p>
<h2 id="指数分布族以及参数推断"><a href="#指数分布族以及参数推断" class="headerlink" title="指数分布族以及参数推断"></a>指数分布族以及参数推断</h2><p>伯努利分布<br>多项式分布<br>泊松分布<br>伽马分布<br>Beta分布<br>Dirichlet分布<br>Wishart分布(高维的gamma)<br>高斯分布<br>都是指数分布族</p>
<p>指数分布族的一般形式</p>
<script type="math/tex; mode=display">P(y;\eta)=b(y)exp(\eta^TT(y)-a(\eta))</script><p>T(y)是一个充分统计量，一般其=y<br>$\eta$是分布的自然参数<br>于是3个参数a,b,$\eta$可以确定一个指数分布族</p>
<p>或者<img src="./1570718905207.png" alt="Alt text"><br>例子：<br><img src="./1570719026838.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【概率模型】HMM(隐马尔可夫模型)</title>
    <url>/2019/12/26/%E3%80%90%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E3%80%91HMM(%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B)/</url>
    <content><![CDATA[<h1 id="【概率模型】HMM-隐马尔可夫模型"><a href="#【概率模型】HMM-隐马尔可夫模型" class="headerlink" title="【概率模型】HMM(隐马尔可夫模型)"></a>【概率模型】HMM(隐马尔可夫模型)</h1><h2 id="马尔科夫过程"><a href="#马尔科夫过程" class="headerlink" title="马尔科夫过程"></a>马尔科夫过程</h2><p>马尔科夫过程就是一个状态转移图<br>其可以有N个状态。状态到状态的转换是赋予概率的。<br>于是可以用$N<em>N$的<em>*概率转移矩阵</em></em>表示<br>如一个例子<br>假设几个月大的宝宝每天做三件事：玩（兴奋状态）、吃（饥饿状态）、睡（困倦状态），这三件事按下图所示的方向转移：<br><img src="./1557584384147.png" alt="Alt text"><br>这就是一个简单的马尔可夫过程。需要注意的是，这和确定性系统不同，每个转移都是有概率的，宝宝的状态是经常变化的，而且会任意在两个状态间切换：<br><img src="./1557584394585.png" alt="Alt text"><br>如图。这个过程的概率转移矩阵A为<br><img src="./1557584410083.png" alt="Alt text"><br>每行累加和为1.</p>
<h3 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h3><p>有时我们无法看到$状态序列Q$,只能看到观察序列（或输出序列）$O$<br>这时隐马尔可夫模型就产生了。<br>一个是<strong>可观测的状态集O</strong>和一个<strong>隐藏状态集Q</strong><br>还是上面的例子。为了简化描述，将“玩”这个状态去掉，让宝宝每天除了吃就是睡<br><img src="./1557584565105.png" alt="Alt text"><br>在HMM里。我们使用<strong>混淆矩阵B</strong><br><img src="./1557584603179.png" alt="Alt text"><br>且运用<strong>独立性假设</strong>：假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其它观测状态无关。<br><img src="./1557584626812.png" alt="Alt text"></p>
<h4 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h4><ul>
<li>N 表示隐藏状态的数量，我们要么知道确切的值，要么猜测该值；</li>
<li>M 表示可观测状态的数量，可以通过训练集获得；</li>
<li>π={πi} 为初始状态概率；代表的是刚开始的时候各个隐藏状态的发生概率；</li>
<li>$A=\{a_{ij}\}$为隐藏状态的转移矩阵；N*N维矩阵，代表的是第一个状态到第二个状态发生的概率；</li>
<li>$B=\{b_{ij}\}$为混淆矩阵，N*M矩阵，代表的是处于某个隐状态的条件下，某个观测发生的概率。</li>
</ul>
<h4 id="HMM要解决的问题"><a href="#HMM要解决的问题" class="headerlink" title="HMM要解决的问题"></a>HMM要解决的问题</h4><p>HMM主要解决三大类问题</p>
<ul>
<li>模型评估问题<br>已知一个观察序列。和模型λ=（A,B,π}的条件下，观察序列O的概率，即P(O|λ}。<br>对应算法：向前算法、向后算法</li>
<li>解码问题<br>从观察序列推断隐藏状态序列<br>也就是已知模型参数和可观察状态序列，怎样选择一个状态序列S={S1,S2,…,ST}，能最好的解释观测序列O。<br>对于算法<strong>维特比算法</strong></li>
<li>参数估计问题<br>数据集仅有观测序列，如何调整模型参数 λ=(π, A, B), 使得P(O|λ)最大<br>对应算法：鲍姆-韦尔奇算法</li>
</ul>
<h4 id="模型评估问题"><a href="#模型评估问题" class="headerlink" title="模型评估问题"></a>模型评估问题</h4><h5 id="遍历法"><a href="#遍历法" class="headerlink" title="遍历法"></a>遍历法</h5><p>实现较为简单，罗列可能情况后将其相加即可。共有3种可观察状态，每个可观察状态对应2种隐藏状态，共有2^3 = 8中可能的情况。其中一种：<br><img src="./1557585034087.png" alt="Alt text"><br>需要计算$|O|^{|S|}$种情况</p>
<h5 id="Forward-Algorithm"><a href="#Forward-Algorithm" class="headerlink" title="Forward Algorithm"></a>Forward Algorithm</h5><p><img src="./1557585176936.png" alt="Alt text"><br><img src="./1557585201503.png" alt="Alt text"><br><img src="./1557585205814.png" alt="Alt text"></p>
<blockquote>
<p>思想就是<br>我们可以定义一个前向变量</p>
<script type="math/tex; mode=display">\alpha_t(i)=P(O_1O_2...O_t,q_t=s_i|\lambda)</script><p>用来表示在时刻t，输出了状态$O_1O_2…O_t$,并且位于状态$s_i$的概率<br>于是下一时刻的输出序列概率就可以用前一时刻的前向变量来表示<br><img src="./1557625643936.png" alt="Alt text"><br>如图<br>对于t+1时刻的前向变量$\alpha_{t+1}(j)=(\sum_{t=1}^Na_t(i)a_{ij})b_j(O_{t+1})$<br>解释就是先根据前面t时每个前向变量来求出，从t下每个状态转移到t+1下某状态j的概率，然后求出从$s_j$状态输出某值$O_{t+1}$的概率<br>迭代求到最终时间T的所有N个状态的前向变量后。就可以终结求和<script type="math/tex">P(O|\mu)=\sum_{i=1}^N\alpha_T(i)</script></p>
<h5 id="Backward-Algorithm"><a href="#Backward-Algorithm" class="headerlink" title="Backward Algorithm"></a>Backward Algorithm</h5><p>和前向算法差不多。不过从最终输出开始干<br>引入后向变量</p>
<script type="math/tex; mode=display">\beta_t(i)=P(O_{t+1}O_{t+2}...O_T|q_t=s_i,\mu)</script><p><img src="./1557626672606.png" alt="Alt text"></p>
</blockquote>
<p>算法步骤</p>
<ul>
<li>1.初始化$\beta_T(i)=1$</li>
<li>2.迭代$\beta_t(i)=\sum_{j=1}^Ta_{ij}b_j(O_{t+1})\beta_{t+1}(j)$</li>
<li>3.终结$P(O|\mu)=\sum_{i=1}^N\pi_ib_i(O_1)\beta_1(i)$<h4 id="解码问题"><a href="#解码问题" class="headerlink" title="解码问题"></a>解码问题</h4><h5 id="维特比算法-Viterbi-Algorithm-也可用于卷积码译码"><a href="#维特比算法-Viterbi-Algorithm-也可用于卷积码译码" class="headerlink" title="维特比算法(Viterbi Algorithm)(也可用于卷积码译码)"></a>维特比算法(Viterbi Algorithm)(也可用于卷积码译码)</h5><blockquote>
<p>用于解决已知一个输出序列，怎样找到一个状态序列能最好地解释这个输出序列<br><img src="https://pic1.zhimg.com/50/v2-256fa2a9e05193edb2ff4a61fc919ef5_hd.gif" alt="avatar"><br>上图是Viterbi算法的动画图。简单来说就是：从开始状态之后每走一步，就记录下到达该状态的所有路径的概率最大值，然后以此最大值为基准继续向后推进。显然，如果这个最大值都不能使该状态成为最大似然状态路径上的结点的话，那些小于它的概率值（以及对应的路径）就更没有可能了。</p>
</blockquote>
</li>
</ul>
<p><img src="./1557585878655.png" alt="Alt text"></p>
<blockquote>
<p>先来定义一个维特比变量$\delta_t(i)=max_{q_1,q_2,..q_{t-1}}P(q_1,q_2,…,q_t=s_i,O_1O_2…O_t|\mu)$<br>就是某一时刻t下，HMM沿着某一条路径到达s_i的概率。（动态规划法）..和找最短路径的算法差不多<br>$\delta_{t+1}(i)=max_j[\delta_t(j)<em>a_{ji}]</em>b_i(O_{t+1})$<br>找出前一时刻转移到当前时刻状态i并输出某O的最大概率.</p>
</blockquote>
<h4 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h4><h5 id="Forward-backward-algorithm"><a href="#Forward-backward-algorithm" class="headerlink" title="Forward-backward algorithm"></a>Forward-backward algorithm</h5><p>其实就是使用期望最大算法</p>
<ul>
<li><p>首先初始化参数。<br>初始化初始状态概率$\pi_i$,要满足和为1<br>初始化转移矩阵A,满足行和为1<br>初始化输出概率矩阵B<br>$\sum_{k=1}^Mb_j(k)=1$<br>表示某状态下，输出所有结果的概率和为1</p>
</li>
<li><p>EM计算</p>
<ul>
<li><strong>E步骤</strong>:由现有的参数，估计$\xi_t(i,j)$和$\gamma_t(i)$<br>$\xi$表示在已知参数和输出结果下，从状态i到状态j的转移概率<br>$\gamma$表示在时间t时，位于状态$s_i$的概率</li>
<li>用E中得到的值重新估计参数<br> $\pi_i=\gamma_1(i)$<br> $a_{ij}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t{(j)}}$<br> $b_{j}(k)=\frac{\sum_{t=1}^{T}\gamma_t(j)*\delta(O_t,v_k)}{\sum_{t=1}^{T-1}\gamma_t{(j)}}$</li>
</ul>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【概率模型】CRF_Conditional Random Field(条件随机场)</title>
    <url>/2019/12/26/%E3%80%90%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E3%80%91CRF_Conditional%20Random%20Field(%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA)/</url>
    <content><![CDATA[<h1 id="【概率模型】CRF-Conditional-Random-Field-条件随机场"><a href="#【概率模型】CRF-Conditional-Random-Field-条件随机场" class="headerlink" title="【概率模型】CRF:Conditional Random Field(条件随机场)"></a>【概率模型】CRF:Conditional Random Field(条件随机场)</h1><blockquote>
<p>CRF主要用于序列标注，可以简单理解为对序列的每一帧都进行分类</p>
<h2 id="逐帧softmax"><a href="#逐帧softmax" class="headerlink" title="逐帧softmax"></a>逐帧softmax</h2><p>为了解决上述问题。可以利用逐帧softmax<br>将这个序列用 CNN 或者 RNN 进行编码后，接一个全连接层用 softmax 激活，如下图所示：<br><img src="./1557629879751.png" alt="Alt text"></p>
<h2 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h2><p>然而，当我们设计标签时，比如用 s、b、m、e 的 4 个标签来做字标注法的分词，目标输出序列本身会带有一些上下文关联，比如 s 后面就不能接 m 和 e，等等。逐标签 softmax 并没有考虑这种输出层面的上下文关联，所以它意味着把这些关联放到了编码层面，希望模型能自己学到这些内容，但有时候会“强模型所难”。 </p>
</blockquote>
<p>而 CRF 则更直接一点，它<strong>将输出层面的关联分离了出来</strong>，这使得模型在学习上更为“从容”：<br><img src="./1557630131916.png" alt="Alt text"><br>而在序列标注任务中，我们的正确答案是一般是唯一的。比如“今天天气不错”，如果对应的分词结果是“今天/天气/不/错”，那么目标输出序列就是 bebess，除此之外别的路径都不符合要求。</p>
<p>换言之，在序列标注任务中，我们的研究的基本单位应该是路径，我们要做的事情，是从 k^n 条路径选出正确的一条，那就意味着，如果将它<strong>视为一个分类问题</strong>，那么将是 k^n 类中选一类的分类问题。<br><img src="./1557630124813.png" alt="Alt text"><br>这就是逐帧 softmax 和 CRF 的根本不同了：<strong>前者将序列标注看成是 n 个 k 分类问题，后者将序列标注看成是 1 个 k^n 分类问题。</strong><br>具体来讲，在 CRF 的序列标注问题中，我们要计算的是条件概率：<br><img src="./1557630182441.png" alt="Alt text"></p>
<p>我们举个例子：<br><img src="./1557665166565.png" alt="Alt text"><br>我们可以得到以下模型图：<br><img src="./1557665178660.png" alt="Alt text"><br>当模型输入句子 ”Dog caught the cat“ 时，我们希望模型能够输出标注序列：“n v a n”的概率最大<br>那么如何根据这个状态图计算出序列”n v a n“的出现的概率呢？<br>这里就引出了<strong>概率无向图模型</strong>：（注：个人认为条件随机场模型是一个概率无向图模型，而线性链条件随机场是一个有向图模型）</p>
<p>对于上列图，我们定义两种特征</p>
<ul>
<li><strong>转移特征</strong><br>定义在边上的特征。<img src="./1557665271002.png" alt="Alt text"><br>表示观察序列X在i及i-1位置上的标记转移概率</li>
<li><strong>状态特征</strong><br>定义在点上的特征<script type="math/tex; mode=display">s_k(y_i,X,i)</script>表示对于观察序列X其i位置的标记概率</li>
</ul>
<p><img src="./1557665438893.png" alt="Alt text"><br><img src="./1557666060888.png" alt="Alt text"></p>
<h4 id="定义CRF中的特征函数"><a href="#定义CRF中的特征函数" class="headerlink" title="定义CRF中的特征函数"></a>定义CRF中的特征函数</h4><p>现在，我们正式地定义一下什么是CRF中的特征函数，所谓特征函数，就是这样的函数，它接受四个参数： </p>
<ol>
<li>句子s（就是我们要标注词性的句子） </li>
<li>i，用来表示句子s中第i个单词 </li>
<li>l_i，表示要评分的标注序列给第i个单词标注的词性 </li>
<li>l_i-1，表示要评分的标注序列给第i-1个单词标注的词性</li>
</ol>
<p>它的输出值是0或者1,0表示要评分的标注序列不符合这个特征，1表示要评分的标注序列符合这个特征。</p>
<p>Note:这里，我们的特征函数仅仅依靠当前单词的标签和它前面的单词的标签对标注序列进行评判，这样建立的CRF也叫作线性链CRF，这是CRF中的一种简单情况。为简单起见，本文中我们仅考虑线性链CRF。</p>
<h2 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h2><p>考虑NLP中的消除歧义问题。集合$A$是结果候选集合，$B$是歧义点的上下文<br>于是$f(a,b)$为一个特征<br>运用最大熵模型</p>
<script type="math/tex; mode=display">\hat p(a|b)=argmax_{p\in P} H(p)</script><p>可以看出最大熵模型，是寻找一个分布，在这个分布下熵达到最大</p>
<script type="math/tex; mode=display">H(p)=H(A|B)=\sum_b p(b)H(A|B=b)=-\sum_{a,b}p(b)[p(a|b)\log p(a|b)]</script><p>于是可以转换为问题</p>
<script type="math/tex; mode=display">\hat p(a|b)=argmax (-\sum_{a,b}\hat p(b)[p(a|b)\log p(a|b)])</script><script type="math/tex; mode=display">\hat p(a,b)\approx \frac{Count(a,b)}{\sum_{A,B}Count(a,b)}=\frac{1}{Z(b)}exp(\sum_{i=1}^l \lambda_i\centerdot f_i(a,b))\\Z(b)为归一化因子,使\sum_a \hat p(a|b)=1</script><h4 id="从特征函数到概率"><a href="#从特征函数到概率" class="headerlink" title="从特征函数到概率"></a>从特征函数到概率</h4><p>定义好一组特征函数后，我们要给每个特征函数f_j赋予一个权重λ_j。现在，只要有一个句子s，有一个标注序列l，我们就可以利用前面定义的特征函数集来对l评分<br><img src="./1557666558002.png" alt="Alt text"><br>标准化<br><img src="./1557666653710.png" alt="Alt text"><br><img src="./1557666778762.png" alt="Alt text"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a href="https://www.jiqizhixin.com/articles/2018-05-23-3" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2018-05-23-3</a></li>
<li>[2] <a href="https://blog.csdn.net/dcx_abc/article/details/78319246" target="_blank" rel="noopener">https://blog.csdn.net/dcx_abc/article/details/78319246</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>【ソフト工学】Gitコマンド</title>
    <url>/2019/12/26/%E3%80%90%E3%82%BD%E3%83%95%E3%83%88%E5%B7%A5%E5%AD%A6%E3%80%91Git%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/</url>
    <content><![CDATA[<h1 id="【ソフト工学】Gitコマンド"><a href="#【ソフト工学】Gitコマンド" class="headerlink" title="【ソフト工学】Gitコマンド"></a>【ソフト工学】Gitコマンド</h1><h2 id="よく使用のコマンド"><a href="#よく使用のコマンド" class="headerlink" title="よく使用のコマンド"></a>よく使用のコマンド</h2><h3 id="远程仓库相关"><a href="#远程仓库相关" class="headerlink" title="远程仓库相关"></a>远程仓库相关</h3><p>检出仓库：<strong>git clone git://github.com/jquery/jquery.git</strong><br>查看远程仓库：<strong>git remote -v</strong><br>添加远程仓库：<strong>git remote add [name] [url]</strong><br>删除远程仓库：<strong>git remote rm [name]</strong><br>修改远程仓库： <strong>git remote set-url —push[name][newUrl]</strong><br>拉取远程仓库： <strong>git pull [remoteName] [localBranchName]</strong><br>推送远程仓库： <strong>git push [remoteName] [localBranchName]</strong></p>
<h3 id="上传项目到远程分支"><a href="#上传项目到远程分支" class="headerlink" title="上传项目到远程分支"></a>上传项目到远程分支</h3><p>1.初始化本地仓库<br><code>Git init</code><br>2.上传修改的文件<br><code>git add *</code><br>3.commit 文件<br><code>git commit -m &quot;test&quot;</code><br>4.创建分支<br><code>git branch test</code><br>5.切换分支<br><code>git checkout test</code><br>6.关联远程分支<br><code>git remote add origin https://github.com/yangxiaoyan20/BowlingScore.git</code><br>7.push<br><code>git push origin test</code></p>
<p>修改后重新push<br>1、git add .<br>2、git commit -m “test” &nbsp;（”test“为分支名）<br>3、git branch test（创建分支）<br>4、git checkout &nbsp;test （切换分支）<br>5、git push origin test:test</p>
<p>commit，然后pull，然后再push</p>
<h2 id="error："><a href="#error：" class="headerlink" title="error："></a>error：</h2><p>1.fatal: refusing to merge unrelated histories<br><strong>git pull origin master -–allow-unrelated-histories</strong></p>
]]></content>
  </entry>
  <entry>
    <title>【Robotics】机器人学导论</title>
    <url>/2019/12/26/%E3%80%90Robotics%E3%80%91%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6%E5%AF%BC%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="【Robotics】机器人学导论"><a href="#【Robotics】机器人学导论" class="headerlink" title="【Robotics】机器人学导论"></a>【Robotics】机器人学导论</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><p>基本部件：机械手、末端执行器、驱动器（肌肉）、传感器、控制器、处理器、软件</p>
<h3 id="自由度"><a href="#自由度" class="headerlink" title="自由度"></a>自由度</h3><p>一般有6个自由度。3个用来确定 空间中的位置，3个用来确定姿态</p>
<h3 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h3><p><img src="./1561112847279.png" alt="Alt text"></p>
<p>1、基坐标系（Base Coordinate System）<br>2、大地坐标系（World Coordinate System）<br>3、工具坐标系（Tool Coordinate System）<br>4、工件坐标系（Work Object Coordinate System）</p>
<h2 id="位置运动学"><a href="#位置运动学" class="headerlink" title="位置运动学"></a>位置运动学</h2><h3 id="1-n、o、a坐标轴"><a href="#1-n、o、a坐标轴" class="headerlink" title="1.n、o、a坐标轴"></a>1.n、o、a坐标轴</h3><p><strong>n=normal (垂直后面两种轴), 【o=orientstion(图中y轴), a=approach(用来接近物体，z轴)】</strong><br>用$F_{n,o,a}$表示</p>
<h4 id="在固定参考坐标系原点表示"><a href="#在固定参考坐标系原点表示" class="headerlink" title="在固定参考坐标系原点表示"></a>在固定参考坐标系原点表示</h4><p>坐标系是在原点的，只不过旋转之类的变换过了</p>
<script type="math/tex; mode=display">
 F=\left[
 \begin{matrix}
   n_x & o_x & a_x \\
   n_y & o_y & a_y \\
   n_z & o_z & a_z
  \end{matrix}
  \right] \tag{3}</script><h4 id="在固定坐标系的非原点表示"><a href="#在固定坐标系的非原点表示" class="headerlink" title="在固定坐标系的非原点表示"></a>在固定坐标系的非原点表示</h4><p>相对坐标系不在原点。需要加第4个位置向量</p>
<script type="math/tex; mode=display">
F= \left[
 \begin{matrix}
   n_x & o_x & a_x & p_x\\
   n_y & o_y & a_y  & p_y\\
   n_z & o_z & a_z  & p_z\\
   0 & 0 & 0 & 1
  \end{matrix}
  \right] \tag{3}</script><p>前3个为0表示是方向向量，第4个为1表示是位置向量（使用比例因子为1）<br>空间中的一个3维物体也可以用上面的矩阵表示</p>
<p>条件限制：3个向量n o a相互垂直，也就是点积为0<br>每个旋转向量是单位向量</p>
<h4 id="变换的表示"><a href="#变换的表示" class="headerlink" title="变换的表示"></a>变换的表示</h4><h5 id="平移矩阵"><a href="#平移矩阵" class="headerlink" title="平移矩阵"></a>平移矩阵</h5><p><strong>左乘</strong></p>
<script type="math/tex; mode=display">
T= \left[
 \begin{matrix}
   1& 0& 0& d_x\\
   0 & 1 & 0  & d_y\\
   0 & 0 & 1  & d_z\\
   0 & 0 & 0 & 1
  \end{matrix}
  \right] \tag{3}</script><h5 id="旋转矩阵"><a href="#旋转矩阵" class="headerlink" title="旋转矩阵"></a>旋转矩阵</h5><p>绕X轴旋转。<br>左乘</p>
<script type="math/tex; mode=display">
R_{ot}(x,\theta)= \left[
 \begin{matrix}
   1& 0& 0\\
   0 & cos \theta & -sin\theta \\
   0 & sin\theta& cos\theta
  \end{matrix}
  \right] \tag{3}</script><p>绕y轴旋转。<br>左乘</p>
<script type="math/tex; mode=display">
R_{ot}(y,\theta)= \left[
 \begin{matrix}
  cos \theta& 0&  sin\theta\\
   0 &  1&0 \\
   -sin\theta & 0& cos\theta
  \end{matrix}
  \right] \tag{3}</script><p>绕z轴旋转。<br>左乘</p>
<script type="math/tex; mode=display">
R_{ot}(z,\theta)= \left[
 \begin{matrix}
 cos \theta& -sin\theta& 0\\
  sin\theta &  cos\theta &0 \\
   0 & 0&1
  \end{matrix}
  \right] \tag{3}</script><h4 id="相对运动坐标系的变换"><a href="#相对运动坐标系的变换" class="headerlink" title="相对运动坐标系的变换"></a>相对运动坐标系的变换</h4><p>相对当前坐标系的变换<br>需要把变换矩阵右乘后，这一堆矩阵左乘要变换的坐标</p>
<h4 id="矩阵逆的快速运算"><a href="#矩阵逆的快速运算" class="headerlink" title="矩阵逆的快速运算"></a>矩阵逆的快速运算</h4><p>1.旋转矩阵</p>
<script type="math/tex; mode=display">Rot(x,\theta)^{-1}=Rot(x,\theta)^T</script><p>2.平移矩阵</p>
<script type="math/tex; mode=display">
T= \left[
 \begin{matrix}
   n_x& o_x& a_x& p_x\\
   n_y & o_y & o_y  & p_y\\
   n_z & o_z & a_Z  & p_z\\
   0 & 0 & 0 & 1
  \end{matrix}
  \right] \tag{3}</script><p><img src="./1561185660769.png" alt="Alt text"></p>
<h3 id="正逆运动学"><a href="#正逆运动学" class="headerlink" title="正逆运动学"></a>正逆运动学</h3><p><strong>正运动学</strong>:已知所有关节变量，通过正运动学方程计算机器人某时刻的位姿<br><strong>逆运动学</strong>:知道一个位姿，确定所有关节变量</p>
<h4 id="正逆运动学方程"><a href="#正逆运动学方程" class="headerlink" title="正逆运动学方程"></a>正逆运动学方程</h4><ul>
<li>1.直角坐标<br>所有驱动机构都是线性的<br>就是利用平移矩阵T</li>
<li>2.圆柱坐标<br>1个旋转 2个线性运动<br>分为3步：<br>沿x轴移动r,绕z轴旋转$\alpha$,沿z轴走l.</li>
<li>3.球坐标<br>2个旋转，1个线性运动<br>先平移r,再绕y轴转$\beta$,再绕z轴转$\gamma$</li>
<li>4.链式坐标<br>由3个旋转组成<br><img src="./1561187537595.png" alt="Alt text">公式后面推导</li>
</ul>
<p><strong>RPY变换</strong></p>
<ul>
<li>绕a轴(x)旋转 -&gt;<strong>滚动</strong></li>
<li>绕o轴(y)旋转-&gt;<strong>俯仰</strong></li>
<li>绕n轴(z)旋转-&gt;<strong>偏航</strong></li>
</ul>
<p>x走指向正面，于是<br>绕x轴转就是<strong>横滚(Roll)</strong><br>绕y轴就是<strong>俯仰(Pitch)</strong><br>绕z轴就是<strong>偏航(Yaw)</strong></p>
<p>于是 变换可以看做  <script type="math/tex">^RT_H=T * RPY</script></p>
<p><strong>欧拉变换</strong></p>
<script type="math/tex; mode=display">Euler(\phi,\theta,\psi)=Rot(a,\phi)Rot(o,\theta)Rot(a,\psi)</script><p>求姿态矩阵同样，左乘一个逆，解方程</p>
<p>用于<strong>直角坐标</strong>:$^RT_H=T(p_x,p_y,p_z)<em>RPY(\phi_a,\phi_o,\phi_n)$<br>用于<strong>求坐标</strong>:$^RT_H=T(r,\beta,\gamma)</em>Euler(\phi,\theta,\psi)$</p>
<h4 id="正运动学D-H表示"><a href="#正运动学D-H表示" class="headerlink" title="正运动学D-H表示"></a>正运动学D-H表示</h4><p>首先为关节建x和z轴（不用y）<br>建模步骤：<br>1.所有关节用z轴表示，是旋转的话是右手规则的旋转方向，滑动的话是直线运动方向<br>2.编号n-1,n,n+1….<br>3.找z轴公垂线，连起来<br>4.考虑变换  <script type="math/tex">x_n-z_n -> x_{n+1}-z_{n+1}</script><br>4.1 让x姿势一致：绕$z_n$旋转$\theta_{n+1}$<br>4.2 让z重叠: 沿$z_n$平移$d_{n+1}$<br>4.3 让x重叠: 沿x轴移动$a_{n+1}$<br>4.4 让z对准: 绕$x_{n+1}$旋转$\alpha_{n+1}$</p>
<script type="math/tex; mode=display">^nT_{n+1}=A_{n+1}=Rot(z,\theta_{n+1})Trans(0,0,d_{n+1})Trans(a_{n+1},0,0)Rot(x,\alpha_{n+1})</script><p>有多少个关节就有多少个A乘起来<br>为了简化计算<br>画参数表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">#</th>
<th style="text-align:right">$\theta$</th>
<th style="text-align:center">d</th>
<th>a</th>
<th>$\alpha$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">0-1</td>
<td style="text-align:right"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">1-2</td>
<td style="text-align:right"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">2-3</td>
<td style="text-align:right"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="逆运动学解"><a href="#逆运动学解" class="headerlink" title="逆运动学解"></a>逆运动学解</h4><p>一般解：</p>
<script type="math/tex; mode=display">^RT_H=A_1A_2...A_6=[RHS]</script><p>左乘一个逆。 解方程</p>
<h3 id="微分运动和速度"><a href="#微分运动和速度" class="headerlink" title="微分运动和速度"></a>微分运动和速度</h3><script type="math/tex; mode=display">
 \left[
 \begin{matrix}
   \delta_{Y_1}\\
   \delta_{Y_2}\\
   .\\
   \delta_{Y_n} 
  \end{matrix}
  \right]=[ 雅可比矩阵][关节微分运动]</script><p>也就是</p>
<script type="math/tex; mode=display">[D]=[J][D_\theta]</script><p>两边/dt就是速度微分关系(运动微分方程-&gt;速度微分方程)</p>
<h4 id="微分平移"><a href="#微分平移" class="headerlink" title="微分平移"></a>微分平移</h4><p>一样，位姿矩阵B左乘个平移矩阵就行</p>
<h4 id="微分旋转"><a href="#微分旋转" class="headerlink" title="微分旋转"></a>微分旋转</h4><p>利用以下等式替代</p>
<script type="math/tex; mode=display">sin \delta x=\delta x\\cos \delta x=1</script><p>然后也是左乘旋转矩阵<br><strong>在微分旋转中，由于微分量很小，可以认为相乘的顺序不重要</strong></p>
<h4 id="绕轴q的微分旋转"><a href="#绕轴q的微分旋转" class="headerlink" title="绕轴q的微分旋转"></a>绕轴q的微分旋转</h4><p>可看作是绕3个轴的微分旋转而成</p>
<script type="math/tex; mode=display">(d\theta)q=(\delta x)i+(\delta y)j+(\delta z)k</script><p>于是</p>
<script type="math/tex; mode=display">Rot(q,d\theta)=Rot(x,\delta x)Rot(y,\delta y)Rot(z,\delta z)</script><p><strong>结果中可以忽略高阶微分（也就是多个微分量相乘的项）</strong></p>
<h4 id="坐标系的微分"><a href="#坐标系的微分" class="headerlink" title="坐标系的微分"></a>坐标系的微分</h4><script type="math/tex; mode=display">[T+dT]=[Trans(dx,dy,dz)Rot(q,d\theta)][T]\\ [dT]=[Trans(dx,dy,dz)Rot(q,\theta)-I][T]\\ [dT]=[\Delta][T]</script><p>$\Delta$也叫微分算子</p>
<h4 id="坐标系间的微分变化"><a href="#坐标系间的微分变化" class="headerlink" title="坐标系间的微分变化"></a>坐标系间的微分变化</h4><script type="math/tex; mode=display">[dT]=[\Delta][T]=[T][^T\Delta]\\ ->[T^{-1}][\Delta][T]=[T^{-1}][T][^T\Delta]\\ [^T\Delta]=[T^{-1}][\Delta][T]</script><p>$^T\Delta$是相对于当前坐标系的微分算子，$Delta$是相对于固定参考坐标系的<br>有$$<br>T= \left[<br> \begin{matrix}<br>   n_x&amp; o_x&amp; a_x&amp; p_x\\<br>   n_y &amp; o_y &amp; o_y  &amp; p_y\\<br>   n_z &amp; o_z &amp; a_Z  &amp; p_z\\<br>   0 &amp; 0 &amp; 0 &amp; 1<br>  \end{matrix}<br>  \right] \tag{3}</p>
<script type="math/tex; mode=display">
和</script><p>\Delta= \left[<br> \begin{matrix}<br>   0&amp; -\delta z&amp; \delta y&amp; dx\\<br>   \delta z &amp; 0 &amp; -\delta x  &amp; dy\\<br>   -\delta y &amp; \delta x &amp; 0  &amp; dz\\<br>   0 &amp; 0 &amp; 0 &amp; 0<br>  \end{matrix}<br>  \right] \tag{3}</p>
<script type="math/tex; mode=display">

#####雅克比矩阵计算
每行是对应一个参数的运动学方程  $dp_i=[vartheta]$

$[dT_i]=[\Delta][T_i]$

#####雅克比求逆
$$[D_\theta]=[J^{-1}][D]</script><h3 id="动力学分析和力"><a href="#动力学分析和力" class="headerlink" title="动力学分析和力"></a>动力学分析和力</h3><h4 id="拉格朗日力学"><a href="#拉格朗日力学" class="headerlink" title="拉格朗日力学"></a>拉格朗日力学</h4><script type="math/tex; mode=display">L=K-P\\T_i=\frac{\vartheta}{\vartheta {t}}(\frac{\vartheta L}{\vartheta \dot{\theta_i}})-\frac{\vartheta L}{\vartheta \theta_i}\\F_i=\frac{\vartheta}{\vartheta {t}}(\frac{\vartheta L}{\vartheta \dot{x_i}})-\frac{\vartheta L}{\vartheta x_i}</script><h2 id="轨迹规划"><a href="#轨迹规划" class="headerlink" title="轨迹规划"></a>轨迹规划</h2><blockquote>
<p>前面研究如何从关节变量推断出机器人的位置（运动学），或者已知位姿推断出关节变量（逆运动学）</p>
</blockquote>
<h3 id="一次多项式规划"><a href="#一次多项式规划" class="headerlink" title="一次多项式规划"></a>一次多项式规划</h3><p>相当于匀速前进，速度为常数，加速度为0</p>
<h3 id="三次多项式规划"><a href="#三次多项式规划" class="headerlink" title="三次多项式规划"></a>三次多项式规划</h3><script type="math/tex; mode=display">\theta(t)=c_0+c_1t+c_2t^2+c_3t^3</script><p>条件:$\theta(t_i)=\theta_i,\theta(t_f)=\theta_f,\dot{\theta}(t_i)=0,\dot{\theta}(t_f)=0$<br>求导，代入条件即可<br>三次多项式能规划 起始时间和速度 但是不能规划加速度</p>
<h3 id="五次多项式规划"><a href="#五次多项式规划" class="headerlink" title="五次多项式规划"></a>五次多项式规划</h3><p>加上了及速度<br>求导2次来解</p>
<h3 id="抛物线过渡性线段"><a href="#抛物线过渡性线段" class="headerlink" title="抛物线过渡性线段"></a>抛物线过渡性线段</h3><p>过渡时间$t_b=\frac{\theta_i-\theta_f+\omega t_f}{\omega}$</p>
<p>拉普拉斯变换、反变换<br><strong>将时域转为拉普拉斯域</strong></p>
<script type="math/tex; mode=display">\Im[f(t)]=F(s)=\int_0^\infty f(t)e^{-st}dt</script><script type="math/tex; mode=display">f^n(t)=>s^nF(s)-s^{n-1}f(0)-s^{n-2}f(0)-...-f^{n-1}(0)</script><p>结构图化简：<br><img src="./1561721544726.png" alt="Alt text"><br>控制论<br><img src="./1561856947610.png" alt="Alt text"></p>
<ul>
<li>开环传递函数<script type="math/tex; mode=display">OLTF=G(s)H(s) \tag{返回回路断开时反馈信号和误差信号之比}</script></li>
<li>前馈传递函数<script type="math/tex; mode=display">G(s)</script></li>
<li>闭环传递函数:输出与输入之比<script type="math/tex; mode=display">CLTF=\frac{Y(s)}{R(s)}=\frac{G(s)}{1+G(s)H(s)}</script><h3 id="PID"><a href="#PID" class="headerlink" title="PID"></a>PID</h3></li>
</ul>
<p>控制算法有<br><strong>PID</strong>，<strong>模糊控制</strong>，<strong>神经网络控制</strong>，<strong>遗传算法</strong>……</p>
<p><img src="./1561868534849.png" alt="Alt text"><br><strong>e(t)是偏差信号 , r(t)为设定值，y(t)为被调量测量值.输入为偏差信号e(t)=r(t)-y(t)</strong><br>输出为偏差信号的<strong>比例、积分、微分</strong>的线性组合</p>
<script type="math/tex; mode=display">u(t)=K_p[e(t)+\frac{1}{T_I}\int_0^te(t)dt+T_D\frac{de(t)}{dt}] \tag{PID控制律}</script><blockquote>
<p>传递函数是指零初始条件下线性系统响应（即输出）量的拉普拉斯变换（或z变换）与激励（即输入）量的拉普拉斯变换之比。记作G（s）=Y（s）/U（s），其中Y（s）、U（s)分别为输出量和输入量的拉普拉斯变换。</p>
</blockquote>
<p>传递函数$G(s)=K_p+\frac{K_I}{s}+K_Ds$<br>推导:<br><img src="./1561869853209.png" alt="Alt text"><br><img src="./1561869943163.png" alt="Alt text"><br><img src="./1561870004577.png" alt="Alt text"></p>
<h4 id="比例控制器"><a href="#比例控制器" class="headerlink" title="比例控制器"></a>比例控制器</h4><p>$u(t)=K_pe(t)+u_0$<br>K_p为比例系数 u_0为控制量初值<br>比例控制器<strong>对于偏差是及时反应的</strong>，存在跃阶</p>
<h4 id="比例积分"><a href="#比例积分" class="headerlink" title="比例积分"></a>比例积分</h4><p>为了消除比例控制存在的静差<br>$u(t)=K_p[e(t)+\frac{1}{T_I\int_0^te(t)dt}]+u_0$<br>偏差存在积分就会起作用知道偏差为0<br><strong>降低了系统速度</strong></p>
<h4 id="PID-1"><a href="#PID-1" class="headerlink" title="PID"></a>PID</h4><p>加入微分。对偏差的任何变化都会起作用，以调整系统的输出。可以克服震荡，减少超调量。</p>
<h4 id="串级PID"><a href="#串级PID" class="headerlink" title="串级PID"></a>串级PID</h4><p>先计算主回路(PID1),然后副回路(PID2,响应速度快)</p>
<p><img src="./1561870896958.png" alt="Alt text"><br>内回路为速度反馈。外回路为角度反馈</p>
]]></content>
  </entry>
  <entry>
    <title>【OS】オペレーティングシステム復習</title>
    <url>/2019/12/26/%E3%80%90OS%E3%80%91%E3%82%AA%E3%83%9A%E3%83%AC%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E5%BE%A9%E7%BF%92/</url>
    <content><![CDATA[<h1 id="【OS】オペレーティングシステム復習"><a href="#【OS】オペレーティングシステム復習" class="headerlink" title="【OS】オペレーティングシステム復習"></a>【OS】オペレーティングシステム復習</h1><h2 id="序論"><a href="#序論" class="headerlink" title="序論"></a>序論</h2><p><strong>オペレーティングシステムの目的:</strong></p>
<blockquote>
<p>Provide a environment in which a user can execute programs in a convenient and efficient manner<br>i.e ユーザー操作を易いになる</p>
</blockquote>
<h3 id="オペレーティングシステムって、何をする？"><a href="#オペレーティングシステムって、何をする？" class="headerlink" title="オペレーティングシステムって、何をする？"></a>オペレーティングシステムって、何をする？</h3><p><strong>オペレーティングシステムは３つのコンポーネントを分けられます</strong></p>
<ul>
<li>hardware<br>CPU, I/O devices, memory </li>
<li>operating system</li>
<li>application software</li>
<li>user</li>
</ul>
<h4 id="ユーザービュー-User-view"><a href="#ユーザービュー-User-view" class="headerlink" title="ユーザービュー(User view)"></a>ユーザービュー(User view)</h4><p><strong>OS is designed mostly for ‘EASE OF USE’</strong></p>
<h4 id="システムビュー-System-View"><a href="#システムビュー-System-View" class="headerlink" title="システムビュー(System View)"></a>システムビュー(System View)</h4><p><strong>resource allocator</strong></p>
<h4 id="オペレーティングシステム定義"><a href="#オペレーティングシステム定義" class="headerlink" title="オペレーティングシステム定義"></a>オペレーティングシステム定義</h4><p>A program running at all time on the computer(<strong>kernel</strong>)</p>
<h3 id="オペレーティングシステム組織"><a href="#オペレーティングシステム組織" class="headerlink" title="オペレーティングシステム組織"></a>オペレーティングシステム組織</h3><h4 id="BOOT-Process"><a href="#BOOT-Process" class="headerlink" title="BOOT Process"></a>BOOT Process</h4><ul>
<li><strong>BIOS</strong><br>开启电源后BIOS自检，然后按BIOS设定的boot设备顺序，将控制权交给最前设备</li>
<li><strong>MBR(Master Boot Record)</strong><br>read first 512B(Tell computer to go where to find the OS)</li>
<li><strong>Boot from Disk</strong><br>read <strong>VBR(Volume Boot record)</strong></li>
<li><strong>Operating System</strong></li>
</ul>
<h4 id="System-call-Monitor-call"><a href="#System-call-Monitor-call" class="headerlink" title="System call/Monitor call"></a>System call/Monitor call</h4><blockquote>
<p><strong>bootstrap program:</strong><br>In ROM(<strong>firmware</strong>), init CPU <strong>register,device controller,memory content</strong></p>
</blockquote>
<p>Every device has a device controller<br><strong>DMA:</strong><br>设置好 <strong>缓冲，指针，计数器</strong>后，device controller能够直接在本地缓冲和内存间传递一整块，只用一次中断。</p>
<h2 id="Keyword"><a href="#Keyword" class="headerlink" title="Keyword"></a>Keyword</h2><p><strong>Kernel</strong><br><strong>DMA</strong><br><strong>Interrupt</strong><br><strong>job scheduling</strong><br><strong>API</strong><br><strong>microkernel</strong><br><strong>message-passing modal</strong><br><strong>shared-memory modal</strong><br><strong>Preemptive</strong><br><strong>dispatcher</strong><br><strong>PCB</strong><br><strong>peterson锁</strong><br><strong>自旋锁</strong><br><strong>读者、写者问题   </strong><br><strong>SPOOLING 技术</strong><br><strong>Belady 异象</strong><br>第23行Application.LoadLevel(&amp;quot;Scene_2&amp;quot;);//切换到场景Scene_2 在vs2015里面已经过时了。要修改一下，改为SceneManager.LoadScene(&amp;quot;Scene_2&amp;quot;);//切换到场景Scene_2; 引用也要增加。第3行后面加入using UnityEngine.SceneManagement;</p>
]]></content>
  </entry>
  <entry>
    <title>【OS】FCFS,SJF,SRT</title>
    <url>/2019/12/26/%E3%80%90OS%E3%80%91FCFS,SJF,SRT/</url>
    <content><![CDATA[<h1 id="【OS】FCFS-SJF-SRT"><a href="#【OS】FCFS-SJF-SRT" class="headerlink" title="【OS】FCFS,SJF,SRT"></a>【OS】FCFS,SJF,SRT</h1><blockquote>
<p>班级:软1708<br>姓名:黄万鸿<br>学号:201792015<br>算法选择:FCFS,SJF,SRT</p>
</blockquote>
<p>[TOC]</p>
<h2 id="运行结果展示"><a href="#运行结果展示" class="headerlink" title="运行结果展示"></a>运行结果展示</h2><blockquote>
<p>程序内部，使用时钟进行每次时间+1的模拟，为了简化输出，只输出重要的时间点（非每个单位时间都输出）</p>
<h3 id="第一部分-FCFS"><a href="#第一部分-FCFS" class="headerlink" title="第一部分:FCFS"></a>第一部分:FCFS</h3><p><strong>执行过程:  </strong><br><img src="./1555325687931.png" alt="Alt text"><br><strong>结果评估:</strong><br><img src="./1555325789639.png" alt="Alt text"></p>
</blockquote>
<h3 id="第二部分-SJF"><a href="#第二部分-SJF" class="headerlink" title="第二部分:SJF"></a>第二部分:SJF</h3><p><strong>执行过程:  </strong><br><img src="./1555325907676.png" alt="Alt text"></p>
<p><strong>结果评估:</strong><br><img src="./1555325924090.png" alt="Alt text"></p>
<h3 id="第三部分-SRT"><a href="#第三部分-SRT" class="headerlink" title="第三部分:SRT"></a>第三部分:SRT</h3><p><strong>执行过程:  </strong><br><img src="./1555325948952.png" alt="Alt text"><br><img src="./1555325955663.png" alt="Alt text"><br><img src="./1555325962121.png" alt="Alt text"><br><img src="./1555325969070.png" alt="Alt text"><br><img src="./1555325974499.png" alt="Alt text"><br><img src="./1555325980008.png" alt="Alt text"></p>
<p><strong>结果评估:</strong><br><img src="./1555325998346.png" alt="Alt text"></p>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><h3 id="1-主函数"><a href="#1-主函数" class="headerlink" title="1.主函数"></a>1.主函数</h3><pre><code class="lang-java">static void Main(string[] args)
        {

            //从命令行获取数据
            List&lt;sim_process&gt; sps = getTask_FromCom();
            List&lt;sim_process&gt; sps_c1 = new List&lt;sim_process&gt;();
            List&lt;sim_process&gt; sps_c2 = new List&lt;sim_process&gt;();


            sps.ForEach((item) =&gt; sps_c1.Add(new sim_process(item.need_T, item.taskname, item.arriveT)));
            sps.ForEach((item) =&gt; sps_c2.Add(new sim_process(item.need_T, item.taskname, item.arriveT)));
            sceduler sc = new sceduler();


            //创建模拟进程
            foreach(sim_process spi in sps)
            {
                sc.insertprocess(spi);
            }

            sc.FCFS();
            sc.cleanqueue();


            foreach (sim_process spi in sps_c1)
            {
                sc.insertprocess(spi);
            }
            sc.SJF();
            sc.cleanqueue();


            foreach (sim_process spi in sps_c2)
            {
                sc.insertprocess(spi);
            }
            sc.SRT();



            Console.ReadLine();
        }
</code></pre>
<h2 id="获取数据的函数"><a href="#获取数据的函数" class="headerlink" title="获取数据的函数"></a>获取数据的函数</h2><pre><code class="lang-cpp">static List&lt;sim_process&gt; getTask_FromCom()
        {
            List&lt;sim_process&gt; sps = new List&lt;sim_process&gt;();
            Console.WriteLine(&quot;请按 进程号 到达时间 要求执行时间 的格式输入(输入-1结束):&quot;);
            while (true)
            {
                int[] c=new int[3];
                string input = Console.ReadLine();
                string[] ss = input.Split(&#39; &#39;);
                for(int i = 0;i&lt;ss.Length;i++)
                {
                    if (Int32.Parse(ss[i]) == -1) return sps;
                    c[i] = Int32.Parse(ss[i]);
                }
                sps.Add(new sim_process(c[2], c[0].ToString(), c[1]));
            }
            return sps;
        }
</code></pre>
<h3 id="模拟作业类"><a href="#模拟作业类" class="headerlink" title="模拟作业类"></a>模拟作业类</h3><pre><code class="lang-cpp">    class sim_process
    {
        static Random r = new Random();
        public int pid;
        public string taskname;
        public int need_T; //任务所需时间
        public int arriveT = 0;
        public int waitT = 0;
        public int endT = 0;
        public int startT = 0;
        public sim_process(int T,string name,int arrt=0)  //提供所需时间，名字，到达时间（默认为0）
        {
            need_T = T;
            taskname = name;
            arriveT = arrt;
            pid = r.Next(0,10000) ;  //随机获取一个虚拟PID
        }
    }
</code></pre>
<h3 id="调度器类"><a href="#调度器类" class="headerlink" title="调度器类"></a>调度器类</h3><pre><code class="lang-cpp">class sceduler
    {
        List&lt;sim_process&gt; queue = new List&lt;sim_process&gt;(); //任务列表
        int curT = 0;
        public void cleanqueue()   //清空任务列表
        {
            queue = new List&lt;sim_process&gt;();
        }

        public void initTimer()  
        {
            curT = 0;
        }

        public void insertprocess(sim_process sp)   //加入一个任务到任务列表
        {
            queue.Add(sp);
        }

      //先来先服务
        public void FCFS()
        {
            foreach (sim_process sp in queue)
            {
                Console.WriteLine(&quot;作业&quot; + sp.taskname + &quot;(区间时间=&quot; + sp.need_T.ToString() + &quot;) 加入任务列表，等待调度  simulate pid=&quot; + sp.pid.ToString());
            }



            Console.WriteLine(&quot;----------------------Sceduling Start(FCFS)------------------------&quot;);
            List&lt;sim_process&gt; curQueue = new List&lt;sim_process&gt;();  //调度列表
            List&lt;sim_process&gt; exesx = new List&lt;sim_process&gt;();  //一个list保存执行顺序
            int curRUN = -1;  //当前执行的任务标志（代表当前执行调度列表中的哪任务）
            int i = queue.Count; //记录需要执行的进程数
            int curT = 0;
            //开始执行调度
            while (true)
            {
                //检测是否有进程进入
                foreach (sim_process s in queue)
                {
                    if (s.arriveT == curT)
                    {
                        curQueue.Add(s);
                        Console.WriteLine(&quot;In &quot; + curT.ToString() + &quot; Task:&quot; + s.taskname + &quot; arrived&quot;);
                    }
                }

                //调度为空，那就不管，时间+1后继续
                if (curQueue.Count == 0) { curT++; continue; }


                //是否空闲，空闲则调度一个
                if (curRUN == -1)
                {
                    curRUN = 0;

                    //修改信息，循环是为了找到当前正在执行的任务在任务列表中的位置
                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (queue[k].pid == curQueue[0].pid)
                        {
                            queue[k].startT = curT;
                            exesx.Add(queue[k]);   
                        }
                    }


                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; start&quot;);
                }

                //非空闲，看是否结束
                else
                {
                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (queue[k].pid == curQueue[0].pid)
                        {
                            //Console.WriteLine(queue[k].startT.ToString() +&quot;,&quot;+ queue[k].need_T.ToString());
                            if (queue[k].startT + queue[k].need_T == curT)//一个任务的结束条件
                            {
                                Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; End&quot;);
                                curRUN = -1;
                                i--;
                                curQueue.RemoveAt(0);
                                queue[k].endT = curT;
                                //检查看是否需要开启新进程
                                if (curQueue.Count != 0)
                                {
                                    curRUN = 0;
                                    int j = 0;
                                    for (; j &lt; queue.Count; j++)
                                    {
                                        if (queue[j].pid == curQueue[curRUN].pid)
                                        {
                                            queue[j].startT = curT;
                                            //queue[j].waitT++;
                                            exesx.Add(queue[j]);
                                            break;
                                        }

                                    }
                                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + queue[j].taskname + &quot; start&quot;);


                                }
                            }
                        }
                    }


                }


                /*foreach (sim_process s in queue)
                {
                    Console.WriteLine(&quot;t=&quot; + curT.ToString() + &quot; 调度作业:&quot; + s.taskname);
                    s.waitT = curT;
                    curT += s.need_T;
                    s.endT = curT;
                }*/
                for (int k = 1; k &lt; curQueue.Count; k++)
                {
                    for (int l = 0; l &lt; queue.Count; l++)
                    {
                        if (queue[l].pid == curQueue[k].pid)
                        {
                            queue[l].waitT++;
                        }
                    }
                }
                if (i &lt;= 0) break;
                curT++;
            }




            Console.WriteLine(&quot;t=&quot; + curT.ToString() + &quot; 调度结束&quot;);
            Console.WriteLine(&quot;----------------------Sceduling End(FCFS)------------------------&quot;);
//开始评估
            Console.WriteLine(&quot;----------------------Evaluation(FCFS)------------------------&quot;);
            int avgwait = 0;
            double avgdc = 0;
            double avgzz = 0;
            foreach (sim_process s in queue)
            {
                avgzz += (s.endT - s.arriveT);
                avgwait += s.waitT;
                Console.WriteLine(&quot;Task:&quot; + s.taskname + &quot; arrive at:&quot; + s.arriveT.ToString() + &quot; end at:&quot; + s.endT.ToString() + &quot; Wait Time:&quot; + s.waitT.ToString() + &quot; 周转时间:&quot; + (s.endT - s.arriveT).ToString() + &quot; 带权周转时间:&quot; + ((s.endT - s.arriveT) / (double)s.need_T).ToString());
                avgdc += ((s.endT - s.arriveT) / (double)s.need_T);
            }
            Console.WriteLine(&quot;Average Wait:&quot; + (avgwait / queue.Count).ToString());
            Console.WriteLine(&quot;平均周转:&quot; + (avgzz / queue.Count).ToString());
            Console.WriteLine(&quot;平均带权周转:&quot; + (avgdc / queue.Count).ToString());
            foreach (sim_process sr in exesx)
            {
                Console.Write(sr.taskname + &quot;-&gt;&quot;);
            }
            Console.Write(&quot;\n\n\n\n&quot;);
            cleanqueue();
        }




        public void SJF()
        {
            foreach (sim_process sp in queue)
            {
                Console.WriteLine(&quot;作业&quot; + sp.taskname + &quot;(区间时间=&quot; + sp.need_T.ToString() + &quot;) 加入队列  simulate pid=&quot; + sp.pid.ToString());
            }



            Console.WriteLine(&quot;----------------------Sceduling Start(SJF)------------------------&quot;);
            List&lt;sim_process&gt; curQueue = new List&lt;sim_process&gt;();
            List&lt;sim_process&gt; exesx = new List&lt;sim_process&gt;();
            int curRUN = -1;
            int i = queue.Count; //记录需要执行的进程数
            int curT = 0;



            //开始执行调度
            while (true)
            {
                //检测是否有任务进入，若有的话，加入调度队列


                foreach (sim_process s in queue)
                {
                    if (s.arriveT == curT)
                    {
                        curQueue.Add(s);
                        Console.WriteLine(&quot;In &quot; + curT.ToString() + &quot; Task:&quot; + s.taskname + &quot; arrived&quot;);
                    }
                }

                if (curQueue.Count == 0) { curT++; continue; }  //如果调度队列为空，不管

                //是否空闲，空闲则调度一个
                if (curRUN == -1)
                {



                    curRUN = 0;

                    //寻找最短作业
                    for (int m = 0; m &lt; curQueue.Count; m++)
                    {
                        if (curQueue[m].need_T &lt; curQueue[curRUN].need_T) { curRUN = m; }
                    }

                    //修改原进程信息
                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (queue[k].pid == curQueue[curRUN].pid)
                        {
                            queue[k].startT = curT;
                            exesx.Add(queue[k]);
                        }
                    }


                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; start&quot;);
                }



                //非空闲，看是否结束
                else
                {
                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (curRUN == -1) break;
                        if (queue[k].pid == curQueue[curRUN].pid)
                        {
                            //Console.WriteLine(queue[k].startT.ToString() +&quot;,&quot;+ queue[k].need_T.ToString());
                            if (queue[k].startT + queue[k].need_T == curT)
                            {
                                Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; End&quot;);
                                curQueue.RemoveAt(curRUN);
                                curRUN = -1;
                                i--;

                                queue[k].endT = curT;
                                //检查看是否需要开启新进程
                                if (curQueue.Count != 0)
                                {
                                    curRUN = 0;

                                    //寻找最短作业
                                    for (int m = 0; m &lt; curQueue.Count; m++)
                                    {
                                        if (curQueue[m].need_T &lt; curQueue[curRUN].need_T) { curRUN = m; }
                                    }


                                    int j = 0;
                                    for (; j &lt; queue.Count; j++)
                                    {
                                        if (queue[j].pid == curQueue[curRUN].pid)
                                        {
                                            queue[j].startT = curT;
                                            //queue[j].waitT++;
                                            exesx.Add(queue[j]);
                                            break;
                                        }

                                    }
                                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + queue[j].taskname + &quot; start&quot;);


                                }
                            }
                        }
                    }


                }


                /*foreach (sim_process s in queue)
                {
                    Console.WriteLine(&quot;t=&quot; + curT.ToString() + &quot; 调度作业:&quot; + s.taskname);
                    s.waitT = curT;
                    curT += s.need_T;
                    s.endT = curT;
                }*/
                for (int k = 0; k &lt; curQueue.Count; k++)
                {
                    if (k == curRUN) continue;
                    for (int l = 0; l &lt; queue.Count; l++)
                    {
                        if (queue[l].pid == curQueue[k].pid)
                        {
                            queue[l].waitT++;
                        }
                    }
                }
                if (i &lt;= 0) break;
                curT++;
            }




            Console.WriteLine(&quot;t=&quot; + curT.ToString() + &quot; 调度结束&quot;);
            Console.WriteLine(&quot;----------------------Sceduling End(SJF)------------------------&quot;);
            Console.WriteLine(&quot;----------------------Evaluation(SJF)------------------------&quot;);
            int avgwait = 0;
            double avgdc = 0;
            double avgzz = 0;
            foreach (sim_process s in queue)
            {
                avgzz += (s.endT - s.arriveT);
                avgwait += s.waitT;
                Console.WriteLine(&quot;Task:&quot; + s.taskname + &quot; arrive at:&quot; + s.arriveT.ToString() + &quot; end at:&quot; + s.endT.ToString() + &quot; Wait Time:&quot; + s.waitT.ToString() + &quot; 周转时间:&quot; + (s.endT - s.arriveT).ToString() + &quot; 带权周转时间:&quot; + ((s.endT - s.arriveT) / (double)s.need_T).ToString());
                avgdc += ((s.endT - s.arriveT) / (double)s.need_T);
            }
            Console.WriteLine(&quot;Average Wait:&quot; + (avgwait / queue.Count).ToString());
            Console.WriteLine(&quot;平均周转:&quot; + (avgzz / queue.Count).ToString());
            Console.WriteLine(&quot;平均带权周转:&quot; + (avgdc / queue.Count).ToString());

            foreach (sim_process sr in exesx)
            {
                Console.Write(sr.taskname + &quot;-&gt;&quot;);
            }
            Console.Write(&quot;\n\n&quot;);
            cleanqueue();
        }

        public void SRT()
        {
            foreach (sim_process sp in queue)
            {
                Console.WriteLine(&quot;作业&quot; + sp.taskname + &quot;(区间时间=&quot; + sp.need_T.ToString() + &quot;) 加入队列  simulate pid=&quot; + sp.pid.ToString());
            }



            Console.WriteLine(&quot;----------------------Sceduling Start(SRT)------------------------&quot;);
            List&lt;sim_process&gt; curQueue = new List&lt;sim_process&gt;();
            List&lt;sim_process&gt; exesx = new List&lt;sim_process&gt;();
            List&lt;sim_process&gt; queue2 = new List&lt;sim_process&gt;();
            queue.ForEach((item) =&gt; queue2.Add(new sim_process(item.need_T,item.taskname,item.arriveT)));
            bool[] ifstart = new bool[queue.Count];
            for (int x = 0; x &lt; ifstart.Length; x++)
            {
                ifstart[x] = false;
            }
            int curRUN = -1;
            int i = queue.Count; //记录需要执行的进程数
            int curT = 0;



            //开始执行调度
            while (true)
            {
                //检测是否有任务进入，若有的话，加入调度队列

                //Console.WriteLine(&quot;In T=&quot; + curT.ToString());
                foreach (sim_process s in queue)
                {
                    if (s.arriveT == curT)
                    {
                        curQueue.Add(s);
                        Console.WriteLine(&quot;In &quot; + curT.ToString() + &quot; Task:&quot; + s.taskname + &quot; arrived&quot;);

                    }
                }

                if (curQueue.Count == 0) { curT++; continue; }  //如果调度队列为空，不管






                //是否空闲，空闲则调度一个
                if (curRUN == -1)
                {
                    curRUN = 0;

                    //寻找最短作业
                    for (int m = 0; m &lt; curQueue.Count; m++)
                    {
                        if (curQueue[m].need_T &lt; curQueue[curRUN].need_T) { curRUN = m; }
                    }

                    //修改原进程信息
                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (queue[k].pid == curQueue[curRUN].pid)
                        {
                            if (!ifstart[k])
                            {
                                queue[k].startT = curT;
                                ifstart[k] = true;
                            }
                            exesx.Add(queue[k]);
                        }
                    }


                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; start&quot;);
                }



                //非空闲，看是否结束/抢占
                else
                {



                    for (int k = 0; k &lt; queue.Count; k++)
                    {
                        if (curRUN == -1) break;
                        if (queue[k].pid == curQueue[curRUN].pid)
                        {
                            //Console.WriteLine(queue[k].startT.ToString() +&quot;,&quot;+ queue[k].need_T.ToString());
                            if (curQueue[curRUN].need_T &lt;= 0)
                            {
                                Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + curQueue[curRUN].taskname + &quot; End&quot;);
                                curQueue.RemoveAt(curRUN);
                                curRUN = -1;
                                i--;

                                queue[k].endT = curT;
                                //检查看是否需要开启新进程
                                if (curQueue.Count != 0)
                                {
                                    curRUN = 0;




                                    //寻找最短作业
                                    for (int m = 0; m &lt; curQueue.Count; m++)
                                    {
                                        if (curQueue[m].need_T &lt; curQueue[curRUN].need_T) { curRUN = m; }
                                    }
                                    Console.WriteLine(curRUN+curQueue[curRUN].taskname);

                                    int j = 0;
                                    for (; j &lt; queue.Count; j++)
                                    {
                                        if (queue[j].pid == curQueue[curRUN].pid)
                                        {
                                            if (!ifstart[j])
                                            {
                                                queue[j].startT = curT;
                                                ifstart[j] = true;
                                            }
                                            //queue[j].waitT++;
                                            exesx.Add(queue[j]);
                                            break;
                                        }

                                    }
                                    Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + queue[j].taskname + &quot; start&quot;);


                                }
                            }
                            else
                            {
                                int min = curRUN;
                                //寻找最短作业
                                for (int m = 0; m &lt; curQueue.Count; m++)
                                {
                                    if (curQueue[m].need_T &lt; curQueue[curRUN].need_T) { min = m; }
                                }

                                Console.WriteLine(&quot;T=&quot;+curT.ToString()+&quot; 最短作业为:&quot; + curQueue[min].taskname);

                                if (!(min == curRUN))
                                {
                                    curRUN = min;
                                    //修改原进程信息
                                    for (int k2 = 0; k2 &lt; queue.Count; k2++)
                                    {
                                        if (queue[k2].pid == curQueue[min].pid)
                                        {
                                            if (!ifstart[k2])
                                            {
                                                queue[k2].startT = curT;
                                                ifstart[k2] = true;
                                            }
                                            Console.WriteLine(&quot;In T=&quot; + curT.ToString() + &quot; Task:&quot; + queue[k2].taskname + &quot; start&quot;);
                                            exesx.Add(queue[k2]);
                                        }
                                    }

                                }
                            }
                        }


                    }


                    for (int k = 0; k &lt; curQueue.Count; k++)
                    {
                        if (k == curRUN) continue;
                        for (int l = 0; l &lt; queue.Count; l++)
                        {
                            if (queue[l].pid == curQueue[k].pid)
                            {
                                queue[l].waitT++;
                            }
                        }
                    }
                    if (i &lt;= 0) break;
                }
                curT++;

                    if (curRUN != -1)
                    {
                        curQueue[curRUN].need_T--;
                    }

            }




                Console.WriteLine(&quot;t=&quot; + curT.ToString() + &quot; 调度结束&quot;);
                Console.WriteLine(&quot;----------------------Sceduling End(SRT)------------------------&quot;);
                Console.WriteLine(&quot;----------------------Evaluation(SRT)------------------------&quot;);
                int avgwait = 0;
                double avgdc = 0;
                double avgzz = 0;
                for (int i2=0;i2&lt;queue.Count;i2++)
                {
                    sim_process s = queue[i2];
                    avgzz += (s.endT - s.arriveT);
                    avgwait += s.waitT;
                    Console.WriteLine(queue2[i2].need_T);
                    Console.WriteLine(&quot;Task:&quot; + s.taskname + &quot; arrive at:&quot; + s.arriveT.ToString() + &quot; end at:&quot; + s.endT.ToString() + &quot; Wait Time:&quot; + s.waitT.ToString() + &quot; 周转时间:&quot; + (s.endT - s.arriveT).ToString() + &quot; 带权周转时间:&quot; + ((s.endT - s.arriveT) / (double)queue2[i2].need_T).ToString());
                    avgdc += ((s.endT - s.arriveT) / (double)queue2[i2].need_T);
                }
                Console.WriteLine(&quot;Average Wait:&quot; + (avgwait / queue.Count).ToString());
                Console.WriteLine(&quot;平均周转:&quot; + (avgzz / queue.Count).ToString());
                Console.WriteLine(&quot;平均带权周转:&quot; + (avgdc / queue.Count).ToString());

                foreach (sim_process sr in exesx)
                {
                    Console.Write(sr.taskname + &quot;-&gt;&quot;);
                }
                Console.Write(&quot;\n\n&quot;);
                cleanqueue();
            }

        }
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>【NLP】Skip-gram</title>
    <url>/2019/12/26/%E3%80%90NLP%E3%80%91Skip-gram/</url>
    <content><![CDATA[<h2 id="【NLP】Skip-gram"><a href="#【NLP】Skip-gram" class="headerlink" title="【NLP】Skip-gram"></a>【NLP】Skip-gram</h2><p><img src="./1557413185378.png" alt="Alt text"><br>上图的Skip-gram的结构图<br>我们的目标是利用最左边的输入词向量(图里为shape=(10000<em>1))来训练隐藏层<br>隐藏层的结果是shape=(10000</em>300)的矩阵。也就是<strong>词向量</strong><br>于是$W_1$是大小为$(1,300)$的矩阵<br>如果我们一次输入多个词向量那就是<br>输入$(10000,n)大小,W_1’s\quad size=(n,300)$<br>中间层是线性的。不用激活函数，<br>于是经过$W_2$（也是词向量）到输出层得到结果。输出层结果为(10000,1)的大小。经过softmax后就得到分类概率<br><img src="./1557553740748.png" alt="Alt text"></p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>假设输入的word pair为$（ants, able）$，则模型拟合的目标是 $Max P(able|ants)$ ,同时也需要满足 $Min P (other words 丨ants) $，这里利用的是对数似然函数作为目标函数。上述表述中$ P（able 丨ants）$ 可表示为：<br><img src="./1557413876972.png" alt="Alt text"></p>
<p>根据$ P（able丨ants）$ 和 $P(other words丨ants) $，可构建似然函数:<br><img src="./1557413910113.png" alt="Alt text"><br>对数化<br><img src="./1557413924777.png" alt="Alt text"><br><img src="./1557413998958.png" alt="Alt text"><br><img src="./1557414005212.png" alt="Alt text"></p>
<h2 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h2><h3 id="负采样-negative-sample"><a href="#负采样-negative-sample" class="headerlink" title="负采样 negative sample"></a>负采样 negative sample</h3><p>负采样是加快训练速度的一种方法，这里的负可以理解为负样本。针对训练样本（ants, able），able这个词是正样本，词表中除able外的所有词都是负样本。负采样是对负样本进行采样，不进行负采样时，对每一个训练样本模型需要拟合一个正样本和九千九百九十九个负样本。加入负采样后，只需要从这九千九百九十九个负样本中挑出来几个进行拟合，大大节省了计算资源。那么应该挑几个负样本，根据什么进行挑呢？Google给出的建议是挑5-20个，怎么挑是根据词在语料中出现的概率，概率越大越有可能被选中，具体计算公式为：<br><img src="./1557414067008.png" alt="Alt text"><br>其中f(<em>)表示</em>出现的概率。</p>
<h3 id="层次softmax"><a href="#层次softmax" class="headerlink" title="层次softmax"></a>层次softmax</h3><p>层次softmax的目的和负采样一样，也是为了加快训练速度，但它相对复杂，没有负采样这种来的简单粗暴。具体来说，使用层次softmax时图4中的模型输出层不再是使用one-hot加softmax回归，而是使用Huffman树加softmax回归。在模型训练的时候首先统计语料中词语的词频，然后根据词频来构建Huffman树，如图7所示，树的根节点可理解为输入词的词向量，叶子节点表示词表中的词，其它节点没有什么实际含义，仅起到辅助作用。<br><img src="./1557414102605.png" alt="Alt text"></p>
<p>为什么使用Huffman树可以加快训练速度？答案是输出层不使用one-hot来表示，softmax回归就不需要对那么多0（也即负样本）进行拟合，仅仅只需要拟合输出值在Huffman树中的一条路径。假设词表大小为N，一条路径上节点的个数可以用来估计，就是说只需要拟合次，这给计算量带来了指数级的减少。此外，由于Huffman编码是不等长编码，频率越高的词越接近根节点，这也使计算量有所降低。</p>
<p>怎么对树中的节点进行拟合呢？如图7所示，假设训练样本的输出词是 w_{2} ，则从根节点走到 w_{2} 经过了 n(w_{2},2),n(w_{3},3) 这两个节点。由于Huffman树是二叉树，这意味着只需要判断向左还是向右就可以从根节点走到 w_{2} ，判断向左还是向右其实就是进行二分类。图7中的例子，“root(input)-&gt;left-&gt;left-&gt;right()”这条路径的概率可表示为：<br><img src="./1557414123789.png" alt="Alt text"></p>
<p>其中 θ_{i} 表示路径中第i个节点的权值向量。注意一点，softmax regression 做二分类的时候就退化为了logistic regression，因此虽然叫层次softmax但公式中其实用的是logistic function。根据上述公式就可构建根据Huffman树来进行softmax回归的cost function，进而根据梯度下降对模型进行训练求解。</p>
]]></content>
  </entry>
  <entry>
    <title>【NLP】LSA(Latent Semantic Analysis-潜在语义分析)</title>
    <url>/2019/12/26/%E3%80%90NLP%E3%80%91LSA(Latent%20Semantic%20Analysis-%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90)/</url>
    <content><![CDATA[<h1 id="【NLP】LSA-Latent-Semantic-Analysis-潜在语义分析"><a href="#【NLP】LSA-Latent-Semantic-Analysis-潜在语义分析" class="headerlink" title="【NLP】LSA(Latent Semantic Analysis:潜在语义分析)"></a>【NLP】LSA(Latent Semantic Analysis:潜在语义分析)</h1><blockquote>
<p>LSA是基于co-occurance matrix的</p>
</blockquote>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1.计算courpus中出现的词的集合<br>2.创建co-occurance matrix<br>3.计算co-occurance矩阵<br>4.SVD降维。得到词向量</p>
]]></content>
  </entry>
  <entry>
    <title>【NLP】GloVe(Global Vectors for Word Representation)</title>
    <url>/2019/12/26/%E3%80%90NLP%E3%80%91GloVe(Global%20Vectors%20for%20Word%20Representation)/</url>
    <content><![CDATA[<h1 id="【NLP】GloVe-Global-Vectors-for-Word-Representation"><a href="#【NLP】GloVe-Global-Vectors-for-Word-Representation" class="headerlink" title="【NLP】GloVe(Global Vectors for Word Representation)"></a>【NLP】GloVe(Global Vectors for Word Representation)</h1><h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><ul>
<li><p>1.Construct A <strong>co-occurance</strong> matrix $X$ according to corpus<br>Commonly element $X_{i,j}$ in co-occurance matrix represent the time of word j appear in i’s <strong>context window</strong>.<br>Generally,it’s minimun unit is 1.<br>But GloVe don’t think so.    It think the weight should decrease with distance.<br>提出了一个衰减函数（decreasing weighting）：<br>decay=1/d<br>用于计算权重</p>
</li>
<li><p>构建词向量（Word Vector）和共现矩阵（Co-ocurrence Matrix）之间的近似关系，论文的作者提出以下的公式可以近似地表达两者之间的关系：</p>
<script type="math/tex; mode=display">w_i^Tw_j+b_i+b_j=log(X_{ij})</script><p><img src="./1557457722952.png" alt="Alt text"></p>
</li>
<li><p>loss function<br><img src="./1557457799442.png" alt="Alt text"><br><img src="./1557457847187.png" alt="Alt text"></p>
</li>
<li><p>训练<br><img src="./1557457980882.png" alt="Alt text"></p>
</li>
</ul>
<h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>首先GloVe是基于共现矩阵(co-occurrance Matrix)的<br>于是第一步也是需要先计算共现矩阵$X$<br>$X_{i,j}$表示词j在词i窗口内出现的次数<br>$X_i=\sum_j^NX_{i,j}$表示共现矩阵的某行和。也就是在窗口内出现词的总数<br>那么<br>$P_{i,k}=\frac{X_{i,k}}{X_i}$表示条件概率。也就是词$k$在词$i$上下文出现的概率<br>作者发现对于两个条件概率的比例<br>$ratio_{i,j,k}=\frac{P_{i,k}}{P_{j,k}}$<br>有<img src="./1558093722416.png" alt="Alt text"></p>
<p>于是我们想到用一个函数$g(v_i,v_j,v_k)$（参数为3个词向量），去拟合$ration_{i,j,k}$。这样就能训练出词向量了。<br>代价函数可以这么写</p>
<script type="math/tex; mode=display">J=\sum_{i,j,k}^N(ration_{i,j,k}-g(v_i,v_j,v_k))^2</script><p>..但是会发现复杂度是$O(N^3)$.需要想办法降低复杂度</p>
<p>我们要考虑词向量$v_i$,$v_j$的关系。所以$(v_i-v_j)^T$应该是个不错的选择<br>然后ratio是个标量。$g$的计算结果应该也是标量。那么$(v_i-v_j)^Tv_k$应该不错</p>
<p>然后套层exp就是我们要的函数g了<script type="math/tex">g(v_i,v_j,v_k)=exp[(v_i-v_j)^Tv_k]</script><br>至于为什么要加exp是为了化简。<br>我们的目标是让$\frac{P_{i,k}}{P_{j,k}}$和$g(v_i,v_j,v_k)$尽可能接近。<br>那么由上式有<script type="math/tex">g=exp(v_i^Tv_k-v_j^Tv_k)</script><br>那么有$P_{i,k}=exp(v_i^Tv_k)和P_{j,k}=exp(v_j^Tv_k)$<br>两边取对数就变成</p>
<script type="math/tex; mode=display">log P_{i,j}=v_i^Tv_k</script><p>那代价函数可以变成</p>
<script type="math/tex; mode=display">J=\sum_{i,j}^N(log(P_{i,j})-v_i^Tv_k)^k</script><p>现在复杂度降到$N^2$了。<br>但是数学上有点问题<br>因为我们知道$P_{i,j}$和$P_{j,i}$是不同的。。但是$v_i^Tv_j=v_j^Tv_i$<br>所以我们还需要修改一下。<br>因为$log P_{i,j}=log(X_{i,j})-log(X_i)=v_i^Tv_j$<br>把$X_i$化为两个偏差项$b_i,b_j$即可<br>于是就得到我们的最终损失函数<script type="math/tex">J=\sum_{i,j}^Nf(X_{i,j})(v_i^Tv_j+b_i+b_j-log(X_{i,j}))^2</script><br>其中$f(X_{i,j})$是权重函数。出现频率越高的词权重应该越高<br><img src="./1558094865073.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【Cipher Theory】Elliptic Curve Cipher</title>
    <url>/2019/12/26/%E3%80%90Cipher%20Theory%E3%80%91Elliptic%20Curve%20Cipher/</url>
    <content><![CDATA[<h1 id="【Cipher-Theory】Elliptic-Curve-Cipher"><a href="#【Cipher-Theory】Elliptic-Curve-Cipher" class="headerlink" title="【Cipher Theory】Elliptic Curve Cipher"></a>【Cipher Theory】Elliptic Curve Cipher</h1><p><img src="./1576641649030.png" alt="Alt text"><br><img src="./1576641702503.png" alt="Alt text"><br><img src="./1576641725012.png" alt="Alt text"><br><img src="./1576641764498.png" alt="Alt text"><br><img src="./1576641843503.png" alt="Alt text"><br><img src="./1576641984368.png" alt="Alt text"><br><img src="./1576642003800.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【Algorithm】Divide And Conquer &amp; Complexity calculation</title>
    <url>/2019/12/26/%E3%80%90Algorithm%E3%80%91Divide%20And%20Conquer%20&amp;%20Complexity%20calculation/</url>
    <content><![CDATA[<h1 id="【Algorithm】Divide-And-Conquer-amp-Complexity-calculation"><a href="#【Algorithm】Divide-And-Conquer-amp-Complexity-calculation" class="headerlink" title="【Algorithm】Divide And Conquer &amp; Complexity calculation"></a>【Algorithm】Divide And Conquer &amp; Complexity calculation</h1><ul>
<li><p>1、Divide the problem into a number of subproblems that are smaller instances of the same problem.</p>
</li>
<li><p>2、Conquer the subproblems by solving them recursively. If the subproblem sizes are small enough, however, just solve the subproblems in a straightforward manner.</p>
</li>
<li>3、Combine the solutions to the subproblems into the solution for the original problem.</li>
</ul>
<p>归并排序就是一个用分治法的经典例子，这里我用它来举例描述一下上面的步骤：</p>
<p>1、归并排序首先把原问题拆分成2个规模更小的子问题。<br>2、递归地求解子问题，当子问题规模足够小时，可以一下子解决它。在这个例子中就是，当数组中的元素只有1个时，自然就有序了。<br>3、最后，把子问题的解（已排好序的子数组）合并成原问题的解。</p>
<h2 id="Recursion-Expression"><a href="#Recursion-Expression" class="headerlink" title="Recursion Expression"></a>Recursion Expression</h2><p><img src="./1576643686556.png" alt="Alt text"></p>
<p>利用递归式分析分治法复杂度 : 1.写出递归式 （递归+分解复杂度+合并复杂度） 2.画出递归树 3.计算</p>
<h2 id="Ways-to-calc-Recursion-Expression"><a href="#Ways-to-calc-Recursion-Expression" class="headerlink" title="Ways to calc Recursion Expression"></a>Ways to calc Recursion Expression</h2><p>这三种方法分别是：代入法，递归树法，和主方法。代入法是一种十分强大的方法，它几乎可以求解所有的递归式。然而，对于一些“小鸡”来说，不需要这么强大的“牛刀”。对于一些特定类型的递归式（具体类型在主方法的小节中会介绍），用主方法可以用更少的时间得到一个更确切的界。<img src="./1576643943494.png" alt="Alt text"><br><img src="./1576644154481.png" alt="Alt text"><br><img src="./1576644228867.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>【转】TCP、IP、ARP协议之间的工作关系</title>
    <url>/2019/12/26/%E3%80%90%E8%BD%AC%E3%80%91TCP%E3%80%81IP%E3%80%81ARP%E5%8D%8F%E8%AE%AE%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<blockquote>
<p><strong>转于:<a href="https://www.cnblogs.com/itsad/p/8250503.html" target="_blank" rel="noopener">https://www.cnblogs.com/itsad/p/8250503.html</a></strong> 版权归原作者所有</p>
</blockquote>
<p>TCP协议与ARP协议位于不同的层，不能用“并列”的思维来考虑。TCP位于传输层，而ARP工作在网络层（也有说法是数据链路层，主要看怎么理解），但实际上掌管网络层的大boss是IP协议，ARP协议用于实现IP地址向MAC地址的转换，不过是个跑龙套的。</p>
<p>除此之外，网络层想要把数据发出去还要依靠数据链路层，在局域网中，数据链路层和之下的物理层最常见的莫过于802.3协议栈了，也就是大名鼎鼎的以太网。</p>
<p>注：802.3/以太网并不是一个协议，也不是一个分层。它是对局域网内部通信的一个实现标准，囊括了从物理层到链路层的一坨协议。以下简单使用“802.3”来代表802.3中链路层及以下负责数据传送的协议集。</p>
<p>在网络分层模型中，下层要为上层提供服务，而上层的一切行动都要靠下层们为它跑腿。打个简单的比方，TCP就好比是老板，而IP是项目主管，ARP和802.3则是为以上二位跑腿的小员工。现在老板TCP想要向外发送一个SYN请柬。以下是大致剧情……</p>
<hr>
<p>TCP：IP你过来，我现在要给“destinationIP”发送一个SYN请柬，请柬我已经写好了，剩下的就交给你了，限你n秒之内给我回话！（老板任性地走了……）。</p>
<p>IP拿到请柬后用信封封好，写上自己的IP地址和接收方的IP地址。然后将自己的网络号与<strong>destinationIP</strong>对比：<br><strong>1. 刚好在同一个网段，心想目标就在我们小区内（局域网），这就好办了（跳至 —- #1 —- 处）。</strong><br><strong>2. IP一看不在同一个网段，心想不妙，只能求助收发室了（网关/路由器）（跳至 —- #2 —- 处）。</strong></p>
<p><strong>—- #1 —-</strong><br>IP：ARP你过来，给我查查这个“destinationIP”的详细地址在哪（MAC地址）。</p>
<p>ARP：（翻了翻自己的笔记本<strong>（ARP缓存）</strong>没找到，他摇了摇头，接着打开了小区广播）<strong> “destinationIP”</strong>听到请回答，我需要你的详细地址。</p>
<p>过了一会ARP收到了一个回电，不出所料，destinationIP汇报了自己的MAC地址。ARP把MAC地址交给了IP。<br>跳至<strong> —- #3 —- </strong>处</p>
<p><strong>—- #2 —-</strong><br>IP：（把默认网关的IP地址指给ARP）这是收发室的IP，你给我查查它的详细地址（MAC地址）。</p>
<p>ARP翻开了自己的笔记本，很快找到了收发室的详细地址，并把MAC地址交给了IP，他庆幸这次不需要再打开小区广播扰民了~<br>跳至 —- #3 —- 处</p>
<p><strong>—- #3 —-</strong><br>IP：802.3你过来，我这里有一封写好的信你帮我送出去，MAC地址我已经帮你查好了。</p>
<p>最终，802.3按照得到的MAC屁颠屁颠地将信件送到收发室，并登记了自己的MAC地址。</p>
<p>此处省略n万字…… 结束~</p>
<hr>
<p>注意：<br>ARP协议是和以太网配套使用的，如果你的局域网的底层实现并不是以太网（比如令牌环网、HDDI等），那么你可能压根就不需要ARP请求！<br>从始至终，IP协议只处理与IP地址有关的部分；<br>ARP协议只处理查询MAC地址；<br>802.3链路层协议只负责MAC-MAC之间的实际传送；<br>这就是网络分层，各司其职。</p>
<p>===================================</p>
<p>最后，你问我TCP发出SYN请求和ARP广播谁先，当然是SYN请求在先了！但是如果没有ARP广播SYN请求还不是纸上谈兵？所以问谁先谁后是没有意义的，分清楚谁是boss、谁是小弟就好了。</p>
]]></content>
  </entry>
  <entry>
    <title>[排队论]</title>
    <url>/2019/12/26/%5B%E6%8E%92%E9%98%9F%E8%AE%BA%5D/</url>
    <content><![CDATA[<h1 id="排队论"><a href="#排队论" class="headerlink" title="[排队论]"></a>[排队论]</h1><h2 id="M-M-S-S-e-g-电话系统"><a href="#M-M-S-S-e-g-电话系统" class="headerlink" title="M/M/S/S e.g. 电话系统"></a>M/M/S/S e.g. 电话系统</h2><p>到达：$\lambda$的指数分布<br>消灭: $n\mu$的指数分布 (n是客户数量)<br>窗口数:$N$<br><img src="./1565418510612.png" alt="Alt text"><br><img src="./1565418704641.png" alt="Alt text"><br><img src="./1565418761237.png" alt="Alt text"></p>
<h2 id="M-M-1-infty"><a href="#M-M-1-infty" class="headerlink" title="M/M/1/$\infty$"></a>M/M/1/$\infty$</h2><blockquote>
<p>M/M/1<br><strong>过程进入状态n的速率等于过程离开状态n的速率。</strong><br>于是我们可以得到第一个概率方程 $\lambda P_0=\mu P_1$</p>
</blockquote>
<p><img src="./1565418956515.png" alt="Alt text"><br><img src="./1565418978273.png" alt="Alt text"><br><img src="./1565418984959.png" alt="Alt text"></p>
<blockquote>
<p>$P_1=\frac{\lambda}{\mu}P_0$<br>…<br>$P_{n+1}=\frac{\lambda}{\mu}P_n+(P_n-\frac{\lambda}{\mu}P_{n-1})=(\frac{\lambda}{\mu})^{n+1}P_0$<br>排队价格等式:<script type="math/tex">P\{X\ge n\}=(\lambda \div \mu)P\{X\ge n-1\}</script><br><strong>顾客平均数=L=<script type="math/tex">\sum_{n=0}^\infty{nP_n}=\frac{\lambda}{\mu-\lambda}</script></strong><br>求和函数 $\sum_n nx^n$:转换成$\sum_n (n+1)x^n-x^n$,前面一项是求导<br>W=L\ $\lambda$ (平均等待时间)<br>$W_Q=W-E[S]=W-\frac{1}{\mu}$ (平均等待排队时间)<br>$L_Q=\lambda W_Q$ (排队等待的平均用户数量)</p>
<h2 id="M-M-S-infty"><a href="#M-M-S-infty" class="headerlink" title="M/M/S/$\infty$"></a>M/M/S/$\infty$</h2><p><img src="./1565419031035.png" alt="Alt text"><br><img src="./1565419040873.png" alt="Alt text"><br><img src="./1565419046141.png" alt="Alt text"><br><img src="./1565419054714.png" alt="Alt text"></p>
<h2 id="2-经典排队模型"><a href="#2-经典排队模型" class="headerlink" title="2.经典排队模型"></a>2.经典排队模型</h2><p>其格式为： A/B/n/S/Z</p>
</blockquote>
<ul>
<li>A：顾客到达的规律；B：服务时间分布；n：服务台数目；S：队列容量的大小；Z：服务规程</li>
</ul>
<p>若队列容量大小为∞时，可简化为A/B/n/Z</p>
<p>若还为先来先服务时，可简化为A/B/n</p>
<p>其中A、B的分布可用以下字母表示：</p>
<ul>
<li><p>M（Markov）：若描述到达（A），则表示泊松到达；若描述服务（B），则指具有指数分布的时间。</p>
</li>
<li><p>G（General）：一般分布。</p>
</li>
<li><p>Ek（Erlang）：表示到达间隔或服务间隔服从k阶爱尔朗分布</p>
</li>
</ul>
<p>还有D：定长分布（常数间隔）、H：超几何分布、L：H项式分布</p>
<p>典型的Z有：FCFS、LCFS、PR、RSS</p>
<h2 id="3-基本排队关系"><a href="#3-基本排队关系" class="headerlink" title="3.基本排队关系"></a>3.基本排队关系</h2><p>由利特尔法则（Little’s Law），有以下公式：</p>
<p>（1）$L_q=λW_q$</p>
<p><strong>Wq是一个顾客平均排队等待的时间</strong>，λ是顾客平均到达率，所以在Wq时间内有λWq个顾客到达，<strong>Lq表示排队等待服务的平均顾客数量</strong>，故Lq=λWq。</p>
<p>（2）L=λW</p>
<p>系统中的平均顾客数（L）（包括等待的和正在被服务的顾客）等于顾客的平均到达率（λ）乘以一个顾客<strong>在系统中花费的平均时间（W）</strong>。</p>
<p>（3）W=Wq+1/μ</p>
<p>一个顾客在系统中花费的时间（W），就是它等待的时间（Wq）加上被服务的时间（1/μ）。</p>
<h2 id="四、几个常用的排队模型"><a href="#四、几个常用的排队模型" class="headerlink" title="四、几个常用的排队模型"></a>四、几个常用的排队模型</h2><p>1.排队模型与生灭过程：</p>
<p>※如果用N(t)表示时刻t系统中的顾客数，则{N(t),t&gt;=0}就构成了一个随机过程。如果用“生”表示顾客的到达，“灭”表示顾客的离去，则对许多排队过程来说，{N(t),t&gt;=0}是一类特殊的随机过程——生灭过程。</p>
<p>※服务台忙的时间比率（服务强度）：顾客到达速率/服务速率，即ρ=λ/μ.</p>
<p>生灭排队模型，到达速率与离开速率依赖于系统中客户数目<br>（1）M/M/1：<br>$\lambda_n=\lambda\\\mu_n=\mu$<br>(2) 障碍M/M/1<br>$\lambda_n=\lambda\alpha_n\\\mu_n=\mu$<br>发现有n人时，以a_n的概率加入系统<br>有限容量n: a_n=1(n<N)否则a_n=0
(3)M/M/k
$\lambda_n=\lambda$(到达速率)
$\mu_n=n\mu (\le k),k\mu(>k)$<br>小于k时每个客户都能接受服务。离开速率就是$n\mu$<br>P_n是有n人的时间比例<br><img src="./1565445909591.png" alt="Alt text"><br><img src="./1565446099530.png" alt="Alt text"></p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/12/22/hello-world%20-%20Copy/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/12/22/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
